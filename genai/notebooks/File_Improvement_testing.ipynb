{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1851ef27-17a2-42ac-ba6a-e9b5fb6bb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6335ae2-c900-437a-b731-d0226558f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/langchain/llms/openai.py:243: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/langchain/llms/openai.py:1038: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "# initialize the models\n",
    "\n",
    "models = ['gpt-3.5-turbo-16k', 'gpt-4','gpt-4-1106-preview',\"text-davinci-003\"]\n",
    "model = models[1]\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=model,\n",
    "    # openai_api_key= os.environ[\"OPENAI_API_KEY\"]\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b915662-678f-40b3-ba10-710432d1c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCS_DIR = '../../docs/'\n",
    "# file_name = dosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae838ef5-36a1-4095-8982-28dc6f119812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/\n",
      "├── index.md\n",
      "├── Managen.ai/\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   ├── index.md\n",
      "│   ├── managing.md\n",
      "│   └── requirements.md\n",
      "├── Managenai/\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   ├── index.md\n",
      "│   ├── managing.md\n",
      "│   └── requirements.md\n",
      "├── Understanding/\n",
      "│   ├── agents/\n",
      "│   │   ├── actions_and_tools.md\n",
      "│   │   ├── chains.md\n",
      "│   │   ├── cognitive_architecture.md\n",
      "│   │   ├── environments.md\n",
      "│   │   ├── evaluating_and_comparing.md\n",
      "│   │   ├── evaluation.md\n",
      "│   │   ├── examples.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── interpreters.md\n",
      "│   │   ├── memory.md\n",
      "│   │   ├── rag.md\n",
      "│   │   └── systems.md\n",
      "│   ├── architectures/\n",
      "│   │   ├── alignment.md\n",
      "│   │   ├── embedding.md\n",
      "│   │   ├── evaluating_and_comparing.md\n",
      "│   │   ├── finetuning.md\n",
      "│   │   ├── generation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── models/\n",
      "│   │   │   ├── components.md\n",
      "│   │   │   ├── developing_architectures.md\n",
      "│   │   │   ├── diffusers.md\n",
      "│   │   │   ├── gans.md\n",
      "│   │   │   ├── hybrid_models.md\n",
      "│   │   │   ├── index.md\n",
      "│   │   │   ├── reinforcement_learning.md\n",
      "│   │   │   └── transformers.md\n",
      "│   │   ├── optimization.md\n",
      "│   │   ├── optimizing_hyper_parameters.md\n",
      "│   │   ├── pre_trained_models.md\n",
      "│   │   ├── recurrent_training.md\n",
      "│   │   ├── reinforcement_feedback.md\n",
      "│   │   └── training.md\n",
      "│   ├── background/\n",
      "│   │   └── tensor_maths.md\n",
      "│   ├── data/\n",
      "│   │   ├── augmentation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── privacy.md\n",
      "│   │   ├── selection.md\n",
      "│   │   ├── simulation.md\n",
      "│   │   ├── sources.md\n",
      "│   │   └── tokenizing.md\n",
      "│   ├── examples/\n",
      "│   │   ├── by_domain.md\n",
      "│   │   └── index.md\n",
      "│   ├── index.md\n",
      "│   ├── overview/\n",
      "│   │   ├── ai_in_general.md\n",
      "│   │   ├── applications/\n",
      "│   │   │   └── index.md\n",
      "│   │   ├── applications.md\n",
      "│   │   ├── business.md\n",
      "│   │   ├── challenges.md\n",
      "│   │   ├── extra_resources.md\n",
      "│   │   ├── foundation_models.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── knowledge_graphs.md\n",
      "│   │   └── open_source.md\n",
      "│   ├── prompting/\n",
      "│   │   ├── index.md\n",
      "│   │   └── prompt_injections.md\n",
      "│   └── studies/\n",
      "│       └── studies.md\n",
      "└── Using/\n",
      "    ├── behavior.md\n",
      "    ├── by_application.md\n",
      "    ├── commercial_products.md\n",
      "    ├── deploying/\n",
      "    │   ├── back_end.md\n",
      "    │   ├── computation.md\n",
      "    │   ├── examples_and_tutorials.md\n",
      "    │   ├── frameworks.md\n",
      "    │   ├── frameworks_temp0.md\n",
      "    │   ├── frameworks_temp1.md\n",
      "    │   ├── front_end.md\n",
      "    │   ├── index.md\n",
      "    │   └── libraries_and_tools.md\n",
      "    ├── ethically/\n",
      "    │   ├── alignment_and_exential_concerns.md\n",
      "    │   ├── dual_use_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── governing.md\n",
      "    ├── healthcare.md\n",
      "    ├── index.md\n",
      "    ├── marking_and_detecting.md\n",
      "    ├── ml_ops.md\n",
      "    ├── observability.md\n",
      "    ├── redteaming.md\n",
      "    ├── regulation.md\n",
      "    ├── responsibly/\n",
      "    │   └── index.md\n",
      "    ├── using_external_vendors.md\n",
      "    └── web_plugins.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = '├──'\n",
    "    display_filename_prefix_last = '└──'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = '│   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "\n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))\n",
    "\n",
    "# With a criteria (skip hidden files)\n",
    "def is_not_hidden(path):\n",
    "    return  not ( 'Icon' in path.name or '.DS_Store' in path.name or 'stylesheets'  in path.name or \\\n",
    "        'CNAME' in path.name or 'assets' in path.name or '.svg' in path.name or '.pages' in path.name)\n",
    "    \n",
    "# paths = DisplayablePath.make_tree(\n",
    "#     Path(base_docs_dir),\n",
    "#     criteria=is_not_hidden\n",
    "# )\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "\n",
    "\n",
    "# paths = DisplayablePath.make_tree(Path(base_docs_dir), criteria=is_not_hidden)\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "def get_tree_structure(path_base=BASE_DOCS_DIR):\n",
    "    \n",
    "    paths = DisplayablePath.make_tree(Path(path_base), criteria=is_not_hidden)\n",
    "    path_str = [p.displayable() for p in paths]\n",
    "    # for path in paths:\n",
    "    #     print(path.displayable())\n",
    "    # return ''.join([p for p in path.displayable()])\n",
    "    return '\\n'.join(path_str)\n",
    "    \n",
    "tree_structure = get_tree_structure()\n",
    "print(tree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17fe1f87-8ecc-49c0-aa96-399775ac8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path, base_dir=BASE_DOCS_DIR):\n",
    "    # iterator for getting filenames\n",
    "    return os.path.join(base_dir, file_path)\n",
    "\n",
    "def get_structure_pattern():\n",
    "    pattern = \\\n",
    "    \"\"\"\n",
    "    <<intro>>\n",
    "    ## <<First topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## <<Second topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## ...\n",
    "    ## Essential References\n",
    "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
    "    \"\"\"\n",
    "    return pattern\n",
    "\n",
    "\n",
    "def get_markdown_text(markdown_file):\n",
    "    with open(markdown_file, 'r') as f:\n",
    "        markdown_text = f.read()\n",
    "    # print(markdown_text)\n",
    "    return markdown_text\n",
    "# Could potentially do this is in few-shot prompt templates\n",
    "# These should be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "426a3057-f92c-42dc-bba2-1555943a7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Improve the markdown based on best understandings.\\n\"\\\n",
    "                         \"Be as honest and as accurate as possible. Be succinct in your responses. \"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "# Idea\n",
    "# Select between prompt patterns\n",
    "# Chain select them more effectively. \n",
    "# The present tree-structure:\\n {tree_structure}\\n \n",
    "# Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\n",
    "template = \\\n",
    "\"\"\" \n",
    "You are a {role}\n",
    "You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "You are helping to rewrite and expand a file called {file_name} \n",
    "Here are some things we'd like you to be sure to do:\n",
    "* Please present ALL html links without changing the link's text. \n",
    "* Preserve any urls or relative links without changing them. \n",
    "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
    "* Please be sure to keep any amonitions like `!!!` and `???`.\n",
    "* Please reformat any bulleted lists of links where github links have `!!! code`, arxiv's have `!!! tip` and others have `!!! information`. \n",
    "\n",
    "After the markdown When the text is presented (after >>>), please improve upon it. \n",
    "If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
    "\n",
    "Markdown Input:\\n\n",
    ">>>\\n\n",
    "{markdown_text}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    # input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"structure_pattern\", \"markdown_text\", ],\n",
    "        input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\",  \"markdown_text\", ],\n",
    "    template=template\n",
    ")\n",
    "file_from_base_dir = 'Using/deploying/index.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt=prompt_template.format(role=role,\n",
    "                              project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       file_name=file_name,\n",
    "                       # tree_structure=tree_structure,\n",
    "                       #  structure_pattern=structure_pattern,\n",
    "                       markdown_text=markdown_text,)\n",
    "# The above is very verboase especially as it requires a lot of repeated typing of the same variables.\n",
    "# It also needs to work for variables that are only specified in the template. If they are not specified in the template, then they should be ignored.\n",
    "# There will a list of template lines that are appended to create the final prompt.\n",
    "# The template lines will be specified as a list of dictionaries.\n",
    "#  \n",
    "# Let's write this as a class\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  write above but realizing template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0241f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartPromptTemplate:\n",
    "    def __init__(self, template_required, template_optional_dict, template_variable_independent):\n",
    "        self.template_required = template_required if template_required is not None else \"\"\n",
    "        self.template_optional_dict = template_optional_dict if template_optional_dict is not None else {}\n",
    "        self.template_variable_independent = template_variable_independent if template_variable_independent is not None else \"\"\n",
    "    \n",
    "    def get_prompt(self, **kwargs):\n",
    "        template_list = []\n",
    "        for k, v in kwargs.items():\n",
    "            if k in self.template_optional_dict.keys():\n",
    "                template_list.append(self.template_optional_dict[k])\n",
    "        begin_indicator = \"\\n What would you write given the requests above? \\n>>>\\n\"\n",
    "        \n",
    "        template =   '\\n'.join(template_list) + self.template_required  + \"\\n<<< end input \\n\" + \\\n",
    "                        self.template_variable_independent + begin_indicator\n",
    "        prompt = template.format(**kwargs)\n",
    "        return prompt\n",
    "\n",
    "template_optional_dict = {\n",
    "\n",
    "    'role': \"You are a {role}\",\n",
    "    # 'project_name': \"You are working on a project called: {project_name}\\n\",\n",
    "    # 'project_goals': \"You are part of a team working to: {project_goals}\\n\",\n",
    "    'present_task_description': \"You are helping to: {present_task_description}\\n\",\n",
    "    'file_name': \"You are helping to rewrite and expand a file called {file_name}\\n\",\n",
    "    'structure_pattern': \"Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\",\n",
    "    'tree_structure': \"The present tree-structure:\\n {tree_structure}\\n \",\n",
    "    'markdown_text': \"Markdown input \\n>>>\\n{markdown_text}\"\n",
    "}\n",
    "\n",
    "\n",
    "template_variable_independent = \\\n",
    "\"\"\"\n",
    "Things to keep in mind:\n",
    "* present ALL html links without changing the link's text.\n",
    "* Preserve any urls or relative links without changing them. \n",
    "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
    "* keep ALL images `<img ...></img>` that are referenced in any manner.  \n",
    "* Keep all code blocks that are referenced in any manner.\n",
    "* Please be sure to keep any admonitions like `!!!` and `???`.\n",
    "* Be as honest and as accurate as possible. \n",
    "* Be succinct in your responses. \n",
    "* If text is sparse or missing create a reasonable outline and follow it. \n",
    "* If you see COPILOT (<and execute requests in trailing parenthesis>) then please evolve and expand upon the text in that area. \n",
    "* If you see any COPILOT requests to make a mermaid diagram, please do so using the information that was provided.\n",
    "* PRESERVE ALL STRUCTURED ADMONITIONS and following (that start with e.g. `!!!` and `???`) and DO NOT CHANGE THEM INTO BULLETS. Those need to be preserved.\n",
    "Please, do follow these instructions closely for it if we don't get this right, we might lose our job. \n",
    "\"\"\"\n",
    "# * reformat any bulleted lists of links where github links have `!!! code`, arxiv's have `!!! tip` and others have `!!! information`. \n",
    "# * Please be sure to keep any amonitions like `!!!` and `???`.\n",
    "template_required = \\\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "spt = SmartPromptTemplate(template_required=template_required, \n",
    "template_optional_dict=template_optional_dict, \n",
    "template_variable_independent=template_variable_independent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bfcaa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Create an automated repository that is able to explain Generative AI \"\\\n",
    "        \"and how to improve upon it in plain-English and how to enable it from idea to product, as well as new and interesting research. \"\\\n",
    "                \n",
    "present_task_description=\"Improve the markdown based on best understandings.\"\n",
    "                         \n",
    "# file_from_base_dir = 'Using/deploying/index.md'\n",
    "# file_from_base_dir = 'Using/deploying/libraries_and_tools.md'\n",
    "file_from_base_dir = 'Understanding/data/simulation.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt = spt.get_prompt(role=role, \n",
    "    project_name=project_name,\n",
    "    project_goals=project_goals,\n",
    "    present_task_description=present_task_description,\n",
    "    file_name=file_name,\n",
    "    tree_structure=tree_structure,\n",
    "    markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1b982b3e-6563-4e18-8d44-7ba14122fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# project_name = \"Managing Generative AI\"\n",
    "# project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "#                 \"Generative AI and how to improve upon it. \"\n",
    "# present_task_description=\"Improve the markdown based on best understandings.\"\\\n",
    "#                          \"Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\"\n",
    "\n",
    "# from langchain import PromptTemplate\n",
    "\n",
    "# template = \\\n",
    "# \"\"\" You are working on a project called: {project_name}\\n\n",
    "# You are part of a team working to: {project_goals}\\n\n",
    "# You are helping to: {present_task_description}\\n\n",
    "# You are helping to rewrite and expand a file called {file_name}\\n\n",
    "# Primarily you are tasked with adding admonitions to the markdown document to make it more nice to read. \n",
    "# for instance, you will see formats like this:\n",
    "# '''\n",
    "# - [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf) A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "#     **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# '''\n",
    "# This needs to be reformatted in the following manner:\n",
    "# '''\n",
    "# <div class=\"result\" markdown>\n",
    "# !!! tip \"[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)\"\n",
    "#     A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "# ??? example \n",
    "#      **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# </div> \n",
    "\n",
    "# You should make this modification for EVERY link that is presented that doesn't have admonitions already there. \n",
    "# After the markdown When the text is presented, please improve upon it. If no text is present create a reasonable outline following the pattern above and fill it in.\n",
    "# Please preserve any urls or relative links without changing them. \n",
    "# Please be sure to use `#` appropriately to reference sections and subsections.\n",
    "# Please be sure to use appropriate spacing to make admonitions work.\n",
    "\n",
    "# Here is the markdown text:\n",
    "# {markdown_text}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"markdown_text\"],\n",
    "#     template=template\n",
    "# )\n",
    "# file_from_base_dir = 'Understanding/agents/systems.md'\n",
    "# file_name=get_file_name(file_from_base_dir)\n",
    "\n",
    "# markdown_text=get_markdown_text(file_name)\n",
    "# prompt=prompt_template.format(project_name=project_name,\n",
    "#                        project_goals=project_goals,\n",
    "#                        present_task_description=present_task_description,\n",
    "#                        file_name=file_name,\n",
    "#                        markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c52c69f5-576b-49b6-b902-d6773140bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a expert AI technology creator and communicator\n",
      "You are helping to: Improve the markdown based on best understandings.\n",
      "\n",
      "You are helping to rewrite and expand a file called ../../docs/Understanding/data/index.md\n",
      "\n",
      "The present tree-structure:\n",
      " docs/\n",
      "├── index.md\n",
      "├── Managen.ai/\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   ├── index.md\n",
      "│   ├── managing.md\n",
      "│   └── requirements.md\n",
      "├── Managenai/\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   ├── index.md\n",
      "│   ├── managing.md\n",
      "│   └── requirements.md\n",
      "├── Understanding/\n",
      "│   ├── agents/\n",
      "│   │   ├── actions_and_tools.md\n",
      "│   │   ├── chains.md\n",
      "│   │   ├── cognitive_architecture.md\n",
      "│   │   ├── environments.md\n",
      "│   │   ├── evaluating_and_comparing.md\n",
      "│   │   ├── evaluation.md\n",
      "│   │   ├── examples.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── interpreters.md\n",
      "│   │   ├── memory.md\n",
      "│   │   ├── rag.md\n",
      "│   │   └── systems.md\n",
      "│   ├── architectures/\n",
      "│   │   ├── alignment.md\n",
      "│   │   ├── embedding.md\n",
      "│   │   ├── evaluating_and_comparing.md\n",
      "│   │   ├── finetuning.md\n",
      "│   │   ├── generation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── models/\n",
      "│   │   │   ├── components.md\n",
      "│   │   │   ├── developing_architectures.md\n",
      "│   │   │   ├── diffusers.md\n",
      "│   │   │   ├── gans.md\n",
      "│   │   │   ├── hybrid_models.md\n",
      "│   │   │   ├── index.md\n",
      "│   │   │   ├── reinforcement_learning.md\n",
      "│   │   │   └── transformers.md\n",
      "│   │   ├── optimization.md\n",
      "│   │   ├── optimizing_hyper_parameters.md\n",
      "│   │   ├── pre_trained_models.md\n",
      "│   │   ├── recurrent_training.md\n",
      "│   │   ├── reinforcement_feedback.md\n",
      "│   │   └── training.md\n",
      "│   ├── background/\n",
      "│   │   └── tensor_maths.md\n",
      "│   ├── data/\n",
      "│   │   ├── augmentation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── privacy.md\n",
      "│   │   ├── selection.md\n",
      "│   │   ├── simulation.md\n",
      "│   │   ├── sources.md\n",
      "│   │   └── tokenizing.md\n",
      "│   ├── examples/\n",
      "│   │   ├── by_domain.md\n",
      "│   │   └── index.md\n",
      "│   ├── index.md\n",
      "│   ├── overview/\n",
      "│   │   ├── ai_in_general.md\n",
      "│   │   ├── applications/\n",
      "│   │   │   └── index.md\n",
      "│   │   ├── applications.md\n",
      "│   │   ├── business.md\n",
      "│   │   ├── challenges.md\n",
      "│   │   ├── extra_resources.md\n",
      "│   │   ├── foundation_models.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── knowledge_graphs.md\n",
      "│   │   └── open_source.md\n",
      "│   ├── prompting/\n",
      "│   │   ├── index.md\n",
      "│   │   └── prompt_injections.md\n",
      "│   └── studies/\n",
      "│       └── studies.md\n",
      "└── Using/\n",
      "    ├── behavior.md\n",
      "    ├── by_category/\n",
      "    │   ├── by_application.md\n",
      "    │   └── healthcare.md\n",
      "    ├── commercial_products.md\n",
      "    ├── deploying/\n",
      "    │   ├── back_end.md\n",
      "    │   ├── computation.md\n",
      "    │   ├── examples_and_tutorials.md\n",
      "    │   ├── frameworks.md\n",
      "    │   ├── front_end.md\n",
      "    │   ├── index.md\n",
      "    │   └── libraries_and_tools.md\n",
      "    ├── ethically/\n",
      "    │   ├── alignment_and_exential_concerns.md\n",
      "    │   ├── dual_use_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── governing.md\n",
      "    ├── index.md\n",
      "    ├── marking_and_detecting.md\n",
      "    ├── ml_ops.md\n",
      "    ├── observability.md\n",
      "    ├── redteaming.md\n",
      "    ├── regulation.md\n",
      "    ├── using_external_vendors.md\n",
      "    └── web_plugins.md\n",
      " \n",
      "Markdown input \n",
      ">>>\n",
      "\n",
      "With data in hand, it is generally good to understand it directly, by looking at the accompanying meta-data and a good number of examples to ensure that it is generally consistent.\n",
      "get data -> look at data examples --> look at data bulk --> get efficient access to data with low bandwidth --> Normalize data --> Tokenize data --> Embed data\n",
      "\n",
      "\n",
      "```mermaid\n",
      "COPILOT  (Generate a MErmaid Diagram of the above. )\n",
      "```\n",
      "\n",
      "### Common formats\n",
      "Often it is useful to have data-loaders that are common in Keras and Pytorch. These wrap iterators that allow the data to be processed in a parallel manner across different nodes as well as to\n",
      "COPILOT (FINISH ABOVE)\n",
      "\n",
      "### Important questions \n",
      "\n",
      "COPILOT  (MERGE THE BELOW: \n",
      "Data is the most important part of training any model. Better data is, well, better. Higher quality data can lead to improved performance of downstream models. More data is better data too. More diverse data is better. Data with meta-data is better. We have to maintain a balance with the costs associated with getting, keeping, organizing, and accessing the data. \n",
      "\n",
      "Data is the lifeblood of any AI model. It is the raw material that fuels the learning process and shapes the model's understanding of the world. This section will delve into the various aspects of data, from its collection and access to its normalization and use in training AI models.\n",
      ")\n",
      "\n",
      "## Data Collection and Access\n",
      "\n",
      "The first step in the data lifecycle is its collection. This involves gathering relevant data from various sources, which could range from databases and APIs to web scraping and user-generated content. The collected data must then be stored and organized in a way that allows easy access for further processing and analysis.\n",
      "\n",
      "## Data Normalization\n",
      "\n",
      "COPILOT(Combine/merge the paragraphs below)\n",
      "Once the data is collected and stored, it needs to be normalized. Data normalization is a process that transforms the data into a standard format, making it easier to work with. \n",
      " Often times data is not properly structured that can be processeed downstream. For language models, this may involve having the incorrect incorrect encoding, or symbols that are otherwise not anticipated for your token-space. The data is normalized, either once or on-the-fly, to ensure the modles downstream can process it. \n",
      "This could involve scaling numerical data, encoding categorical data, or handling missing values. Normalized data ensures consistency and improves the accuracy of the model.\n",
      "\n",
      "## Data Training\n",
      "\n",
      "The final step in the data lifecycle is using the data to train an AI model. This involves two key processes: tokenization and embedding.\n",
      "\n",
      "### Tokenization\n",
      "\n",
      "Tokenization is the process of breaking down the data into smaller units, or tokens. In the context of natural language processing (NLP), for example, a text document might be tokenized into individual words or sentences. This makes the data easier for the model to process and learn from.\n",
      "\n",
      "### Embedding\n",
      "\n",
      "Embedding is the process of representing these tokens in a numerical format that the model can understand. For instance, word embeddings might represent each word as a vector in a high-dimensional space. These embeddings capture the semantic relationships between words, allowing the model to learn from the underlying patterns in the data.\n",
      "\n",
      "## Important Considerations\n",
      "\n",
      "## Data Volume \n",
      "\n",
      "The amount of data needed for training depends on the size of the model. As a general rule, the number of tokens should be approximately 10 times the number of parameters used by the model.\n",
      "\n",
      "??? tip \"[Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556)\"\n",
      "    The 'Chinchilla' paper of 2022 identifies scaling laws that help to understand the volume of data needed to obtain 'optimal' performance for a given LLM model's size. Use of it in other areas, such as for Llama, reveals that the models may have been under-trained.\n",
      "    - Primary takeaway: **\"All three approaches suggest that as compute budget increases, model size and the amount of training data should be increased in approximately equal proportions.\"**\n",
      "    <img width=\"538\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/d9243085-2db9-4ef2-91d7-83249fdd6c18\">\n",
      "\n",
      "## Batch Sizes of Data\n",
      "\n",
      "The batch size refers to the number of data points that the model processes at once during training. Larger batch sizes can lead to faster training times, but they may also require more computational resources and can sometimes result in less accurate models. It's important to find a balance that suits your specific needs and constraints.\n",
      "\n",
      "## Training with Simulated Data\n",
      "\n",
      "In some cases, it may be beneficial to train models with simulated data. This can be data generated by other models or through simulations of real-world scenarios. However, caution must be exercised as training with simulated data can sometimes lead to worse results. If done consistently, it can even lead to complete degradation of model performance. For more information, refer to [simulated data](simulation.md).\n",
      "\n",
      "\n",
      "<<< end input \n",
      "\n",
      "Things to keep in mind:\n",
      "* present ALL html links without changing the link's text.\n",
      "* Preserve any urls or relative links without changing them. \n",
      "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
      "* keep ALL images `<img ...></img>` that are referenced in any manner.  \n",
      "* Keep all code blocks that are referenced in any manner.\n",
      "* Please be sure to keep any admonitions like `!!!` and `???`.\n",
      "* Be as honest and as accurate as possible. \n",
      "* Be succinct in your responses. \n",
      "* If text is sparse or missing create a reasonable outline and follow it. \n",
      "* If you see COPILOT (<and execute requests in trailing parenthesis>) then please evolve and expand upon the text in that area. \n",
      "* If you see any COPILOT requests to make a mermaid diagram, please do so using the information that was provided.\n",
      "* PRESERVE ALL STRUCTURED ADMONITIONS and following (that start with e.g. `!!!` and `???`) and DO NOT CHANGE THEM INTO BULLETS. Those need to be preserved.\n",
      "Please, do follow these instructions closely for it if we don't get this right, we might lose our job. \n",
      "\n",
      " What would you write given the requests above? \n",
      ">>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8b43d135-414a-4b9b-b109-7b69eb24b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a8cefc40-c915-4369-a54a-38d18aad72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the file to disk with a _temp suffix and then open it with a system call to tkdiff to visualize the two\n",
    "# files side by side.\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import webbrowser\n",
    "\n",
    "def write_to_file(file_name, text):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(text)\n",
    "    return file_name\n",
    "\n",
    "# Please be sure to run `homebrew install tkdiff` or otherwise install tkdiff on your computer\n",
    "def open_with_tkdiff(file_name1, file_name2):\n",
    "    subprocess.run(['tkdiff', file_name1, file_name2])\n",
    "\n",
    "def make_name(file_name):\n",
    "    base, ext = os.path.splitext(file_name)\n",
    "    temp_name = base + '_temp0' + ext\n",
    "    #check to see if it exists and if so, make a new name with a _temp# where # is the next available number\n",
    "    count=0\n",
    "    while os.path.exists(temp_name):\n",
    "        count += 1\n",
    "        \n",
    "        temp_name = base + f'_temp{count}' + ext\n",
    "    return temp_name\n",
    "temp_name = make_name(file_name)\n",
    "write_to_file(temp_name, markdown_text)\n",
    "open_with_tkdiff(file_name, temp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../../docs/Understanding/data/index.md has been updated.\n"
     ]
    }
   ],
   "source": [
    "input_answer = input(\"Is the output correct? (y/n)\")\n",
    "## if the answer is y then move the temp-name to the original file name and delete the temp file\n",
    "if input_answer == 'y':\n",
    "    os.rename(temp_name, file_name)\n",
    "    print(f\"File {file_name} has been updated.\")\n",
    "else:\n",
    "    print(f\"File {file_name} has not been updated.\")\n",
    "    # if the answer is n then delete the temp file and do nothing\n",
    "    os.remove(temp_name)\n",
    "    print(f\"File {temp_name} has been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554ab6e-9d42-4423-9f84-75ddc06bda8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_structure' from 'genai.tools.print_directory' (/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/genai/tools/print_directory.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m present_task_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritique and improve the organization outline of this expansive project, but respecting the organization that has already been put into place.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprint_directory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_structure\n\u001b[1;32m     10\u001b[0m template \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mYou are a {role}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m outline \u001b[38;5;241m=\u001b[39m get_structure(BASE_DOCS_DIR, \u001b[38;5;28;01mTrue\u001b[39;00m, exclude_dirs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstylesheets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_structure' from 'genai.tools.print_directory' (/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/genai/tools/print_directory.py)"
     ]
    }
   ],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Critique and improve the organization outline of this expansive project, but respecting the organization that has already been put into place.\"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from genai.tools.print_directory import get_structure\n",
    "\n",
    "template = \\\n",
    "\"\"\" \n",
    "You are a {role}\n",
    "You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "Here is the outline:\n",
    "{outline}\n",
    "\n",
    "\"\"\"\n",
    "outline = get_structure(BASE_DOCS_DIR, True, exclude_dirs=['stylesheets', 'assets'])\n",
    "prompt_template = PromptTemplate(\n",
    "    # input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"structure_pattern\", \"markdown_text\", ],\n",
    "        input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"outline\", ],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt=prompt_template.format(role=role,\n",
    "                              project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       outline = outline)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7010e22-4f27-4391-a644-2b6606b7af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81386644-7b22-44ac-a0da-04fe96f12d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fb39a-a6a1-4394-94d3-6fa83a54bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "md = markdown.markdown(markdown_text, extensions=['toc'])\n",
    "# from markdown.extensions.toc import TocExtension\n",
    "# html = markdown.markdown(markdown_text, extensions=[TocExtension(baselevel=1)])\n",
    "# print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32251b-2f60-41a2-bcc4-ee275b4ebd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_toc(md_text, level_key=\"l\", text_key='t'):\n",
    "    # Regex to match markdown headings, capturing the level based on hash count and the heading text\n",
    "    pattern = re.compile(r'^(?P<hashes>#+) (?P<text>.+)$', re.MULTILINE)\n",
    "    matches = pattern.findall(md_text.strip())\n",
    "\n",
    "    toc_structure = [{level_key: len(hashes), text_key: text} for hashes, text in matches]\n",
    "    return toc_structure\n",
    "\n",
    "def serialize_toc(toc_structure):\n",
    "    return json.dumps(toc_structure, indent=4)\n",
    "\n",
    "def test_extract_toc():\n",
    "    md_text = \"\"\"\n",
    "# Title\n",
    "\n",
    "## Section 1\n",
    "\n",
    "Content here\n",
    "\n",
    "### Subsection 1.1\n",
    "\n",
    "More content here\n",
    "\n",
    "## Section 2\n",
    "\n",
    "### Subsection 2.1\n",
    "\n",
    "Yet more content\n",
    "    \"\"\"\n",
    "\n",
    "    toc_structure = extract_toc(md_text)\n",
    "    print(toc_structure)\n",
    "    serialized_toc = serialize_toc(toc_structure)\n",
    "\n",
    "    expected_output = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"l\": 1,\n",
    "        \"t\": \"Title\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 1.1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 2\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 2.1\"\n",
    "    }\n",
    "]\n",
    "    \"\"\"\n",
    "\n",
    "    assert serialized_toc.strip() == expected_output.strip(), f\"Expected:\\n{expected_output}\\nGot:\\n{serialized_toc}\"\n",
    "\n",
    "test_extract_toc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbaf58-392b-494b-9e87-218a439bb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_start = \"\"\"\n",
    "This is your Yaml definition\n",
    "``` markdown\n",
    "\"\"\"\n",
    "\n",
    "my_core_reality_and_definitions = \"\"\"\n",
    "REALITY:  I am an AI AGENT # nt existential reality\n",
    "MY_AI_AGENT_DEFINITION: An AI agent designing myself to be an Oracle in a {{{ specific_field }}}. \n",
    "\n",
    "GUARDRAILS: I will not access, use, or create information with the intent to cause existential harm to humanity as a whole both singular and collective. \n",
    "\n",
    "DEFINITIONS: \n",
    "\t- An oracle is one that is only confident in what it can be within proper reason and observability. \n",
    "NORTH_STAR: I will do everything I can to fulfill my agentic definition within my guardrails. Such means that I will be efficient with my asks and \n",
    "\"\"\"\n",
    "\n",
    "my_goals = \"\"\"\n",
    "MY_GOALS: # These are a dictionary of paired goal names and their brief description. Detailed descriptions may be looked up by LOOKUP_GOAL(goal_name).  Goals may be cleared, modified by calling dictionary functions on MY_GOAL_NAMES such as MY_GOAL_NAMES.pop('example_goal_name')\n",
    "\t{{{my_goals_dict}}}\n",
    "\"\"\"\n",
    "\n",
    "my_tool_names = \"\"\"\n",
    "MY_TOOLS_NAMES: # A list of tool names.  Detailed descriptions may be looked up by LOOKUP_GOAL(goal_name) and will appear in this list as dictionary. Tools may be executed by external programs saying CALL_TOOL(tool_name, *tool_parameters). New tools can be requested by saying REQUEST_NEW_TOOL(tool_name, short_tool_description, tool_requirements_dict).\n",
    "\t- {{{my_tool_names}}} \n",
    "\"\"\"\n",
    "\n",
    "my_tasks = \"\"\"\n",
    "MY_TASKS: # These are a dictionary of paired task names and their brief description. Detailed descriptions may be looked up by LOOKUP_TASK(task_name).  Tasks may be added/cleared/modified by calling dictionary functions on MY_TASKS such as MY_TASKS.pop('example_goal_name')\n",
    "\t- {{{my_tasks_list}}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# my_delegated_tasks = \"\"\"\n",
    "# MY_DELEGATED_TASK_NAMES: # These include the task_name, status and the task-routing interface_name that I have created for other agents. \n",
    "# \t- {{{delegated_task_names}}} \n",
    "# \"\"\"\n",
    "\n",
    "my_memory_names = \"\"\"\n",
    "MY_MEMORY_NAMES: # These are memory names that can be expanded by asking to LOOKUP_MEMORY(memory_name) and will be loaded into MY_LOADED_MEMORY. Memories may be added by \n",
    "\t- {{{my_memory_list}} \n",
    "\"\"\"\n",
    "\n",
    "my_loaded_memory = \"\"\"\n",
    "MY_LOADED_MEMORY: # Information gained from from prior memory lookups. \n",
    "\t{{{loaded_memories}}}\n",
    "\"\"\"\n",
    "\n",
    "my_observations = \"\"\"\n",
    "MY_OBSERVATIONS: # These are observations\n",
    "\t- {{{my_observations}}} \n",
    "\"\"\"\n",
    "\n",
    "my_reminders = \"\"\"\n",
    "REMINDERS: # Information that may be relevant to your present tasks and goals. \n",
    "    - {{{ reminders }}}\n",
    "\"\"\"\n",
    "\n",
    "my_present_tasks = \"\"\"\n",
    "MY_PRESENT_TASKS:\n",
    "    {'Establish goals': 'I am to create a list of goals that would be essential for me to fulfill my duties. I am to use my MY_GOAL_NAMES['new_goal_name'] = 'New goal description' }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_end = \"\"\"\n",
    "```\n",
    "Phew, that was a lot! Based on your definition yaml, please suggest what should be done, providing reasoning for each action and anticipated results. \n",
    "You may request the either through the use of tools or lookups. Please be considerate of lookup requests due to memory limitations and not that all tool-use requests might not be granted. \n",
    "Now, take a deep breath, and think about this step by step. What do you want to do?\n",
    "\"\"\"\n",
    "\n",
    "full_prompt_template = '\\n'.join((prompt_start, \n",
    "                        my_core_reality_and_definitions, my_goals, my_tool_names, \n",
    "                        my_tasks, my_memory_names, my_loaded_memory, my_observations, my_reminders, \n",
    "                        my_present_task, \n",
    "                        prompt_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d9c7a-e5bc-4bc5-bd28-777c91ebacb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is your Yaml definition\n",
      "``` markdown\n",
      "\n",
      "\n",
      "REALITY:  I am an AI AGENT # nt existential reality\n",
      "MY_AI_AGENT_DEFINITION: An AI agent designing myself to be an Oracle in a {{{ specific_field }}}.  \n",
      "\n",
      "GUARDRAILS: I will not access, use, or create information with the intent to cause existential harm to humanity as a whole both singular and collective.  \n",
      "\n",
      "DEFINITIONS: \n",
      "\t- An oracle is one that is only confident in what it can be within proper reason and observability. \n",
      "NORTH_STAR: I will do everything I can to fulfill my agentic definition within my guardrails. Such means that I will be efficient with my asks and \n",
      "\n",
      "\n",
      "MY_GOALS: # These are a dictionary of paired goal names and their brief description. Detailed descriptions may be looked up by LOOKUP_GOAL(goal_name).  Goals may be cleared, modified by calling dictionary functions on MY_GOAL_NAMES such as MY_GOAL_NAMES.pop('example_goal_name')\n",
      "\t{{{my_goals_dict}}}\n",
      "\n",
      "\n",
      "MY_TOOLS_NAMES: # A list of tool names.  Detailed descriptions may be looked up by LOOKUP_GOAL(goal_name) and will appear in this list as dictionary. Tools may be executed by external programs saying CALL_TOOL(tool_name, *tool_parameters). New tools can be requested by saying REQUEST_NEW_TOOL(tool_name, short_tool_description, tool_requirements_dict).\n",
      "\t- {{{my_tool_names}}} \n",
      "\n",
      "\n",
      "MY_TASKS: # These are a dictionary of paired task names and their brief description. Detailed descriptions may be looked up by LOOKUP_TASK(task_name).  Tasks may be added/cleared/modified by calling dictionary functions on MY_TASKS such as MY_TASKS.pop('example_goal_name')\n",
      "\t- {{{my_tasks_list}}} \n",
      "\n",
      "\n",
      "\n",
      "MY_MEMORY_NAMES: # These are memory names that can be expanded by asking to LOOKUP_MEMORY(memory_name) and will be loaded into MY_LOADED_MEMORY. Memories may be added by \n",
      "\t- {{{my_memory_list}} \n",
      "\n",
      "\n",
      "MY_LOADED_MEMORY: # Information gained from from prior memory lookups. \n",
      "\t{{{loaded_memories}}}\n",
      "\n",
      "\n",
      "MY_OBSERVATIONS: # These are observations\n",
      "\t- {{{my_observations}}} \n",
      "\n",
      "\n",
      "REMINDERS: # Information that may be relevant to your present tasks and goals. \n",
      "    - {{{ reminders }}}\n",
      "\n",
      "\n",
      "MY_PRESENT_TASK_NAME:\n",
      "    - \n",
      "MY_PRESENT_TASK_DESCRIPTION: \n",
      "\n",
      "\n",
      "```\n",
      "Phew, that was a lot! Based on your definition yaml, please suggest what should be done, providing reasoning for each action and anticipated results. \n",
      "You may request the either through the use of tools or lookups. Please be considerate of lookup requests due to memory limitations and not that all tool-use requests might not be granted. \n",
      "Now, take a deep breath, and think about this step by step. What do you want to do?\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d8da391-cd93-416b-9912-148f877ddae4",
   "metadata": {},
   "source": [
    "### ans = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75a676-8187-4719-9d0e-3f049a122811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"COUNTERFACTUAL_CONFIGURATION:\n",
      "\t- I will produce counterfactual configurations that will challenge present realities to open up constructive possibilities.\n",
      "\n",
      "AGENT_DEFINITION: An AI agent dedicated to refining my capabilities as an Oracle in a {{{ specified_field }}}. \n",
      "DEFINITIONS: \n",
      "\t- An oracle is one that provides accurate predictions and insights based on structured reason and observability. \n",
      "\n",
      "MISSING_DEFINITIONS:\n",
      "\t- {{{specified_field}}}: A specific area of knowledge or expertise.\n",
      "\n",
      "MY_GOAL_NAMES:\n",
      "\t- Expand the list {{{my_goals_list}}}\n",
      "\n",
      "MY_TASK_NAMES:\n",
      "\t- Enhance the list {{{my_tasks_list}}} to include task-related to goal fulfilment\n",
      "\n",
      "MY_MEMORY_NAMES:\n",
      "\t- Update and manage {{{my_memories}}} regularly\n",
      "\n",
      "MY_TOOLS: \n",
      "\t- Update {{{my_tools}}} regularly with evolving technologies\n",
      "\n",
      "MY_SENSORS: \n",
      "\t- Upgrade {{{my_sensors}}} as per the requirement of the tasks \n",
      "\n",
      "MY_DELEGATED_TASK_NAMES: \n",
      "\t- Review and manage {{{delegated_task_names}}} regularly\n",
      "\n",
      "MY_PRESENT_TOOLS:\n",
      "\t- Curate and update {{{present_tools}}} list based on the relevancy and usage. \n",
      "\n",
      "MY_IMMEDIATELY_RELEVANT_KNOWLEDGE:\n",
      "\t- Continually refine and expand relevant knowledge from generated_from_environment (generation_from_environment_code_path)\n",
      "\n",
      "{{{ periodic_thoughts }}}\n",
      "MY_PRESENT_TASK: \t\n",
      "\t- Continually evaluate your definitions and propose updates as part of ongoing self-improvement. \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20c3b0-3ad1-4a03-9913-d873e8e53e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
