{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851ef27-17a2-42ac-ba6a-e9b5fb6bb76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6335ae2-c900-437a-b731-d0226558f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ian/miniforge3/envs/genai/lib/python3.10/site-packages/langchain/llms/openai.py:173: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ian/miniforge3/envs/genai/lib/python3.10/site-packages/langchain/llms/openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# initialize the models\n",
    "\n",
    "models = ['gpt-3.5-turbo-16k', 'gpt-4','gpt-4-32k',\"text-davinci-003\"]\n",
    "model = models[1]\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=model,\n",
    "    openai_api_key= os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b915662-678f-40b3-ba10-710432d1c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCS_DIR = '../../docs/'\n",
    "# file_name = dosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae838ef5-36a1-4095-8982-28dc6f119812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/\n",
      "├── Engineering/\n",
      "│   ├── actions_and_tools.md\n",
      "│   ├── ai_in_general.md\n",
      "│   ├── by_domain.md\n",
      "│   ├── chain_optimization.md\n",
      "│   ├── computation.md\n",
      "│   ├── evaluating_and_comparing.md\n",
      "│   ├── examples.md\n",
      "│   ├── finetuning.md\n",
      "│   ├── frameworks_and_tools.md\n",
      "│   ├── front_end.md\n",
      "│   ├── index.md\n",
      "│   ├── interpreters.md\n",
      "│   ├── memory.md\n",
      "│   ├── model_deployment.md\n",
      "│   ├── models.md\n",
      "│   └── optimizing_model_reliability.md\n",
      "├── index.md\n",
      "├── Managen.ai/\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   ├── index.md\n",
      "│   └── managing.md\n",
      "├── Understanding/\n",
      "│   ├── agents/\n",
      "│   │   ├── actions_and_tools.md\n",
      "│   │   ├── agents.md\n",
      "│   │   ├── chains.md\n",
      "│   │   ├── environments.md\n",
      "│   │   ├── evaluation.md\n",
      "│   │   ├── examples.md\n",
      "│   │   ├── frameworks.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── memory.md\n",
      "│   │   └── systems.md\n",
      "│   ├── background/\n",
      "│   │   └── tensor_maths.md\n",
      "│   ├── data/\n",
      "│   │   ├── augmentation.md\n",
      "│   │   ├── embedding.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── privacy.md\n",
      "│   │   ├── selection.md\n",
      "│   │   ├── sources.md\n",
      "│   │   └── tokenizing.md\n",
      "│   ├── index.md\n",
      "│   ├── models/\n",
      "│   │   ├── alignment.md\n",
      "│   │   ├── call_optimization.md\n",
      "│   │   ├── classes/\n",
      "│   │   │   ├── components.md\n",
      "│   │   │   ├── developing_architectures.md\n",
      "│   │   │   ├── diffusers.md\n",
      "│   │   │   ├── gans.md\n",
      "│   │   │   ├── hybrid_models.md\n",
      "│   │   │   ├── index.md\n",
      "│   │   │   ├── reinforcement_learning.md\n",
      "│   │   │   └── transformers.md\n",
      "│   │   ├── distillation.md\n",
      "│   │   ├── evaluation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── models.md\n",
      "│   │   ├── optimizing_hyper_parameters.md\n",
      "│   │   ├── prompt_engineering/\n",
      "│   │   │   ├── prompt_injections.md\n",
      "│   │   │   └── prompting.md\n",
      "│   │   ├── rag.md\n",
      "│   │   ├── reinforcement_feedback.md\n",
      "│   │   └── training.md\n",
      "│   ├── overview/\n",
      "│   │   ├── applications.md\n",
      "│   │   ├── challenges.md\n",
      "│   │   ├── extra_resources.md\n",
      "│   │   └── index.md\n",
      "│   └── studies/\n",
      "│       └── studies.md\n",
      "└── Using/\n",
      "    ├── by_application.md\n",
      "    ├── commercial_products.md\n",
      "    ├── ethically/\n",
      "    │   ├── alignment_and_exential_concerns.md\n",
      "    │   ├── dual_use_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── governing.md\n",
      "    ├── index.md\n",
      "    ├── marking_and_detecting.md\n",
      "    ├── ml_ops.md\n",
      "    ├── observability.md\n",
      "    ├── regulation.md\n",
      "    ├── responsibly/\n",
      "    └── web_plugins.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = '├──'\n",
    "    display_filename_prefix_last = '└──'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = '│   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "\n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))\n",
    "\n",
    "# With a criteria (skip hidden files)\n",
    "def is_not_hidden(path):\n",
    "    return  not ( 'Icon' in path.name or '.DS_Store' in path.name or 'stylesheets'  in path.name or \\\n",
    "        'CNAME' in path.name or 'assets' in path.name or '.svg' in path.name or '.pages' in path.name)\n",
    "    \n",
    "# paths = DisplayablePath.make_tree(\n",
    "#     Path(base_docs_dir),\n",
    "#     criteria=is_not_hidden\n",
    "# )\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "\n",
    "\n",
    "# paths = DisplayablePath.make_tree(Path(base_docs_dir), criteria=is_not_hidden)\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "def get_tree_structure(path_base=BASE_DOCS_DIR):\n",
    "    \n",
    "    paths = DisplayablePath.make_tree(Path(path_base), criteria=is_not_hidden)\n",
    "    path_str = [p.displayable() for p in paths]\n",
    "    # for path in paths:\n",
    "    #     print(path.displayable())\n",
    "    # return ''.join([p for p in path.displayable()])\n",
    "    return '\\n'.join(path_str)\n",
    "    \n",
    "tree_structure = get_tree_structure()\n",
    "print(tree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fe1f87-8ecc-49c0-aa96-399775ac8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path, base_dir=BASE_DOCS_DIR):\n",
    "    # iterator for getting filenames\n",
    "    return os.path.join(base_dir, file_path)\n",
    "\n",
    "def get_structure_pattern():\n",
    "    pattern = \\\n",
    "    \"\"\"\n",
    "    <<intro>>\n",
    "    ## <<First topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## <<Second topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## ...\n",
    "    ## Essential References\n",
    "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
    "    \"\"\"\n",
    "    return pattern\n",
    "\n",
    "\n",
    "def get_markdown_text(markdown_file):\n",
    "    with open(markdown_file, 'r') as f:\n",
    "        markdown_text = f.read()\n",
    "    # print(markdown_text)\n",
    "    return markdown_text\n",
    "# Could potentially do this is in few-shot prompt templates\n",
    "# These should be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "426a3057-f92c-42dc-bba2-1555943a7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Improve the markdown based on best understandings.\"\\\n",
    "                         \"Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \\\n",
    "\"\"\" You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "You are helping to rewrite and expand a file called {file_name} in the present tree-structure:\\n {tree_structure}\\n \n",
    "Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\n",
    "Please present html links without changing the link's text. \n",
    "After the markdown When the text is presented (after >>>), please improve upon it. If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
    "Please preserve any urls or relative links without changing them. \n",
    "Please be sure to use `#` appropriately to reference sections and subsections.\n",
    "Please be sure to keep any amonitions like `!!! tip` and use others when appropriate\n",
    "Markdown Response: \n",
    ">>>\\n\n",
    "{markdown_text}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"markdown_text\", \"structure_pattern\"],\n",
    "    template=template\n",
    ")\n",
    "file_from_base_dir = 'Understanding/data/sources.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt=prompt_template.format(project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       file_name=file_name,\n",
    "                       tree_structure=tree_structure,\n",
    "                        structure_pattern=structure_pattern,\n",
    "                       markdown_text=markdown_text,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b982b3e-6563-4e18-8d44-7ba14122fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# project_name = \"Managing Generative AI\"\n",
    "# project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "#                 \"Generative AI and how to improve upon it. \"\n",
    "# present_task_description=\"Improve the markdown based on best understandings.\"\\\n",
    "#                          \"Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\"\n",
    "\n",
    "# from langchain import PromptTemplate\n",
    "\n",
    "# template = \\\n",
    "# \"\"\" You are working on a project called: {project_name}\\n\n",
    "# You are part of a team working to: {project_goals}\\n\n",
    "# You are helping to: {present_task_description}\\n\n",
    "# You are helping to rewrite and expand a file called {file_name}\\n\n",
    "# Primarily you are tasked with adding admonitions to the markdown document to make it more nice to read. \n",
    "# for instance, you will see formats like this:\n",
    "# '''\n",
    "# - [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf) A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "#     **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# '''\n",
    "# This needs to be reformatted in the following manner:\n",
    "# '''\n",
    "# <div class=\"result\" markdown>\n",
    "# !!! tip \"[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)\"\n",
    "#     A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "# ??? example \n",
    "#      **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# </div> \n",
    "\n",
    "# You should make this modification for EVERY link that is presented that doesn't have admonitions already there. \n",
    "# After the markdown When the text is presented, please improve upon it. If no text is present create a reasonable outline following the pattern above and fill it in.\n",
    "# Please preserve any urls or relative links without changing them. \n",
    "# Please be sure to use `#` appropriately to reference sections and subsections.\n",
    "# Please be sure to use appropriate spacing to make admonitions work.\n",
    "\n",
    "# Here is the markdown text:\n",
    "# {markdown_text}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"markdown_text\"],\n",
    "#     template=template\n",
    "# )\n",
    "# file_from_base_dir = 'Understanding/agents/systems.md'\n",
    "# file_name=get_file_name(file_from_base_dir)\n",
    "\n",
    "# markdown_text=get_markdown_text(file_name)\n",
    "# prompt=prompt_template.format(project_name=project_name,\n",
    "#                        project_goals=project_goals,\n",
    "#                        present_task_description=present_task_description,\n",
    "#                        file_name=file_name,\n",
    "#                        markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c52c69f5-576b-49b6-b902-d6773140bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You are working on a project called: Managing Generative AI\n",
      "\n",
      "You are part of a team working to: Overall: Create an automated repository that is able to explain in plain-English and in code, Generative AI and how to improve upon it. \n",
      "\n",
      "You are helping to: Improve the markdown based on best understandings.Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\n",
      "\n",
      "You are helping to rewrite and expand a file called ../../docs/Understanding/data/sources.md in the present tree-structure:\n",
      " docs/\n",
      "├── .pages\n",
      "├── assets/\n",
      "│   ├── genai_logo_edited.svg\n",
      "│   └── genai_logo_v1.png\n",
      "├── CNAME\n",
      "├── Engineering/\n",
      "│   ├── .pages\n",
      "│   ├── actions_and_tools.md\n",
      "│   ├── commercial_products.md\n",
      "│   ├── computation.md\n",
      "│   ├── deployment.md\n",
      "│   ├── examples.md\n",
      "│   ├── frameworks_and_tools.md\n",
      "│   ├── index.md\n",
      "│   ├── interpreters.md\n",
      "│   ├── marking_and_detecting.md\n",
      "│   ├── memory.md\n",
      "│   ├── models.md\n",
      "│   ├── observability.md\n",
      "│   ├── regulation.md\n",
      "│   └── web_plugins.md\n",
      "├── index.md\n",
      "├── Managen.ai/\n",
      "│   ├── .pages\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   └── managing.md\n",
      "├── stylesheets/\n",
      "│   └── extra.css\n",
      "└── Understanding/\n",
      "    ├── .pages\n",
      "    ├── agents/\n",
      "    │   ├── .pages\n",
      "    │   ├── actions_and_tools.md\n",
      "    │   ├── agents.md\n",
      "    │   ├── chains.md\n",
      "    │   ├── environments.md\n",
      "    │   ├── evaluation.md\n",
      "    │   ├── examples.md\n",
      "    │   ├── frameworks.md\n",
      "    │   ├── index.md\n",
      "    │   ├── memory.md\n",
      "    │   └── systems.md\n",
      "    ├── data/\n",
      "    │   ├── .pages\n",
      "    │   ├── augmentation.md\n",
      "    │   ├── data.md\n",
      "    │   ├── embedding.md\n",
      "    │   ├── privacy.md\n",
      "    │   ├── selection.md\n",
      "    │   ├── sources.md\n",
      "    │   └── tokenizing.md\n",
      "    ├── ethical_concerns/\n",
      "    │   ├── .pages\n",
      "    │   ├── alignment_and_exential_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── index.md\n",
      "    ├── models/\n",
      "    │   ├── .pages\n",
      "    │   ├── alignment.md\n",
      "    │   ├── classes/\n",
      "    │   │   ├── .pages\n",
      "    │   │   ├── diffusers.md\n",
      "    │   │   ├── gans.md\n",
      "    │   │   ├── index.md\n",
      "    │   │   ├── RL.md\n",
      "    │   │   └── transformers.md\n",
      "    │   ├── distillation.md\n",
      "    │   ├── evaluation.md\n",
      "    │   ├── index.md\n",
      "    │   ├── rag.md\n",
      "    │   └── training.md\n",
      "    ├── overview/\n",
      "    │   ├── .pages\n",
      "    │   ├── ai_in_general.md\n",
      "    │   ├── applications.md\n",
      "    │   ├── challenges.md\n",
      "    │   ├── extra_resources.md\n",
      "    │   └── index.md\n",
      "    ├── prompt_engineering/\n",
      "    │   ├── prompt_injections.md\n",
      "    │   └── prompting.md\n",
      "    └── studies/\n",
      "        └── studies.md\n",
      " \n",
      "Please use a heading/subheading structure that follows the general pattern : \n",
      "    <<intro>>\n",
      "    ## <<First topic>>\n",
      "    ### <<topic sub component>>\n",
      "    ### <<topic sub component>>\n",
      "    ### ...\n",
      "    ## <<Second topic>>\n",
      "    ### <<topic sub component>>\n",
      "    ### ...\n",
      "    ## ...\n",
      "    ## Essential References\n",
      "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
      "    \n",
      "\n",
      "Please present html links without changing the link's text. \n",
      "After the markdown When the text is presented (after >>>), please improve upon it. If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
      "Please preserve any urls or relative links without changing them. \n",
      "Please be sure to use `#` appropriately to reference sections and subsections.\n",
      "Markdown Response: \n",
      ">>>\n",
      "\n",
      "\n",
      "## Data sources\n",
      "\n",
      "\n",
      "RedPajama\n",
      "Pile\n",
      "CommonCrawl (webscrape)\n",
      "C4 (CommonCrawl)\n",
      "Github\n",
      "Books\n",
      "Arxiv\n",
      "StackExchange\n",
      "\n",
      "- [unarXive 2022: All arXiv Publications Pre-Processed for NLP](https://arxiv.org/pdf/2303.14957.pdf)\n",
      "\n",
      "- [Redpajama](https://www.together.xyz/blog/redpajama)\n",
      "- [BIG-bench](https://github.com/google/BIG-bench/blob/main/docs/doc.md) APACHE 2.0\n",
      "- [Metaseq](https://github.com/facebookresearch/metaseq/) For working with Oen pre-trained transformers (from fairseq)\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b43d135-414a-4b9b-b109-7b69eb24b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8cefc40-c915-4369-a54a-38d18aad72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Introduction to Data Sources\n",
      "\n",
      "Generative AI relies on data sources of various types for training and execution. Here, a collection of known sources is presented, ranging from text data sets to larger repositories of structured and unstructured information.\n",
      "\n",
      "## Data Sources Explored\n",
      "\n",
      "### RedPajama\n",
      "\n",
      "RedPajama is a large-scale data repository particularly useful for generative AI models. Details regarding its structure, usage, and access are available through the [Redpajama](https://www.together.xyz/blog/redpajama) link.\n",
      "\n",
      "### Pile\n",
      "\n",
      "\"Pile\" is a comprehensive and large-scale collection of English text data, assembled specifically for AI model training. It includes text from a wide variety of sources and genres, thus providing a broad-based training environment for models.\n",
      "\n",
      "### CommonCrawl (webscrape)\n",
      "\n",
      "CommonCrawl is a broad web scrape repository that offers a vast amount of text data. It is particularly useful due to its dynamic nature and the constant updates with new information.\n",
      "\n",
      "### C4 (CommonCrawl)\n",
      "\n",
      "The C4, or \"Cleaned CommonCrawl Corpus\", is an extremely useful derivative of the CommonCrawl repository. By cleaning and formalizing the data in CommonCrawl, the C4 repository provides a more refined and streamlined data set for Generative Models.\n",
      "\n",
      "### Github\n",
      "\n",
      "The GitHub platform is an immense repository of code data, which offers usefulness in training code-based, generative AI models or AI models meant to work on code repositories.\n",
      "\n",
      "### Books\n",
      "\n",
      "Book repositories and databases provide a vast amount of organized and structured text data, ideal for models that try to understand and generate human-like (or book-like) text.\n",
      "\n",
      "### Arxiv\n",
      "\n",
      "Arxiv is a paper repository that provides a significant amount of scientific and academic text data. AI models trained on such data can generate high-quality scientific or technical text. \n",
      "\n",
      "### StackExchange\n",
      "\n",
      "The Q&A site StackExchange provides structured conversational data, useful in training models that respond to queries or in dialogue-based AI systems.\n",
      "\n",
      "## Open Data Repositories\n",
      "\n",
      "- [unarXive 2022: All arXiv Publications Pre-Processed for NLP](https://arxiv.org/pdf/2303.14957.pdf)\n",
      "\n",
      "The above link directs to a pre-processed version of the entirety of arXiv's publication database, as of 2022. This source allows for easy NLP modeling on high level scientific and technical literature.\n",
      "\n",
      "- [Metaseq](https://github.com/facebookresearch/metaseq/)\n",
      "\n",
      "Metaseq is an open-source codebase by Facebook Research for working with Open pre-trained transformers from fairseq.\n",
      "\n",
      "## License Details\n",
      "\n",
      "[BIG-bench](https://github.com/google/BIG-bench/blob/main/docs/doc.md) APACHE 2.0\n",
      "\n",
      "BIG-bench, a project developed by Google and available on GitHub, is distributed under the Apache 2.0 License.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "These data sources, coupled with their potential applications, form the foundation on which modern generative AI models are built. From developing sophisticated conversational AI to technical text generation, these repositories offer a wide spectrum of data types to meet different requirements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "711fb39a-a6a1-4394-94d3-6fa83a54bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "md = markdown.markdown(markdown_text, extensions=['toc'])\n",
    "# from markdown.extensions.toc import TocExtension\n",
    "# html = markdown.markdown(markdown_text, extensions=[TocExtension(baselevel=1)])\n",
    "# print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b32251b-2f60-41a2-bcc4-ee275b4ebd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'l': 1, 't': 'Title'}, {'l': 2, 't': 'Section 1'}, {'l': 3, 't': 'Subsection 1.1'}, {'l': 2, 't': 'Section 2'}, {'l': 3, 't': 'Subsection 2.1'}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_toc(md_text, level_key=\"l\", text_key='t'):\n",
    "    # Regex to match markdown headings, capturing the level based on hash count and the heading text\n",
    "    pattern = re.compile(r'^(?P<hashes>#+) (?P<text>.+)$', re.MULTILINE)\n",
    "    matches = pattern.findall(md_text.strip())\n",
    "\n",
    "    toc_structure = [{level_key: len(hashes), text_key: text} for hashes, text in matches]\n",
    "    return toc_structure\n",
    "\n",
    "def serialize_toc(toc_structure):\n",
    "    return json.dumps(toc_structure, indent=4)\n",
    "\n",
    "def test_extract_toc():\n",
    "    md_text = \"\"\"\n",
    "# Title\n",
    "\n",
    "## Section 1\n",
    "\n",
    "Content here\n",
    "\n",
    "### Subsection 1.1\n",
    "\n",
    "More content here\n",
    "\n",
    "## Section 2\n",
    "\n",
    "### Subsection 2.1\n",
    "\n",
    "Yet more content\n",
    "    \"\"\"\n",
    "\n",
    "    toc_structure = extract_toc(md_text)\n",
    "    print(toc_structure)\n",
    "    serialized_toc = serialize_toc(toc_structure)\n",
    "\n",
    "    expected_output = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"l\": 1,\n",
    "        \"t\": \"Title\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 1.1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 2\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 2.1\"\n",
    "    }\n",
    "]\n",
    "    \"\"\"\n",
    "\n",
    "    assert serialized_toc.strip() == expected_output.strip(), f\"Expected:\\n{expected_output}\\nGot:\\n{serialized_toc}\"\n",
    "\n",
    "test_extract_toc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacbaf58-392b-494b-9e87-218a439bb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a28916-5f7d-4334-a77d-a629b42c0a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
