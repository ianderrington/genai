{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851ef27-17a2-42ac-ba6a-e9b5fb6bb76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6335ae2-c900-437a-b731-d0226558f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ian/miniforge3/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "/Users/ian/miniforge3/envs/langchain/lib/python3.9/site-packages/langchain/llms/openai.py:172: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ian/miniforge3/envs/langchain/lib/python3.9/site-packages/langchain/llms/openai.py:750: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "# initialize the models\n",
    "\n",
    "models = ['gpt-3.5-turbo-16k', 'gpt-4','gpt-4-32k',\"text-davinci-003\"]\n",
    "model = models[1]\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=model,\n",
    "    openai_api_key= os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b915662-678f-40b3-ba10-710432d1c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCS_DIR = '../../docs/'\n",
    "# file_name = dosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae838ef5-36a1-4095-8982-28dc6f119812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/\n",
      "├── .pages\n",
      "├── assets/\n",
      "│   ├── genai_logo_edited.svg\n",
      "│   └── genai_logo_v1.png\n",
      "├── CNAME\n",
      "├── Engineering/\n",
      "│   ├── .pages\n",
      "│   ├── actions_and_tools.md\n",
      "│   ├── commercial_products.md\n",
      "│   ├── computation.md\n",
      "│   ├── deployment.md\n",
      "│   ├── examples.md\n",
      "│   ├── frameworks_and_tools.md\n",
      "│   ├── index.md\n",
      "│   ├── interpreters.md\n",
      "│   ├── marking_and_detecting.md\n",
      "│   ├── memory.md\n",
      "│   ├── models.md\n",
      "│   ├── observability.md\n",
      "│   ├── regulation.md\n",
      "│   └── web_plugins.md\n",
      "├── index.md\n",
      "├── Managing/\n",
      "│   ├── .pages\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   └── managing.md\n",
      "├── stylesheets/\n",
      "│   └── extra.css\n",
      "└── Understanding/\n",
      "    ├── .pages\n",
      "    ├── agents/\n",
      "    │   ├── .pages\n",
      "    │   ├── actions_and_tools.md\n",
      "    │   ├── agents.md\n",
      "    │   ├── chains.md\n",
      "    │   ├── environments.md\n",
      "    │   ├── evaluation.md\n",
      "    │   ├── examples.md\n",
      "    │   ├── frameworks.md\n",
      "    │   ├── index.md\n",
      "    │   ├── memory.md\n",
      "    │   └── systems.md\n",
      "    ├── data/\n",
      "    │   ├── .pages\n",
      "    │   ├── augmentation.md\n",
      "    │   ├── data.md\n",
      "    │   ├── embedding.md\n",
      "    │   ├── preprocessing.md\n",
      "    │   ├── privacy.md\n",
      "    │   ├── quality.md\n",
      "    │   ├── sources.md\n",
      "    │   └── tokenizing.md\n",
      "    ├── ethical_concerns/\n",
      "    │   ├── .pages\n",
      "    │   ├── alignment_and_exential_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── index.md\n",
      "    ├── models/\n",
      "    │   ├── .pages\n",
      "    │   ├── alignment.md\n",
      "    │   ├── classes/\n",
      "    │   │   ├── .pages\n",
      "    │   │   ├── diffusers.md\n",
      "    │   │   ├── gans.md\n",
      "    │   │   ├── index.md\n",
      "    │   │   ├── RL.md\n",
      "    │   │   └── transformers.md\n",
      "    │   ├── distillation.md\n",
      "    │   ├── evaluation.md\n",
      "    │   ├── index.md\n",
      "    │   ├── rag.md\n",
      "    │   └── training.md\n",
      "    ├── overview/\n",
      "    │   ├── .pages\n",
      "    │   ├── ai_in_general.md\n",
      "    │   ├── applications.md\n",
      "    │   ├── challenges.md\n",
      "    │   ├── extra_resources.md\n",
      "    │   └── index.md\n",
      "    ├── prompt_engineering/\n",
      "    │   ├── prompt_injections.md\n",
      "    │   └── prompting.md\n",
      "    └── studies/\n",
      "        └── studies.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = '├──'\n",
    "    display_filename_prefix_last = '└──'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = '│   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "\n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))\n",
    "\n",
    "# With a criteria (skip hidden files)\n",
    "def is_not_hidden(path):\n",
    "    return ( '.pages' in path.name or not path.name.startswith(\".\") ) and 'Icon' not in path.name\n",
    "    \n",
    "# paths = DisplayablePath.make_tree(\n",
    "#     Path(base_docs_dir),\n",
    "#     criteria=is_not_hidden\n",
    "# )\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "\n",
    "\n",
    "# paths = DisplayablePath.make_tree(Path(base_docs_dir), criteria=is_not_hidden)\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "def get_tree_structure(path_base=BASE_DOCS_DIR):\n",
    "    \n",
    "    paths = DisplayablePath.make_tree(Path(path_base), criteria=is_not_hidden)\n",
    "    path_str = [p.displayable() for p in paths]\n",
    "    # for path in paths:\n",
    "    #     print(path.displayable())\n",
    "    # return ''.join([p for p in path.displayable()])\n",
    "    return '\\n'.join(path_str)\n",
    "    \n",
    "tree_structure = get_tree_structure()\n",
    "print(tree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fe1f87-8ecc-49c0-aa96-399775ac8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path, base_dir=BASE_DOCS_DIR):\n",
    "    # iterator for getting filenames\n",
    "    return os.path.join(base_dir, file_path)\n",
    "\n",
    "def get_structure_pattern():\n",
    "    pattern = \\\n",
    "    \"\"\"\n",
    "    <<intro>>\n",
    "    ## <<First topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## <<Second topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## ...\n",
    "    ## Essential References\n",
    "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
    "    \"\"\"\n",
    "    return pattern\n",
    "\n",
    "\n",
    "def get_markdown_text(markdown_file):\n",
    "    with open(markdown_file, 'r') as f:\n",
    "        markdown_text = f.read()\n",
    "    # print(markdown_text)\n",
    "    return markdown_text\n",
    "# Could potentially do this is in few-shot prompt templates\n",
    "# These should be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426a3057-f92c-42dc-bba2-1555943a7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Improve the markdown based on best understandings.\"\\\n",
    "                         \"Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \\\n",
    "\"\"\" You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "You are helping to rewrite and expand a file called {file_name} in the present tree-structure:\\n {tree_structure}\\n \n",
    "Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\n",
    "Please present html links without changing the link's text. \n",
    "After the markdown When the text is presented (after >>>), please improve upon it. If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
    "Please preserve any urls or relative links without changing them. \n",
    "Please be sure to use `#` appropriately to reference sections and subsections.\n",
    "Markdown Response: \n",
    ">>>\\n\n",
    "{markdown_text}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"markdown_text\", \"structure_pattern\"],\n",
    "    template=template\n",
    ")\n",
    "file_from_base_dir = 'Understanding/overview/applications.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt=prompt_template.format(project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       file_name=file_name,\n",
    "                       tree_structure=tree_structure,\n",
    "                        structure_pattern=structure_pattern,\n",
    "                       markdown_text=markdown_text,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b982b3e-6563-4e18-8d44-7ba14122fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# project_name = \"Managing Generative AI\"\n",
    "# project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "#                 \"Generative AI and how to improve upon it. \"\n",
    "# present_task_description=\"Improve the markdown based on best understandings.\"\\\n",
    "#                          \"Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\"\n",
    "\n",
    "# from langchain import PromptTemplate\n",
    "\n",
    "# template = \\\n",
    "# \"\"\" You are working on a project called: {project_name}\\n\n",
    "# You are part of a team working to: {project_goals}\\n\n",
    "# You are helping to: {present_task_description}\\n\n",
    "# You are helping to rewrite and expand a file called {file_name}\\n\n",
    "# Primarily you are tasked with adding admonitions to the markdown document to make it more nice to read. \n",
    "# for instance, you will see formats like this:\n",
    "# '''\n",
    "# - [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf) A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "#     **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# '''\n",
    "# This needs to be reformatted in the following manner:\n",
    "# '''\n",
    "# <div class=\"result\" markdown>\n",
    "# !!! tip \"[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)\"\n",
    "#     A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "# ??? example \n",
    "#      **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# </div> \n",
    "\n",
    "# You should make this modification for EVERY link that is presented that doesn't have admonitions already there. \n",
    "# After the markdown When the text is presented, please improve upon it. If no text is present create a reasonable outline following the pattern above and fill it in.\n",
    "# Please preserve any urls or relative links without changing them. \n",
    "# Please be sure to use `#` appropriately to reference sections and subsections.\n",
    "# Please be sure to use appropriate spacing to make admonitions work.\n",
    "\n",
    "# Here is the markdown text:\n",
    "# {markdown_text}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"markdown_text\"],\n",
    "#     template=template\n",
    "# )\n",
    "# file_from_base_dir = 'Understanding/agents/systems.md'\n",
    "# file_name=get_file_name(file_from_base_dir)\n",
    "\n",
    "# markdown_text=get_markdown_text(file_name)\n",
    "# prompt=prompt_template.format(project_name=project_name,\n",
    "#                        project_goals=project_goals,\n",
    "#                        present_task_description=present_task_description,\n",
    "#                        file_name=file_name,\n",
    "#                        markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52c69f5-576b-49b6-b902-d6773140bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You are working on a project called: Managing Generative AI\n",
      "\n",
      "You are part of a team working to: Overall: Create an automated repository that is able to explain in plain-English and in code, Generative AI and how to improve upon it. \n",
      "\n",
      "You are helping to: Improve the markdown based on best understandings.Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\n",
      "\n",
      "You are helping to rewrite and expand a file called ../../docs/Understanding/overview/applications.md in the present tree-structure:\n",
      " docs/\n",
      "├── .pages\n",
      "├── assets/\n",
      "│   ├── genai_logo_edited.svg\n",
      "│   └── genai_logo_v1.png\n",
      "├── CNAME\n",
      "├── Engineering/\n",
      "│   ├── .pages\n",
      "│   ├── actions_and_tools.md\n",
      "│   ├── commercial_products.md\n",
      "│   ├── computation.md\n",
      "│   ├── deployment.md\n",
      "│   ├── examples.md\n",
      "│   ├── frameworks_and_tools.md\n",
      "│   ├── index.md\n",
      "│   ├── interpreters.md\n",
      "│   ├── marking_and_detecting.md\n",
      "│   ├── memory.md\n",
      "│   ├── models.md\n",
      "│   ├── observability.md\n",
      "│   ├── regulation.md\n",
      "│   └── web_plugins.md\n",
      "├── index.md\n",
      "├── Managing/\n",
      "│   ├── .pages\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   └── managing.md\n",
      "├── stylesheets/\n",
      "│   └── extra.css\n",
      "└── Understanding/\n",
      "    ├── .pages\n",
      "    ├── agents/\n",
      "    │   ├── .pages\n",
      "    │   ├── actions_and_tools.md\n",
      "    │   ├── agents.md\n",
      "    │   ├── chains.md\n",
      "    │   ├── environments.md\n",
      "    │   ├── evaluation.md\n",
      "    │   ├── examples.md\n",
      "    │   ├── frameworks.md\n",
      "    │   ├── index.md\n",
      "    │   ├── memory.md\n",
      "    │   └── systems.md\n",
      "    ├── data/\n",
      "    │   ├── .pages\n",
      "    │   ├── augmentation.md\n",
      "    │   ├── data.md\n",
      "    │   ├── embedding.md\n",
      "    │   ├── preprocessing.md\n",
      "    │   ├── privacy.md\n",
      "    │   ├── quality.md\n",
      "    │   ├── sources.md\n",
      "    │   └── tokenizing.md\n",
      "    ├── ethical_concerns/\n",
      "    │   ├── .pages\n",
      "    │   ├── alignment_and_exential_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── index.md\n",
      "    ├── models/\n",
      "    │   ├── .pages\n",
      "    │   ├── alignment.md\n",
      "    │   ├── classes/\n",
      "    │   │   ├── .pages\n",
      "    │   │   ├── diffusers.md\n",
      "    │   │   ├── gans.md\n",
      "    │   │   ├── index.md\n",
      "    │   │   ├── RL.md\n",
      "    │   │   └── transformers.md\n",
      "    │   ├── distillation.md\n",
      "    │   ├── evaluation.md\n",
      "    │   ├── index.md\n",
      "    │   ├── rag.md\n",
      "    │   └── training.md\n",
      "    ├── overview/\n",
      "    │   ├── .pages\n",
      "    │   ├── ai_in_general.md\n",
      "    │   ├── applications.md\n",
      "    │   ├── challenges.md\n",
      "    │   ├── extra_resources.md\n",
      "    │   └── index.md\n",
      "    ├── prompt_engineering/\n",
      "    │   ├── prompt_injections.md\n",
      "    │   └── prompting.md\n",
      "    └── studies/\n",
      "        └── studies.md\n",
      " \n",
      "Please use a heading/subheading structure that follows the general pattern : \n",
      "    <<intro>>\n",
      "    ## <<First topic>>\n",
      "    ### <<topic sub component>>\n",
      "    ### <<topic sub component>>\n",
      "    ### ...\n",
      "    ## <<Second topic>>\n",
      "    ### <<topic sub component>>\n",
      "    ### ...\n",
      "    ## ...\n",
      "    ## Essential References\n",
      "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
      "    \n",
      "\n",
      "Please present html links without changing the link's text. \n",
      "After the markdown When the text is presented (after >>>), please improve upon it. If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
      "Please preserve any urls or relative links without changing them. \n",
      "Please be sure to use `#` appropriately to reference sections and subsections.\n",
      "Markdown Response: \n",
      ">>>\n",
      "\n",
      "## General Categories\n",
      "\n",
      "### Summarization \n",
      "\n",
      "### Semantic Search\n",
      "\n",
      "Embedding of an input has the niceness that semantic, or 'meaning' nearness can be found via distance calculations. This enables semantic search.\n",
      "This is important for memory recall with imperfect inputs, and for action routing based. \n",
      "\n",
      "### Knowledge graph building\n",
      "\n",
      "\n",
      "- [GPT for knowledge graphs](https://medium.com/@m-elbably/gpt-graph-a-simple-tool-for-knowledge-graph-exploration-70e0e3861716) and [Github](https://github.com/m-elbably/gpt-graph)\n",
      "\n",
      "- [Ontology mapping](https://medium.com/@peter.lawrence_47665/encouraging-results-for-knowledge-graph-extraction-by-llm-ontology-prompting-60a7e5dcaf0a)\n",
      "\n",
      "\n",
      "### Prose Generation\n",
      "\n",
      "Here is a non-extensive list of useful manners to use LLM generation of prose generation:\n",
      "\n",
      "- Cleaning up draft, or lower quality texts or notes\n",
      "- Brainstorming and ideation \n",
      "- Providing an initial draft for human editing\n",
      "- Generating summaries and executive summaries\n",
      "- Creating descriptions and explanations\n",
      "- Rewriting for different target audiences\n",
      "- Expanding on key points \n",
      "- Improving flow and readability\n",
      "- Adding examples and analogies\n",
      "- Filling in missing details\n",
      "- Extrapolating from key points\n",
      "- Creating fictional scenarios\n",
      "- Writing product descriptions\n",
      "- Writing blog posts and news articles\n",
      "- Writing stories and novels\n",
      "\n",
      "## Code Generation\n",
      "\n",
      "Very powerfully it can generate code to accomplish a task based on natural language input. This is very promising but still requires human oversight, due to the [challenge](./challenges.md) associated with using Automated AI systems without human input or oversight.\n",
      "\n",
      "## References by field\n",
      "\n",
      "### Code\n",
      "\n",
      "- [Wizard Coding](https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder)\n",
      "- [AutoPR](https://github.com/irgolic/AutoPR)\n",
      "- [Codium pr-agent](https://github.com/Codium-ai/pr-agent) \n",
      "- [Summarization with Langchain] https://github.com/EnkrateiaLucca/summarization_with_langchain A splendid view of a quick streamlit app that does PDF summarization. \n",
      "\n",
      "### Component replacements\n",
      "\n",
      "- [GPT as backend](https://github.com/RootbeerComputer/backend-GPT)\n",
      "\n",
      "## Book Writing\n",
      "\n",
      "- [Pyprompt chatgpt](http://morganlancer.com/en/portfolio/pyprompt_chatgpt)\n",
      "\n",
      "- [Motion GPT](https://github.com/openmotionlab/motiongpt)\n",
      "\n",
      "## Sound and Music Generation\n",
      "\n",
      "- [AudioCraft (Meta)](https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/)\n",
      "\n",
      "## Audio Visual Generation\n",
      "\n",
      "- [Showrunner Agents](https://fablestudio.github.io/showrunner-agents/)\n",
      "\n",
      "## Science and Tech\n",
      "\n",
      "- [Emergent autonomous scientific research](https://arxiv.org/pdf/2304.05332.pdf)\n",
      "<img width=\"658\" alt=\"image\" src=\"https://github.com/ianderrington/general/assets/76016868/7fd5c4ce-9468-4cf2-a9b9-d3913b66e656\">\n",
      "\n",
      "\n",
      "### Robotics\n",
      "\n",
      "- [CLAIRIFY](https://ac-rad.github.io/clairify/) Translates English to domain-specific languages like robots. \n",
      "  - https://arxiv.org/abs/2303.14100\n",
      "- [RT-2](https://robotics-transformer2.github.io/assets/rt2.pdf) An impressive demonstration of multi-step fusing (PaLI-X) and Pathways Language model Embodied (PaLM-E) as components of it. \n",
      "\n",
      "\n",
      "### Healthcare\n",
      "\n",
      "- [Health system-scale language models are all-purpose prediction engines](https://www.nature.com/articles/s41586-023-06160-y) Uses LLM based system to integrate real time clinical workflows with note-writing and electronic ordering. Generally quite-performant and. a great indication of how they could be used to predict things such as readmission rates, and many other applications. \n",
      "\n",
      "- [LLMs encode clinical knowledge](https://www.nature.com/articles/s41586-023-06291-2)\n",
      "\n",
      "### Chemistry\n",
      "\n",
      "- [Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction](https://openreview.net/pdf?id=SGQi3LgFnqj) A quality framework using heirarchichal metagraphs to stitch-together molecular nodes resulting in leaves that are 'actual' molecules. Using graph neural-diffusion, it does amazingly well even with minimal data-sets (100 examples).\n",
      "<img width=\"1052\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/50894091-fdc9-4a8f-9836-90cec4a147d0\"> \n",
      "\n",
      "i=\n",
      "### Biology\n",
      "\n",
      "- [Evolutionary-scale prediction of atomic-level protein structure with a language model](https://www.science.org/doi/10.1126/science.ade2574) End to end Language model enabling structure sequence pairing, coupled with an equivariant transformer structure model at the end. \n",
      "-  https://arxiv.org/pdf/2303.16416.pdf\n",
      "-  https://arxiv.org/abs/2304.02496\n",
      "-  ！[Biomedical simulation](https://www.biorxiv.org/content/10.1101/2023.06.16.545235v1.full.pdf)\n",
      "\n",
      "## Societal simulations\n",
      "\n",
      "- [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf): \n",
      "  They gave 25 AI agents motivations & memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine’s Day party) but the actions were rated more human than humans roleplaying.\n",
      "  Demo: https://t.co/pYNF4BBveG\n",
      "\n",
      "### Finance\n",
      "\n",
      "- [ML for trading (NOT LLM based)](https://github.com/stefan-jansen/machine-learning-for-trading)\n",
      "- https://github.com/irgolic/AutoPR\n",
      "- [Finance GPT](https://github.com/ai4finance-foundation/fingpt) LLMs for finance\n",
      "\n",
      "\n",
      "### Second Brain\n",
      "\n",
      "\n",
      "- ‼[Quiver](https://github.com/StanGirard/quiv) A LLM for self Second brain. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b43d135-414a-4b9b-b109-7b69eb24b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8cefc40-c915-4369-a54a-38d18aad72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Applications of Generative AI\n",
      "\n",
      "## Understanding Generative AI Applications\n",
      "\n",
      "This document provides an overview of the diverse applications of Generative AI. It explores different categories that utilize Generative AI's capabilities and provides essential references for each field.\n",
      "\n",
      "## Summarization \n",
      "\n",
      "Summarization is a key application for Generative AI. It uses the technology to provide brief, accurate summaries of a larger body of text.\n",
      "\n",
      "## Semantic Search\n",
      "\n",
      "Generative AI has the capability to understand semantic relationships between words and concepts. By embedding an input, the technology can measure semantic, or 'meaning', nearness via distance calculations. This capability enhances the potential for memory recall with imperfect inputs and improves action routing. \n",
      "\n",
      "## Building Knowledge Graphs\n",
      "\n",
      "Knowledge graphs can be created with the help of Generative AI. Understanding relationships between pieces of information allows the technology to create visual representations of connections, improving information processing.\n",
      "\n",
      "## Prose Generation\n",
      "\n",
      "Generative AI can be utilized for a wide range of prose generation applications, such as:\n",
      "\n",
      "- Drafting and refining text and notes.\n",
      "- Brainstorming and ideation.\n",
      "- Generating initial drafts for later human editing.\n",
      "- Creating descriptions and explanations.\n",
      "- Rewriting to target different audiences.\n",
      "- Expanding on key points.\n",
      "- Improving flow and readability.\n",
      "\n",
      "## Code Generation\n",
      "\n",
      "Generative AI can generate code based on natural language inputs. Despite its promising potential, this application still requires human oversight due to associated challenges.\n",
      "\n",
      "# Essential References\n",
      "\n",
      "## Summarization\n",
      "- [Summarization with Langchain](https://github.com/EnkrateiaLucca/summarization_with_langchain): A streamlit app for PDF summarization. \n",
      "\n",
      "## Prose Generation\n",
      "- [Pyprompt chatgpt](http://morganlancer.com/en/portfolio/pyprompt_chatgpt)\n",
      "- [Motion GPT](https://github.com/openmotionlab/motiongpt)\n",
      "\n",
      "## Code Generation\n",
      "- [Wizard Coding](https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder)\n",
      "- [AutoPR](https://github.com/irgolic/AutoPR)\n",
      "- [Codium pr-agent](https://github.com/Codium-ai/pr-agent)\n",
      "\n",
      "## Knowledge Graph Building\n",
      "- [GPT for knowledge graphs](https://medium.com/@m-elbably/gpt-graph-a-simple-tool-for-knowledge-graph-exploration-70e0e3861716)\n",
      "- [Ontology mapping](https://medium.com/@peter.lawrence_47665/encouraging-results-for-knowledge-graph-extraction-by-llm-ontology-prompting-60a7e5dcaf0a) \n",
      "\n",
      "## Sound and Music Generation\n",
      "- [AudioCraft (Meta)](https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/)\n",
      "\n",
      "## Audio Visual Generation\n",
      "- [Showrunner Agents](https://fablestudio.github.io/showrunner-agents/)\n",
      "\n",
      "## Science and Tech\n",
      "- [Emergent autonomous scientific research](https://arxiv.org/pdf/2304.05332.pdf)\n",
      "- [CLAIRIFY](https://ac-rad.github.io/clairify/)\n",
      "- [RT-2](https://robotics-transformer2.github.io/assets/rt2.pdf)\n",
      "\n",
      "## Healthcare\n",
      "- [Health system-scale language models are all-purpose prediction engines](https://www.nature.com/articles/s41586-023-06160-y)\n",
      "- [LLMs encode clinical knowledge](https://www.nature.com/articles/s41586-023-06291-2)\n",
      "\n",
      "## Chemistry\n",
      "- [Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction](https://openreview.net/pdf?id=SGQi3LgFnqj)\n",
      "\n",
      "## Biology\n",
      "- [Evolutionary-scale prediction of atomic-level protein structure with a language model](https://www.science.org/doi/10.1126/science.ade2574)\n",
      "\n",
      "## Societal Simulations\n",
      "- [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)\n",
      "\n",
      "## Finance\n",
      "- [ML for trading (NOT LLM based)](https://github.com/stefan-jansen/machine-learning-for-trading)\n",
      "- [Finance GPT](https://github.com/ai4finance-foundation/fingpt) \n",
      "\n",
      "## Second Brain\n",
      "- [Quiver](https://github.com/StanGirard/quiv) A LLM for self Second brain. \n",
      "\n",
      "These references provide an insight into the versatility and broad range of applications for Generative AI.\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "711fb39a-a6a1-4394-94d3-6fa83a54bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "md = markdown.markdown(markdown_text, extensions=['toc'])\n",
    "# from markdown.extensions.toc import TocExtension\n",
    "# html = markdown.markdown(markdown_text, extensions=[TocExtension(baselevel=1)])\n",
    "# print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b32251b-2f60-41a2-bcc4-ee275b4ebd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'l': 1, 't': 'Title'}, {'l': 2, 't': 'Section 1'}, {'l': 3, 't': 'Subsection 1.1'}, {'l': 2, 't': 'Section 2'}, {'l': 3, 't': 'Subsection 2.1'}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_toc(md_text, level_key=\"l\", text_key='t'):\n",
    "    # Regex to match markdown headings, capturing the level based on hash count and the heading text\n",
    "    pattern = re.compile(r'^(?P<hashes>#+) (?P<text>.+)$', re.MULTILINE)\n",
    "    matches = pattern.findall(md_text.strip())\n",
    "\n",
    "    toc_structure = [{level_key: len(hashes), text_key: text} for hashes, text in matches]\n",
    "    return toc_structure\n",
    "\n",
    "def serialize_toc(toc_structure):\n",
    "    return json.dumps(toc_structure, indent=4)\n",
    "\n",
    "def test_extract_toc():\n",
    "    md_text = \"\"\"\n",
    "# Title\n",
    "\n",
    "## Section 1\n",
    "\n",
    "Content here\n",
    "\n",
    "### Subsection 1.1\n",
    "\n",
    "More content here\n",
    "\n",
    "## Section 2\n",
    "\n",
    "### Subsection 2.1\n",
    "\n",
    "Yet more content\n",
    "    \"\"\"\n",
    "\n",
    "    toc_structure = extract_toc(md_text)\n",
    "    print(toc_structure)\n",
    "    serialized_toc = serialize_toc(toc_structure)\n",
    "\n",
    "    expected_output = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"l\": 1,\n",
    "        \"t\": \"Title\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 1.1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 2\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 2.1\"\n",
    "    }\n",
    "]\n",
    "    \"\"\"\n",
    "\n",
    "    assert serialized_toc.strip() == expected_output.strip(), f\"Expected:\\n{expected_output}\\nGot:\\n{serialized_toc}\"\n",
    "\n",
    "test_extract_toc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacbaf58-392b-494b-9e87-218a439bb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a28916-5f7d-4334-a77d-a629b42c0a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
