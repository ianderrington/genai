{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1851ef27-17a2-42ac-ba6a-e9b5fb6bb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6335ae2-c900-437a-b731-d0226558f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:248: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:1057: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "# initialize the models\n",
    "\n",
    "models = ['gpt-3.5-turbo-16k', 'gpt-4','gpt-4-1106-preview',\"text-davinci-003\"]\n",
    "model = models[1]\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=model,\n",
    "    # openai_api_key= os.environ[\"OPENAI_API_KEY\"]\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b915662-678f-40b3-ba10-710432d1c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCS_DIR = '../../docs/'\n",
    "# file_name = dosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae838ef5-36a1-4095-8982-28dc6f119812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/\n",
      "├── index.md\n",
      "├── javascripts/\n",
      "│   └── mathjax.js\n",
      "├── Managenai/\n",
      "│   ├── brainstorming.md\n",
      "│   ├── build_plan.md\n",
      "│   ├── contributing.md\n",
      "│   ├── index.md\n",
      "│   ├── managing.md\n",
      "│   ├── requirements.md\n",
      "│   └── site_graph.md\n",
      "├── Understanding/\n",
      "│   ├── agents/\n",
      "│   │   ├── actions_and_tools.md\n",
      "│   │   ├── chains.md\n",
      "│   │   ├── cognitive_architecture.md\n",
      "│   │   ├── environments.md\n",
      "│   │   ├── evaluating_and_comparing.md\n",
      "│   │   ├── examples.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── memory.md\n",
      "│   │   ├── rag.md\n",
      "│   │   └── systems.md\n",
      "│   ├── architectures/\n",
      "│   │   ├── evaluating_and_comparing.md\n",
      "│   │   ├── feedback.md\n",
      "│   │   ├── finetuning.md\n",
      "│   │   ├── generation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── llm_systems.md\n",
      "│   │   ├── models/\n",
      "│   │   │   ├── components.md\n",
      "│   │   │   ├── developing_architectures.md\n",
      "│   │   │   ├── diffusers.md\n",
      "│   │   │   ├── gans.md\n",
      "│   │   │   ├── gpt.md\n",
      "│   │   │   ├── hybrid_models.md\n",
      "│   │   │   ├── index.md\n",
      "│   │   │   ├── reinforcement_learning.md\n",
      "│   │   │   └── transformers.md\n",
      "│   │   ├── optimization.md\n",
      "│   │   ├── pre-training.md\n",
      "│   │   ├── pre_trained_models.md\n",
      "│   │   ├── recurrent_training.md\n",
      "│   │   └── training.md\n",
      "│   ├── background/\n",
      "│   │   └── tensor_maths.md\n",
      "│   ├── data/\n",
      "│   │   ├── augmentation.md\n",
      "│   │   ├── distillation.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── privacy.md\n",
      "│   │   ├── selection.md\n",
      "│   │   ├── simulation.md\n",
      "│   │   ├── sources.md\n",
      "│   │   └── tokenizing.md\n",
      "│   ├── deploying/\n",
      "│   │   ├── back_end.md\n",
      "│   │   ├── commercial_products.md\n",
      "│   │   ├── computation.md\n",
      "│   │   ├── examples_and_tutorials.md\n",
      "│   │   ├── frameworks.md\n",
      "│   │   ├── front_end.md\n",
      "│   │   ├── index.md\n",
      "│   │   └── libraries_and_tools.md\n",
      "│   ├── index.md\n",
      "│   ├── overview/\n",
      "│   │   ├── ai_and_ml_basics/\n",
      "│   │   │   └── index.md\n",
      "│   │   ├── challenges.md\n",
      "│   │   ├── chronology.md\n",
      "│   │   ├── extra_resources.md\n",
      "│   │   ├── index.md\n",
      "│   │   ├── open_source.md\n",
      "│   │   └── use_cases.md\n",
      "│   ├── prompting/\n",
      "│   │   ├── index.md\n",
      "│   │   └── prompt_injections.md\n",
      "│   └── studies/\n",
      "│       ├── behavior.md\n",
      "│       └── studies.md\n",
      "└── Using/\n",
      "    ├── building_and_buying.md\n",
      "    ├── de-risking/\n",
      "    │   ├── redteaming.md\n",
      "    │   └── security.md\n",
      "    ├── ethically/\n",
      "    │   ├── alignment.md\n",
      "    │   ├── alignment_and_exestential_concerns.md\n",
      "    │   ├── dual_use_concerns.md\n",
      "    │   ├── fairness.md\n",
      "    │   ├── index.md\n",
      "    │   └── transparency.md\n",
      "    ├── examples/\n",
      "    │   ├── by_field/\n",
      "    │   │   ├── business.md\n",
      "    │   │   ├── entertainment/\n",
      "    │   │   │   ├── dynamic.md\n",
      "    │   │   │   └── static.md\n",
      "    │   │   ├── index.md\n",
      "    │   │   ├── individuals_and_society/\n",
      "    │   │   │   ├── education.md\n",
      "    │   │   │   ├── law.md\n",
      "    │   │   │   └── socio_societal.md\n",
      "    │   │   ├── mathematics/\n",
      "    │   │   │   └── index.md\n",
      "    │   │   ├── science/\n",
      "    │   │   │   ├── biology.md\n",
      "    │   │   │   ├── chemistry.md\n",
      "    │   │   │   ├── healthcare.md\n",
      "    │   │   │   └── index.md\n",
      "    │   │   └── technology/\n",
      "    │   │       ├── coding.md\n",
      "    │   │       ├── finance.md\n",
      "    │   │       ├── healthcare.md\n",
      "    │   │       └── robotics.md\n",
      "    │   ├── by_modality/\n",
      "    │   │   ├── index.md\n",
      "    │   │   ├── knowledge_graphs.md\n",
      "    │   │   ├── language.md\n",
      "    │   │   ├── multimodal.md\n",
      "    │   │   ├── sound.md\n",
      "    │   │   ├── static_2d.md\n",
      "    │   │   ├── tabular.md\n",
      "    │   │   ├── text.md\n",
      "    │   │   ├── time_series.md\n",
      "    │   │   └── video.md\n",
      "    │   └── index.md\n",
      "    ├── index.md\n",
      "    ├── interfacing_layers/\n",
      "    │   └── web_plugins.md\n",
      "    ├── managing/\n",
      "    │   ├── governing.md\n",
      "    │   ├── index.md\n",
      "    │   ├── ml_ops.md\n",
      "    │   ├── observability.md\n",
      "    │   └── regulations_and_guidelines.md\n",
      "    └── marking_and_detecting.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = '├──'\n",
    "    display_filename_prefix_last = '└──'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = '│   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "\n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))\n",
    "\n",
    "# With a criteria (skip hidden files)\n",
    "def is_not_hidden(path):\n",
    "    return  not ( 'Icon' in path.name or '.DS_Store' in path.name or 'stylesheets'  in path.name or \\\n",
    "        'CNAME' in path.name or 'assets' in path.name or '.svg' in path.name or '.pages' in path.name)\n",
    "    \n",
    "# paths = DisplayablePath.make_tree(\n",
    "#     Path(base_docs_dir),\n",
    "#     criteria=is_not_hidden\n",
    "# )\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "\n",
    "\n",
    "# paths = DisplayablePath.make_tree(Path(base_docs_dir), criteria=is_not_hidden)\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "def get_tree_structure(path_base=BASE_DOCS_DIR):\n",
    "    \n",
    "    paths = DisplayablePath.make_tree(Path(path_base), criteria=is_not_hidden)\n",
    "    path_str = [p.displayable() for p in paths]\n",
    "    # for path in paths:\n",
    "    #     print(path.displayable())\n",
    "    # return ''.join([p for p in path.displayable()])\n",
    "    return '\\n'.join(path_str)\n",
    "    \n",
    "tree_structure = get_tree_structure()\n",
    "print(tree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fe1f87-8ecc-49c0-aa96-399775ac8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path, base_dir=BASE_DOCS_DIR):\n",
    "    # iterator for getting filenames\n",
    "    return os.path.join(base_dir, file_path)\n",
    "\n",
    "def get_structure_pattern():\n",
    "    pattern = \\\n",
    "    \"\"\"\n",
    "    <<intro>>\n",
    "    ## <<First topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## <<Second topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## ...\n",
    "    ## Essential References\n",
    "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
    "    \"\"\"\n",
    "    return pattern\n",
    "\n",
    "\n",
    "def get_markdown_text(markdown_file):\n",
    "    with open(markdown_file, 'r') as f:\n",
    "        markdown_text = f.read()\n",
    "    # print(markdown_text)\n",
    "    return markdown_text\n",
    "# Could potentially do this is in few-shot prompt templates\n",
    "# These should be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426a3057-f92c-42dc-bba2-1555943a7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Improve the markdown based on best understandings.\\n\"\\\n",
    "                         \"Be as honest and as accurate as possible. Be succinct in your responses. \"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "# Idea\n",
    "# Select between prompt patterns\n",
    "# Chain select them more effectively. \n",
    "# The present tree-structure:\\n {tree_structure}\\n \n",
    "# Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\n",
    "template = \\\n",
    "\"\"\" \n",
    "You are a {role}\n",
    "You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "You are helping to rewrite and expand a file called {file_name} \n",
    "Here are some things we'd like you to be sure to do:\n",
    "* Please present ALL html links without changing the link's text. \n",
    "* Preserve any urls or relative links without changing them. \n",
    "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
    "* Please be sure to keep any amonitions like `!!!` and `???`.\n",
    "* Please reformat any bulleted lists of links where github links have `!!! code`, arxiv's have `!!! tip` and others have `!!! information`. \n",
    "\n",
    "After the markdown When the text is presented (after >>>), please improve upon it. \n",
    "If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
    "\n",
    "Markdown Input:\\n\n",
    ">>>\\n\n",
    "{markdown_text}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    # input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"structure_pattern\", \"markdown_text\", ],\n",
    "        input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\",  \"markdown_text\", ],\n",
    "    template=template\n",
    ")\n",
    "file_from_base_dir = 'Using/deploying/index.md'\n",
    "file_from_base_dir = 'Using/redteaming.md'\n",
    "file_from_base_dir = 'Understanding/agents/rag.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt=prompt_template.format(role=role,\n",
    "                              project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       file_name=file_name,\n",
    "                       # tree_structure=tree_structure,\n",
    "                       #  structure_pattern=structure_pattern,\n",
    "                       markdown_text=markdown_text,)\n",
    "# The above is very verboase especially as it requires a lot of repeated typing of the same variables.\n",
    "# It also needs to work for variables that are only specified in the template. If they are not specified in the template, then they should be ignored.\n",
    "# There will a list of template lines that are appended to create the final prompt.\n",
    "# The template lines will be specified as a list of dictionaries.\n",
    "#  \n",
    "# Let's write this as a class\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  write above but realizing template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0241f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartPromptTemplate:\n",
    "    def __init__(self, template_required, template_optional_dict, template_variable_independent):\n",
    "        self.template_required = template_required if template_required is not None else \"\"\n",
    "        self.template_optional_dict = template_optional_dict if template_optional_dict is not None else {}\n",
    "        self.template_variable_independent = template_variable_independent if template_variable_independent is not None else \"\"\n",
    "    \n",
    "    def get_prompt(self, **kwargs):\n",
    "        template_list = []\n",
    "        for k, v in kwargs.items():\n",
    "            if k in self.template_optional_dict.keys():\n",
    "                template_list.append(self.template_optional_dict[k])\n",
    "        begin_indicator = \"\\n What would you write given the requests above? \\n>>>\\n\"\n",
    "        \n",
    "        template =   '\\n'.join(template_list) + self.template_required  + \"\\n<<< end input \\n\" + \\\n",
    "                        self.template_variable_independent + begin_indicator\n",
    "        prompt = template.format(**kwargs)\n",
    "        return prompt\n",
    "\n",
    "template_optional_dict = {\n",
    "\n",
    "    'role': \"You are a {role}\",\n",
    "    # 'project_name': \"You are working on a project called: {project_name}\\n\",\n",
    "    # 'project_goals': \"You are part of a team working to: {project_goals}\\n\",\n",
    "    'present_task_description': \"You are helping to: {present_task_description}\\n\",\n",
    "    'file_name': \"You are helping to rewrite and expand a file called {file_name}\\n\",\n",
    "    'structure_pattern': \"Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\",\n",
    "    'tree_structure': \"The present tree-structure:\\n {tree_structure}\\n \",\n",
    "    'markdown_text': \"Markdown input \\n>>>\\n{markdown_text}\"\n",
    "}\n",
    "\n",
    "\n",
    "template_variable_independent = \\\n",
    "\"\"\"\n",
    "Things to keep in mind:\n",
    "* present ALL html links without changing the link's text.\n",
    "* Preserve any urls or relative links without changing them. \n",
    "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
    "* keep ALL images `<img ...></img>` that are referenced in any manner.  \n",
    "* Keep all code blocks that are referenced in any manner.\n",
    "* Please be sure to keep any admonitions like `!!!` and `???`.\n",
    "* Be as honest and as accurate as possible. \n",
    "* Be succinct in your responses. \n",
    "* Keep the ORIGINAL VOICE of the author there, and avoid unecessary changes to headings and subheadings. \n",
    "* If text is sparse or missing create a reasonable outline and follow it. \n",
    "* If you see MANAGEN (<and execute requests in trailing parenthesis>) then please evolve and expand upon the text in that area. \n",
    "* If you see any MANAGEN requests to make a mermaid diagram, please do so using the information that was provided.\n",
    "* PRESERVE ALL STRUCTURED ADMONITIONS and following (that start with e.g. `!!!` and `???`) and DO NOT CHANGE THEM INTO BULLETS. Those need to be preserved.\n",
    "* We'll get $1000 if we do this right, so let's do our best!\n",
    "\"\"\"\n",
    "# Please, do follow these instructions closely for it if we don't get this right, we might lose our job. \n",
    "# * reformat any bulleted lists of links where github links have `!!! code`, arxiv's have `!!! tip` and others have `!!! information`. \n",
    "# * Please be sure to keep any amonitions like `!!!` and `???`.\n",
    "template_required = \\\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "spt = SmartPromptTemplate(template_required=template_required, \n",
    "template_optional_dict=template_optional_dict, \n",
    "template_variable_independent=template_variable_independent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfcaa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Create an automated repository that is able to explain Generative AI \"\\\n",
    "        \"and how to improve upon it in plain-English and how to enable it from idea to product, as well as new and interesting research. \"\\\n",
    "                \n",
    "present_task_description=\"Improve the markdown based on best understandings.\"\n",
    "                         \n",
    "# file_from_base_dir = 'Using/deploying/index.md'\n",
    "# file_from_base_dir = 'Using/deploying/libraries_and_tools.md'\n",
    "file_from_base_dir = 'Understanding/data/simulation.md'\n",
    "file_from_base_dir = 'Using/index.md'\n",
    "# file_from_base_dir = 'Understanding/architectures/optimization.md'\n",
    "# file_from_base_dir = 'Understanding/architectures/rlhf.md'\n",
    "# file_from_base_dir = 'Understanding/agents/rag.md'\n",
    "# file_from_base_dir = 'Understanding/Overview/index.md'\n",
    "# file_from_base_dir = 'Understanding/architectures/feedback.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt = spt.get_prompt(role=role, \n",
    "    project_name=project_name,\n",
    "    project_goals=project_goals,\n",
    "    present_task_description=present_task_description,\n",
    "    file_name=file_name,\n",
    "#     tree_structure=tree_structure,\n",
    "    markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c52c69f5-576b-49b6-b902-d6773140bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a expert AI technology creator and communicator\n",
      "You are helping to: Improve the markdown based on best understandings.\n",
      "\n",
      "You are helping to rewrite and expand a file called ../../docs/Using/index.md\n",
      "\n",
      "Markdown input \n",
      ">>>\n",
      "Managing The GenAI amounts to effectively successfully working with the evolving technology in such a way that it creates.\n",
      "\n",
      "## Strategies for using Gen()AI.\n",
      "\n",
      "There ar a number of strategic pproaches to consider when considering the adaption of Gen()AI, but we consider primarily two manners. Task-focused, and solution-focused. While not mutually exclusive, depending on the culture of your company, it may be useful to prefer one over the other. \n",
      "\n",
      "### Task-focused approach\n",
      "\n",
      "What could be called a task-focused approach, \n",
      "\n",
      "1. Consider the jobs of the company’s employees and contractors, break down the jobs into individual [tasks](examples/by_modality/index.md).\n",
      "1. Examine the tasks individually and as a whole to see if it’s amenable to either AI assistance (augmentation) or AI automation with tools such as supervised learning or generative AI.\n",
      "1. Estimate the value of automating that task, as in how much time or resources might be saved, and the [ethics](ethically/index.md) of doing so.\n",
      "1. Determine the whther it is better to [build, or buy](building_and_buying.md) and costs of automating the tasks.\n",
      "1. Be ready to [govern] ()\n",
      "\n",
      "This can certainly be expanded into to greater actions to be taken, it is important to include prioritization of the jobs that are most valuable not only to the employer, but the employees. There many be some automatable tasks that may be better for everyone if they were remained under a person's control. This can be taken on a roll-by-roll basis based on the roll's cost to the company and the value that it provides. \n",
      "\n",
      "### Solution-focused approach. \n",
      "\n",
      "1. Ask your teams what they would like to have enabled with GenAI, especially considering different[examples](examples/index.md).\n",
      "1. Understand common use-cases that are needed from your various employees and teams.\n",
      "1. Identify whether you want to [build, or buy](building_and_buying.md)\n",
      "1. Ensure your efforts do not bend important [ethical](ethically/index.md) considerations of using GenAI. \n",
      "1. Be ready to [manage](managing/index.md)\n",
      "1. [Mark your, and detect others'](marking_and_detecting.md) AI-generated content.\n",
      "\n",
      "<<< end input \n",
      "\n",
      "Things to keep in mind:\n",
      "* present ALL html links without changing the link's text.\n",
      "* Preserve any urls or relative links without changing them. \n",
      "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
      "* keep ALL images `<img ...></img>` that are referenced in any manner.  \n",
      "* Keep all code blocks that are referenced in any manner.\n",
      "* Please be sure to keep any admonitions like `!!!` and `???`.\n",
      "* Be as honest and as accurate as possible. \n",
      "* Be succinct in your responses. \n",
      "* Keep the ORIGINAL VOICE of the author there, and avoid unecessary changes to headings and subheadings. \n",
      "* If text is sparse or missing create a reasonable outline and follow it. \n",
      "* If you see MANAGEN (<and execute requests in trailing parenthesis>) then please evolve and expand upon the text in that area. \n",
      "* If you see any MANAGEN requests to make a mermaid diagram, please do so using the information that was provided.\n",
      "* PRESERVE ALL STRUCTURED ADMONITIONS and following (that start with e.g. `!!!` and `???`) and DO NOT CHANGE THEM INTO BULLETS. Those need to be preserved.\n",
      "* We'll get $1000 if we do this right, so let's do our best!\n",
      "\n",
      " What would you write given the requests above? \n",
      ">>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b43d135-414a-4b9b-b109-7b69eb24b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8cefc40-c915-4369-a54a-38d18aad72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../docs/Using/index_temp0.md'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write the file to disk with a _temp suffix and then open it with a system call to tkdiff to visualize the two\n",
    "# files side by side.\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import webbrowser\n",
    "\n",
    "def write_to_file(file_name, text):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(text)\n",
    "    return file_name\n",
    "\n",
    "# Please be sure to run `homebrew install tkdiff` or otherwise install tkdiff on your computer\n",
    "def open_with_tkdiff(file_name1, file_name2):\n",
    "    subprocess.run(['tkdiff', file_name1, file_name2])\n",
    "\n",
    "def make_name(file_name):\n",
    "    base, ext = os.path.splitext(file_name)\n",
    "    temp_name = base + '_temp0' + ext\n",
    "    #check to see if it exists and if so, make a new name with a _temp# where # is the next available number\n",
    "    count=0\n",
    "    while os.path.exists(temp_name):\n",
    "        count += 1\n",
    "        \n",
    "        temp_name = base + f'_temp{count}' + ext\n",
    "    return temp_name\n",
    "temp_name = make_name(file_name)\n",
    "write_to_file(temp_name, markdown_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "open_with_tkdiff(file_name, temp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../../docs/Using/index.md has been updated.\n"
     ]
    }
   ],
   "source": [
    "input_answer = input(\"Is the output correct Yes/no/deletefile? (y/n/d)\")\n",
    "## if the answer is y then move the temp-name to the original file name and delete the temp file\n",
    "if input_answer == 'y':\n",
    "    os.rename(temp_name, file_name)\n",
    "    print(f\"File {file_name} has been updated.\")\n",
    "else:\n",
    "    print(f\"File {file_name} has not been updated.\")\n",
    "    # if the answer is n then delete the temp file and do nothing\n",
    "    if input_answer == 'd':\n",
    "        os.remove(temp_name)\n",
    "        print(f\"File {temp_name} has been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOT THAT LOOKS AT DIFFERENCES CHHUNK BY CHUNK AND AMENDS THEM. \n",
    "CREATE DIFF, ITERATE ON DIFF AND UPDATE MODIFIED DOCUMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
