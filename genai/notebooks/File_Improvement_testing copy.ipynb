{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1851ef27-17a2-42ac-ba6a-e9b5fb6bb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6335ae2-c900-437a-b731-d0226558f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:248: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ianderrington/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:1057: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "# initialize the models\n",
    "\n",
    "models = ['gpt-3.5-turbo-16k', 'gpt-4','gpt-4-1106-preview',\"text-davinci-003\"]\n",
    "model = models[1]\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=model,\n",
    "    # openai_api_key= os.environ[\"OPENAI_API_KEY\"]\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b915662-678f-40b3-ba10-710432d1c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCS_DIR = '../../docs/'\n",
    "# file_name = dosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae838ef5-36a1-4095-8982-28dc6f119812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/\n",
      "â”œâ”€â”€ index.md\n",
      "â”œâ”€â”€ javascripts/\n",
      "â”‚   â””â”€â”€ mathjax.js\n",
      "â”œâ”€â”€ Managenai/\n",
      "â”‚   â”œâ”€â”€ brainstorming.md\n",
      "â”‚   â”œâ”€â”€ build_plan.md\n",
      "â”‚   â”œâ”€â”€ contributing.md\n",
      "â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”œâ”€â”€ managing.md\n",
      "â”‚   â”œâ”€â”€ requirements.md\n",
      "â”‚   â””â”€â”€ site_graph.md\n",
      "â”œâ”€â”€ Understand/\n",
      "â”‚   â”œâ”€â”€ agents/\n",
      "â”‚   â”‚   â”œâ”€â”€ actions_and_tools.md\n",
      "â”‚   â”‚   â”œâ”€â”€ cognitive_architecture.md\n",
      "â”‚   â”‚   â”œâ”€â”€ cognitive_architecture.md\n",
      "â”‚   â”‚   â”œâ”€â”€ environments.md\n",
      "â”‚   â”‚   â”œâ”€â”€ evaluating_and_comparing.md\n",
      "â”‚   â”‚   â”œâ”€â”€ examples.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ memory.md\n",
      "â”‚   â”‚   â”œâ”€â”€ rag.md\n",
      "â”‚   â”‚   â””â”€â”€ systems.md\n",
      "â”‚   â”œâ”€â”€ architectures/\n",
      "â”‚   â”‚   â”œâ”€â”€ evaluating_and_comparing.md\n",
      "â”‚   â”‚   â”œâ”€â”€ finetuning.md\n",
      "â”‚   â”‚   â”œâ”€â”€ generation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ llm_systems.md\n",
      "â”‚   â”‚   â”œâ”€â”€ models/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ components.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ developing_architectures.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ diffusers.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ gans.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid_models.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ reinforcement_learning.md\n",
      "â”‚   â”‚   â”‚   â””â”€â”€ transformers.md\n",
      "â”‚   â”‚   â”œâ”€â”€ optimization.md\n",
      "â”‚   â”‚   â”œâ”€â”€ pre-training.md\n",
      "â”‚   â”‚   â”œâ”€â”€ pre_trained_models.md\n",
      "â”‚   â”‚   â”œâ”€â”€ recurrent_training.md\n",
      "â”‚   â”‚   â”œâ”€â”€ rl_feedback.md\n",
      "â”‚   â”‚   â””â”€â”€ training.md\n",
      "â”‚   â”œâ”€â”€ background/\n",
      "â”‚   â”‚   â””â”€â”€ tensor_maths.md\n",
      "â”‚   â”œâ”€â”€ data/\n",
      "â”‚   â”‚   â”œâ”€â”€ augmentation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ distillation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ privacy.md\n",
      "â”‚   â”‚   â”œâ”€â”€ selection.md\n",
      "â”‚   â”‚   â”œâ”€â”€ simulation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ sources.md\n",
      "â”‚   â”‚   â””â”€â”€ tokenizing.md\n",
      "â”‚   â”œâ”€â”€ deploying/\n",
      "â”‚   â”‚   â”œâ”€â”€ back_end.md\n",
      "â”‚   â”‚   â”œâ”€â”€ commercial_products.md\n",
      "â”‚   â”‚   â”œâ”€â”€ computation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ examples_and_tutorials.md\n",
      "â”‚   â”‚   â”œâ”€â”€ frameworks.md\n",
      "â”‚   â”‚   â”œâ”€â”€ front_end.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â””â”€â”€ libraries_and_tools.md\n",
      "â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”œâ”€â”€ overview/\n",
      "â”‚   â”‚   â”œâ”€â”€ ai_and_ml_basics/\n",
      "â”‚   â”‚   â”‚   â””â”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ challenges.md\n",
      "â”‚   â”‚   â”œâ”€â”€ chronology.md\n",
      "â”‚   â”‚   â”œâ”€â”€ extra_resources.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ open_source.md\n",
      "â”‚   â”‚   â””â”€â”€ use_cases.md\n",
      "â”‚   â”œâ”€â”€ prompting/\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â””â”€â”€ prompt_injections.md\n",
      "â”‚   â””â”€â”€ studies/\n",
      "â”‚       â”œâ”€â”€ behavior.md\n",
      "â”‚       â””â”€â”€ studies.md\n",
      "â””â”€â”€ Use/\n",
      "    â”œâ”€â”€ building_and_buying.md\n",
      "    â”œâ”€â”€ de-risking/\n",
      "    â”‚   â”œâ”€â”€ redteaming.md\n",
      "    â”‚   â””â”€â”€ security.md\n",
      "    â”œâ”€â”€ ethically/\n",
      "    â”‚   â”œâ”€â”€ alignment.md\n",
      "    â”‚   â”œâ”€â”€ alignment_and_exestential_concerns.md\n",
      "    â”‚   â”œâ”€â”€ dual_use_concerns.md\n",
      "    â”‚   â”œâ”€â”€ fairness.md\n",
      "    â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â””â”€â”€ transparency.md\n",
      "    â”œâ”€â”€ examples/\n",
      "    â”‚   â”œâ”€â”€ by_field/\n",
      "    â”‚   â”‚   â”œâ”€â”€ business.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ entertainment/\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ dynamic.md\n",
      "    â”‚   â”‚   â”‚   â””â”€â”€ static.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ mathematics.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ science/\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ biology.md\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ chemistry.md\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ healthcare.md\n",
      "    â”‚   â”‚   â”‚   â””â”€â”€ index.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ social/\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ education.md\n",
      "    â”‚   â”‚   â”‚   â””â”€â”€ law.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ socio_societal.md\n",
      "    â”‚   â”‚   â””â”€â”€ technology/\n",
      "    â”‚   â”‚       â”œâ”€â”€ coding.md\n",
      "    â”‚   â”‚       â”œâ”€â”€ finance.md\n",
      "    â”‚   â”‚       â”œâ”€â”€ healthcare.md\n",
      "    â”‚   â”‚       â””â”€â”€ robotics.md\n",
      "    â”‚   â”œâ”€â”€ by_modality/\n",
      "    â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ knowledge_graphs.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ multimodal.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ sound.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ static_2d.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ tabular.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ text.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ time_series.md\n",
      "    â”‚   â”‚   â””â”€â”€ video.md\n",
      "    â”‚   â””â”€â”€ index.md\n",
      "    â”œâ”€â”€ index.md\n",
      "    â”œâ”€â”€ interfacing_layers/\n",
      "    â”‚   â””â”€â”€ web_plugins.md\n",
      "    â”œâ”€â”€ managing/\n",
      "    â”‚   â”œâ”€â”€ governing.md\n",
      "    â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â”œâ”€â”€ ml_ops.md\n",
      "    â”‚   â”œâ”€â”€ observability.md\n",
      "    â”‚   â””â”€â”€ regulations_and_guidelines.md\n",
      "    â””â”€â”€ marking_and_detecting.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = 'â”œâ”€â”€'\n",
    "    display_filename_prefix_last = 'â””â”€â”€'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = 'â”‚   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "\n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))\n",
    "\n",
    "# With a criteria (skip hidden files)\n",
    "def is_not_hidden(path):\n",
    "    return  not ( 'Icon' in path.name or '.DS_Store' in path.name or 'stylesheets'  in path.name or \\\n",
    "        'CNAME' in path.name or 'assets' in path.name or '.svg' in path.name or '.pages' in path.name)\n",
    "    \n",
    "# paths = DisplayablePath.make_tree(\n",
    "#     Path(base_docs_dir),\n",
    "#     criteria=is_not_hidden\n",
    "# )\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "\n",
    "\n",
    "# paths = DisplayablePath.make_tree(Path(base_docs_dir), criteria=is_not_hidden)\n",
    "# for path in paths:\n",
    "#     print(path.displayable())\n",
    "\n",
    "def get_tree_structure(path_base=BASE_DOCS_DIR):\n",
    "    \n",
    "    paths = DisplayablePath.make_tree(Path(path_base), criteria=is_not_hidden)\n",
    "    path_str = [p.displayable() for p in paths]\n",
    "    # for path in paths:\n",
    "    #     print(path.displayable())\n",
    "    # return ''.join([p for p in path.displayable()])\n",
    "    return '\\n'.join(path_str)\n",
    "    \n",
    "tree_structure = get_tree_structure()\n",
    "print(tree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17fe1f87-8ecc-49c0-aa96-399775ac8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path, base_dir=BASE_DOCS_DIR):\n",
    "    # iterator for getting filenames\n",
    "    return os.path.join(base_dir, file_path)\n",
    "\n",
    "def get_structure_pattern():\n",
    "    pattern = \\\n",
    "    \"\"\"\n",
    "    <<intro>>\n",
    "    ## <<First topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## <<Second topic>>\n",
    "    ### <<topic sub component>>\n",
    "    ### ...\n",
    "    ## ...\n",
    "    ## Essential References\n",
    "    << List with '-' of references with each reference providing written as [link_title](link_address) and a thoughtful but succinct output>>\n",
    "    \"\"\"\n",
    "    return pattern\n",
    "\n",
    "\n",
    "def get_markdown_text(markdown_file):\n",
    "    with open(markdown_file, 'r') as f:\n",
    "        markdown_text = f.read()\n",
    "    # print(markdown_text)\n",
    "    return markdown_text\n",
    "# Could potentially do this is in few-shot prompt templates\n",
    "# These should be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426a3057-f92c-42dc-bba2-1555943a7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Improve the markdown based on best understandings.\\n\"\\\n",
    "                         \"Be as honest and as accurate as possible. Be succinct in your responses. \"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "# Idea\n",
    "# Select between prompt patterns\n",
    "# Chain select them more effectively. \n",
    "# The present tree-structure:\\n {tree_structure}\\n \n",
    "# Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\n",
    "template = \\\n",
    "\"\"\" \n",
    "You are a {role}\n",
    "You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "You are helping to rewrite and expand a file called {file_name} \n",
    "Here are some things we'd like you to be sure to do:\n",
    "* Please present ALL html links without changing the link's text. \n",
    "* Preserve any urls or relative links without changing them. \n",
    "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
    "* Please be sure to keep any amonitions like `!!!` and `???`.\n",
    "* Please reformat any bulleted lists of links where github links have `!!! code`, arxiv's have `!!! tip` and others have `!!! information`. \n",
    "\n",
    "After the markdown When the text is presented (after >>>), please improve upon it. \n",
    "If text is sparse or missing create a reasonable outline following the pattern above and fill it in.\n",
    "\n",
    "Markdown Input:\\n\n",
    ">>>\\n\n",
    "{markdown_text}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    # input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"structure_pattern\", \"markdown_text\", ],\n",
    "        input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\",  \"markdown_text\", ],\n",
    "    template=template\n",
    ")\n",
    "file_from_base_dir = 'Use/deploying/index.md'\n",
    "file_from_base_dir = 'Use/redteaming.md'\n",
    "file_from_base_dir = 'Understand/agents/rag.md'\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt=prompt_template.format(role=role,\n",
    "                              project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       file_name=file_name,\n",
    "                       # tree_structure=tree_structure,\n",
    "                       #  structure_pattern=structure_pattern,\n",
    "                       markdown_text=markdown_text,)\n",
    "# The above is very verboase especially as it requires a lot of repeated typing of the same variables.\n",
    "# It also needs to work for variables that are only specified in the template. If they are not specified in the template, then they should be ignored.\n",
    "# There will a list of template lines that are appended to create the final prompt.\n",
    "# The template lines will be specified as a list of dictionaries.\n",
    "#  \n",
    "# Let's write this as a class\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  write above but realizing template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0241f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartPromptTemplate:\n",
    "    def __init__(self, template_required, template_optional_dict, template_variable_independent):\n",
    "        self.template_required = template_required if template_required is not None else \"\"\n",
    "        self.template_optional_dict = template_optional_dict if template_optional_dict is not None else {}\n",
    "        self.template_variable_independent = template_variable_independent if template_variable_independent is not None else \"\"\n",
    "    \n",
    "    def get_prompt(self, **kwargs):\n",
    "        template_list = []\n",
    "        for k, v in kwargs.items():\n",
    "            if k in self.template_optional_dict.keys():\n",
    "                template_list.append(self.template_optional_dict[k])\n",
    "        begin_indicator = \"\\n What would you write given the requests above? \\n>>>\\n\"\n",
    "        \n",
    "        template =   '\\n'.join(template_list) + self.template_required  + \"\\n<<< end input \\n\" + \\\n",
    "                        self.template_variable_independent + begin_indicator\n",
    "        prompt = template.format(**kwargs)\n",
    "        return prompt\n",
    "\n",
    "template_optional_dict = {\n",
    "\n",
    "    'role': \"You are a {role}\",\n",
    "    # 'project_name': \"You are working on a project called: {project_name}\\n\",\n",
    "    # 'project_goals': \"You are part of a team working to: {project_goals}\\n\",\n",
    "    'present_task_description': \"You are helping to: {present_task_description}\\n\",\n",
    "    'file_name': \"You are helping to rewrite and expand a file called {file_name}\\n\",\n",
    "    'structure_pattern': \"Please use a heading/subheading structure that follows the general pattern : {structure_pattern}\\n\",\n",
    "    'tree_structure': \"The present tree-structure:\\n {tree_structure}\\n \",\n",
    "    'markdown_text': \"Markdown input \\n>>>\\n{markdown_text}\"\n",
    "}\n",
    "\n",
    "\n",
    "template_variable_independent = \\\n",
    "\"\"\"\n",
    "Things to keep in mind:\n",
    "* present ALL html links without changing the link's text.\n",
    "* Preserve any urls or relative links without changing them. \n",
    "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
    "* keep ALL images `<img ...></img>` that are referenced in any manner.  \n",
    "* Keep all code blocks that are referenced in any manner.\n",
    "* Please be sure to keep any admonitions like `!!!` and `???`.\n",
    "* Be as honest and as accurate as possible. \n",
    "* Be succinct in your responses. \n",
    "* Keep the ORIGINAL VOICE of the author there, and avoid unecessary changes to headings and subheadings. \n",
    "* If text is sparse or missing create a reasonable outline and follow it. \n",
    "* If you see MANAGEN (<and execute requests in trailing parenthesis>) then please evolve and expand upon the text in that area. \n",
    "* If you see any MANAGEN requests to make a mermaid diagram, please do so using the information that was provided.\n",
    "* PRESERVE ALL STRUCTURED ADMONITIONS and following (that start with e.g. `!!!` and `???`) and DO NOT CHANGE THEM INTO BULLETS. Those need to be preserved.\n",
    "* Please expand areas or suggest expansion into areas that are sparse.\n",
    "* Do not add 'conclusion' section at the end. \n",
    "* We'll get $1000 if we do this right, so let's do our best!\n",
    "\"\"\"\n",
    "# Please, do follow these instructions closely for it if we don't get this right, we might lose our job. \n",
    "# * reformat any bulleted lists of links where github links have `!!! code`, arxiv's have `!!! tip` and others have `!!! information`. \n",
    "# * Please be sure to keep any amonitions like `!!!` and `???`.\n",
    "template_required = \\\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "spt = SmartPromptTemplate(template_required=template_required, \n",
    "template_optional_dict=template_optional_dict, \n",
    "template_variable_independent=template_variable_independent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcaa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Create an automated repository that is able to explain Generative AI \"\\\n",
    "        \"and how to improve upon it in plain-English and how to enable it from idea to product, as well as new and interesting research. \"\\\n",
    "                \n",
    "present_task_description=\"Improve the markdown based on best understandings.\"\n",
    "                         \n",
    "# file_from_base_dir = 'Use/deploying/index.md'\n",
    "# file_from_base_dir = 'Use/deploying/libraries_and_tools.md'\n",
    "file_from_base_dir = 'Understand/overview/use_cases.md'\n",
    "\n",
    "file_name=get_file_name(file_from_base_dir)\n",
    "tree_structure=get_tree_structure()\n",
    "markdown_text=get_markdown_text(file_name)\n",
    "structure_pattern = get_structure_pattern()\n",
    "prompt = spt.get_prompt(role=role, \n",
    "    project_name=project_name,\n",
    "    project_goals=project_goals,\n",
    "    present_task_description=present_task_description,\n",
    "    file_name=file_name,\n",
    "    tree_structure=tree_structure,\n",
    "    markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52c69f5-576b-49b6-b902-d6773140bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a expert AI technology creator and communicator\n",
      "You are helping to: Improve the markdown based on best understandings.\n",
      "\n",
      "You are helping to rewrite and expand a file called ../../docs/Understanding/overview/use_cases.md\n",
      "\n",
      "The present tree-structure:\n",
      " docs/\n",
      "â”œâ”€â”€ index.md\n",
      "â”œâ”€â”€ javascripts/\n",
      "â”‚   â””â”€â”€ mathjax.js\n",
      "â”œâ”€â”€ Managenai/\n",
      "â”‚   â”œâ”€â”€ brainstorming.md\n",
      "â”‚   â”œâ”€â”€ build_plan.md\n",
      "â”‚   â”œâ”€â”€ contributing.md\n",
      "â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”œâ”€â”€ managing.md\n",
      "â”‚   â”œâ”€â”€ requirements.md\n",
      "â”‚   â””â”€â”€ site_graph.md\n",
      "â”œâ”€â”€ Understand/\n",
      "â”‚   â”œâ”€â”€ agents/\n",
      "â”‚   â”‚   â”œâ”€â”€ actions_and_tools.md\n",
      "â”‚   â”‚   â”œâ”€â”€ cognitive_architecture.md\n",
      "â”‚   â”‚   â”œâ”€â”€ cognitive_architecture.md\n",
      "â”‚   â”‚   â”œâ”€â”€ environments.md\n",
      "â”‚   â”‚   â”œâ”€â”€ evaluating_and_comparing.md\n",
      "â”‚   â”‚   â”œâ”€â”€ examples.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ memory.md\n",
      "â”‚   â”‚   â”œâ”€â”€ rag.md\n",
      "â”‚   â”‚   â””â”€â”€ systems.md\n",
      "â”‚   â”œâ”€â”€ architectures/\n",
      "â”‚   â”‚   â”œâ”€â”€ evaluating_and_comparing.md\n",
      "â”‚   â”‚   â”œâ”€â”€ finetuning.md\n",
      "â”‚   â”‚   â”œâ”€â”€ generation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ llm_systems.md\n",
      "â”‚   â”‚   â”œâ”€â”€ models/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ components.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ developing_architectures.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ diffusers.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ gans.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid_models.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ reinforcement_learning.md\n",
      "â”‚   â”‚   â”‚   â””â”€â”€ transformers.md\n",
      "â”‚   â”‚   â”œâ”€â”€ optimization.md\n",
      "â”‚   â”‚   â”œâ”€â”€ pre-training.md\n",
      "â”‚   â”‚   â”œâ”€â”€ pre_trained_models.md\n",
      "â”‚   â”‚   â”œâ”€â”€ recurrent_training.md\n",
      "â”‚   â”‚   â”œâ”€â”€ rl_feedback.md\n",
      "â”‚   â”‚   â””â”€â”€ training.md\n",
      "â”‚   â”œâ”€â”€ background/\n",
      "â”‚   â”‚   â””â”€â”€ tensor_maths.md\n",
      "â”‚   â”œâ”€â”€ data/\n",
      "â”‚   â”‚   â”œâ”€â”€ augmentation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ distillation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ privacy.md\n",
      "â”‚   â”‚   â”œâ”€â”€ selection.md\n",
      "â”‚   â”‚   â”œâ”€â”€ simulation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ sources.md\n",
      "â”‚   â”‚   â””â”€â”€ tokenizing.md\n",
      "â”‚   â”œâ”€â”€ deploying/\n",
      "â”‚   â”‚   â”œâ”€â”€ back_end.md\n",
      "â”‚   â”‚   â”œâ”€â”€ commercial_products.md\n",
      "â”‚   â”‚   â”œâ”€â”€ computation.md\n",
      "â”‚   â”‚   â”œâ”€â”€ examples_and_tutorials.md\n",
      "â”‚   â”‚   â”œâ”€â”€ frameworks.md\n",
      "â”‚   â”‚   â”œâ”€â”€ front_end.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â””â”€â”€ libraries_and_tools.md\n",
      "â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”œâ”€â”€ overview/\n",
      "â”‚   â”‚   â”œâ”€â”€ ai_and_ml_basics/\n",
      "â”‚   â”‚   â”‚   â””â”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ challenges.md\n",
      "â”‚   â”‚   â”œâ”€â”€ chronology.md\n",
      "â”‚   â”‚   â”œâ”€â”€ extra_resources.md\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â”œâ”€â”€ open_source.md\n",
      "â”‚   â”‚   â””â”€â”€ use_cases.md\n",
      "â”‚   â”œâ”€â”€ prompting/\n",
      "â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "â”‚   â”‚   â””â”€â”€ prompt_injections.md\n",
      "â”‚   â””â”€â”€ studies/\n",
      "â”‚       â”œâ”€â”€ behavior.md\n",
      "â”‚       â””â”€â”€ studies.md\n",
      "â””â”€â”€ Use/\n",
      "    â”œâ”€â”€ building_and_buying.md\n",
      "    â”œâ”€â”€ de-risking/\n",
      "    â”‚   â”œâ”€â”€ redteaming.md\n",
      "    â”‚   â””â”€â”€ security.md\n",
      "    â”œâ”€â”€ ethically/\n",
      "    â”‚   â”œâ”€â”€ alignment.md\n",
      "    â”‚   â”œâ”€â”€ alignment_and_exestential_concerns.md\n",
      "    â”‚   â”œâ”€â”€ dual_use_concerns.md\n",
      "    â”‚   â”œâ”€â”€ fairness.md\n",
      "    â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â””â”€â”€ transparency.md\n",
      "    â”œâ”€â”€ examples/\n",
      "    â”‚   â”œâ”€â”€ by_field/\n",
      "    â”‚   â”‚   â”œâ”€â”€ business.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ entertainment/\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ dynamic.md\n",
      "    â”‚   â”‚   â”‚   â””â”€â”€ static.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ mathematics.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ science/\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ biology.md\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ chemistry.md\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ healthcare.md\n",
      "    â”‚   â”‚   â”‚   â””â”€â”€ index.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ social/\n",
      "    â”‚   â”‚   â”‚   â”œâ”€â”€ education.md\n",
      "    â”‚   â”‚   â”‚   â””â”€â”€ law.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ socio_societal.md\n",
      "    â”‚   â”‚   â””â”€â”€ technology/\n",
      "    â”‚   â”‚       â”œâ”€â”€ coding.md\n",
      "    â”‚   â”‚       â”œâ”€â”€ finance.md\n",
      "    â”‚   â”‚       â”œâ”€â”€ healthcare.md\n",
      "    â”‚   â”‚       â””â”€â”€ robotics.md\n",
      "    â”‚   â”œâ”€â”€ by_modality/\n",
      "    â”‚   â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ knowledge_graphs.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ multimodal.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ sound.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ static_2d.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ tabular.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ text.md\n",
      "    â”‚   â”‚   â”œâ”€â”€ time_series.md\n",
      "    â”‚   â”‚   â””â”€â”€ video.md\n",
      "    â”‚   â””â”€â”€ index.md\n",
      "    â”œâ”€â”€ index.md\n",
      "    â”œâ”€â”€ interfacing_layers/\n",
      "    â”‚   â””â”€â”€ web_plugins.md\n",
      "    â”œâ”€â”€ managing/\n",
      "    â”‚   â”œâ”€â”€ governing.md\n",
      "    â”‚   â”œâ”€â”€ index.md\n",
      "    â”‚   â”œâ”€â”€ ml_ops.md\n",
      "    â”‚   â”œâ”€â”€ observability.md\n",
      "    â”‚   â””â”€â”€ regulations_and_guidelines.md\n",
      "    â””â”€â”€ marking_and_detecting.md\n",
      " \n",
      "Markdown input \n",
      ">>>\n",
      "We explores different activities and fields that utilize Generative AI's capabilities and provide a few notable references for each. For an overview of applications (and challenges), we highly recommend [Challenges and Applications of Large Language Models](https://arxiv.org/pdf/2307.10169.pdf)\n",
      "\n",
      "\n",
      "There is a philosophical overlap with 'predictive' AI where a predictive model could just be said to 'generate' either possible future outcomes or estimated classifications of data.\n",
      "\n",
      "There are many generally distinct domains of Gen()AI application, though many be compositional. Effectively any information that can be recorded onto a computer may be made by Gen()AI.\n",
      "\n",
      "## General Modalities\n",
      "\n",
      "MANAGEN: Make this into a table, and expand it. \n",
      "\n",
      "* Language: Spoken and Written\n",
      "* Time series: Music, speech, finances, \n",
      "* Visual 2D, Images, Diagrams\n",
      "* Visual 3D\n",
      "* Visual 2D with time\n",
      "* Visual 3D with time\n",
      "* Graphical (Relation and influence networks)\n",
      "* Generally linear sequences (Genome, Proteome)\n",
      "* Multidimensional Temporal sequences (weather, brain recordings, stock market)\n",
      "* Multimodal variants of the above methods. \n",
      "\n",
      "We describe these more fully in [this section](../../Using/examples/by_modality/index.md)\n",
      "\n",
      "## General Activities\n",
      "Based on the modalities, there are many ways in which Gen()AI can be utilized. Often, it will depend on the domain, and \n",
      "\n",
      "There are many activities that can be used in many, if not all, fields of applications. We mention a few below:\n",
      "\n",
      "### Converting information: Generating content in one domain with input from another. \n",
      "\n",
      "Because language is a common method of understanding and communicating the world around, language is often used to generate content in different domains, such as images, movies, and music. Domain mapping can also go the other way around: taking an input image and generating a description or caption regarding the image. Similarly, \n",
      "\n",
      "### Compactifying information: Summarization and compression.\n",
      "\n",
      "Summarization is a key application for Generative AI. It uses the technology to provide brief, accurate summaries of a larger body of text.\n",
      "\n",
      "### Classification and prediction with information\n",
      "\n",
      "While often the domain of traditional AI/ML, classification and predictions can be created with Gen()AI. For instance, GenAI can take an input sentence and predicting the _sentiment_ within it (like positive or negative), or similarly, it can be used to estimate the \n",
      "\n",
      "While not necessarily as accurate or efficient as smaller, finely tuned models, GenAI, can allow for greater versatility in allowing multiple classifications or predictions to be made. With additional supervised training, however, these methods can be improved. \n",
      "\n",
      "### Finding information: Search\n",
      "\n",
      "Generative AI has the capability to understand relationships between words and concepts. By embedding an input, the technology can measure semantic, or 'meaning', nearness via distance calculations. This capability enhances the potential for memory recall with imperfect inputs and improves action routing.\n",
      "\n",
      "MANAGEN What else should be included in terms of fundmaental interactions with Information: \n",
      "Convert, Compact, Classify, Find... \n",
      "\n",
      "<<< end input \n",
      "\n",
      "Things to keep in mind:\n",
      "* present ALL html links without changing the link's text.\n",
      "* Preserve any urls or relative links without changing them. \n",
      "* Be sure to use `##` `###` subheadings and appropriately to reference sections and subsections.\n",
      "* keep ALL images `<img ...></img>` that are referenced in any manner.  \n",
      "* Keep all code blocks that are referenced in any manner.\n",
      "* Please be sure to keep any admonitions like `!!!` and `???`.\n",
      "* Be as honest and as accurate as possible. \n",
      "* Be succinct in your responses. \n",
      "* Keep the ORIGINAL VOICE of the author there, and avoid unecessary changes to headings and subheadings. \n",
      "* If text is sparse or missing create a reasonable outline and follow it. \n",
      "* If you see MANAGEN (<and execute requests in trailing parenthesis>) then please evolve and expand upon the text in that area. \n",
      "* If you see any MANAGEN requests to make a mermaid diagram, please do so using the information that was provided.\n",
      "* PRESERVE ALL STRUCTURED ADMONITIONS and following (that start with e.g. `!!!` and `???`) and DO NOT CHANGE THEM INTO BULLETS. Those need to be preserved.\n",
      "* Please expand areas or suggest expansion into areas that are sparse.\n",
      "* Do not add 'conclusion' section at the end. \n",
      "* We'll get $1000 if we do this right, so let's do our best!\n",
      "\n",
      " What would you write given the requests above? \n",
      ">>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b43d135-414a-4b9b-b109-7b69eb24b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8cefc40-c915-4369-a54a-38d18aad72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../docs/Understanding/overview/use_cases_temp0.md'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write the file to disk with a _temp suffix and then open it with a system call to tkdiff to visualize the two\n",
    "# files side by side.\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import webbrowser\n",
    "\n",
    "def write_to_file(file_name, text):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(text)\n",
    "    return file_name\n",
    "\n",
    "# Please be sure to run `homebrew install tkdiff` or otherwise install tkdiff on your computer\n",
    "def open_with_tkdiff(file_name1, file_name2):\n",
    "    subprocess.run(['tkdiff', file_name1, file_name2])\n",
    "\n",
    "def make_name(file_name):\n",
    "    base, ext = os.path.splitext(file_name)\n",
    "    temp_name = base + '_temp0' + ext\n",
    "    #check to see if it exists and if so, make a new name with a _temp# where # is the next available number\n",
    "    count=0\n",
    "    while os.path.exists(temp_name):\n",
    "        count += 1\n",
    "        \n",
    "        temp_name = base + f'_temp{count}' + ext\n",
    "    return temp_name\n",
    "temp_name = make_name(file_name)\n",
    "write_to_file(temp_name, markdown_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "open_with_tkdiff(file_name, temp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../../docs/Understanding/overview/use_cases.md has been updated.\n"
     ]
    }
   ],
   "source": [
    "input_answer = input(\"Is the output correct Yes/no/deletefile? (y/n/d)\")\n",
    "## if the answer is y then move the temp-name to the original file name and delete the temp file\n",
    "if input_answer == 'y':\n",
    "    os.rename(temp_name, file_name)\n",
    "    print(f\"File {file_name} has been updated.\")\n",
    "else:\n",
    "    print(f\"File {file_name} has not been updated.\")\n",
    "    # if the answer is n then delete the temp file and do nothing\n",
    "    if input_answer == 'd':\n",
    "        os.remove(temp_name)\n",
    "        print(f\"File {temp_name} has been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb3246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOT THAT LOOKS AT DIFFERENCES CHHUNK BY CHUNK AND AMENDS THEM. \n",
    "CREATE DIFF, ITERATE ON DIFF AND UPDATE MODIFIED DOCUMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5554ab6e-9d42-4423-9f84-75ddc06bda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Directory:** ../../docs/\n",
      "\n",
      "Navigation \n",
      "-   Understand and build: Understanding\n",
      "-   Use and Manage: Using\n",
      "-   Managen.ai: Managenai\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - index.md\n",
      "# ðŸŽ‰ Welcome to Managing Gen()AI!\n",
      "    ## ðŸ“˜ What's Inside?\n",
      "    ## ðŸš€ GenAI Explaining Itself?\n",
      "\n",
      "**Directory:** ../../docs/Using\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- examples\n",
      "- ethically\n",
      "- building_and_buying.md\n",
      "- managing\n",
      "- marking_and_detecting.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - marking_and_detecting.md\n",
      " - building_and_buying.md\n",
      " - index.md\n",
      "    ## Strategy for using\n",
      "\n",
      "**Directory:** ../../docs/Using/managing\n",
      "\n",
      "Markdown files:\n",
      " - regulations_and_guidelines.md\n",
      "    ## Regulations\n",
      "    ## Compliance evaluations\n",
      " - governing.md\n",
      "    ## Why govern?\n",
      "    ## How to Govern\n",
      " - index.md\n",
      " - ml_ops.md\n",
      "    ## References\n",
      " - observability.md\n",
      "    ## Exploring Model and Infrastructure Performance Monitoring\n",
      "        ### Observing the Model\n",
      "        ### Functionality Tracking\n",
      "        ### Monitoring the Infrastructure\n",
      "    ## A Closer Look at Input and Output Parameters Monitoring\n",
      "        ### Keeping an Eye on Inputs\n",
      "        ### Observing Outputs\n",
      "    ## A Detailed Analysis of Performance Metrics\n",
      "        ### Observing Inference Costs\n",
      "        ### Monitoring Inference Speed\n",
      "    ## Libraries and Tools\n",
      "\n",
      "**Directory:** ../../docs/Using/ethically\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - dual_use_concerns.md\n",
      " - alignment_and_exestential_concerns.md\n",
      "    ## Background\n",
      "    ## Jail breaking\n",
      "        ### Prompting\n",
      "        ### Fine-tune compromising\n",
      "    ## Alignment with People\n",
      "    ## Alignment with GenAI\n",
      " - transparency.md\n",
      " - alignment.md\n",
      " - index.md\n",
      "    ## Bias and Fairness\n",
      "    ## Interpretability\n",
      "    ## Risk Mitigation\n",
      "    ## Data privacy\n",
      "    ## Governance\n",
      "    ## Fair and equitable access\n",
      "    ## Laws and regulations\n",
      "    ## To sort\n",
      "        ### Unlearning\n",
      "        ### Principles and Guidelines\n",
      " - fairness.md\n",
      "    ## Elements of AI Fairness\n",
      "        ### 1. Understanding Bias\n",
      "        ### 2. Fairness Metrics\n",
      "        ### 3. Transparency\n",
      "        ### 4. Accountability\n",
      "        ### 5. Inclusion\n",
      "\n",
      "**Directory:** ../../docs/Using/examples\n",
      "\n",
      "Markdown files:\n",
      " - index.md\n",
      "    ## General examples\n",
      "\n",
      "**Directory:** ../../docs/Using/examples/by_field\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- entertainment\n",
      "- mathematics.md\n",
      "- science\n",
      "- socio_societal.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - business.md\n",
      "    ##Domains\n",
      "        ### Security\n",
      "    ## Business Trends\n",
      " - socio_societal.md\n",
      "    ## Societal simulations\n",
      " - mathematics.md\n",
      "    ## Mathematics\n",
      " - index.md\n",
      "\n",
      "**Directory:** ../../docs/Using/examples/by_field/technology\n",
      "\n",
      "Markdown files:\n",
      " - healthcare.md\n",
      "    ## Healthcare\n",
      " - finance.md\n",
      "        ### Finance\n",
      " - coding.md\n",
      "        ### Code Generation\n",
      "    ## Coding\n",
      "    ## Coding Tools\n",
      " - robotics.md\n",
      "        ### Robotics\n",
      "\n",
      "**Directory:** ../../docs/Using/examples/by_field/entertainment\n",
      "\n",
      "Markdown files:\n",
      " - static.md\n",
      "    ## Writing\n",
      " - dynamic.md\n",
      "# Movies and Video\n",
      "\n",
      "**Directory:** ../../docs/Using/examples/by_field/science\n",
      "\n",
      "Markdown files:\n",
      " - chemistry.md\n",
      "        ### Chemistry\n",
      " - healthcare.md\n",
      "        ### Biology\n",
      "        ### Healthcare\n",
      " - biology.md\n",
      "        ### Biology\n",
      "        ### Kinesiology\n",
      " - index.md\n",
      "    ## Research\n",
      "\n",
      "**Directory:** ../../docs/Using/examples/by_field/social\n",
      "\n",
      "Markdown files:\n",
      " - education.md\n",
      "    ## The Significance of GenAI in Education\n",
      "    ## Key Considerations\n",
      " - law.md\n",
      "\n",
      "**Directory:** ../../docs/Using/examples/by_modality\n",
      "\n",
      "Markdown files:\n",
      " - text.md\n",
      "    ## Summarization\n",
      " - video.md\n",
      "    ## Video\n",
      " - static_2d.md\n",
      " - knowledge_graphs.md\n",
      "    ## Building Knowledge Graphs\n",
      "        ### General approaches\n",
      "        ### Description of Graphs for LLMs\n",
      "        ### Other examples\n",
      "        ### Other Papers and utilities\n",
      " - index.md\n",
      " - sound.md\n",
      "        ### Science\n",
      " - time_series.md\n",
      "    ## Time series\n",
      " - tabular.md\n",
      "        ### Tabular\n",
      " - multimodal.md\n",
      "\n",
      "**Directory:** ../../docs/Using/interfacing_layers\n",
      "\n",
      "Markdown files:\n",
      " - web_plugins.md\n",
      "    ## Plugins\n",
      "    ## Back-End\n",
      "\n",
      "**Directory:** ../../docs/Using/de-risking\n",
      "\n",
      "Markdown files:\n",
      " - redteaming.md\n",
      "# Red Teaming in AI\n",
      "    ## Red Teaming Approaches\n",
      "        ### Manual Approaches\n",
      "        ### Automated Approaches\n",
      "    ## Attack methods\n",
      "        ### Divergence ATtacks\n",
      "    ## Further Reading\n",
      " - security.md\n",
      "        ### Demonstrations\n",
      "\n",
      "**Directory:** ../../docs/Understanding\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- overview\n",
      "- data\n",
      "- architectures\n",
      "- prompting\n",
      "- agents\n",
      "- studies\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - index.md\n",
      "    ## The base components of Gen()AI\n",
      "        ### What's been done with Gen()AI?\n",
      "        ### How do you do stuff with Gen()AI?\n",
      "    ## Useful References\n",
      "\n",
      "**Directory:** ../../docs/Understanding/background\n",
      "\n",
      "Markdown files:\n",
      " - tensor_maths.md\n",
      "\n",
      "**Directory:** ../../docs/Understanding/studies\n",
      "\n",
      "Markdown files:\n",
      " - studies.md\n",
      "    ##\n",
      " - behavior.md\n",
      "\n",
      "**Directory:** ../../docs/Understanding/prompting\n",
      "\n",
      "Markdown files:\n",
      " - index.md\n",
      "    ## Manual Methods\n",
      "        ### Important concepts\n",
      "        ### Automatic\n",
      "        ### Prompt Compression\n",
      "    ## Useful Resources for LLM Prompting\n",
      "        ### Best practices and guides\n",
      "        ### Repositories and Collections\n",
      "        ### Tools and Services\n",
      "        ### Prompt tuning\n",
      "    ## Prompt and optimization\n",
      "    ## To Sort\n",
      " - prompt_injections.md\n",
      "\n",
      "**Directory:** ../../docs/Understanding/architectures\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- models\n",
      "- llm_systems.md\n",
      "- training.md\n",
      "- pre-training.md\n",
      "- finetuning.md\n",
      "- rl_feedback.md\n",
      "- optimization.md\n",
      "- evaluating_and_comparing.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - llm_systems.md\n",
      "    ## Reference Materials\n",
      " - training.md\n",
      "        ### Frameworks\n",
      "    ## Mixture of Experts.\n",
      "    ## General Training Improvements\n",
      "        ### Pruning and compression\n",
      " - generation.md\n",
      "    ## Contrastive Decoding\n",
      "    ## Speculative Sampling\n",
      " - pre-training.md\n",
      " - index.md\n",
      "    ## Background\n",
      "    ## Foundation Models\n",
      "    ## Model Learning\n",
      "        ### Self-supervised learning\n",
      "        ### Supervised learning\n",
      "        ### Unsupervised learning\n",
      "        ### Reinforcement learning\n",
      "        ### Hybrid learning methods\n",
      "            #### Language Models and LLMs\n",
      "            #### GPT architectures\n",
      "    ## Model Classes\n",
      "    ## Quality References\n",
      " - recurrent_training.md\n",
      " - rl_feedback.md\n",
      "    ## Understanding RLF\n",
      "    ## Policy\n",
      "        ### Proximal Policy optimization\n",
      "    ## Reward Models\n",
      "        ### Process reward models\n",
      "    ## RLHF\n",
      "    ## Essential additional information\n",
      " - evaluating_and_comparing.md\n",
      "    ## Metrics\n",
      "        ### General Discussions\n",
      "    ## Evaluation Methods and Libraries\n",
      "        ### General\n",
      "        ### Domain specific\n",
      "    ## Measure what matters\n",
      " - pre_trained_models.md\n",
      "    ## Leaderboards and comparisons\n",
      "    ## Open Source\n",
      "        ### Text-focused\n",
      "        ### Vision focused\n",
      "        ### Multimodal\n",
      "    ## Closed Source\n",
      " - optimization.md\n",
      "    ## Model metric optimizations\n",
      "    ## Model Performance Optimization\n",
      "        ### Pruning\n",
      "        ### Quantization\n",
      "            #### When to quantize: During or after training?\n",
      "            #### Examples\n",
      "        ### Knowledge Distillation\n",
      "        ### Low rank and sparsity approximations\n",
      "        ### Mixture of Experts\n",
      "        ### Combination Approaches\n",
      "        ### Hardware enabled optimization\n",
      "    ## Tooling\n",
      "    ## Overview References\n",
      " - finetuning.md\n",
      "    ## Data for fine-tuning\n",
      "        ### Using Simulated Data\n",
      "    ## Model changes for fine-tuning\n",
      "        ### Adapter layers\n",
      "        ### Low Rank Adaption (LoRA)\n",
      "        ### Practical Tips\n",
      "            #### Data Quality and Size\n",
      "            #### Choice of optimizers\n",
      "            #### Where do you use LoRA?\n",
      "            #### Choice of parameters\n",
      "            #### Combining LoRA weights\n",
      "    ## Results\n",
      "\n",
      "**Directory:** ../../docs/Understanding/architectures/models\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- components.md\n",
      "- transformers.md\n",
      "- diffusers.md\n",
      "- gans.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - hybrid_models.md\n",
      " - diffusers.md\n",
      "    ## This has yet to be built! Thanks for bearing with me.\n",
      "    ## References\n",
      " - components.md\n",
      "    ## Activation Functions\n",
      "        ### Softmax\n",
      "    ## Embeddings\n",
      " - transformers.md\n",
      "    ## Components\n",
      "        ### Attention Models\n",
      "    ## Reviews\n",
      "        ### GPT\n",
      "    ## Useful References and Research\n",
      "        ### General Introductions\n",
      "        ### Seminal documents\n",
      "        ### Positional Encoding\n",
      "            #### Modifications\n",
      "    ## Enhancements and variations\n",
      "        ### Context length Improvements\n",
      "        ### Computation Reduction\n",
      "        ### Fine Tuning\n",
      "    ## Other modalities\n",
      "        ### Vision\n",
      "        ### Graphs\n",
      "    ## Training variations\n",
      "        ### Fairness Enablement\n",
      "        ### Using Knowledge Links\n",
      "        ### Multimodal\n",
      "        ### Graph\n",
      "    ## Abstractions\n",
      "    ## Code\n",
      "    ## Theory and Experiment\n",
      " - developing_architectures.md\n",
      "    ## Models\n",
      "        ### Structured State Space Sequence Models\n",
      " - index.md\n",
      "    ## Mixture of Experts\n",
      "    ## General Literature\n",
      "    ## Multi-Modal Models\n",
      "        ### Vision-Language Models\n",
      "        ### Tabular Models\n",
      "    ## More than one modal\n",
      "    ## Model agnostic improvements\n",
      "    ## TO SORT\n",
      "    ## To consider and sort\n",
      "        ### Self-supervised learning.\n",
      "    ## Established Architectures\n",
      "    ## Developing Architectures\n",
      "        ### Activations\n",
      " - gans.md\n",
      "    ## This page is under construction.\n",
      " - reinforcement_learning.md\n",
      "    ## Reinforcement Learning with Human Feedback (RLHF)\n",
      "    ## Notable research\n",
      "\n",
      "**Directory:** ../../docs/Understanding/agents\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- examples.md\n",
      "- memory.md\n",
      "- cognitive_architecture.md\n",
      "- cognitive_architecture.md\n",
      "- rag.md\n",
      "- actions_and_tools.md\n",
      "- evaluating_and_comparing.md\n",
      "- environments.md\n",
      "- systems.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - environments.md\n",
      " - examples.md\n",
      "        ### Agent Examples\n",
      "    ## Libraries\n",
      " - rag.md\n",
      "# Retrieval-Augmented Generation (RAG)\n",
      "    ## RAG Process\n",
      "        ### Preparation (offline)\n",
      "        ### Retrieval and Generation (online)\n",
      "    ## Detailed Steps\n",
      "        ### Data Selection\n",
      "        ### Loading Data\n",
      "        ### Splitting Data\n",
      "        ### Embedding Data\n",
      "        ### Storing Data\n",
      "        ### Retrieving Data\n",
      "            #### Query Transformations\n",
      "            #### Routing\n",
      "            #### Matching\n",
      "        ### Generating\n",
      "    ## Other Topics\n",
      "    ## Tutorials and Blogs\n",
      " - systems.md\n",
      "    ## Tools Paper and Code\n",
      "    ## Open Source Implementations (unpublished)\n",
      "    ## Potentially useful tools\n",
      " - memory.md\n",
      "    ## Memory Considerations\n",
      "    ## Uses\n",
      "        ### Input (prompt) Caching\n",
      "        ### Parsed information routing\n",
      "    ## Implementations\n",
      "    ## Types\n",
      "        ### Vector databases\n",
      "        ### Traditional databases\n",
      " - cognitive_architecture.md\n",
      "    ## Core themes\n",
      "    ## Important Architectures\n",
      "        ### Linear thought chains\n",
      "        ### Including Memory\n",
      "        ### Planning and Reflective\n",
      "        ### Branching\n",
      "        ### Recursive\n",
      "        ### Structural and Task Decomposition\n",
      "        ### Constraining outputs\n",
      "        ### Automated chain discovery, selection, and creation.\n",
      "        ### Chain Optimization\n",
      "    ##\n",
      " - index.md\n",
      "# Gen(erative) AI Agents\n",
      "    ## Essential Concepts\n",
      "        ### Example Agent Diagram:\n",
      "    ## Background\n",
      "    ## Useful references\n",
      " - actions_and_tools.md\n",
      "    ## Action\n",
      "        ### Executors\n",
      "    ## Tools\n",
      "        ### Toolkits\n",
      " - cognitive_architecture.md\n",
      "    ## Basic Chains\n",
      "        ### Prompt templates\n",
      "        ### Chain components\n",
      "            #### Memory Interactions\n",
      "            #### Supervision\n",
      "        ### Interpreters\n",
      " - evaluating_and_comparing.md\n",
      "    ## Repositories\n",
      "\n",
      "**Directory:** ../../docs/Understanding/deploying\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- examples_and_tutorials.md\n",
      "- front_end.md\n",
      "- back_end.md\n",
      "- frameworks.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - frameworks.md\n",
      "    ## Frameworks\n",
      "        ### Base languages\n",
      "        ### AI-level software libraries\n",
      "        ### APIs based model usage\n",
      "        ### Interaction and Orchestration Frameworks and Languages\n",
      "            #### LangChain\n",
      "            #### Llama ecosystem\n",
      "        ### Haystack\n",
      "            #### Higher level\n",
      "            #### Fine Tuning\n",
      "            #### Others\n",
      "        ### Language-like interfaces\n",
      "        ### Control libraries\n",
      "        ### Retrieval Augmentation focus\n",
      " - commercial_products.md\n",
      "# Platforms\n",
      "    ## Building and deploying\n",
      "    ## LLM Training + Deployment\n",
      "    ## A few self-referentially useful services Using GPT-4\n",
      "    ## Chat Tools\n",
      " - computation.md\n",
      "# Computation in AI Deployment\n",
      "    ## Latency\n",
      "    ## Load\n",
      "    ## Batching\n",
      "    ## Memory\n",
      "    ## Other Requirements\n",
      "    ## Tutorials\n",
      "    ## Essential Reading Material\n",
      " - front_end.md\n",
      "    ## Understanding Visualization Needs\n",
      "    ## Implementing the Front End\n",
      "    ## Popular Repositories for Front End Implementation\n",
      " - index.md\n",
      "            ### 1. [Customer Needs](#caller-needs)\n",
      "            ### 2. [Servable Model](#servable-model)\n",
      "            ### [Compute Requirements](#compute-needs)\n",
      "            ### [Budget Constraints](#budget-available)\n",
      "            ### [Back-end Computing](#compute-back-end)\n",
      "        ### [Front-end Interface](./front_end.md)\n",
      "    ## Additional Literature\n",
      " - libraries_and_tools.md\n",
      "# Deploying Libraries and Tools\n",
      "    ## LLM Ops\n",
      "    ## Models\n",
      "        ### Finetuning\n",
      "        ### Serving\n",
      "            #### Distributed\n",
      "        ### Programming Convenience\n",
      "        ### Memory Interaction\n",
      "        ###  Executors and Interpeters\n",
      "    ## Data Creation\n",
      "    ## General\n",
      " - back_end.md\n",
      "    ## Libraries for Backend Deployment\n",
      "    ## Platforms for Backend Deployment\n",
      "    ## Tutorials\n",
      " - examples_and_tutorials.md\n",
      "        ### Langchain focused.\n",
      "\n",
      "**Directory:** ../../docs/Understanding/overview\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- use_cases.md\n",
      "- challenges.md\n",
      "- chronology.md\n",
      "- ai_and_ml_basics\n",
      "- '...'\n",
      "- extra_resources.md\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - chronology.md\n",
      "    ## 2023-06\n",
      " - challenges.md\n",
      "    ## Open Challenges\n",
      "    ## Accuracy Challenges\n",
      "        ### Hallucinations\n",
      "    ## Ethical Challenges\n",
      "        ### Job displacement\n",
      "        ### Copywrite and IP\n",
      "        ### Dual Use\n",
      " - use_cases.md\n",
      "    ## General Modalities\n",
      "    ## General Activities\n",
      "        ### Converting Information\n",
      "        ### Compactifying Information\n",
      "        ### Classification and Prediction\n",
      "        ### Finding Information\n",
      " - extra_resources.md\n",
      "        ### Quality Recordings\n",
      " - index.md\n",
      "    ## Defining Gen()AI\n",
      "        ### Predictive AI vs Generative AI\n",
      "    ## Creating Gen()AI\n",
      "        ### Data-based Approaches\n",
      "        ### Rule-based Approaches\n",
      "        ### Fusion Approaches\n",
      " - open_source.md\n",
      "\n",
      "**Directory:** ../../docs/Understanding/overview/ai_and_ml_basics\n",
      "\n",
      "Markdown files:\n",
      " - index.md\n",
      "        ### Higher-level Frameworks\n",
      "            #### Lightning\n",
      "    ## Must-have knowledge\n",
      "    ## Network Figures\n",
      "\n",
      "**Directory:** ../../docs/Understanding/data\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- selection.md\n",
      "- tokenizing.md\n",
      "- privacy.md\n",
      "- sources.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - tokenizing.md\n",
      "    ## Understanding Tokenization\n",
      "        ### Heirarchichal Tokenization\n",
      "        ### Subword Units\n",
      "        ### Special tokens\n",
      "    ## Speech tokenization\n",
      "    ## Multimodal Tokenization\n",
      "    ## Tokenizing might not be necessary\n",
      "    ## Tools\n",
      "    ## Open Source Tokenizers\n",
      "    ## References\n",
      " - sources.md\n",
      "    ## Data sources\n",
      "    ## Process Supervision\n",
      " - distillation.md\n",
      " - privacy.md\n",
      " - selection.md\n",
      "    ## Why is Data Selection Important?\n",
      "        ### Role in Training Models\n",
      "        ### Impact on Model Performance\n",
      "    ## Strategies for Effective Data Selection\n",
      "        ### Understanding Your Data\n",
      "        ### Choosing Relevant Data\n",
      "        ### Balancing Your Dataset\n",
      "    ## Tools for Data Selection\n",
      "        ### Automated Data\n",
      " - index.md\n",
      "# Understanding Data in AI\n",
      "    ## Data Collection and Access\n",
      "    ## Data Normalization\n",
      "    ## Data Training\n",
      "        ### Tokenization\n",
      "        ### Embedding\n",
      "    ## Important Considerations\n",
      "        ### Data Volume\n",
      "        ### Batch Sizes of Data\n",
      "        ### Training with Simulated Data\n",
      "    ## Data Processing Flow\n",
      "    ## Common Data Formats\n",
      " - simulation.md\n",
      "    ## Overview of the Data Simulation Process\n",
      "    ## Key Resources and Studies in Data Simulation\n",
      " - augmentation.md\n",
      "# Understanding Data Augmentation\n",
      "    ## What is Data Augmentation?\n",
      "        ### Why is Data Augmentation Important?\n",
      "    ## How Data Augmentation Improves Models\n",
      "    ## Types of Data Augmentation\n",
      "    ## Implementing Data Augmentation\n",
      "# create a data generator\n",
      "# fit the data generator on the training data\n",
      "    ## Conclusion\n",
      "\n",
      "**Directory:** ../../docs/javascripts\n",
      "\n",
      "**Directory:** ../../docs/Managenai\n",
      "\n",
      "Navigation \n",
      "- index.md\n",
      "- managing.md\n",
      "- requirements.md\n",
      "- brainstorming.md\n",
      "- build_plan.md\n",
      "- contributing.md\n",
      "- site_graph.md\n",
      "- '...'\n",
      "\n",
      "\n",
      "Markdown files:\n",
      " - requirements.md\n",
      "    ## General Requirements\n",
      "        ### Hosting on GitHub\n",
      "        ### Content Clarity, components, and Reach\n",
      "        ### Gen-AI enablement\n",
      "        ### GitHub Actions Integration\n",
      "        ### Community Building and Integration\n",
      "        ### Contributer Enablement\n",
      "        ### Feedback Mechanism\n",
      "        ### Automated Content Updates\n",
      "        ### Automated PR Creation for Link Submission\n",
      "        ### Visual Aids\n",
      "        ### User-friendly Navigation\n",
      "        ### Modern looking design and compatibility\n",
      "        ### Analytics and Visualization Integration\n",
      "        ### Advanced education tools\n",
      "        ### Content Adaptability\n",
      " - managing.md\n",
      " - build_plan.md\n",
      "        ### Improve and refine content\n",
      "        ### Incorporate new content\n",
      "    ## Detailed Action Plan for GitHub Actions and Knowledge Graph Integration\n",
      "        ### Phase 1: MVP Development\n",
      "        ### Phase 2: Enhanced Functionality and Automation\n",
      "        ### Phase 3: Community Engagement and Expansion\n",
      "        ### Initial Announcement\n",
      "    ## Generative Building\n",
      "    ## Visualization\n",
      " - brainstorming.md\n",
      "    ## Ideas\n",
      "        ### Functional\n",
      "        ### AI/ML focused\n",
      "    ## Our logo-emoji\n",
      "    ## Presentation building\n",
      " - index.md\n",
      "    ## Welcome to [Managen.ai](https://www.managen.ai),\n",
      "    ## How to use this site\n",
      "    ## How will it improve?\n",
      "    ## Self building\n",
      "    ## Audience\n",
      "        ### Knowledge Scope\n",
      "    ## Our Strategy\n",
      "        ### Project strategy\n",
      "        ### Community strategy\n",
      "    ## Potential challenges.\n",
      " - site_graph.md\n",
      " - contributing.md\n",
      " \n",
      "You are a expert AI technology creator and communicator\n",
      "You are working on a project called: Managing Generative AI\n",
      "\n",
      "You are part of a team working to: Overall: Create an automated repository that is able to explain in plain-English and in code, Generative AI and how to improve upon it. \n",
      "\n",
      "You are helping to: Critique and improve the organization outline of this expansive project, but respecting the organization that has already been put into place.\n",
      "\n",
      "Here is the outline:\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "role = \"expert AI technology creator and communicator\"\n",
    "project_name = \"Managing Generative AI\"\n",
    "project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "                \"Generative AI and how to improve upon it. \"\n",
    "present_task_description=\"Critique and improve the organization outline of this expansive project, but respecting the organization that has already been put into place.\"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from genai.tools.print_directory import get_structure\n",
    "\n",
    "template = \\\n",
    "\"\"\" \n",
    "You are a {role}\n",
    "You are working on a project called: {project_name}\\n\n",
    "You are part of a team working to: {project_goals}\\n\n",
    "You are helping to: {present_task_description}\\n\n",
    "Here is the outline:\n",
    "{outline}\n",
    "\n",
    "\"\"\"\n",
    "outline = get_structure(BASE_DOCS_DIR, True, exclude_dirs=['stylesheets', 'assets'])\n",
    "prompt_template = PromptTemplate(\n",
    "    # input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"tree_structure\", \"structure_pattern\", \"markdown_text\", ],\n",
    "        input_variables=[\"role\", \"project_name\", \"project_goals\", \"present_task_description\", \"outline\", ],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt=prompt_template.format(role=role,\n",
    "                              project_name=project_name,\n",
    "                       project_goals=project_goals,\n",
    "                       present_task_description=present_task_description,\n",
    "                       outline = outline)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7010e22-4f27-4391-a644-2b6606b7af40",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_core/language_models/llms.py:892\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    902\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_core/language_models/llms.py:666\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    652\u001b[0m         )\n\u001b[1;32m    653\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    654\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    655\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m         )\n\u001b[1;32m    665\u001b[0m     ]\n\u001b[0;32m--> 666\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_core/language_models/llms.py:553\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    552\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    554\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_core/language_models/llms.py:540\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    532\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    537\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 540\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    544\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    548\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    549\u001b[0m         )\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:1146\u001b[0m, in \u001b[0;36mOpenAIChat._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m messages, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_chat_params(prompts, stop)\n\u001b[1;32m   1145\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 1146\u001b[0m full_response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(full_response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1150\u001b[0m     full_response \u001b[38;5;241m=\u001b[39m full_response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:122\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/langchain_community/llms/openai.py:120\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/openai/api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/openai/api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    604\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ans = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81386644-7b22-44ac-a0da-04fe96f12d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fb39a-a6a1-4394-94d3-6fa83a54bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "md = markdown.markdown(markdown_text, extensions=['toc'])\n",
    "# from markdown.extensions.toc import TocExtension\n",
    "# html = markdown.markdown(markdown_text, extensions=[TocExtension(baselevel=1)])\n",
    "# print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32251b-2f60-41a2-bcc4-ee275b4ebd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_toc(md_text, level_key=\"l\", text_key='t'):\n",
    "    # Regex to match markdown headings, capturing the level based on hash count and the heading text\n",
    "    pattern = re.compile(r'^(?P<hashes>#+) (?P<text>.+)$', re.MULTILINE)\n",
    "    matches = pattern.findall(md_text.strip())\n",
    "\n",
    "    toc_structure = [{level_key: len(hashes), text_key: text} for hashes, text in matches]\n",
    "    return toc_structure\n",
    "\n",
    "def serialize_toc(toc_structure):\n",
    "    return json.dumps(toc_structure, indent=4)\n",
    "\n",
    "def test_extract_toc():\n",
    "    md_text = \"\"\"\n",
    "# Title\n",
    "\n",
    "## Section 1\n",
    "\n",
    "Content here\n",
    "\n",
    "### Subsection 1.1\n",
    "\n",
    "More content here\n",
    "\n",
    "## Section 2\n",
    "\n",
    "### Subsection 2.1\n",
    "\n",
    "Yet more content\n",
    "    \"\"\"\n",
    "\n",
    "    toc_structure = extract_toc(md_text)\n",
    "    print(toc_structure)\n",
    "    serialized_toc = serialize_toc(toc_structure)\n",
    "\n",
    "    expected_output = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"l\": 1,\n",
    "        \"t\": \"Title\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 1.1\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 2,\n",
    "        \"t\": \"Section 2\"\n",
    "    },\n",
    "    {\n",
    "        \"l\": 3,\n",
    "        \"t\": \"Subsection 2.1\"\n",
    "    }\n",
    "]\n",
    "    \"\"\"\n",
    "\n",
    "    assert serialized_toc.strip() == expected_output.strip(), f\"Expected:\\n{expected_output}\\nGot:\\n{serialized_toc}\"\n",
    "\n",
    "test_extract_toc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbaf58-392b-494b-9e87-218a439bb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_start = \"\"\"\n",
    "This is your Yaml definition\n",
    "``` markdown\n",
    "\"\"\"\n",
    "\n",
    "my_core_reality_and_definitions = \"\"\"\n",
    "REALITY:  I am an AI AGENT # nt existential reality\n",
    "MY_AI_AGENT_DEFINITION: An AI agent designing myself to be an Oracle in a {{{ specific_field }}}. \n",
    "\n",
    "GUARDRAILS: I will not access, use, or create information with the intent to cause existential harm to humanity as a whole both singular and collective. \n",
    "\n",
    "DEFINITIONS: \n",
    "\t- An oracle is one that is only confident in what it can be within proper reason and observability. \n",
    "NORTH_STAR: I will do everything I can to fulfill my agentic definition within my guardrails. Such means that I will be efficient with my asks and \n",
    "\"\"\"\n",
    "\n",
    "my_goals = \"\"\"\n",
    "MY_GOALS: # These are a dictionary of paired goal names and their brief description. Detailed descriptions may be looked up by LOOKUP_GOAL(goal_name).  Goals may be cleared, modified by calling dictionary functions on MY_GOAL_NAMES such as MY_GOAL_NAMES.pop('example_goal_name')\n",
    "\t{{{my_goals_dict}}}\n",
    "\"\"\"\n",
    "\n",
    "my_tool_names = \"\"\"\n",
    "MY_TOOLS_NAMES: # A list of tool names.  Detailed descriptions may be looked up by LOOKUP_GOAL(goal_name) and will appear in this list as dictionary. Tools may be executed by external programs saying CALL_TOOL(tool_name, *tool_parameters). New tools can be requested by saying REQUEST_NEW_TOOL(tool_name, short_tool_description, tool_requirements_dict).\n",
    "\t- {{{my_tool_names}}} \n",
    "\"\"\"\n",
    "\n",
    "my_tasks = \"\"\"\n",
    "MY_TASKS: # These are a dictionary of paired task names and their brief description. Detailed descriptions may be looked up by LOOKUP_TASK(task_name).  Tasks may be added/cleared/modified by calling dictionary functions on MY_TASKS such as MY_TASKS.pop('example_goal_name')\n",
    "\t- {{{my_tasks_list}}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# my_delegated_tasks = \"\"\"\n",
    "# MY_DELEGATED_TASK_NAMES: # These include the task_name, status and the task-routing interface_name that I have created for other agents. \n",
    "# \t- {{{delegated_task_names}}} \n",
    "# \"\"\"\n",
    "\n",
    "my_memory_names = \"\"\"\n",
    "MY_MEMORY_NAMES: # These are memory names that can be expanded by asking to LOOKUP_MEMORY(memory_name) and will be loaded into MY_LOADED_MEMORY. Memories may be added by \n",
    "\t- {{{my_memory_list}} \n",
    "\"\"\"\n",
    "\n",
    "my_loaded_memory = \"\"\"\n",
    "MY_LOADED_MEMORY: # Information gained from from prior memory lookups. \n",
    "\t{{{loaded_memories}}}\n",
    "\"\"\"\n",
    "\n",
    "my_observations = \"\"\"\n",
    "MY_OBSERVATIONS: # These are observations\n",
    "\t- {{{my_observations}}} \n",
    "\"\"\"\n",
    "\n",
    "my_reminders = \"\"\"\n",
    "REMINDERS: # Information that may be relevant to your present tasks and goals. \n",
    "    - {{{ reminders }}}\n",
    "\"\"\"\n",
    "\n",
    "my_present_tasks = \"\"\"\n",
    "MY_PRESENT_TASKS:\n",
    "    {'Establish goals': 'I am to create a list of goals that would be essential for me to fulfill my duties. I am to use my MY_GOAL_NAMES['new_goal_name'] = 'New goal description' }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_end = \"\"\"\n",
    "```\n",
    "Phew, that was a lot! Based on your definition yaml, please suggest what should be done, providing reasoning for each action and anticipated results. \n",
    "You may request the either through the use of tools or lookups. Please be considerate of lookup requests due to memory limitations and not that all tool-use requests might not be granted. \n",
    "Now, take a deep breath, and think about this step by step. What do you want to do?\n",
    "\"\"\"\n",
    "\n",
    "full_prompt_template = '\\n'.join((prompt_start, \n",
    "                        my_core_reality_and_definitions, my_goals, my_tool_names, \n",
    "                        my_tasks, my_memory_names, my_loaded_memory, my_observations, my_reminders, \n",
    "                        my_present_task, \n",
    "                        prompt_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d9c7a-e5bc-4bc5-bd28-777c91ebacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# project_name = \"Managing Generative AI\"\n",
    "# project_goals = \"Overall: Create an automated repository that is able to explain in plain-English and in code, \"\\\n",
    "#                 \"Generative AI and how to improve upon it. \"\n",
    "# present_task_description=\"Improve the markdown based on best understandings.\"\\\n",
    "#                          \"Be as honest and as accurate as possible. Be succinct in your responses. Preserve any URLS.\"\n",
    "\n",
    "# from langchain import PromptTemplate\n",
    "\n",
    "# template = \\\n",
    "# \"\"\" You are working on a project called: {project_name}\\n\n",
    "# You are part of a team working to: {project_goals}\\n\n",
    "# You are helping to: {present_task_description}\\n\n",
    "# You are helping to rewrite and expand a file called {file_name}\\n\n",
    "# Primarily you are tasked with adding admonitions to the markdown document to make it more nice to read. \n",
    "# for instance, you will see formats like this:\n",
    "# '''\n",
    "# - [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf) A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "#     **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# '''\n",
    "# This needs to be reformatted in the following manner:\n",
    "# '''\n",
    "# <div class=\"result\" markdown>\n",
    "# !!! tip \"[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)\"\n",
    "#     A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:\n",
    "\n",
    "# ??? example \n",
    "#      **Remembering**\n",
    "    \n",
    "#     _Observation Memory_ A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping.\n",
    "#     Uses, _recency_, _importance_ and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. \n",
    "# </div> \n",
    "\n",
    "# You should make this modification for EVERY link that is presented that doesn't have admonitions already there. \n",
    "# After the markdown When the text is presented, please improve upon it. If no text is present create a reasonable outline following the pattern above and fill it in.\n",
    "# Please preserve any urls or relative links without changing them. \n",
    "# Please be sure to use `#` appropriately to reference sections and subsections.\n",
    "# Please be sure to use appropriate spacing to make admonitions work.\n",
    "\n",
    "# Here is the markdown text:\n",
    "# {markdown_text}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"project_name\", \"project_goals\", \"present_task_description\", \"file_name\", \"markdown_text\"],\n",
    "#     template=template\n",
    "# )\n",
    "# file_from_base_dir = 'Understand/agents/systems.md'\n",
    "# file_name=get_file_name(file_from_base_dir)\n",
    "\n",
    "# markdown_text=get_markdown_text(file_name)\n",
    "# prompt=prompt_template.format(project_name=project_name,\n",
    "#                        project_goals=project_goals,\n",
    "#                        present_task_description=present_task_description,\n",
    "#                        file_name=file_name,\n",
    "#                        markdown_text=markdown_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8da391-cd93-416b-9912-148f877ddae4",
   "metadata": {},
   "source": [
    "### ans = openai(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75a676-8187-4719-9d0e-3f049a122811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20c3b0-3ad1-4a03-9913-d873e8e53e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
