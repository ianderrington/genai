
Like other applications, deployment of LLM technologies will rely on front-end and back-end components. Front-end will allow for ease-of-use of the components. Back-end components enable the hosting, serving, and recording of any information that is needed for [observability](./observability.md). 

## Front End Interfaces
People have to access it to be useful

- [GPT Graph](https://github.com/m-elbably/gpt-graph) Allows for a graphical network representation of chat interactions.

### Open source methods

- [Streamlit](https://blog.streamlit.io/langchain-streamlit/)
- [DemoGPT](https://github.com/melih-unsal/DemoGPT) Connects Langchain and streamlit to create dynamic apps that can be repeatedly used for interacting with Chat- GPTs. 



### Plugins 
Plugins are can enable connection of GenAI with input media, often via web interfaces

- [Mini Wob++](http://miniwob.farama.org/) For web interactive environments for accomplishing different tasks. Quite useful.

- Ô∏è[Prompt Genius](https://chrome.google.com/webstore/detail/chatgpt-prompt-genius/jjdnakkfjnnbbckhifcfchagnpofjffo)



- [FastChat Conversation]( https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py) This very nice 'multi model' chat interface class allows for effective translation between different models.


## Back-End

- [MaxAI.me](https://app.maxai.me/my-plan) A nice chrome pluging + eventual system  that makes your openAI connect to data more directly.
