
Like other applications, deployment of LLM technologies will rely on front-end and back-end components. Front-end will allow for ease-of-use of the components. Back-end components enable the hosting, serving, and recording of any information that is needed for [observability](./observability.md). 

## Front End Interfaces
People have to access it to be useful

- [GPT Graph](https://github.com/m-elbably/gpt-graph) Allows for a graphical network representation of chat interactions.

### Open source methods

- [Streamlit](https://blog.streamlit.io/langchain-streamlit/)
- [DemoGPT](https://github.com/melih-unsal/DemoGPT) Connects Langchain and streamlit to create dynamic apps that can be repeatedly used for interacting with Chat- GPTs. 



