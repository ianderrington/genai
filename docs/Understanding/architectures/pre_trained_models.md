TODO:
There are a vast number of both open and closed-source models that can be used. A number of them can be downloaded and run on the appropriate hardware, others may be accessed through APIs.

It is essential to [compare and evaluate](evaluating_and_comparing.md) the models for your intended use-cases to ensure they meet technical, customer, and organizational requirements.

## Leaderboards and comparisons

Here are a few boards that help to aggregate and test models that have been released.

- [Hugging Face LLM leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) An essential chart for documenting the model performance across multiple models.
- [lmsys.org leader board](https://lmsys.org/blog/2023-06-22-leaderboard/)

## Open Source

### Text-focused


??? tip "[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/pdf/2307.09288.pdf) A nearly open source set of 7B-70B models with quality performance"
    <img width="1393" alt="image" src="https://github.com/ianderrington/genai/assets/76016868/5f6a647d-c0dc-453c-9334-3632e86bc19e">



??? code "**Sept, 2023** [Mistral Transformer](https://github.com/mistralai/mistral-src)"

    [Announcement](https://mistral.ai/news/announcing-mistral-7b/)
    [Hugging Face](https://huggingface.co/mistralai)
    ![image](https://github.com/ianderrington/genai/assets/76016868/ad494e0e-c854-4866-88db-be7c379a004a)

- [Llama2](https://ai.meta.com/llama/)
- [Llama2 uncensorred](https://huggingface.co/Tap-M/Luna-AI-Llama2-Uncensored)
- [TinyLlama](https://github.com/jzhang38/TinyLlama)
- [Open Llama](https://github.com/openlm-research/open_llama)
- [UAE Falcon](https://www.tii.ae/news/uaes-falcon-40b-now-royalty-free)
- [Orca (Microsoft)](https://arxiv.org/pdf/2306.02707.pdf)
- [MosaicML](https://www.mosaicml.com/blog/long-context-mpt-7b-8k)
- [LAION-AI](https://github.com/LAION-AI/Open-Assistant) An attempted open-source version of ChatGPT"
- [Unilm](https://github.com/microsoft/unilm) (MSFT)
- [GPT4all](https://gpt4all.io/index.html)
- [DoctorGPT](https://github.com/llSourcell/DoctorGPT)

??? code "[Qwen]"

    Open-source : Qwen-72B and Qwen-1.8B! Including Base, Chat and Quantized versions.

    üåü Qwen-72B has been trained on high-quality data consisting of 3T tokens, boasting a larger parameter scale and more training data to achieve a comprehensive performance upgrade. Additionally, we have expanded the context window length to 32K and enhanced the system prompt capability, allowing users to customize their own AI assistant with just a single prompt.

    üéÅ Qwen-1.8B is our additional gift to the research community, striking a balance between maintaining essential functionalities and maximizing efficiency, generating 2K-length text content with just 3GB of GPU memory.

    ü§ó https://huggingface.co/Qwen
    ü§ñ https://github.com/QwenLM/Qwen

### Vision focused

- [StableLM: Stability AI Language Models](https://github.com/stability-AI/stableLM/)
- [Stable Diffusion](https://github.com/apple/ml-stable-diffusion)

### Multimodal


## Closed Source

??? important "[Gemini](https://blog.google/technology/ai/google-gemini-ai/)"
    [Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
    [Tech Report](https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf)
    <img width="633" alt="image" src="https://github.com/ianderrington/genai/assets/76016868/6e1ff291-fcfc-479d-aa07-d13486d82424">
    <img width="653" alt="image" src="https://github.com/ianderrington/genai/assets/76016868/c21a4954-49d9-4bbb-a364-aae017cc8584">



- [Bard](https://bard.google.com/)
- [Claud]()
- [ChatGPT (OpenAI)](https://openai.com/blog/chatgpt)
- [Medpalm](https://arxiv.org/pdf/2212.13138.pdf)
