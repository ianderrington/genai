
TODO: 

Multi-modal Large Language Models (MLMMs) enable us to connect information from different domains, and bring us closer to artificial general intelligence. 

It can be challenging to fuse different domains of data, such as text and images, for a number of reasons. Here are some essential concepts to consider when working with or building MLMMs.

There are two general methods to create MLMMS: 

1. **Early Fusion**: Combine data modalities and then train a singular model to begin with. 
1. **Late Fusion**: Create separate language models for different modalities and then combine the models under a fine-tuning objective.

Each of these offers different benefits and challenges. 

??? important "[How to Bridge the Gap between Modalities: A Comprehensive Survey on Multi-modal Large Language Model](https://arxiv.org/pdf/2311.07594.pdf)"
    
