## Bias and Fairness

Mitigating bias in data and models
Evaluating model fairness
Inclusive model development
Transparency and Explainability

## Interpretability
Techniques for explainability
Right to explanation
Safety

## Risk Mitigation
Risk assessment
Safeguards against misuse
Privacy

## Data privacy 
Anonymization and de-identification
Encryption and secure computing

## Governance

Internal auditing processes
External oversight
Accountability measures
Access and Inclusion

## Fair and equitable access

Digital divides
Participatory design
Compliance

## Laws and regulations
Responsible development guidelines
Ethics review processes

## To sort
### Unlearning

https://github.com/optml-group/unlearn-saliency
### Principles and Guidelines
https://www.nature.com/articles/d41586-023-03266-1 

Key principles of the living guidelines:

First, the summit participants agreed on three key principles for the use of generative AI in research — accountability, transparency and independent oversight.

Accountability. Humans must remain in the loop to evaluate the quality of generated content; for example, to replicate results and identify bias. Although low-risk use of generative AI — such as summarization or checking grammar and spelling — can be helpful in scientific research, we advocate that crucial tasks, such as writing manuscripts or peer reviews, should not be fully outsourced to generative AI.

Transparency. Researchers and other stakeholders should always disclose their use of generative AI. This increases awareness and allows researchers to study how generative AI might affect research quality or decision-making. In our view, developers of generative AI tools should also be transparent about their inner workings, to allow robust and critical evaluation of these technologies.

Independent oversight. External, objective auditing of generative AI tools is needed to ensure that they are of high quality and used ethically. AI is a multibillion-dollar industry; the stakes are too high to rely on self-regulation.
