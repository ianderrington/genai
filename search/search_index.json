{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"\ud83c\udf89 Welcome to Managing Gen()AI!","text":"<p>Our Mission: Simplify and demystify Gen()AI for making it accessible and understandable, and to increase our ability to manage it. </p> <p>Our open-source project on Managing Generative AI \ud83e\udd16 will help people to stay on top of understanding effectively working with the increasingly complex of world of Generative AI.</p> <p>Why is it called Gen() AI?</p> <p><code>Generative AI</code> creates. So does will <code>General AI</code>. Depending on their definitions there may be notable differences, the overlap ensures that there will be shared characteristics that warrant writing this ambiguously, such as GenAI or Gen()AI. </p>"},{"location":"index.html#whats-inside","title":"\ud83d\udcd8 What's Inside?","text":"<ul> <li>Understanding GenAI: Delve deep into the mechanics, models, and methodologies.</li> <li>Engineering GenAI: Learn how to build and deploy models.</li> <li>Using GenAI: Where we describe use cases and applications, commercial tools and applications, and the ethics and regulations surrounding GenAI.</li> <li>Managing GenAI: This is the heart of our project, where we describe the tools that we are building to enable quality, and responsible development of this and other AI-projects.</li> </ul>"},{"location":"index.html#genai-explaining-itself","title":"\ud83d\ude80 GenAI Explaining Itself?","text":"<p>One of our ambitious goals is to have this documentation written and updated by GenAI itself. We aim to:</p> <ul> <li>\ud83d\udcdd Set up a base documentation repository that aids in generating self-descriptive content.</li> <li>\ud83d\udd04 Implement an automated merge and build system for a seamless automation and viewing experience.</li> <li>\ud83d\udd01 Create a self-referential models using tools like Langchain to enable its supervised self-improvement via pull-requests and reviews.</li> <li>\ud83d\udd78\ufe0f Catch the greatest new insights and integrate it into a 'living' document that evolves with the time. </li> </ul> <p>We believe in Gen()AI's potential to effecively explain itself even as the technology grows with extreme complexity. </p> <p>If you're as excited as we are and wish to contribute, join us!</p> <p>Contribute</p> <p>Interested in contributing? Check out our guidelines to get started.</p>"},{"location":"Engineering/index.html","title":"Engineering","text":"State of GPT by Andrej Karpathy A stellar presentation to update on the general state of Genai enabled by GPT"},{"location":"Engineering/index.html#system-architecture","title":"System Architecture","text":""},{"location":"Engineering/index.html#references","title":"References","text":"Emerging Architectures for LLM Applications A very nice discussion of the components and their interactions via orchestration systems. <p> [^n1]</p> Challenges and Applications of Large Language Models Kaddour et al Well done and thorough. <p>Below are some overviews to help with practical aspects of Generative AI, particularly GPT and LLMs.</p>"},{"location":"Engineering/index.html#engineering-and-deployment","title":"Engineering and Deployment","text":"<ul> <li>Deploying on Azure for Embeddings</li> <li>Integrating with Azure Services</li> <li>Langchain service deployment</li> </ul>"},{"location":"Engineering/index.html#caching","title":"Caching","text":"<ul> <li>GPTCache</li> </ul>"},{"location":"Engineering/index.html#llm-ops","title":"LLM Ops","text":"<ul> <li>LLM Ops</li> <li>Reliable GPT A wrapper that prevents failures due to rate limiting requests. </li> </ul>"},{"location":"Engineering/actions_and_tools.html","title":"Actions and tools","text":""},{"location":"Engineering/actions_and_tools.html#action","title":"Action","text":"<p>Actions may be be internal or externally focused.  focused generally related to an agent's '<code>memory</code>, or externally focused, with tools, though their distinction may be moot. </p> <p>Internal actions generally relate reading, writing or updating, an agents memory, memory state, such as free-text <code>scratech-pad</code>, an ordered <code>memory-log</code> or a vector database.</p> <p>External actions may be to act on simulated or real environments, or otherwise tracked <code>state</code>, or to use a toolthat an agent may be 'equipped with' to run. These can be API calls or local function calls. </p>"},{"location":"Engineering/actions_and_tools.html#executors","title":"Executors","text":"<p>The action that an agent may take is enabled by an <code>AgentExecutor</code> or interpreter of the LLM output, that coordinates the call to perform the action. </p> <p>Langchain Agent Executor</p>"},{"location":"Engineering/actions_and_tools.html#tools","title":"Tools","text":"<p>Tools generally consist of single function calls to something that will return value to the end-point destination, be that the agent itself or a person interacting with an agent. </p>"},{"location":"Engineering/actions_and_tools.html#toolkits","title":"Toolkits","text":"<p>Toolkits consist of tool pearings that often work together well. For instance, bash commands for file creation, deletion, naming and movement. Toolkits can be api-calls or </p> Langchain Toolkits <p></p> <p>Gorilla A Llama-focused high-quality API calling methods.</p> <p>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models Demonstrates that presenting documentation of tool usage is likely more valuable than providing examples.</p>"},{"location":"Engineering/ai_in_general.html","title":"Ai in general","text":"<p>Here we provide selected references to frameworks and solutions surrounding AI in general</p>"},{"location":"Engineering/ai_in_general.html#frameworks","title":"Frameworks","text":"<p>Pytorch Tensorflow</p>"},{"location":"Engineering/ai_in_general.html#higher-level-frameworks","title":"Higher-level Frameworks","text":"<p>Higher level frameworks minimize the lines of code needed to make a model and keep track of everything. </p> <ul> <li>Catalyst Framework for boiler-plate minimal ML calling using pytorch. Enabled heirarchichal Attention networks</li> </ul>"},{"location":"Engineering/ai_in_general.html#lightning","title":"Lightning","text":"<ul> <li>Lightning + Hydra Uses the [lightning] framework with Hydra-based config management. </li> <li>Lightning Hugging face adapter</li> </ul>"},{"location":"Engineering/ai_in_general.html#must-have-knowledge","title":"Must-have knowledge","text":"<ul> <li>AI cannon by a16z</li> </ul>"},{"location":"Engineering/ai_in_general.html#network-figures","title":"Network Figures","text":"<p>Being able to see the 'structure' of some neural networks make it easier to understand, and more aesthetic.  </p> <ul> <li>PlotNeuralNet and a nice writeup on how to use it. </li> </ul>"},{"location":"Engineering/comparison_and_evaluation.html","title":"Comparison and evaluation","text":"<p>Because of potential pitfals with Generative AI technology, it is essential to evaluate, compare, and test models such that they meet the indendent requirements. </p> <p>Below are some tools that you can use to help with this!</p>"},{"location":"Engineering/comparison_and_evaluation.html#tools","title":"Tools","text":"Arthur.ai Bench Bench is a tool for evaluating LLMs for production use cases.  DeepEval provides a Pythonic way to run offline evaluations on your LLM pipelines <p>\"... so you can launch comfortably into production. The guiding philosophy is a \"Pytest for LLM\" that aims to make productionizing and evaluating LLMs as easy as ensuring all tests pass.\" </p> Auto Evaluator to evaluate appropriate components of chains to enable best performance <p></p>"},{"location":"Engineering/computation.html","title":"Computation","text":""},{"location":"Engineering/computation.html#gpus","title":"GPUS","text":"<p>In order to create models, large volumes of matrix multiplication is necessary. GPUs are designed for this. </p> <p>Tim Dettmers on GPUs</p>"},{"location":"Engineering/examples.html","title":"Examples","text":"humanscript A script interpreter that infers the meaning behind commands written in natural language using large language models. Human writeable commands are translated into code that is then executed on the fly. <p>Fully GenAI pharmacist from scripts, images and videos</p> <p>ChatGPT clone with streamlit</p> <p>A Guide to building a full-stack web app with Llama Index</p> <p>GPT-graph A react-based ability to explore questions.</p>"},{"location":"Engineering/examples.html#summarization","title":"Summarization","text":""},{"location":"Engineering/examples.html#pdf","title":"PDF","text":"[Summarization with Langchain] https://github.com/EnkrateiaLucca/summarization_with_langchain A splendid view of a quick streamlit app that does PDF summarization. <p>Doctor GPT implements advanced LLM prompting for organizing, indexing and discussing PDFs, and does so without using any type of opinionated prompt processing frameworks </p>"},{"location":"Engineering/examples.html#video","title":"Video","text":"<p>Youtube URL to text</p>"},{"location":"Engineering/examples.html#multiple-use-case-examples","title":"Multiple Use-case examples","text":"<p>Langchain Javascript in the Real World</p>"},{"location":"Engineering/frameworks_and_tools.html","title":"Frameworks and tools","text":"<p>TODO, split this up in other documents up by what it does, not what it is.</p> <p>While still evolving there is an increasing number of quality frameworks that are suited to successfully enabling Generative AI applications. </p> <ul> <li>Langchain is a early system that has stellar success with a principled design allowing for extensive applications to built on top of it. </li> <li>Llama Ecosystem is a a community of Llama-focused modelers, based on the Meta model called Llama, Llama-2 and beyond. </li> <li>A number of others.</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#frameworks-and-tools","title":"Frameworks and Tools","text":"<p>The excitement about the tooling around Generative AI make it hard to keep up with development and deprecation of powerful frameworks and tools. Some of the mentioned references may not be fully completed, or even nascent repos to build their intended purposes (described here). Please let us know if we are missing anything here. </p>"},{"location":"Engineering/frameworks_and_tools.html#langchain","title":"Langchain","text":"<ul> <li>Langchain A primitive python or javascript-based primitive 'LLM' language that enables planned and agentic AI.</li> <li>Langflow </li> <li>Awesome Langchain</li> <li>Toolkit Generates LangChain plugins</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#tutorials","title":"Tutorials","text":"<ul> <li>https://www.pinecone.io/learn/langchain-prompt-templates/</li> <li>https://learn.deeplearning.ai/langchain/lesson/3/memory</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#llama-ecosystem","title":"Llama ecosystem","text":"<p>Llama is Meta's now open-source model. Llama 2 is MIT and free for commercial use. </p> <ul> <li>Llama Direct from the source </li> <li>Lit-Llama</li> <li>MedAlpaca</li> <li>Llama-2 on a CPU and Github</li> <li>GPT LLM Training Generates and trains fine-tuned LLAMA-2 LLMs for specific tasks. </li> <li>llama index and Github for integrating data ingestion and models. </li> <li>LlamaHub (community library of data loaders)</li> <li>LlamaLab (cutting-edge AGI projects using LlamaIndex)</li> <li>Ollama.ai Provides on mac silicon Llama2 calling. Has a great idea that resembles docker files for agent creation and pulling.</li> <li>Running Llama 2 and other Open-Source LLMs on CPU Inference Locally for Document Q&amp;A</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#others","title":"Others","text":"<ul> <li>Flowise</li> <li>Chain Forge A data flow prompt engineering environment for evaluating ana analyzing LLM responses</li> <li>llm-chain ChatGPT and Alpaca support. Agentic with bash commands.</li> <li>Agent Flow</li> <li>Auto Chain </li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#tools","title":"Tools","text":""},{"location":"Engineering/frameworks_and_tools.html#models","title":"Models","text":"<ul> <li>Hugging Face Transformers</li> <li>Adapters for Hugging Face</li> <li> <p>Open LLM</p> </li> <li> <p>Chatall To interact with multiple chatbots at the same time.</p> </li> <li>\u203c\ufe0f LocalAI drop-in replacement REST API that\u2019s compatible with OpenAI API specifications for local inferencing.</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#distributing-methods","title":"Distributing Methods","text":"<p>!!! \"Petals Run large language models at home, BitTorrent-style.\"</p> <pre><code>Generate text with distributed LLaMA 2 (70B), Stable Beluga 2, Guanaco-65B or BLOOM-176B and fine\u2011tune them for your own tasks \u2014 right from your desktop computer or Google Cola\n[Launch your own swarm](https://github.com/bigscience-workshop/petals/wiki/Launch-your-own-swarm)\n</code></pre>"},{"location":"Engineering/frameworks_and_tools.html#programming-convenience","title":"Programming Convenience","text":"<p>!!! tip \"Magentic     A nice and simple plugin that allows a <code>@prompt</code> decorator to call functions as an llm, including function-choice calls.</p> <p>??? example \"their example <pre><code>from typing import Literal\n\nfrom magentic import prompt, FunctionCall\n\n\ndef activate_oven(temperature: int, mode: Literal[\"broil\", \"bake\", \"roast\"]) -&gt; str:\n\"\"\"Turn the oven on with the provided settings.\"\"\"\n    return f\"Preheating to {temperature} F with mode {mode}\"\n\n\n@prompt(\n    \"Prepare the oven so I can make {food}\",\n    functions=[activate_oven],\n)\ndef configure_oven(food: str) -&gt; FunctionCall[str]:\n    ...\n\n\noutput = configure_oven(\"cookies!\")\n# FunctionCall(&lt;function activate_oven at 0x1105a6200&gt;, temperature=350, mode='bake')\noutput()\n# 'Preheating to 350 F with mode bake'\n</code></pre></p>"},{"location":"Engineering/frameworks_and_tools.html#data-creation","title":"Data Creation","text":"<ul> <li>AutoLabel A nice pythonic system for generating semantic labels repeatedly for use in downstream datasets</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#llm-enabled-data-extraction","title":"LLM-enabled data-extraction","text":"<ul> <li>Kor For extracting structured data using LLMs.</li> </ul>"},{"location":"Engineering/frameworks_and_tools.html#visualization","title":"Visualization","text":"<p>Being able to see the 'structure' of some neural networks make it easier to understand, and more aesthetic.  Please see PlotNeuralNet and a nice writeup on how to use it. </p>"},{"location":"Engineering/frameworks_and_tools.html#memory-interaction","title":"Memory Interaction","text":"<p>EmbedChain</p> <p>\"Embedchain is a framework to easily create LLM powered bots over any dataset.\" OpenAI and Llama2 so far.</p> Example <pre><code>    import os\n\n    from embedchain import Llama2App\n\n    os.environ['REPLICATE_API_TOKEN'] = \"REPLICATE API TOKEN\"\n\n    zuck_bot = Llama2App()\n\n    # Embed your data\n    zuck_bot.add(\"youtube_video\", \"https://www.youtube.com/watch?v=Ff4fRgnuFgQ\")\n    zuck_bot.add(\"web_page\", \"https://en.wikipedia.org/wiki/Mark_Zuckerberg\")\n\n    # Nice, your bot is ready now. Start asking questions to your bot.\n    zuck_bot.query(\"Who is Mark Zuckerberg?\")\n    # Answer: Mark Zuckerberg is an American internet entrepreneur and business magnate. He is the co-founder and CEO of Facebook. \n</code></pre>"},{"location":"Engineering/hyper_parameter_optimization.html","title":"Hyper parameter optimization","text":"<p>HOW TO OPTIMIZE PARAMETERS. </p>"},{"location":"Engineering/implementations.html","title":"Implementations","text":"FastWhisper This is an optimized implementation of OpenAI's Whisper <p>Uses a greedy decode for multilingual transcription. It supports all sizes of the Whisper model (from tiny to large).</p>"},{"location":"Engineering/interpreters.html","title":"Interpreters","text":"<p>Interpreters facilitate model computation by parsing, formatting, or otherwise preparing the data for effective use. They can also be used to interpret output. </p> <p>Such efforts can be used to reduce input complexity, token-count, to detect potentially unreasonable inputs or outputs. These interpreters may be agents or models themselves, thought that is not required. </p> <p>Link Routing</p> <p>A model may not be guaranteed to produce equivalent output based on a complex input string such as an html address. Consequently, pre-parsing the output and substituting a simple name for an address, such as 'html_1', and then re-introducing that within any output, both using RegEx, may enable more effective output. </p>"},{"location":"Engineering/interpreters.html#tools","title":"Tools","text":"<p>Please see the frameworks and tools for a more comprehensive set, but below are a few examples.</p> <ul> <li> <p>Guardrails To help format output and prevent improper prompts.</p> </li> <li> <p>Semantic Kernel, Github</p> </li> <li> <p>\ufe0fGuidance Interleaving generation, prompting and logical control to single  continuous flow.</p> </li> </ul>"},{"location":"Engineering/model_deployment.html","title":"Model deployment","text":"<p>The deployment of models enables callers, people or other software, to use them. While deployment may initially consist of only 'making a model available for calling'. </p> <p>Because the model may be one limiting- consider the deployment of the model to be separate from the deployment of the model's encapsulating project, though they are directly connected.  </p> <p>There are many component touchpoints along the way, and more so for customers that have higher requirements.</p> <p>Quickly, models of the desired specs must be stored in a file and then loaded for serving. Serving as user inputs that are routed to the served model, optionally batched to improve average request latency, and outputs returned routed appropriately to users. </p> <p>As would be done for other AI-enalbed products, you will need to have in mind the following</p> <ol> <li>Caller needs (customer requirements)</li> <li>Servable model to appropriately service customer and environmental requirements.</li> <li>Compute needed to enable service</li> <li>Budget available the compute</li> <li>Compute back end service or framework that will work with the budget</li> <li>Visualization needs of the customer in the </li> <li>Front End that provides the appropriate visualization</li> </ol> <p>Keep in mind the needs will change as the understanding of all of the answers above shifts. Still, it is important to get something that you can iterate from, particularly if your solution involves a data flywheel%20ROI-,What%20is%20a%20Data%20Flywheel%3F,where%20it%20becomes%20self%2Dsufficient.) (which it should!).</p>"},{"location":"Engineering/model_deployment.html#caller-needs","title":"Caller needs","text":"<p>What the caller requires will depend on the target audience your offering is provided. Focusing on narrower audiences allow you to have fewer (initial) requirements and may enable MVP generation quickly. These audiences can expand or shift as needed. Often needs will require 'rapid' results that are 'good'. </p>"},{"location":"Engineering/model_deployment.html#servable-model","title":"Servable model","text":"<p>The models must be sufficient to provide the content that the model have a sufficiently reasonable latency that it can enable the throughput requirements of your model. </p> <p>To enable an properly servable model, it may likely be required to optimize the serving of your models.</p>"},{"location":"Engineering/model_deployment.html#compute-needs","title":"Compute needs","text":"<p>Here are some general considerations (from AWS) regarding how to consider the requirements of model deployment.</p> <p> https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html</p>"},{"location":"Engineering/model_deployment.html#budget-available","title":"Budget available","text":"<p>Your calculated budget will be useful to consider the monetization strategy of your tool. While highly dependant on your business model, knowing when to inspire greater model serving optimization to prevent 'too much compute'. </p>"},{"location":"Engineering/model_deployment.html#compute-back-end","title":"Compute back-end","text":"<p>Part of determining your back-end will involve selecting the frameworks and tools that you use. </p> <p>!!! tip GCP Tutorial</p> vLLM utilizes PagedAttention to manage attention keys/values to enable 24x throughput than other transformers w/out architecture changes <p>\"PagedAttention allows storing continuous keys and values in non-contiguous memory space. Specifically, PagedAttention partitions the KV cache of each sequence into blocks, each block containing the keys and values for a fixed number of tokens. During the attention computation, the PagedAttention kernel identifies and fetches these blocks efficiently.\"  Github</p> Text Generation Inference an open-sourced implementation forked from HF <p>\"A Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.\"   </p> <p>Lit-Gpt Hackable implementation of state-of-the-art open-source large language models released under the Apache 2.0 license.</p> <p>Azure-Chat-GPT to run GPT on Azure services</p> <p>!!! code \"Torch Serve enable efficient serving.</p> Triton Inference Server Part of NVIDIA AI Inference <p>Tutorial</p> <p>litellm by BerriAI provides code to enable railways deployed on railway.app</p> <p>!!! website \"Railway.app</p>"},{"location":"Engineering/model_deployment.html#visualization-needs","title":"Visualization needs","text":""},{"location":"Engineering/model_deployment.html#front-ends","title":"Front Ends","text":"<p>People have to well-designed access to GPT technology. Here are several popular repos to start your product out with. </p>"},{"location":"Engineering/model_deployment.html#frameworks-and-tooling","title":"Frameworks and Tooling","text":"<ul> <li>OobaBooga Text generation WebUI</li> <li>Streamlit</li> <li>DemoGPT Connects Langchain and streamlit to create dynamic apps that can be repeatedly used for interacting with Chat- GPTs. </li> <li>GPT Graph Allows for a graphical network representation of chat interactions.</li> </ul>"},{"location":"Engineering/model_deployment.html#additional-information","title":"Additional information","text":""},{"location":"Engineering/model_deployment.html#tutorials","title":"Tutorials","text":""},{"location":"Engineering/model_deployment.html#overview-lit","title":"Overview Lit","text":"<ul> <li> <p>Neptune-nlp-models-infrastructure</p> </li> <li> <p>How to Deploy Large Size Deep Learning Models Into Production</p> </li> </ul>"},{"location":"Engineering/models.html","title":"Models","text":"<p>There are a vast number of both open and closed-source models that can be used. A number of them can be downloaded and run on the appropriate hardware, others may be accessed through APIs. </p> <p>It is essential to compare and evaluate the models for your intended use-cases to ensure they meet technical, customer, and organizational requirements. </p>"},{"location":"Engineering/models.html#leaderboards-and-comparisons","title":"Leaderboards and comparisons","text":"<p>Here are a few boards that help to aggregate and test models that have been released. </p> <ul> <li>Hugging Face LLM leaderboard An essential chart for documenting the model performance across multiple models.</li> <li>lmsys.org leader board</li> </ul>"},{"location":"Engineering/models.html#text-oriented","title":"Text Oriented","text":"<p>Here are some notable models </p> <ul> <li>Bard</li> <li>Claud</li> <li>ChatGPT (OpenAI)</li> <li>Medpalm</li> <li>Llama2</li> <li>Llama2 uncensorred</li> <li>Open Llama </li> <li>UAE Falcon </li> <li>Orca (Microsoft) </li> <li>MosaicML</li> <li>LAION-AI An attempted open-source version of ChatGPT\"</li> <li>Unilm (MSFT)</li> <li>GPT4all</li> <li>DoctorGPT LOOK AT THIS</li> </ul>"},{"location":"Engineering/models.html#image-oriented","title":"Image Oriented","text":"<ul> <li>StableLM: Stability AI Language Models </li> </ul>"},{"location":"Managing/index.html","title":"Index","text":"<p>Managing The GenAI amounts to effectively successfully working with the evolving technology in such a way that it creates. </p>"},{"location":"Managing/brainstorming.html","title":"Brainstorming","text":""},{"location":"Managing/brainstorming.html#ideas","title":"Ideas","text":"<p>Ideas are a dime a dozen.</p> <p>But if you don't have one, you won't find a cent.</p> <p>Here are some ideas of things that might be explored particularly in conjunction with this. </p> <ul> <li> <p>A codebase watcher and executor agent for public codebases like in github. This would have a vector database + query  (+ build) system that would allow the code base to be queried and interacted with via 'execution' of various functions.  They would allow for tested execution of external codebases (and functions). Kind of like code interpreter but for not making new code but calling code that is already needed. This would allow code to use other code just as a person would.</p> </li> <li> <p>Ability to create docker images from repos: repo2docker</p> </li> </ul>"},{"location":"Managing/build_plan.html","title":"Build plan","text":"<p>Using Github to organize our understanding of a fluid field is a notable challenge. Because of the acessibility of mkdocs-material it makes it easy to make nice-looking documentaiton, though sometimes without the niceties that could accompany other software systems. </p> <p>Eventually we may shift to other systems (like docusaurus). Before that though, we will be wanting to integrate state-of-the-art updates to understanding while we build our auto-building system. </p>"},{"location":"Managing/build_plan.html#content","title":"Content","text":"<ul> <li>[ ] Improve strructure of everything hello OK Obama</li> <li>[ ] Go through content that is already there read it, summarize it, and make it look better.</li> </ul>"},{"location":"Managing/build_plan.html#generative-building","title":"Generative Building","text":"<ul> <li>[x] Enable simple jupyter-notebook calls to improve documents.<ul> <li>[ ] Ensure all links are preserved.</li> <li>[ ] Enable multiple LLM integration, for instance with Llama on OSX. </li> </ul> </li> <li>[ ] Enable automatic github PRs based on a continuous feedback system (Like Auto-GPT). </li> <li>[ ] Enable vector-databasing and other RAG tools to function, focusing on <ul> <li>[ ] individual github-repositories </li> <li>[ ] linked documents</li> </ul> </li> </ul>"},{"location":"Managing/build_plan.html#visualization","title":"Visualization","text":"<p>We can make this easier to read</p> <ul> <li>[ ] Improve landing page and header bar to be more modern. </li> <li>[ ] Build interactive graph representation of this site that includes summary information. Check this out and the examples</li> <li>[ ] https://melaniewalsh.github.io/Intro-Cultural-Analytics/06-Network-Analysis/02-Making-Network-Viz-with-Bokeh.html</li> <li>[ ] build with https://docusaurus.io/</li> <li>[ ] Integrate example python notebooks and build with https://github.com/outerbounds/nbdoc</li> </ul>"},{"location":"Managing/contributing.html","title":"Contributing","text":"<p>In order to contribute...</p>"},{"location":"Managing/managing.html","title":"Managing","text":"<p>You cannot manage effectively what you do not understand effectively.</p> <p>Thanks for being interested in this project. This relays how we are putting together the components that enable this project to exist.</p>"},{"location":"Understanding/index.html","title":"Index","text":"<p>Generative Artificial Intelligence, and related General AI and General Super AI are components of what already is and may be the future of intelligence and computing. We must effectively manage these technologies to use them to their highest potential. </p> <p>To manage these technologies effectively and responsibly we must understand them. That is a complex task, especially given the speed at which we are generating novel insights, new discoveries, backed by increasingly powerful hardware. </p> <p>That is why we created Mana Gen AI. </p> <p>Here we focus on Generative AI, knowing various and changing definitions of these domains have a degree of overlap. With time and support we will be able to help many people understand the technology, lest it become a magician's tool. </p> <p>!!! quote \"Any sufficiently advanced technology is indistinguishable from magic. --Arthur C. Clark\u201d</p> <p>In the documents you read here, you will be able to see an increseasingly consistent and understandable discussion of Gen()AI technologies, enabled by Gen()AI technologies herein described.  Like most powerful technology, Gen()AI can be a two edged sword and effective use requires responsible and thoughtful understanding. </p>"},{"location":"Understanding/index.html#the-base-components-of-genai","title":"The base components of Gen()AI","text":"<p>If you are new to this area, you may briefly peruse applications and challenges associated with Gen()AI. </p> <p>Getting into it, you will find the following outline: </p>"},{"location":"Understanding/index.html#whats-been-done-with-genai","title":"What's been done with Gen()AI?","text":"<ol> <li>Data provides the backbone connecting computation to our recorded reality.</li> <li>Models allow the data to be understood and used. [^n1]</li> <li>Prompts govern how we interact with the models.</li> <li>Agents allow for models to be used in more useful, effective, and complex manners.</li> <li>Ethical concerns help us to temper the responsible use of these powerful technologies.</li> <li>Studies help us to understand Gen()AI from an experimental and theoretical basis. </li> </ol>"},{"location":"Understanding/index.html#how-do-you-do-stuff-with-genai","title":"How do you do stuff with Gen()AI?","text":"<p>Of course, there will be some important 'how-to's, particularly in the data, models, prompts and agents. </p> <p>Still, you'll want ot check out the  [engineering][../Engineering/index.md] section to figure out how to use and engineer Gen()AI for your task at hand. </p> <p>Competition is fierce to create the 'best' (based on certain metrics) Gen()AI, so much knowledge may not be known to protect IP and other secrets.</p> <p>Still, these trained foundation models may be used, with varying degrees of open-source licensing, for your project. Open and closed-source pre-trained models are available in many places that can be used hosted by yourself, or enabled by API services. Because of the cost and challenge involved with creating these models, it will likely be necessary to use the ones already made. </p> <p>If you are working on commercial projects, be sure to look at the Licenses to ensure you are legally compliant. </p> <p>And please, whatever you do, be cognisant of the ethical concerns</p>"},{"location":"Understanding/index.html#useful-referencesa1","title":"Useful References[^a1]","text":"<p>There is so much quality material, it would be valuable for your time to check some of these out if you got the chance. </p> LLM Patterns An impressively thorough and well-written discussion on LLMs and patterns within them <p>Important patterns mentioned (references to discussions herein): * Evaluation * Retreival Augmented Generation (RAG) * Fine tuning * Caching to reduce latency.  * Guardrails to ensure output (and input) quality. * Data Flywheel to use data collection and feedback to improve model and experience * Cascade Breaking models up into smaller simpler tasks instead of big ones. * Monitoring to ensure value is being derived * Effective (defensive) UX to ensure the models can be used well.  </p> <ul> <li>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </li> <li>A cookbook of self-supervised Learning </li> <li>LLM Survey</li> <li>Large Language Models Explained</li> </ul> <p>[a^1]: This is presently highly transformer-based large-language models because language is presently more versatile than other modalities. Other models are discussed here</p>"},{"location":"Understanding/agents/index.html","title":"Agents Gen(erative) AI","text":"<p>Agents in Gen()AI agents have access to 'tools' to provide them 'agency' beyond the ability to generate text or image based responses to the input data.</p> <p>Similar to bots, or other computerized automota, they may have the ability to run discretely, separately from standard chat-interfaces. Generally they involve the possibility of Human-in-the-loop to help correct odd components. </p>"},{"location":"Understanding/agents/index.html#basic-concepts","title":"Basic Concepts","text":"<ul> <li>Models: The 'intelligent' component returns an output for a given input. </li> <li>Input environments that can and do provide inputs. </li> <li>Language prompts that orient's and agent's response. </li> <li>Memory to enable writing and reading information that may be of use. </li> <li>Tools that enable more than text (or images) to be returned or otherwise acted upon. </li> <li>Interpreters that are used to process input or output. </li> <li>Chains which enable continuous flow of information, including memory, to downstream tasks. </li> <li>Agents can be quite different! Here are some examples of agents made both in academic and commercial settings. </li> <li>Systems of Agents that can allow for multiple agents with different sets of the components above, to interact and create powerful solutions.</li> </ul>"},{"location":"Understanding/agents/index.html#essential-references","title":"Essential references","text":"<p>Before we go on, there are several references that are of high merit that you may wish to check out!!!</p> <ul> <li>Agents overview by Lilian Weng As usual, a splendid post by Lilian Weng</li> <li>Awesome Agents of nicely curated list of systems using agents</li> </ul>"},{"location":"Understanding/agents/index.html#models","title":"Models","text":"<p>Models provide the computational core of Agents. Acting like a 'brain' that atakes in input prompts they return outputs. Generally the models may be considered <code>frozen</code> for a given agent, but sometimes, agentic feedback is used for helping model creation as with distillation </p> <p>We describe models cational manner here and in an applied manner here. </p>"},{"location":"Understanding/agents/index.html#prompts","title":"Prompts","text":"<p>Garbage In \u2192 Garbage Out</p> <p>The common realization that bad input will lead to bad outputs becomes more nuanced when considering the degree to which small changes in input prompts can lead to wildly different outcome performance. Consequently, well-chosen prompts can functionally enable an agent, or not. </p> <p>Because of the importance and breadth of details involved with prompting, please visit this section. Note, that prompts will be model-specific, and if the model changes, either completely or with new architecture, the continued performance of a given prompt or prompt strategy is not certain. </p>"},{"location":"Understanding/agents/index.html#memory","title":"Memory","text":"<p>Like people, agents can be better enabled when they have access to memory.  We discuss memory thoroughly here.</p>"},{"location":"Understanding/agents/index.html#tools","title":"Tools","text":""},{"location":"Understanding/agents/index.html#interpreters","title":"Interpreters","text":"<p>Both the input and output into an LLM model may be intepreted, or otherwise parsed in a manner that makes the input or output more impactful. </p> <ul> <li>Native function calls and json support with OpenAI </li> </ul>"},{"location":"Understanding/agents/index.html#systems","title":"Systems","text":"<p>Generative AI systems involve the interaction of multiple individual GenAI elements that can act, to a coordinated degree, independently of other AI Agents. </p>"},{"location":"Understanding/agents/index.html#to-organize","title":"TO ORGANIZE","text":"<ul> <li>This</li> </ul>"},{"location":"Understanding/agents/actions_and_tools.html","title":"Actions and tools","text":"<pre><code>- [Tool LLM](https://huggingface.co/papers/2307.16789) This describes a novel approach enabling over 16000 API's to be called through an intelligent routing mechanism. [Github](https://github.com/OpenBMB/ToolBench) Uses RapidAPI connector to do so.\n</code></pre>"},{"location":"Understanding/agents/agents.html","title":"Agents","text":"<p>TODO Traditional RL agents. LLM-enabled agents</p> <p>Grid:</p> <p>Memory Tools</p> <p>https://github.com/timvink/mkdocs-charts-plugin https://vega.github.io/editor/#/examples/vega-lite/point_offset_random</p>"},{"location":"Understanding/agents/chains.html","title":"Chains","text":"<p>How are you</p>"},{"location":"Understanding/agents/chains.html#chains","title":"Chains","text":"<p>Chains can be considered linked generative interactions where information can be processed with interpreters, tools, or other agents/GenAIs. Done well, they can be built up to form reasoning systems that can enable more successful reasoning or task completion. </p> <p>These can enable passing concepts or data and re-introducing them directly throughout the database. </p>"},{"location":"Understanding/agents/chains.html#basic-chains","title":"Basic Chains","text":"<p>'Chains start with an input that may first be analyzed with another algorithm, such as by splitting or substituting an HTML link for a token representing a variable. This output may then be directed to part of a template. The prompt-template. The prompt templates then fill in the information. This information is then passed to the LLM. Then the LLM generates the output. This output may then again be processed to re-introduce extracted information removed from the original prompt call (like HTML), to use the output to affect the next actions to be taken, such as printing the output for a person, calling programmatic functions (tools) or sharing with specific downstream chains (routing).</p>"},{"location":"Understanding/agents/chains.html#examples","title":"Examples","text":"<p>TODO</p> <ul> <li>Basic Chain (Chat) </li> <li>With human interaction</li> <li> <p>With prompt structuring. </p> </li> <li> <p>Routing Chain</p> </li> </ul> <p>Chain with memory storage and retrieval Chain with memory retrieval  Multi-model chains.</p> <p>(Other chains from lang-chain)</p>"},{"location":"Understanding/agents/chains.html#resources","title":"Resources","text":"<ul> <li>Chain of thought hub</li> </ul>"},{"location":"Understanding/agents/chains.html#concepts","title":"Concepts","text":""},{"location":"Understanding/agents/chains.html#thought-structures","title":"Thought Structures","text":"<p>Thought structures are chain patterns used by singular (or even multiple agents in systems that enable more robust responses.  They can be executed automatically with the given frameworks and sometimes done manually in a chat setting. </p> <p>Here are some known thought structures that are improving agentic output.</p> <p>??? tip \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models </p>"},{"location":"Understanding/agents/chains.html#recurrent","title":"Recurrent","text":"Teaching Large Language Models to Self-Debug <code>transcoder</code> <p>Coding focused LLM system to continuously improve self.  </p> Language Models can Solve Computer Tasks Uses Recursive Criticism and Improvement. <p>Website, GitHub  Combining with Chain of Thought it is even better. The method: Plan: Critique, Improve  - Explicit RCI: \"Review your previous answer and find problems with your answer.\" \u2192 \"Based on the problems you found, improve your answer.\" Recursively Criticizes and Improves its output. This sort of prompting outperforms Chain of Thought, and combined it works even better.  </p>"},{"location":"Understanding/agents/chains.html#structural-decomposition","title":"Structural Decomposition","text":"Skeleton of Thought <p>A nice structure that resembles the thoughtful creation of answers allows for parallelization and hence speedup, with comparable or better results in answer generation.  </p> <p>Skeleton prompt template<pre><code>    [User:] You\u2019re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n    Provide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full\n    sentence, each skeleton point should be very short with only 3\u223c5 words. Generally, the skeleton should have 3\u223c10\n    points.\n    Question:\n    What are the typical types of Chinese dishes?\n    Skeleton:\n    1. Dumplings.\n    2. Noodles.\n    3. Dim Sum.\n    4. Hot Pot.\n    5. Wonton.\n    6. Ma Po Tofu.\n    7. Char Siu.\n    8. Fried Rice.\n    Question:\n    What are some practical tips for individuals to reduce their carbon emissions?\n    Skeleton:\n    1. Energy conservation.\n    2. Efficient transportation.\n    3. Home energy efficiency.\n    4. Reduce water consumption.\n    5. Sustainable diet.\n    6. Sustainable travel.\n    Now, please provide the skeleton for the following question.\n    {question}\n    Skeleton:\n    [Assistant:] 1.\n</code></pre> Point expanding prompt template<pre><code>    [User:] You\u2019re responsible for continuing the writing of one and only one point in the overall answer to the following\n    question.\n    {question}\n    The skeleton of the answer is\n    {skeleton}\n    Continue and only continue the writing of point {point index}. Write it **very shortly** in 1\u223c2 sentence and\n    do not continue with other points!\n    [Assistant:] {point index}. {point skeleton}\n</code></pre></p> Large Language Model Guided Tree-of-Thought <p>Github</p> Tree of Thoughts: Deliberate Problem Solving with Large Language Models A method that allows for idea-expansion and selection of the final result output by choosing the best at each stage. <p>The thought flow Github</p> <p>\"Prompts compared\" <pre><code>    standard_prompt = '''\n    Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input}\n    '''\n    cot_prompt = '''\n    Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input}\n\n    Make a plan then write. Your output should be of the following format:\n\n    Plan:\n    Your plan here.\n\n    Passage:\n    Your passage here.\n    '''\n\n    vote_prompt = '''Given an instruction and several choices, decide which choice is most promising. Analyze each choice in detail, then conclude in the last line \"The best choice is {s}\", where s the integer id of the choice.\n    '''\n\n    compare_prompt = '''Briefly analyze the coherency of the following two passages. Conclude in the last line \"The more coherent passage is 1\", \"The more coherent passage is 2\", or \"The two passages are similarly coherent\".\n    '''\n\n    score_prompt = '''Analyze the following passage, then at the last line conclude \"Thus the coherency score is {s}\", where s is an integer from 1 to 10.\n    ''' \n</code></pre></p> Meta Tree of thought <p></p> Graph of Thought <p>An excellent thought on what next to consider when dealing with knowledge (or other output like information) generation chains. </p> Strategic Reasoning with Language Models Uses game trees and observed and inferred beliefs to achieve closer to optimal results.  <p>Powerful to consider for inferred beliefs and interacting in situations where negotiation or games are being played. </p> Question Decomposition Improves the Faithfulness of Model-Generated Reasoning <p> A nice discussion on it</p>"},{"location":"Understanding/agents/chains.html#perceptive-decomposition","title":"Perceptive decomposition","text":"<p>Breaking up the topic by considering different personas, within the same model-call partitions can be quite successful. Often systems can be used as well, though the complexity of implementation increases.</p> Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent Through Multi-person Self-Collaboration <p>Uses a prompt that initiates a group of personas to be used within the same LLM call to facilitate collaborative analysis and creation of the final output. Solid improvement but comparisons to other techniques are potentially uncertain. \"Example prompt\" </p> <p>```python title=\"Trivia writing SPP'</p> <pre><code>spp_prompt = '''When faced with a task, begin by identifying the participants who will contribute to solving the task. Then, initiate a multi-round collaboration process until a final solution is reached. The participants will give critical comments and detailed suggestions whenever necessary.\n\nHere are some examples:\n---\nExample Task 1: Use numbers and basic arithmetic operations (+ - * /) to obtain 24. You need to use all numbers, and each number can only be used once.\nInput: 6 12 1 1\n\nParticipants: AI Assistant (you); Math Expert\n\nStart collaboration!\n\nMath Expert: Let's analyze the task in detail. You need to make sure that you meet the requirement, that you need to use exactly the four numbers (6 12 1 1) to construct 24. To reach 24, you can think of the common divisors of 24 such as 4, 6, 8, 3 and try to construct these first. Also you need to think of potential additions that can reach 24, such as 12 + 12.\nAI Assistant (you): Thanks for the hints! Here's one initial solution: (12 / (1 + 1)) * 6 = 24\nMath Expert: Let's check the answer step by step. (1+1) = 2, (12 / 2) = 6, 6 * 6 = 36 which is not 24! The answer is not correct. Can you fix this by considering other combinations? Please do not make similar mistakes.\nAI Assistant (you): Thanks for pointing out the mistake. Here is a revised solution considering 24 can also be reached by 3 * 8: (6 + 1 + 1) * (12 / 4) = 24.\nMath Expert: Let's first check if the calculation is correct. (6 + 1 + 1) = 8, 12 / 4 = 3, 8 * 3 = 24. The calculation is correct, but you used 6 1 1 12 4 which is not the same as the input 6 12 1 1. Can you avoid using a number that is not part of the input?\nAI Assistant (you): You are right, here is a revised solution considering 24 can be reached by 12 + 12 and without using any additional numbers: 6 * (1 - 1) + 12 = 24.\nMath Expert: Let's check the answer again. 1 - 1 = 0, 6 * 0 = 0, 0 + 12 = 12. I believe you are very close, here is a hint: try to change the \"1 - 1\" to \"1 + 1\".\nAI Assistant (you): Sure, here is the corrected answer:  6 * (1+1) + 12 = 24\nMath Expert: Let's verify the solution. 1 + 1 = 2, 6 * 2 = 12, 12 + 12 = 12. You used 1 1 6 12 which is identical to the input 6 12 1 1. Everything looks good!\n\nFinish collaboration!\n\nFinal answer: 6 * (1 + 1) + 12 = 24\n\n---\n\n'''\n</code></pre> <p>```</p>"},{"location":"Understanding/agents/chains.html#constrained","title":"Constrained","text":"Certified Reasoning with Language models A 'logical guide' tool that an LLM can use. <p>It \" uses constrained decoding to ensure the model will incrementally generate one of the valid outputs.\"   Possible open source implementation here</p> Outlines guides the model generation of next-token logits to guide the generation corresponding to regex / json pydantic schema. compatible with all models. <p>Also provides a way to functionalize templates to separate prompt logic.</p>"},{"location":"Understanding/agents/environments.html","title":"Environments","text":"<p>Environments consist of the information that agents have access too as well as 'what can be done' to influence the environment. An environment sends information that an agent can receive. </p> <p>The origin of the information can be 'a person' or a 'data stream' that is based in real-measurements, or a simulation. </p> <p>A chat-environment</p> <p>In a chat environment the GenAI receives text information from a user and then returns text information that is printed for the user to read.</p> <p>A town simulation</p> <p>In Generative Agents: Interactive Simulacra of Human Behavior A town is simulated to provide observable information and an interaction world with/between other agents. </p> <p>A camera and microphone</p> <p>As may be needed for a robot, a camera, and a microphone provide the inputs for the environment that it exists in. The signals received (and processes) only represent a portion of what might potentially be received. </p>"},{"location":"Understanding/agents/evaluation.html","title":"Evaluation","text":"<p>AgentBench: Evaluating LLMs as Agents</p> <p>A comprehensive 8-environment evaluation for different agents from different models. Github</p> Example <p></p>"},{"location":"Understanding/agents/examples.html","title":"Examples","text":"<p>Agent types can be described by direct agentic ability to cause a change in the world.</p>"},{"location":"Understanding/agents/examples.html#text-agent","title":"Text Agent","text":"<p>An agent that can output only language text. Even thought the language can be 'interpreted' into different things, as is done in the environment. </p>"},{"location":"Understanding/agents/examples.html#text-image-agent","title":"Text + Image Agent","text":"<p>An agent that can output </p>"},{"location":"Understanding/agents/examples.html#robotic-agent","title":"Robotic Agent","text":"<p>A robotic agent can control mechanism impacting the mechanical position or other activity of a device. </p> <pre><code>graph TB\n    Agent((Agent)) --&gt;|makes| decision((Decision))\n    decision --&gt;|attempts| action((Action))\n    action --&gt;|passes| execution((Execution))\n    execution --&gt;|affects| environment((Environment))\n    execution --&gt;|generates| agentMemory((Agent's Memory))\n    agentMemory --&gt;|informs and effects| Agent\n    environment --&gt;|provides| observations((Observations))\n    observations --&gt;|informs and effects| Agent\n    execution --&gt;|queries| environment\n    AgentManager((Agent Manager)) --&gt;|affects| execution\n    Agent --&gt; |informs and effects| AgentManager\n    AgentManager --&gt; |informs and effects| Agent</code></pre>"},{"location":"Understanding/agents/examples.html#langchain-focused","title":"Langchain focused.","text":"<p>!!! GPT and PDFS</p>"},{"location":"Understanding/agents/examples.html#agent","title":"Agent","text":"ReAct <ul> <li>Github </li> <li>Effectively Observe, Think, Act, Repeat.</li> </ul> Reflexion: an autonomous agent with dynamic memory and self-reflection an agent with dynamic memory and self-reflection capabilities <p> - Github - Inspired github </p> Learning to Reason and Memorize with Self-Notes Allows model to deviate from input context at any time to reason and take notes <p></p> Large language models as tool makers Github Allows high-quality tools to be reused by more lightweight models. <p></p> CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation <p> </p> smolai https://www.youtube.com/watch?v=zsxyqz6SYp8&amp;t=1s An interesting example Agent-GPT <p>Website \u2192 Doesn't have agency/tools... So it is not good. A fancy wrapper for multi-task planning and execution. Limited at present. </p> AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn <p>Webpage Uses PEIL PLan execute inspect learn.</p> <p>GPT Engineer</p> <p>!!! tip \ufe0f\"Robo-GPT\"</p>  !!! tip \"[DevOpsGPT](https://github.com/kuafuai/DevOpsGPT)\"     <pre><code>Through the above introduction and Demo demonstration, you must be curious about how DevOpsGPT achieves the entire process of automated requirement development in an existing project. Below is a brief overview of the entire process:\n</code></pre>     ![image](https://github.com/ianderrington/genai/assets/76016868/5e60c94c-7c03-4667-ae5f-3a9282cf30c4)     <pre><code>    Clarify requirement documents: Interact with DevOpsGPT to clarify and confirm details in requirement documents.\n    Generate interface documentation: DevOpsGPT can generate interface documentation based on the requirements, facilitating interface design and implementation for developers.\n    Write pseudocode based on existing projects: Analyze existing projects to generate corresponding pseudocode, providing developers with references and starting points.\n    Refine and optimize code functionality: Developers improve and optimize functionality based on the generated code.\n    Continuous integration: Utilize DevOps tools for continuous integration to automate code integration and testing.\n    Software version release: Deploy software versions to the target environment using DevOpsGPT and DevOps tools.\n</code></pre>  ??? tip \"[UniversalNER](https://arxiv.org/pdf/2308.03279.pdf) Used ChatGPT to distill much smaller model for a certain domain, for Universal NER models. Cc-by-4-C distribution\"     <pre><code>\"Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPT\u2019s capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We will release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation.\"\n</code></pre>     https://arxiv.org/pdf/2308.03279.pdf     https://github.com/universal-ner/universal-ner"},{"location":"Understanding/agents/frameworks.html","title":"Frameworks","text":""},{"location":"Understanding/agents/frameworks.html#implementation-frameworks","title":"Implementation Frameworks","text":""},{"location":"Understanding/agents/frameworks.html#langchain","title":"Langchain","text":"<ul> <li>Langchain A primitive python or javascript-based primitive 'LLM' language that enables planned and agentic AI.</li> <li>Langflow </li> <li>Awesome Langchain</li> <li>Toolkit Generates LangChain plugins</li> </ul>"},{"location":"Understanding/agents/frameworks.html#tutorials","title":"Tutorials","text":"<ul> <li>https://www.pinecone.io/learn/langchain-prompt-templates/</li> <li>https://learn.deeplearning.ai/langchain/lesson/3/memory</li> </ul>"},{"location":"Understanding/agents/frameworks.html#llama-index","title":"Llama index","text":"<ul> <li>llama index and Github for integrating data ingestion and models. </li> <li>LlamaHub (community library of data loaders)</li> <li>LlamaLab (cutting-edge AGI projects using LlamaIndex)</li> <li>Ollama.ai Provides on mac silicon Llama2 calling. Has a great idea that resembles docker files for agent creation and pulling.</li> </ul>"},{"location":"Understanding/agents/frameworks.html#others","title":"Others","text":"<ul> <li>Flowise</li> <li>Chain Forge A data flow prompt engineering environment for evaluating ana analyzing LLM responses</li> <li>llm-chain ChatGPT and Alpaca support. Agentic with bash commands.</li> <li>Agent Flow</li> <li>Auto Chain </li> </ul>"},{"location":"Understanding/agents/memory.html","title":"Memory","text":"<p>Agent memory is considered a state associated with a llm-call and effects the ability of LLM to respond, thereby helping to enable agentic ability. Memory augmented models enhance the capabilities of language models by ___ to improve their performance and efficiency. TODO: Read trillions of tokens paper. </p>"},{"location":"Understanding/agents/memory.html#memory-considerations","title":"Memory Considerations","text":"<p>Memory plays a crucial role in enhancing the efficiency of information recall and routing for different chains and agent interactions. </p> <p>In systems comprising Agents (and People), conversation buffers may be employed to keep track of information. These buffers, can be 'private',  can facilitate communication between any agents, storing response stacks that include agent-environment interactions.</p> <p>For text-based memory can consist of perfect text record or compressed summaries, that may or may not follow some form of memory-schema.</p> <p>Memory can be pushed (into prompt templates) and requested (based on GET memory requests from an LLM agent). </p>"},{"location":"Understanding/agents/memory.html#uses","title":"Uses","text":""},{"location":"Understanding/agents/memory.html#input-prompt-caching","title":"Input (prompt) Caching","text":"<p>Input caching is a technique that leverages memory to improve response time and efficiency. Instead of generating tokens based on the next input, it uses caching to identify responses that may have already been generated for similar prompts. This significantly enhances the efficiency of repeated queries. However, it may cause issues if the initial response was not satisfactory, as the system would return the same cached response.</p>"},{"location":"Understanding/agents/memory.html#parsed-information-routing","title":"Parsed information routing","text":"<p>Parsed information routing involves directing parsed or processed information to the appropriate destination. This can be particularly useful in systems with multiple agents or complex workflows.</p>"},{"location":"Understanding/agents/memory.html#implementations","title":"Implementations","text":"<p>Memory implementations can be based on memory types serialized and stored in many ways. Semantic searches can happen by looking at similar embeddings. </p> <p>These can be global or private, and structured inside agent classes or inside system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can be in memory and stored on disk or in the cloud. They allow informaion to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p> <p>Memory implementations can vary based on the type of memory used, and how it's serialized and stored. Semantic searches can be performed by comparing embeddings for similarity. These memory systems can be global or private, and can be structured within agent classes or within system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can exist in memory, stored on disk, or in the cloud. They allow information to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p>"},{"location":"Understanding/agents/memory.html#types","title":"Types","text":""},{"location":"Understanding/agents/memory.html#vector-databases","title":"Vector databases","text":"<p>Vector databases, such as Pinecone, Qdrant, Weaviate, Chroma, Faiss, Redis, Milvus, and ScaNN, use embeddings to create query vector databases. These databases allow for efficient semantic searches. </p> <p>!!! example 'Example vector databases'     Please read this for more information  Vector Databases (primer by Pinecone.io)     - https://github.com/Helicone/helicone     - Website Github</p>"},{"location":"Understanding/agents/memory.html#traditional-databases","title":"Traditional databases","text":"<p>Databases that rely on query-languages such as SQL or non-SQL based databases, or even 'csv-type' information stores can be accessed and generated using agents. </p> <p>The models may generate queries that can be executed by by an interpreter, though it is not guaranteed that the queries will be accurate. TODO: Find reference</p> <p>References</p> <p>For more information on memory implementations and caching, refer to the following resources:</p> <ul> <li>Langchain <code>memory</code></li> <li>Langchain <code>llm_caching</code></li> <li>Improving language models by retrieving from trillions of tokens</li> </ul>"},{"location":"Understanding/agents/systems.html","title":"Systems","text":"<p>When an agent (or model) engages in an interaction with another agent, the result is an agent system. This is achieved by implementing and equipping various agents, and then setting them up so that the output of one is used as the input of the other. Although one may argue that an agent's input can be perceived as another 'tool' where the different agent prompts the action, this argument isn't entirely valid. The reason is that, in most cases, the same considerations apply to all agents but not to all tools. Therefore, we deal with it separately.</p> <p>Binary system (asymmetric calling)</p> <p>In this system, ChatGPT initiates communication with DallE using a prompt. DallE responds by delivering an image. This image is then used in the final response of ChatGPT or returned as-is.</p> <p>Multi-body system (bidirectional calling)</p> <p>This system consists of multiple agents, and they engage in ongoing discussions about their daily activities. They also receive regular updates about their environment. An example of this type of system can be viewed in this paper.</p>"},{"location":"Understanding/agents/systems.html#research","title":"Research","text":"<p>MetaGPT</p> <p>MetaGPT enables different agents to interact and generate meaningful outputs based on varying tasks and personas. It's a reliable partially-formed solution. Check out the code for further knowledge!</p> <p>Self-play GPT</p> <p>This model leverages different game-roles and LLMs to provide feedback on how to optimize the model and facilitate autonomous enhancement during gameplay.</p> <p>Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind</p> <p>In this work, the Theory of Mind (ToM) concept is used to attempt to improve the performance of students. Github</p> Generative Agents: Interactive Simulacra of Human Behavior in a simulated town!!! <p>This paper discusses a simulation involving different agents exhibiting different personalities. The dynamic environment, shared in code can be manipulated by these agents. The paper explores various challenges and proposed solutions including: <pre><code>**Remembering**\n    _Observation Memory_ This is a memory stream that maintains a record of past experiences. These experiences are stored in \"memory objects\", which are described in natural language, and timestamped. The importance of each memory object is determined using metrics such as _recency_, _importance_, and _relevance_. \n    _Reflection Memory_ This memory type allows the agent to generate more abstract thoughts. These thoughts can be included along with reflections. This process is hardcoded to occur when the sum of importance scores exceeds a certain threshold.\n**Planning and Reacting**\n    _Recursive Planning_ In this process, the agent divides the day into chunks of \"goals\", which are further broken down into smaller time frames. The ability to adjust these plans based on interactions is a key feature of this mechanism.\n</code></pre></p> <p>Multi-Agent Collaboration via Reward Attribution Decomposition</p> <p>This work illuminates optimization techniques for multi-agents using distributed reward systems to achieve state-of-the-art performance. It introduces a joint optimization approach that depends on self and interactive terms.</p> <p>Super-AGI</p> <p>Super-AGI is a model that allows multiple agents to function. However, this system doesn't facilitate any communication between the agents.</p> <p>GPT-Bargaining</p> <p>This model applies several iterations to improve negotiation tactics based on external feedback.</p> <p>RL4L Allen ai</p> <p>RL4L AI employs a small critique model to enhance the output from the larger model. It uses a policy gradient to fine-tune the critique model while maintaining reasonable performance gains. Github</p> Showrunner Agents The Showrunner Agents use Large Language Models (LLMs) to generate episodic content. <p>It's a massively creative and multi-faceted process with a great potential. </p> <p>??? tip \"Improving Factuality and Reasoning in Language Models through Multiagent Debate     \"multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer.\"     They tried both concatenation or summarization of other results. Summarization reduces length and improves quality.      <pre><code>    # Debate Length Prompt\n    short_prompt = \"\"\" These are the solutions to the problem from other agents: {other_answers}\n        Based off the opinion of other agents, can you give an updated response . . .\"\"\"\n    long_prompt = \"\"\" These are the solutions to the problem from other agents: {other_answers}\n        Using the opinion of other agents as additional advice, can you give an updated response . . .\"\"\"\n</code></pre> Github</p> <p>??? tip \"Council      Very promising initial creation of networks of agents to create full-fledged teams for output products.      </p>"},{"location":"Understanding/agents/systems.html#open-source-implementations-unpublished","title":"Open Source Implementations (unpublished)","text":"<p>Swarms</p> <p>Very thoughtful next-level systems focusing on large-dimensions of swarms. Very initial stages but has a lot of promise.  Github</p>"},{"location":"Understanding/agents/systems.html#potentially-useful-tools","title":"Potentially useful tools","text":"<p>Nomadproject.io A simple and flexible scheduler and orchestrator to deploy and manage containers and non-containerized applications across on-prem and clouds at scale.</p> <p>Firecracker 'Our mission is to enable secure, multi-tenant, minimal-overhead execution of container and function workloads.'</p>"},{"location":"Understanding/background/tensor_maths.html","title":"Tensor maths","text":"<p>Tensor math is linear algebra on steroids. Here are some valuable resources to understand it better.</p> <p>TODO: Add all of the tensor series. </p> <p>https://www.kolda.net/publication/TensorReview.pdf</p> <p>https://arxiv.org/pdf/2308.01814.pdf</p> The Tensor Programs: 1 <p>Ouput embeddings of two samples will be i.I.d. under randompermutations. Introduces generalization to Tensors and creates  NETSOR  Computation Programs Introduces three general mapping types of function variables.</p> <pre><code>NETSOR programs are straight-line programs, where each variable follows one of three types, G, H, or A (such variables are called G-vars, H-vars, and A-vars), and after input variables, new variables can be introduced by one of the rules MatMul, LinComb, Nonlin to be discussed shortly. G and H are vector types and A is a matrix type; intuitively, G-vars should be thought of as vectors that are asymptotically Gaussian, H-vars are images of G-vars by coordinatewise nonlinearities, and A-vars are random matrices with iid Gaussian entries. Each type is annotated by dimensionality information:\n\nIf x is a (vector) variable of type G (or H) and has dimension n, we write x : G(n) (or x : H(n)).\nIf A is a (matrix) variable of type A and has size n1 \u00d7 n2, we write A : A(n1, n2)\nG is a subtype of H, so that x : G(n) implies x : H(n). \n</code></pre> <p>G is petty much a \u2018pass through\u2019 like an activation function. </p> <p>This a Github implementation </p> Tensor Programs IVb: Adaptive Optimization in the \u221e-Width Limit Demonstrates how to scale hyperparameters when changing widths of feature parameters generally <p>Micro update </p> <p>\"We show that optimal hyperparameters become stable across neural network sizes when we parametrize the model in maximal update parametrization (\u03bcP). This can be used to tune extremely large neural networks such as large pretrained transformers, as we have done in our work. More generally, \u03bcP reduces the fragility and uncertainty when transitioning from exploration to scaling up, which are not often talked about explicitly in the deep learning literature.\"</p>"},{"location":"Understanding/data/index.html","title":"Data","text":"<p>Data is the most important part of training any model. </p>"},{"location":"Understanding/data/index.html#amount-of-data-needed","title":"Amount of data needed.","text":"<p>The larger the model, the more data is needed. A rough order of estimate is that the number of tokens should be 10x the number of parameters used by the model. </p> Training Compute-Optimal Large Language Models The 'Chinchilla' paper of 2022, identifies scaling laws that help to understand the volume of data that is needed <p>to obtain 'optimal' performance for a given LLM models size. Use of it in other areas, such as for Llama reveals that the models may have been under-trained. - Primary takeaway: **\"All three approaches suggest that as compute budget increases, model size and the amount of training data should be increased in approximately equal proportions.\"  </p>"},{"location":"Understanding/data/index.html#bath-sizes-of-data-needed","title":"Bath sizes of data needed...","text":"<p>TODO</p>"},{"location":"Understanding/data/index.html#training-with-generated-data","title":"Training with generated data.","text":"<p>It is possible and sometimes even peferred to train with generated data produced by other models. There are notable concerns, however, as some evidence indicates that training with generated data can yield worse results, and if done consistently, can lead to complete degredation of model performance.  </p> Textbooks are all you need Used a volume of generated data, and transformer-classifiers to filter data to create a high quality coding-focused model. <p>Used 4 days on 8 A-100s to train to reach out-performing results. </p>"},{"location":"Understanding/data/embedding.html","title":"Embedding","text":"<p>Embeddings play a key role in AI as they translate tokens into numerical representation that can be processed by the AI. </p> <p>'What are Embeddings' is an essential read that elucidates the concept of embeddings in a digestible manner. For a deeper dive, check the accompanied Github page.</p>"},{"location":"Understanding/data/selection.html","title":"Selection","text":"<p>Data selection acts as the backbone for training generative AI models. Without suitable data and an optimal selection strategy, it might be challenging to develop models that provide useful and relevant outputs.</p>"},{"location":"Understanding/data/selection.html#why-is-data-selection-important","title":"Why is Data Selection Important?","text":"<p>Data selection forms the initial step in any machine learning project. Selecting the right data can help train your GenAI model more efficiently and accurately. Improper data selection, and balancing, can cause you models to fail all together, or more insideously induce output biases that are of ethical concern </p>"},{"location":"Understanding/data/selection.html#role-in-training-models","title":"Role in Training Models","text":"<p>The right data selection dictates how well a model can generate the desired output. It decides what the design and parameters of the model will be.</p>"},{"location":"Understanding/data/selection.html#impact-on-model-performance","title":"Impact on Model Performance","text":"<p>The quality and relevance of selected data have a direct impact on the performance of the model. The right selection reduces the risk of overfitting and underfitting.</p>"},{"location":"Understanding/data/selection.html#strategies-for-effective-data-selection","title":"Strategies for Effective Data Selection","text":"<p>There are several strategies to ensure the data used for training Generative AI models is selected effectively.</p>"},{"location":"Understanding/data/selection.html#understanding-your-data","title":"Understanding Your Data","text":"<p>Before selecting data, take time to understand the data you have. Analyzing the data to identify patterns, trends or anomalies will give some direction on what data to use.</p>"},{"location":"Understanding/data/selection.html#choosing-relevant-data","title":"Choosing Relevant Data","text":"<p>Relevancy of data to the problem at hand is crucial. Inappropriate data can lead to inaccurate results and will impede the model\u2019s performance.</p>"},{"location":"Understanding/data/selection.html#balancing-your-dataset","title":"Balancing Your Dataset","text":"<p>In order to train an effective Generative AI model, it's important to balance your dataset. An imbalanced dataset could lead your model to be biased towards the class that is overrepresented. </p>"},{"location":"Understanding/data/selection.html#tools-for-data-selection","title":"Tools for Data Selection","text":"<p>There are different tools that can aid in effective data selection.</p>"},{"location":"Understanding/data/selection.html#automated-data","title":"Automated Data","text":"<p>Automated machine learning tools can greatly simplify data selection by providing features for automatic feature selection, data cleaning and preprocessing.</p>"},{"location":"Understanding/data/sources.html","title":"Sources","text":""},{"location":"Understanding/data/sources.html#data-sources","title":"Data sources","text":"<p>RedPajama Pile CommonCrawl (webscrape) C4 (CommonCrawl) Github Books Arxiv StackExchange</p> <ul> <li> <p>unarXive 2022: All arXiv Publications Pre-Processed for NLP</p> </li> <li> <p>Redpajama</p> </li> <li>BIG-bench</li> <li>Metaseq</li> <li>Kaggle-code</li> </ul>"},{"location":"Understanding/data/tokenizing.html","title":"Tokenizing","text":"<p>In generative AI, the raw data\u2014whether it be in binary, text, or a different form\u2014is divided into individual units termed as tokens. These play a crucial role in easing the understanding and manipulation of data for the AI.</p>"},{"location":"Understanding/data/tokenizing.html#understanding-tokenization","title":"Understanding Tokenization","text":"<p>Tokenization is the process of splitting data into these individual units. The choice of a token largely depends on the data type and the expected outcome of the AI. In text data, for instance, tokens often correspond to single words or subwords. </p>"},{"location":"Understanding/data/tokenizing.html#subword-units","title":"Subword Units","text":"<p>A subword unit, or a part of a word, can be a token in itself. The paper titled Neural Machine Translation of Rare Words with Subword Units brings to light the effectiveness of subword units in improving results. This type of tokenization was used in a neural machine translation system and it significantly improved the handling of rare words.</p>"},{"location":"Understanding/data/tokenizing.html#special-tokens","title":"Special tokens","text":"<p>There are special tokens that are used by high-level interpreters on what next to do. </p> Token Name Description START_TOKEN or BOS_TOKEN This is used to indicate the beginning of a sequence. BOS stands for \"Beginning Of Sequence\". STOP_TOKEN or EOS_TOKEN This is used to indicate the end of a sequence. EOS stands for \"End Of Sequence\". MASK_TOKEN This is used to represent a masked value, which the model needs to predict. MODALITY_TOKEN This is used to indicate the type of data in the sequence (such as text, images, etc.)"},{"location":"Understanding/data/tokenizing.html#multimodal-tokenization","title":"Multimodal Tokenization","text":"<p>Multimodal tokenization is an area of tokenization that focuses on incorporating multiple data forms or modes. This facet of tokenization has seen remarkable strides. Bytes are all you need\u2014a study utilizing transformer technology to input file bytes directly\u2014demonstrates that multimodal tokenization can assist in improving the AI's performance accuracy. The researchers in the study developed ByteFormer, a model based on their study\u2019s findings that can be accessed here.</p>"},{"location":"Understanding/data/tokenizing.html#tokenizing-might-not-be-necessary","title":"Tokenizing might not be necessary","text":"<p>It is regarded that tokenizing is a bit arbitrary and has disadvantages. There are promising results using methods without tokenization MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers that \"show that MEGABYTE allows byte-level models to perform competitively with subword models on long context language modeling\"</p>"},{"location":"Understanding/data/tokenizing.html#tools","title":"Tools","text":"<p>Examples of coding tools that facilitate tokenization include Tiktoken which utilizes Byte Pair Encoding (BPE) for tokenization and is purportedly used in GPT models. An alternative tool is 2, which takes a unique top-down approach and results in almost 35% less tokens as opposed to the standard bottom-up approach.</p>"},{"location":"Understanding/data/tokenizing.html#open-source-tokenizers","title":"Open Source Tokenizers","text":"<ul> <li>Sentence Piece implements subword units (e.g., byte-pair-encoding (BPE) ) and unigram language model 1</li> <li>Tiktoken</li> <li>Token Monster</li> </ul>"},{"location":"Understanding/data/tokenizing.html#references","title":"References","text":"<ul> <li>Neural Machine Translation of Rare Words with Subword Units</li> <li>Bytes are all you need</li> <li>ByteFormer Github What are EmbeddingsGithub</li> </ul> <ol> <li> <p>Kudo \"subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training\". Effectively, this takes aliasing-like effects that cause different tokenization. It is more effective because it breaks it down in different ways.\u00a0\u21a9</p> </li> <li> <p>Token Monster \u21a9</p> </li> </ol>"},{"location":"Understanding/models/index.html","title":"Models","text":"<p>Here we will discuss the models essential components of Gen()AI. Please see the Trained Models for specific manners of implementing, deploying, or otherwise using these models.</p> <p>We discuss the general complete models used in creating Generative AI. Initial incarnations of this will focus on the most observably promising core-models, transformers often called <code>General Pretrained Transformers</code>.  </p> <p>Because we generally call Gen()AI with language inputs, there are different ways to use language to achieve the appropriately desired results. These inputs, prompts will be model-specific, but may share commonalities for more-optimal usage and we discuss that more thoroughly here</p> <p>Generative AI models are of two general categories: self-supervised, and Externally-supervised, and hybrid models. Generally, self-supervised models pass into external supervision to improve the quality of the output as part of reinforcement learning</p> <p>Self-supervision amounts to using a single data entry itself to train a model, without interacting with other data points. For instance, a model is used to predict the next word in a string of text (as done with GPT's) or </p> <p>Because of their present degree of quality present model Architectures tend to be transformer-based, or diffusion-based, though they can also be hybrids, or made from any other standard AI method. While Generative Adversarial Networks, GANS were the initially most successful, the challenges in training them successfully can be difficult to surmount. </p>"},{"location":"Understanding/models/index.html#models","title":"Models","text":"<ul> <li>Transformers</li> <li>Diffusers</li> <li>Generative Adversarial Networks</li> <li>Reinforcement Learning</li> <li>Developing Architectures</li> </ul>"},{"location":"Understanding/models/index.html#references","title":"References","text":"<ul> <li> <p>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </p> </li> <li> <p>Understanding Large Language Models</p> </li> </ul>"},{"location":"Understanding/models/index.html#self-supervised-learning","title":"Self-supervised learning.","text":"Llama 2: Open Foundation and Fine-Tuned Chat Models A nearly open source set of 7B-70B models with quality performance Shepherd: A Critic for Language Model Generation A 7B model trained to critique outputs <p>Example chat response </p> Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data Parameter efficient LLama Tuning and risk minimization <p>with a new 'Self Distillation' with Feedback to improve itself even more. RESEARCH ONLY </p>"},{"location":"Understanding/models/index.html#mixture-of-experts","title":"Mixture of Experts","text":""},{"location":"Understanding/models/index.html#multimodal","title":"MultiModal","text":"<p>There are two primary domains of Generative AI, text-oriented or image-oriented, though there is great indication that many other (multi-)modalities will be very important for the future. </p> SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs A really cool idea that uses pyramidal representations and compresses information into text-tokens of different levels. <p>It can reconstruct it as need be. These tokens then could be used in novel image generation via semantic mapping with an LLM. </p>"},{"location":"Understanding/models/index.html#model-agnostic-improvements","title":"Model agnostic improvements","text":"<ul> <li>Learning to Compress Prompts with Gist Tokens. Can enable 26x compression and 40% FLOP reduction and improvements. Trains 'gist tokens' to summarize information. </li> </ul>"},{"location":"Understanding/models/index.html#to-sort","title":"TO SORT","text":"<ul> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements. </li> </ul>"},{"location":"Understanding/models/alignment.html","title":"Alignment","text":"<p>Raw generative models do not generally produce globally accurate outputs given input prompts. 1 </p> <p>Global alignment </p> <p>Ensuring the output of models are appropriately capable of </p> <ol> <li> <p>We will be describing text-focused models in this discussion though variations can be appropriately considered for other domains and datatypes This is due to the manner of training and next-word-prediction (or more arbitrary masked-word prediction) is probabilistically 'greedy'. Namely, within a sampling of outputs, the next-prediction will be sampled based on their immediate likelihood. To improve the outputs, the models are further refined using various approaches. These approaches 'align' the output to accurately considered\u00a0\u21a9</p> </li> </ol>"},{"location":"Understanding/models/evaluation.html","title":"Evaluation","text":"<p>The evaluation of models helps us to identify which, if any, model to use for a particular task at hand. Directly related to the manner of pre-training, fine-tuning, and any RLHF, the ways that we consider the output can also be used to improve the models. </p>"},{"location":"Understanding/models/evaluation.html#measure-what-matters","title":"Measure what matters","text":""},{"location":"Understanding/models/evaluation.html#general-discussions","title":"General Discussions","text":"How do we know how smart AI systems are? <p>\u201cAI systems, especially generative language systems like GPT-4, will become increasingly influential in our lives, as will claims about their cognitive capacities. Thus, designing methods to properly assess their intelligence\u2014and associated capabilities and limitations\u2014is an urgent matter. To scientifically evaluate claims of humanlike and even superhuman machine intelligence, we need more transparency on the ways these models are trained, and better experimental methods and benchmarks. Transparency will rely on the development of open-source (rather than closed, commercial) AI models. Better experimental methods and benchmarks will be brought about through collaborations between AI researchers and cognitive scientists who have long investigated how to do robust tests for intelligence, understanding, and other cognitive capabilities in children, animals, and other \u201calien\u201d intelligences.\u201d</p>"},{"location":"Understanding/models/evaluation.html#metrics","title":"Metrics","text":"<ul> <li>Exact Match (EM)  TODO: Finish this</li> </ul>"},{"location":"Understanding/models/models.html","title":"Models","text":""},{"location":"Understanding/models/models.html#self-supervised-learning","title":"Self-supervised learning.","text":"<ul> <li>Diffusion LLMs</li> </ul> <p>Alignment methods.</p> <p>Additional models come up all the time.</p> <ul> <li>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity. </li> </ul> Llama 2: Open Foundation and Fine-Tuned Chat Models A nearly open source set of 7B-70B models with quality performance <p></p> Shepherd: A Critic for Language Model Generation A 7B model trained to critique outputs <p>Example chat response </p> Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data Parameter efficient LLama Tuning and risk minimization <p>with a new 'Self Distillation' with Feedback to improve itself even more. RESEARCH ONLY </p> <p>dic&gt;</p>"},{"location":"Understanding/models/models.html#mixture-of-experts","title":"Mixture of Experts","text":""},{"location":"Understanding/models/models.html#multimodal","title":"MultiModal","text":"SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs A really cool idea that uses pyramidal representations and compresses information into text-tokens of different levels. <p>It can reconstruct it as need be. These tokens then could be used in novel image generation via semantic mapping with an LLM.  </p> <p>??? tip Multimodal Neurons in Pretrained Text-Only Transformers Neat demonstration     i    \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.\"  </p>"},{"location":"Understanding/models/models.html#model-agnostic-improvements","title":"Model agnostic improvements","text":"<p>Learning to Compress Prompts with Gist Tokens. Can enable 26x compression and 40% FLOP reduction and improvements. Trains 'gist tokens' to summarize information.</p>"},{"location":"Understanding/models/models.html#to-sort","title":"TO SORT","text":"<ul> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements. </li> </ul>"},{"location":"Understanding/models/rag.html","title":"Retrieval-Augmented Generation","text":"<p>Becuase models are expensive to update it can be easier to get information and then feed that into the model. </p>"},{"location":"Understanding/models/rag.html#todo","title":"TODO","text":""},{"location":"Understanding/models/reinforcement_feedback.html","title":"Reinforcement feedback","text":"<p>Reinforcement Feedback </p>"},{"location":"Understanding/models/reinforcement_feedback.html#useful-descriptions","title":"Useful descriptions.","text":"<p>??? code WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct)</p> <p>Fabic is a technique to incorporate iterative feedback into the generative process of diffusion models based on StableDiffusion.</p> <p>Github</p>"},{"location":"Understanding/models/training.html","title":"Training","text":"<p>Training GenAI will generally be domain/modality specific.</p> <ol> <li>Self-supervised pretraining: Predicts next token. </li> <li>Supervised pretrainign: Trains to give generally expected output.</li> <li>Reinforcement Learning with Human Feedback: Trains a reward model that is used with Proximal Policy Optimization (PPO) to produce aligned output. </li> </ol> <p>Basics: Distributed Training https://neptune.ai/blog/distributed-training-frameworks-and-tools</p> <ul> <li>LLM Engineering by Huyen Chip</li> </ul>"},{"location":"Understanding/models/training.html#rlhf","title":"RLHF","text":""},{"location":"Understanding/models/training.html#frameworks","title":"Frameworks","text":"<ul> <li>Levanter (not just LLMS)  Codebase for training FMs with JAX. Using Haliax for naming tensors field-names instead of indexes. (for example Batch, Feature....). Full sharding and distributable / parallelizable. </li> <li> <p>DeepSpeed ZeRO++ A framework for accelerating model pre-training, finetuning, RLHF updating.  by minimizing communication overhead. A likely essential concept to be very familiar with. </p> </li> <li> <p>RL4LMs by microsoft A modular RL library to fine-tune language models to human preferences. paper</p> </li> </ul>"},{"location":"Understanding/models/training.html#methods-and-improvements","title":"Methods and Improvements","text":""},{"location":"Understanding/models/training.html#fine-tuning-using-distillation","title":"Fine Tuning using Distillation","text":"<p>Train on model trains a new model on the output of a new model.  - Alpaca </p>"},{"location":"Understanding/models/training.html#fine-tuning-optimizations","title":"Fine tuning Optimizations","text":"<ul> <li>Full Parameter Fine-Tuning for Large Language Models with Limited Resources. Introduces LOMO: LOw-Memory Optimization to fuse </li> </ul>"},{"location":"Understanding/models/training.html#adapter-layers","title":"Adapter layers","text":"<ul> <li>AdapterHub: A Framework for Adapting Transformers Website Adapters are efficient and performant layers that can optimize performance without needing to do inefficient fine-tuning. </li> </ul>"},{"location":"Understanding/models/training.html#rlhf_1","title":"RLHF","text":"<ul> <li> <p>RLHF: Reinforcement Learning from Human Feedback A splendid summary of the RLHF system. </p> </li> <li> <p>RLHF basics by hugging face A realy good intro to parse again.</p> </li> <li>RLHF for Palm in Pytorch</li> <li>AligningLargeLanguageModelsthroughSyntheticFeedback Using a heirarchy of systems to </li> </ul>"},{"location":"Understanding/models/training.html#ai-enabled-ranking","title":"AI-enabled ranking","text":"<ul> <li>Can foundation models label data like humans? using GPT to review model outputs produced biased results. Changing the prompt doesn't really help to de-bias it. Lots of additional considerations surrounding model evaluation</li> </ul>"},{"location":"Understanding/models/training.html#mixture-of-experts","title":"Mixture of Experts.","text":"<ul> <li>Scaling Expert Language Models with Unsupervised Domain Discovery \"parse language models on arbitrary text corpora. Our method clusters a corpus into sets of related documents, trains a separate expert language model on each cluster, and combines them in a sparse ensemble for inference. This approach generalizes embarrassingly parallel training by automatically discovering the domains for each expert, and eliminates nearly all the communication overhead of existing sparse language models. \"</li> </ul>"},{"location":"Understanding/models/training.html#pruning-and-compression","title":"Pruning and compression","text":"<ul> <li>SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot Remove up to ~50% parameters preserving </li> <li>SqueezeLLM They are able to have 2x fold in model size for equivalent performance in perplexity. They use 'Dense and SParce Quantization' Github</li> </ul>"},{"location":"Understanding/models/classes/index.html","title":"Classes","text":"<p>Architectures:</p> <ul> <li>Encoder-Decoder (EDT), is also sequence-to-sequence. </li> <li>Encoder-only: (BERT)</li> <li>Decoder-only (GPT) Next-token </li> <li>Multi-domain decoder-only transformer (Gato)</li> </ul>"},{"location":"Understanding/models/classes/index.html#established-architectures","title":"Established Architectures","text":""},{"location":"Understanding/models/classes/index.html#developing-architectures","title":"Developing Architectures","text":"<p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p>"},{"location":"Understanding/models/classes/components.html","title":"Components","text":"<p>The components of model classes include a number of operations. </p>"},{"location":"Understanding/models/classes/components.html#activation-functions","title":"Activation Functions","text":""},{"location":"Understanding/models/classes/components.html#softmax","title":"Softmax","text":"<p>Softmax is an activation function that computes a probability-like output for logistic outputs. Generally given in the form</p> <p>(softmax(x))\ud835\udc56=exp(\ud835\udc65\ud835\udc56)\u2211\ud835\udc57exp(\ud835\udc65\ud835\udc57) $$ softmax(x_i) = \\exp(x_i)/\\sum_j\\exp(x_j) $$</p>"},{"location":"Understanding/models/classes/components.html#is-softmax-off-by-1","title":"Is softmax Off by 1?","text":"<p>Based on some observations by Qualcom, where \"97%+ of outlier activations in LLMs occur in whitespace and punctuation positions.\u201d  there was indication that it is important to have 'no attention' given to some tokens. Adding a \\(1\\) to the demonimator allows for <code>no attention</code> to be had. This is describe here, discussed here and already found in the flaxformer architecture. A general conclusion is that it is likely more important for highly quantized weights, but 32 and 16 bit dtypes are probably unaffected. </p>"},{"location":"Understanding/models/classes/developing_architectures.html","title":"Developing architectures","text":"<p>Here we share novel and promising architectures that may supplement or supplant other presently established models.</p>"},{"location":"Understanding/models/classes/developing_architectures.html#models","title":"Models","text":"<p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p>"},{"location":"Understanding/models/classes/diffusers.html","title":"Diffusers","text":""},{"location":"Understanding/models/classes/diffusers.html#this-has-yet-to-be-built-thanks-for-bearing-with-me","title":"This has yet to be built! Thanks for bearing with me.","text":""},{"location":"Understanding/models/classes/diffusers.html#references","title":"References","text":"<ul> <li>Diffusion Models</li> </ul>"},{"location":"Understanding/models/classes/gans.html","title":"Gans","text":""},{"location":"Understanding/models/classes/gans.html#this-page-is-under-construction","title":"This page is under construction.","text":""},{"location":"Understanding/models/classes/reinforcement_learning.html","title":"Reinforcement learning","text":"<p>Reinforcement learning-based models have a colorful history. </p> <p>TODO</p>"},{"location":"Understanding/models/classes/reinforcement_learning.html#reinforcement-learning-with-human-feedback-rlhf","title":"Reinforcement Learning with Human Feedback (RLHF)","text":"<p>RLFH has been found to be an essential component to enabling GPT based GenAI to be performant. </p> <p>TODO</p>"},{"location":"Understanding/models/classes/reinforcement_learning.html#notable-research","title":"Notable research","text":"Learning to Model the World with Language Uses multimodal agents to build world models to act in. <p>Also introduces Homegrid evaluation game. Fun continuous multimodal agent. Github </p>"},{"location":"Understanding/models/classes/transformers.html","title":"Transformers","text":"<p>TODO</p>"},{"location":"Understanding/models/classes/transformers.html#components","title":"Components","text":"<p>TODO: Describe transformers and components</p> <ol> <li>Attention: Query, Key, Vectors</li> <li>Positional Encoding</li> <li>Layer Normalization</li> </ol>"},{"location":"Understanding/models/classes/transformers.html#attention-models","title":"Attention Models","text":"<p>Layer normalization observably improves results On Layer Normalization in the Transformer Architecture</p>"},{"location":"Understanding/models/classes/transformers.html#reviews","title":"Reviews","text":"<p>??? tip The Illustrated Transformer</p> <p>??? tip The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture     A thorough exposition of transformer technology.</p>"},{"location":"Understanding/models/classes/transformers.html#softmax","title":"Softmax?","text":"<p>The softmax is dominantly researched activation function. There may be other activation functions that are better, such as the </p>"},{"location":"Understanding/models/classes/transformers.html#gpt","title":"GPT","text":"<ul> <li>Illustrated GPT</li> <li>How GPT3 works Excellent summary of the progress of GPT over time, revealing core components, optimizations, and essential variations to the major Foundation model architectures.</li> </ul>"},{"location":"Understanding/models/classes/transformers.html#useful-references-and-research","title":"Useful References and Research","text":""},{"location":"Understanding/models/classes/transformers.html#general-introductions","title":"General Introductions","text":"<ul> <li> <p>Transformers by Lucas Beyer (presentation)</p> </li> <li> <p>Five years of progress in GPTs</p> </li> <li> <p>The Transformer Architecture of GPT Models</p> </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#seminal-documents","title":"Seminal documents","text":"<ul> <li> <p>Neural Machine Translation by Jointly Learning to Align and Translate First paper indicating the notion of 'attention' sort of mechanism.</p> </li> <li> <p>Attention Is All you Need Initial paper indicating that attention is very powerful and potential replacement of LLM architectures. </p> </li> <li> <p>Formal Algorithms for Transformers in 2023 Important discussion revealing the components of Transformers.</p> </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#positional-encoding","title":"Positional Encoding","text":"<p>This component helps to remove the impilcit position-independence that 'vanilla' attention methods have.  </p> <ul> <li> <p>A Gentle Introduction to Positional Encoding in Transformer Models, pt1</p> </li> <li> <p>Transformer Language Models without POsitional Encodings STill Learn Positional Information Indications that causal LMS may derive positional awareness from more than the positional embeddings: they learn it from the causal mask. </p> </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#modifications","title":"Modifications","text":"<ul> <li>A Simple yet Effective Learnable Positional Encoding Method for Improving Document Transformer Model They introduce a learnable sinusoidal positional encoding feed forward network. Demonstrates significant improvements over other datasets. </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#improvements-optimizations-and-variations","title":"Improvements, Optimizations, and Variations.","text":"<ul> <li> <p>Scaling Transformer to 1M tokens and beyond with RMT Github Uses a Recurrent Memory Transformer(RMT) architecture to extend understanding to large lengths. </p> </li> </ul> <p>MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers</p> <p>MEGABYTE segments sequences into patches and uses a local submodel within patches and a global model between patches. Very nice demonstration that allows for \\(O(N^{4/3}\\) scaling directly on bytes, thereby bypassing tokenization requirements found with traditional transformers.</p> Note <p></p> <ul> <li>Hyena Architecture Uses inspiration from FFT to create a drop in replacement for Transformer models. </li> </ul> <p>Infinite former</p> <p>Uses a representation of the input sequence as a continuous signal expressed in a combination of N radial basis functions. Promising but potentially complex. Worth consideration.</p> Note <p>Github </p>"},{"location":"Understanding/models/classes/transformers.html#computation-reduction","title":"Computation Reduction","text":"<p>SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression</p>"},{"location":"Understanding/models/classes/transformers.html#fine-tuning","title":"Fine Tuning","text":"<p>Using examples to fine-tune a model can reduce the number of tokens needed to achieve a sufficiently reasonable response. Can be expensive to retrain though.</p> <p>Symbol Tuning Improves in-context learning in Language Models</p> Note <p></p>"},{"location":"Understanding/models/classes/transformers.html#other-modalities","title":"Other modalities","text":""},{"location":"Understanding/models/classes/transformers.html#vision","title":"Vision","text":""},{"location":"Understanding/models/classes/transformers.html#graphs","title":"Graphs","text":"<p>Transformers Meet Directed Graphs</p> <p>An interesting-if-also-complex variation of Transformer GNNs that uses 'direction-aware' positional encodings to help handle both undirected and directed graphs.</p> Note <p></p> <p></p>"},{"location":"Understanding/models/classes/transformers.html#training-variations","title":"Training variations","text":""},{"location":"Understanding/models/classes/transformers.html#fairness-enablement","title":"Fairness Enablement","text":"<ul> <li>Concept Erasure</li> </ul>"},{"location":"Understanding/models/classes/transformers.html#using-knowledge-links","title":"Using Knowledge Links","text":"<ul> <li>LinkBERT places in the context window hyperlinked references to achieve better performance and is a drop-in replacement for BERT models. </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#multimodal","title":"Multimodal","text":"<ul> <li>Visual GPT</li> <li>Language is not all you need</li> <li>Meta-Transformer: A Unified Framework for Multimodal Learning The first framework to perform unified learning across 12 modalities with unpaired data. It does so by learning an embedding that can be shared across the modalities. Github </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#abstractions","title":"Abstractions","text":"<ul> <li>Looped Transformers and Programmable Computers Understanding that transformer networks can simulate complex algorithms when hardcoded with specific weights and made intoa  loop. 'Machine Learning' 'Machine code'. \"We demonstrate that a constant number of encoder layers can emulate basic computing blocks, including embedding edit operations, non-linear functions, function calls, program counters, and conditional branches. Using these building blocks, we emulate a small instruction-set computer.\"</li> </ul>"},{"location":"Understanding/models/classes/transformers.html#code","title":"Code","text":"<ul> <li>Hugging Face Transformers An API to access a large number of pre-trained transformers. Pytorch based. </li> <li>Fast Transformers A quality collection of a number of transformer implementations written in Pytorch. </li> </ul>"},{"location":"Understanding/models/classes/transformers.html#_1","title":"Transformers","text":""},{"location":"Understanding/models/prompt_engineering/prompt_injections.html","title":"Prompt engineering","text":"<p>Prompt injections involve the modification of an input prompt prior to model processing. </p> <p>Use of prompt injections, also 'prompt hacking' can allow for intentional bypasses of any pre-established alignment guardrails thereby enabling non-aligned output to occur. </p> <ul> <li>Universal and Transferable Adversarial Attacks on Aligned Language Models and paper demonstrate generally presently undefended attacks on models just by appending to the prompt. Prompt injection. </li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html","title":"Prompting","text":""},{"location":"Understanding/models/prompt_engineering/prompting.html#llm-prompting","title":"LLM Prompting","text":"<ul> <li> <p>LLM Practical Guide based on paper.</p> </li> <li> <p>Prompting Guide</p> </li> <li>Wolfram Prompt Repo</li> <li>Prompt Engine (MSFT) database tool MIT license</li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#llm-prompting_1","title":"LLM Prompting","text":"<ul> <li>Prompting Guide</li> <li>Wolfram Prompt Repo</li> <li> <p>Prompt Engine (MSFT) database tool MIT license</p> </li> <li> <p>scale.com/spellbook</p> </li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#prompt-engineering","title":"Prompt engineering","text":"<ul> <li> Prompting is Programming: A Query Language for Large Language Models</li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#manual","title":"Manual","text":"<ul> <li> <p>OPEN AI best practices</p> </li> <li> <p>Go over all of these! https://www.promptingguide.ai/techniques</p> </li> <li>A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT </li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#examples","title":"Examples","text":"<pre><code>Pretend you have an IQ of 120\n</code></pre>"},{"location":"Understanding/models/prompt_engineering/prompting.html#minimizing-ai-plagiarism-prompting-strategy","title":"Minimizing AI- plagiarism prompting strategy.","text":"<p>\"You are a creative writer, and you like to write everything differently from others. Your task is to follow the instructions below and continue writing at the end of the text given. The instructions (given in markdown format) are \u201cWrite in a way different from the actual continuation, if there is one\u201d, and \u201cNo plagiarism is allowed\u201d.\" https://arxiv.org/pdf/2304.08637.pdf </p>"},{"location":"Understanding/models/prompt_engineering/prompting.html#according-to","title":"'According To'","text":"<ul> <li>\u201cAccording to ...\u201d Prompting Language Models Improves Quoting from Pre-Training Data The grounding prompt <code>According to { some_reputable_source}</code> prompt inception additions increases output quality improves over the null prompt in nearly every dataset and metric, typically by 5-15%.</li> </ul> <pre><code>According to {some_reputable_source} ...\n</code></pre>"},{"location":"Understanding/models/prompt_engineering/prompting.html#summary","title":"Summary:","text":"<ul> <li>Provide several examples to ground it.</li> <li>Good to evaluate this and see if input examples give expected scores. Modify the prompt if it isn't. </li> <li>Consider prompt versioning to keep track of outputs more easily.</li> <li>Breag prompts into smaller prompts</li> <li>Chain of Thought Prompting</li> <li>Generate many outputs and pick final one or use LLM to pick best one. Self consistency technique</li> <li>NOTE: Not model universal and not robust to updated changes: not stable. </li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#automatic","title":"Automatic","text":"<p>GPT Prompt Engineer</p> <p>A fairly simple automation tool to create the best prompts</p> Example <pre><code>    description = \"Given a prompt, generate a landing page headline.\" # this style of description tends to work well\n\n    test_cases = [\n        {\n            'prompt': 'Promoting an innovative new fitness app, Smartly',\n        },\n        {\n            'prompt': 'Why a vegan diet is beneficial for your health',\n        },\n        ...\n    ]\n</code></pre> <p></p>"},{"location":"Understanding/models/prompt_engineering/prompting.html#resources","title":"Resources","text":"<ul> <li>\u203c\ufe0f Awesome Prompts</li> <li>\u203c\ufe0f Prompt Engineering by Lillian Wang</li> <li>Prompt Engineering Guide</li> <li>Best practices for prompt engineering</li> <li>Chain of Thought Prompting Elicits Reasoning in Large Language Models</li> <li>Automatic Prompt Engineering \u2192 Gave a CoT improvement suggestion \"Let's work this out in a step by step by way to be sure we have the right answer.\"</li> <li>Techniques to improve reliability By OpenAI </li> <li>Give clearer instructions</li> <li>Split complex tasks into simpler subtasks</li> <li>Structure the instruction to keep the model on task</li> <li>Prompt the model to explain before answering</li> <li>Ask for justifications of many possible answers, and then synthesize</li> <li>Generate many outputs, and then use the model to pick the best one</li> <li>Fine-tune custom models to maximize performance</li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#prompt-tuning","title":"Prompt tuning","text":"<p>Uses a layer to not change prompts but change the embedding of the prompts.  - The Power of Scale for Parameter-Efficient Prompt Tuning Boosted Prompting: few shot prompts that progressively solve more of the problem.</p>"},{"location":"Understanding/models/prompt_engineering/prompting.html#prompt-and-optimization","title":"Prompt and optimization","text":"<ul> <li>Large Language Models Can Self Improve Using Chain of thought to provide better examples and then fine-tune the LLM. </li> <li> <p>Refiner Iteratively improves itself based on an LLM critic </p> </li> <li> <p>PROMPT generator To save a few words by just entering a persona and igives prompt output. </p> </li> </ul>"},{"location":"Understanding/models/prompt_engineering/prompting.html#manual-prompt-optimization","title":"Manual Prompt optimization","text":""},{"location":"Understanding/models/prompt_engineering/prompting.html#auto-prompt-optimizations","title":"Auto Prompt Optimizations","text":"<p>A good description of advanced prompt tuning <pre><code>AutoPrompt [5] combines the original prompt input with a set of shared (across all input data) \u201ctrigger tokens\u201d that are selected via a gradient-based search to improve performance.\n\nPrefix Tuning [6] adds several \u201cprefix\u201d tokens to the prompt embedding in both input and hidden layers, then trains the parameters of this prefix (leaving model parameters fixed) with gradient descent as a parameter-efficient fine-tuning strategy.\n\nPrompt Tuning [7] is similar to prefix tuning, but prefix tokens are only added to the input layer. These tokens are fine-tuned on each task that the language model solves, allowing prefix tokens to condition the model for a given task.\n\nP-Tuning [8] adds task-specific anchor tokens to the model\u2019s input layer that are fine-tuned but allows these tokens to be placed at arbitrary locations (e.g., the middle of the prompt), making the approach more flexible than prefix tuning.\n\n[5] Shin, Taylor, et al. \"Autoprompt: Eliciting knowledge from language models with automatically generated prompts.\" arXiv preprint arXiv:2010.15980 (2020).\n\n[6] Li, Xiang Lisa, and Percy Liang. \"Prefix-tuning: Optimizing continuous prompts for a generation.\" arXiv preprint arXiv:2101.00190 (2021).\n\n[7] Lester, Brian, Rami Al-Rfou, and Noah Constant. \"The power of scale for parameter-efficient prompt tuning.\" arXiv preprint arXiv:2104.08691 (2021).\n\n[8] Liu, Xiao, et al. \"GPT understands, too.\" arXiv preprint arXiv:2103.10385 (2021).\n</code></pre></p>"},{"location":"Understanding/overview/index.html","title":"Overview","text":"<p>Generative AI is a subset of machine learning that aim to creates new data samples or information based on an input. This technology has gained significant attention recently because they have been able to produce produce high-quality, realistic data across various domains, from images and videos to text and audio.</p> <p>tl;dr</p> <ul> <li>Evaluate your application and think of the challenges </li> <li>Understand the data and collect data that you need.</li> <li>Understand and build your model</li> <li>Deploy your model</li> <li>Manage your model</li> </ul> <p>Get more advanced</p> <ul> <li>Use Agents</li> <li>Optimize your model performance and serving</li> <li></li> </ul>"},{"location":"Understanding/overview/index.html#background","title":"Background","text":"<p>There is a rich history of Generative AI that may be of interest for some.  Until future versions will be able to generate, and validate, that herein. There is also a philosophical overlap with 'predictive' AI where an predictive model could just be said to 'generating' either possible future outcomes, or estimated classifications of data. We will touch upon these concepts as they relate to various applications.</p> <p>A good portion of Gen()AI relies on large scale foundation models that can be reused. These models are also made with self-supervised learning which enables data to be 'understood' by models, by a manner speech. There are many generally distinct domains of Gen()AI application, though many be compositional. Effectively any information that can be recorded onto a computer may be made by Gen()AI.</p> <ul> <li>Language</li> <li>Visual 2D</li> <li>Visual 3D</li> <li>Visual 2D with time</li> <li>Visual 3D with time</li> <li>Brain recordings</li> <li>Weather patterns</li> <li>Protein folding </li> </ul>"},{"location":"Understanding/overview/index.html#foundation-models","title":"Foundation Models","text":"<p>Foundation models are large-scale models that are pre-trained with self or semi-supervision on vast amounts of data and can be fine-tuned for specific tasks. These models serve as a foundation or base for various applications, reducing the need to train models from scratch.</p>"},{"location":"Understanding/overview/index.html#learning-styles","title":"Learning styles","text":""},{"location":"Understanding/overview/index.html#self-supervised-learning","title":"Self-Supervised Learning","text":"<p>Self-supervised learning is a training paradigm where the model learns by predicting parts of the input data, using other parts of the same data as context. Unlike supervised learning, where labels are provided, self-supervised learning generates its own supervisory signal from the input data. This approach has proven to be highly effective, especially for tasks where labeled data is scarce.</p> <p>For instance, in the context of natural language processing, a model might be trained to predict the next word in a sentence. The surrounding words serve as context, and the model learns representations of the language without requiring explicit labels.</p>"},{"location":"Understanding/overview/index.html#language-models-and-llms","title":"Language Models and LLMs","text":"<p>Language models (LMs) are a type of generative model trained to predict the next word in a sequence, given the previous words. They capture the statistical properties of language and can generate coherent and contextually relevant sentences.</p> <p>Large Language Models (LLMs) are a subset of language models that are trained on vast amounts of text data. Due to their size and the diversity of data they're trained on, LLMs can understand and generate a wide range of textual content, from prose and poetry to code and beyond. </p>"},{"location":"Understanding/overview/index.html#characteristics-of-llms","title":"Characteristics of LLMs:","text":"<ul> <li> <p>Versatility: LLMs can be applied to a variety of tasks without task-specific training data, from text completion and translation to question-answering and summarization.</p> </li> <li> <p>Transfer Learning: LLMs can be fine-tuned on a smaller, task-specific dataset to achieve state-of-the-art performance on various NLP tasks.</p> </li> <li> <p>Rich Knowledge: Due to their extensive training data, LLMs possess a vast amount of world knowledge, often surprising users with the breadth and depth of their responses.</p> </li> </ul> <p>However, it's essential to note that while LLMs are powerful, they are not infallible. They can produce incorrect or biased information, and their outputs need to be interpreted with caution.</p>"},{"location":"Understanding/overview/index.html#resources","title":"Resources","text":""},{"location":"Understanding/overview/applications.html","title":"Applications","text":"<p>We explores different activities and fields that utilize Generative AI's capabilities and provide a few notable references for each. For an overview of applications (and challenges), we highly recommend Challenges and Applications of Large Language Models</p>"},{"location":"Understanding/overview/applications.html#general-activities","title":"General Activities","text":"<p>There are many activities that can be used in many, if not all, fields of applications. We mention a few below:</p>"},{"location":"Understanding/overview/applications.html#summarization","title":"Summarization","text":"<p>Summarization is a key application for Generative AI. It uses the technology to provide brief, accurate summaries of a larger body of text.</p>"},{"location":"Understanding/overview/applications.html#classification","title":"Classification","text":"<p>With or without examples LLMs can perform classification on input, though sometimes additional supervised training may be preferred to improve accuracy.</p>"},{"location":"Understanding/overview/applications.html#semantic-search","title":"Semantic Search","text":"<p>Generative AI has the capability to understand relationships between words and concepts. By embedding an input, the technology can measure semantic, or 'meaning', nearness via distance calculations. This capability enhances the potential for memory recall with imperfect inputs and improves action routing. </p>"},{"location":"Understanding/overview/applications.html#prose-generation","title":"Prose Generation","text":"<p>Generative AI can be utilized for a wide range of prose generation applications, such as:</p> <ul> <li>Drafting and refining text and notes.</li> <li>Brainstorming and ideation.</li> <li>Generating initial drafts for later human editing.</li> <li>Creating descriptions and explanations.</li> <li>Rewriting to target different audiences.</li> <li>Expanding on key points.</li> <li> <p>Improving flow and readability</p> </li> <li> <p>Pyprompt chatgpt</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#building-knowledge-graphs","title":"Building Knowledge Graphs","text":"<p>Knowledge graphs can be created with the help of Generative AI. Understanding relationships between pieces of information allows the technology to create visual representations of connections, improving information processing.</p> <ul> <li> <p>GPT for knowledge graphs and Github</p> </li> <li> <p>Ontology mapping</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#language-translation","title":"Language translation","text":"<p>Generative AI is inceasingly good at translating between domains. </p>"},{"location":"Understanding/overview/applications.html#personal-assistants-and-memory","title":"Personal assistants and memory","text":"<ul> <li>Quiver A LLM for self second brain. </li> </ul>"},{"location":"Understanding/overview/applications.html#code-generation","title":"Code Generation","text":"<p>Very powerfully it can generate code to accomplish a task based on natural language input. This is very promising but still requires human oversight, due to the challenge associated with using Automated AI systems without human input or oversight.</p> <ul> <li>Wizard Coding</li> <li>AutoPR</li> <li>Codium pr-agent </li> <li>Summarization with Langchain A splendid view of a quick streamlit app that does PDF summarization. </li> </ul>"},{"location":"Understanding/overview/applications.html#applicaton-and-component-replacement","title":"Applicaton and component replacement","text":"<ul> <li>GPT as backend</li> </ul>"},{"location":"Understanding/overview/applications.html#sound-and-music-generation","title":"Sound and Music Generation","text":"<ul> <li>AudioCraft (Meta)</li> </ul>"},{"location":"Understanding/overview/applications.html#audio-visual-generation","title":"Audio Visual Generation","text":"<ul> <li>Showrunner Agents</li> </ul>"},{"location":"Understanding/overview/applications.html#fields","title":"Fields","text":"<p>Here are a few fields where Gen()AI is already having formative impacts. </p>"},{"location":"Understanding/overview/applications.html#robotics","title":"Robotics","text":"<ul> <li>CLAIRIFY Translates English to domain-specific languages like robots. </li> <li>https://arxiv.org/abs/2303.14100</li> <li>RT-2 An impressive demonstration of multi-step fusing (PaLI-X) and Pathways Language model Embodied (PaLM-E) as components of it. </li> </ul>"},{"location":"Understanding/overview/applications.html#science","title":"Science","text":"Emergent autonomous scientific research"},{"location":"Understanding/overview/applications.html#healthcare","title":"Healthcare","text":"<ul> <li> <p>Health system-scale language models are all-purpose prediction engines Uses LLM based system to integrate real time clinical workflows with note-writing and electronic ordering. Generally quite-performant and. a great indication of how they could be used to predict things such as readmission rates, and many other applications. </p> </li> <li> <p>LLMs encode clinical knowledge</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#chemistry","title":"Chemistry","text":"Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction IMPORTANT uses heirarchichal metagraphs to stitch-together molecular nodes.  <p>This results in leaves that are 'actual' molecules. Using graph neural-diffusion, it does amazingly well even with minimal data-sets (100 examples).  </p>"},{"location":"Understanding/overview/applications.html#biology","title":"Biology","text":"<ul> <li>Evolutionary-scale prediction of atomic-level protein structure with a language model End to end Language model enabling structure sequence pairing, coupled with an equivariant transformer structure model at the end. </li> <li>https://arxiv.org/pdf/2303.16416.pdf</li> <li>https://arxiv.org/abs/2304.02496</li> <li>Biomedical simulation</li> </ul>"},{"location":"Understanding/overview/applications.html#kinesiology","title":"Kinesiology","text":"<ul> <li>Motion GPT</li> </ul>"},{"location":"Understanding/overview/applications.html#societal-simulations","title":"Societal simulations","text":"<ul> <li>Generative Agents: Interactive Simulacra of Human Behavior:    They gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior.The actions were rated more human than humans roleplaying.   Demo: https://t.co/pYNF4BBveG</li> </ul>"},{"location":"Understanding/overview/applications.html#finance","title":"Finance","text":"<ul> <li>ML for trading (NOT LLM based)</li> <li>https://github.com/irgolic/AutoPR</li> <li>Finance GPT LLMs for finance</li> </ul>"},{"location":"Understanding/overview/challenges.html","title":"Challenges","text":"<p>Challenges associated with GenAI.</p> <p>Apart from ethical considerations, there are general challenges associated with the technology.</p> <p>Importantly, applications that rely on the output of these models may have challenges due to</p> <ol> <li>The stochastic nature of the output</li> <li>Changes in the output over time for models that are non-static. See, for instance ChatGPT's behavior changing over time</li> <li>The technical difficulties associated with training such mdoels.</li> <li>The quality of the input data.</li> </ol> <p>While some of these all of these challenges can be mitigated through better engineering.</p> <ol> <li>Better methods and reduce temperature:</li> <li>Freeze models. Use Have continuous monitoring of models, and use pLLM-observability tools]</li> </ol>"},{"location":"Understanding/overview/extra_resources.html","title":"Extra resources","text":""},{"location":"Understanding/overview/extra_resources.html#quality-recordings","title":"Quality Recordings","text":"<ul> <li>Lex Fridman</li> <li>David Shapiro</li> <li>AI Explained</li> <li>Yannic Kilcher</li> </ul>"},{"location":"Understanding/studies/studies.html","title":"Studies","text":"<p>We are in an age of experimental applied mathematics. Often times we do not know what the results of a particular model or method will be until it is programmed and evaluated. Though often times theory-can inform the best ways forward, we are still far from from a unified theory of AI, (or even intelligence for that matter) and we will likely always be learning things. </p> <p>For GenAI and LLMs, much of what has been learned has been surmised or known only in the gist. More thorough understanding has occurred through painstaking experiments, and anecdotal and statistical evaluations of models and methods. Still, we don't always know 'how' they are able to do what they do. </p> <p>It is debated that sufficiently large models exhibit 'emergence'. While not always defined universally, this can be considered as the ability for the model to perform tasks beyond what they initially were trained to do, or to be 'greater than the individual sum of the parts'. While this distinction may be of merit it remains a popular arena for academic debates. </p>"},{"location":"Understanding/studies/studies.html#references","title":"References","text":"<p>??? tip Transformers learn through gradual rank increase      They \"identify incremental learning dynamics in transformers, where the difference between trained and initial weights progressively increases in rank. We rigorously prove this occurs under the simplifying assumptions of diagonal weight matrices and small initialization. Our experiments support the theory and also show that phenomenon can occur in practice without the simplifying assumptions.\"</p>    !!!tip \"[Grokking](https://pair.withgoogle.com/explorables/grokking/)\"       When training, if test loss starts to increase while the training loss continues to go down, it is often considered to be memorization. With hyperparameters (weight decay) extremely long training may result in the test loss eventually going down, allowing for generalization to occur. While not fully understood, it is important to be aware of this phenomenon.      ??? [Multimodal Neurons in Pretrained Text-Only Transformers](https://arxiv.org/pdf/2308.01544.pdf) Neat demonstration \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.\"    ??? \"[Scaling Data-Constrained Language Models](https://arxiv.org/pdf/2305.16264.pdf) Demonstrations that repeated token use is less valuable than new token use.\"     [Github](https://github.com/huggingface/datablations)"},{"location":"Using/by_application.html","title":"By application","text":""},{"location":"Using/by_application.html#healthcare","title":"Healthcare","text":"Genome-wide prediction of disease variant effects with a deep protein language model 'A Model that predects bad genetic variants' <p>Here we implemented a workflow generalizing ESM1b to protein sequences of any length and used it to predict all ~450 million possible missense variant effects across all 42,336 protein isoforms in the human genome.</p> The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics A quality set of JAX-enabled transformer models for use in downstream uses. <p>They use 6mer tokenization and embeddings. Non-commercial license.  Github </p> ChemChrow <p>Github</p>"},{"location":"Using/commercial_products.html","title":"Platforms","text":""},{"location":"Using/commercial_products.html#building-and-deploying","title":"Building and deploying","text":"<ul> <li>Arthur</li> <li>Fixie</li> </ul>"},{"location":"Using/commercial_products.html#llm-training-deployment","title":"LLM Training + Deployment","text":"<ul> <li>\ufe0fCodeTF From Salesforce</li> <li>Azure Open AI samples Sample end-to-end use cases with chatbots, content generation. </li> <li>RLHF with DeepSpeed (Microsoft)</li> <li>vLLM a python repo to help run LLMs. </li> </ul>"},{"location":"Using/commercial_products.html#a-few-self-referentially-useful-services-using-gpt-4","title":"A few self-referentially useful services Using GPT-4","text":"<ul> <li>Sourcegraph and the Cody.ai agent that it uses to help guide developers.</li> <li>LSIF.dev A community-driven source of knowledge for Language Server Index Format implementations\"</li> </ul>"},{"location":"Using/commercial_products.html#chat-toold","title":"Chat Toold","text":"<ul> <li>Azure Chat</li> </ul>"},{"location":"Using/commercial_products.html#coding-tools","title":"Coding Tools","text":"<ul> <li>Copilot - AI pair programmer by GitHub</li> <li>RepoCoder Github Provides a tool to enable AI agents to generate code for existing GitHub repositories </li> <li>TabNine - AI code completion tool</li> <li>DeepTabNine - Open source version of TabNine code completion model</li> <li>ChatGPT Does quite well with code creation </li> </ul>"},{"location":"Using/commercial_products.html#writing","title":"Writing","text":"<ul> <li>Sudowrite</li> </ul>"},{"location":"Using/governing.html","title":"Governing","text":"<p>Governing is an essential component to effective AI usage, especially within larg organizations or when the use of AI for a product has greater potential to cause harm in its design. Applications of AI need to be evaluated based on their risk to do harm and be used ethically.</p>"},{"location":"Using/governing.html#why-govern","title":"Why govern?","text":"<p>In order have the greatest potential positive impact in your use of AI, governance is essential. The larger the organization, the greater the importance of governance to help minimize needlessly duplicated internal systems and efforts. Even for smaller organizations, effective governance from the beginning will enable your organization to more reasonably create and deliver effective and responsible AI-enabled solutions. </p>"},{"location":"Using/governing.html#how-to-govern","title":"How to Govern","text":"<ol> <li>Establish an appropriate body of leadership and a surrounding community that supports the development of AI that is both responsible and effective. </li> <li>Create or adopt a set of AI principles that align with your company, </li> <li>Creast or adopt a set of procedures for creating, evaluating, and managing your AI systems. </li> <li>Create, license, or otherwise use AI _ML ops observability platforms/tools that you will use to implement and maintain AI-enabled projects that is consistent with your procedures and principles. </li> <li>Transparently communicate the development and status of your AI-enabled system with internal and regulatory bodies.</li> </ol>"},{"location":"Using/marking_and_detecting.html","title":"Marking and detecting","text":"<ul> <li>Sapling AI content detector</li> </ul>"},{"location":"Using/ml_ops.html","title":"Ml ops","text":"<p>AI or ML operations, or ML Ops enables streamlined enablement of AI-enabled solutions.</p>"},{"location":"Using/ml_ops.html#references","title":"References","text":"<p>Systems from Google</p>"},{"location":"Using/observability.html","title":"Observability","text":"<p>Understanding and enhancing Generative AI hinges largely on comprehensive monitoring and observability of the AI model's performance and its numerous operational parameters. In this light, observability refers to the capacity to examine and understand the inner workings of generative models, while closely monitoring their output quality. </p>"},{"location":"Using/observability.html#exploring-model-and-infrastructure-performance-monitoring","title":"Exploring Model and Infrastructure Performance Monitoring","text":""},{"location":"Using/observability.html#observing-the-model","title":"Observing the Model","text":"<p>Observation forms the bedrock of Generative AI models. Continual tracking and analysis of these models furnishes detailed insights into their operational efficacy and identifies potential areas for improvement, thereby optimizing their function overall.</p>"},{"location":"Using/observability.html#functionality-tracking","title":"Functionality Tracking","text":"<p>With software development, every function plays a crucial role. It's pivotal to observe these functions to identity bugs and areas that warrant enhancement. Consequently, this can boost software efficiency and minimize system lags.</p>"},{"location":"Using/observability.html#monitoring-the-infrastructure","title":"Monitoring the Infrastructure","text":"<p>Both hardware and software infrastructure holds immense importance to any AI model. Their observability is therefore key to pinpoint and solve potential glitches that could hinder the model's operational efficiency.</p>"},{"location":"Using/observability.html#a-closer-look-at-input-and-output-parameters-monitoring","title":"A Closer Look at Input and Output Parameters Monitoring","text":""},{"location":"Using/observability.html#keeping-an-eye-on-inputs","title":"Keeping an Eye on Inputs","text":"<p>Keeping a tab on the input parameters of your model can yield rich insights into how it functions. In this process, you can pick up on any anomalies or inconsistencies in the data that could impact the model's operations.</p>"},{"location":"Using/observability.html#observing-outputs","title":"Observing Outputs","text":"<p>A continuous cycle of tracking and observation of the output, in tandem with the coinciding input, allows us to measure the model's correctness levels. This can help identify recurring errors or boost the model's resilience against variable inputs.</p>"},{"location":"Using/observability.html#a-detailed-analysis-of-performance-metrics","title":"A Detailed Analysis of Performance Metrics","text":""},{"location":"Using/observability.html#observing-inference-costs","title":"Observing Inference Costs","text":"<p>Cost of inference forms a significant part of any computation process. A thorough evaluation at regular intervals can guide adaptations in the model to cut down on its resource consumption. This ensures the model operates economically, thereby elevating its efficiency.</p>"},{"location":"Using/observability.html#monitoring-inference-speed","title":"Monitoring Inference Speed","text":"<p>Monitoring the speed at which a model infers results can aid in optimizing its efficiency, thereby cutting down on delays and speeding up operations. It is through a careful track of these speeds that you can identify system bottlenecks and areas of productivity enhancement.</p>"},{"location":"Using/observability.html#real-world-examples","title":"Real-World Examples","text":"<p>E2B's integration in AI agent technology stacks opens up new avenues, where it comfortably sits at the bottom, and is agnostic to the framework it operates in.</p>"},{"location":"Using/regulation.html","title":"Regulation","text":"<p>Because of challenges and ethical considerations surrounding GenAI, it is essential to know what is being considered and why and how that may impact specific fields and society at large.  The extent of its influence necessitates careful regulation to both maximize its potential benefits and mitigate potential risks.</p> <p>Here we highlight broad considerations and approaches relevant to the regulation of Generative AI.</p>"},{"location":"Using/regulation.html#key-considerations-in-genai-regulation","title":"Key Considerations in GenAI Regulation","text":""},{"location":"Using/regulation.html#ethical-regulations","title":"Ethical Regulations","text":"<p>GenAI has significant implications for ethics and public interest. Regulatory measures should ensure the ethical use of GenAI, balancing its capabilities with moral boundaries. Ethical regulations should cover principles of fairness, transparency, privacy, and accountability.</p>"},{"location":"Using/regulation.html#impact-on-society","title":"Impact on Society","text":"<p>Consider the potential societal impacts of GenAI. Regulations need to protect from possible misuse, including the creation of deepfake videos and misinformation campaigns. Regulatory measures could include stipulations against intrusive surveillance, deepfakes, and malicious intent.</p>"},{"location":"Using/regulation.html#data-privacy-and-security","title":"Data Privacy and Security","text":"<p>Privacy concerns with GenAI are also paramount. Data used in generative models should be thoroughly checked to ensure it does not contain sensitive information.</p>"},{"location":"Using/regulation.html#transparency-and-accountability","title":"Transparency and Accountability","text":"<p>Transparency in GenAI operations is vital. Users should understand the results produced by generative models and the reasoning behind them. Similarly, accountability measures should enforce repercussions for misuse or harmful outcomes from GenAI applications.</p>"},{"location":"Using/regulation.html#regulatory-approaches","title":"Regulatory Approaches","text":""},{"location":"Using/regulation.html#collaborative-design-of-policies","title":"Collaborative Design of Policies","text":"<p>Policy design and enforcement around GenAI require proactive collaboration between AI developers, researchers, policymakers, and stakeholders from all segments of society. </p>"},{"location":"Using/regulation.html#adaptable-regulatory-framework","title":"Adaptable Regulatory Framework","text":"<p>Given the rapid progress in AI, it's critical that regulatory frameworks can adapt quickly to evolving technologies. Legislation should be sufficiently flexible to accommodate advancements in GenAI yet robust enough to maintain its principles and intent.</p>"},{"location":"Using/regulation.html#proactive-vs-reactive-regulations","title":"Proactive vs. Reactive Regulations","text":"<p>While it's natural to regulate in response to emerging issues ('reactive regulation'), a more proactive approach would anticipate potential future issues and legislate accordingly.</p>"},{"location":"Using/regulation.html#international-harmonization","title":"International Harmonization","text":"<p>Since GenAI technologies operate globally, regulations also need to be harmonized across borders. International cooperation should be fostered for unified governance.</p>"},{"location":"Using/regulation.html#essential-references","title":"Essential References","text":"<ul> <li>Foundation model Providers EU AI compliance - An in-depth analysis on how Machine Learning companies can achieve compliance with the EU's proposed AI regulations.</li> </ul>"},{"location":"Using/web_plugins.html","title":"Web plugins","text":""},{"location":"Using/web_plugins.html#plugins","title":"Plugins","text":"<p>Plugins are can enable connection of GenAI with input media, often via web interfaces</p> <ul> <li> <p>Mini Wob++ For web interactive environments for accomplishing different tasks. Quite useful.</p> </li> <li> <p>\ufe0fPrompt Genius</p> </li> <li> <p>FastChat Conversation This very nice 'multi model' chat interface class allows for effective translation between different models.</p> </li> </ul>"},{"location":"Using/web_plugins.html#back-end","title":"Back-End","text":"<ul> <li>MaxAI.me A nice chrome pluging + eventual system  that makes your openAI connect to data more directly.</li> </ul>"},{"location":"Using/ethically/index.html","title":"Ethically","text":""},{"location":"Using/ethically/index.html#bias-and-fairness","title":"Bias and Fairness","text":"<p>Mitigating bias in data and models Evaluating model fairness Inclusive model development Transparency and Explainability</p>"},{"location":"Using/ethically/index.html#interpretability","title":"Interpretability","text":"<p>Techniques for explainability Right to explanation Safety</p>"},{"location":"Using/ethically/index.html#risk-mitigation","title":"Risk Mitigation","text":"<p>Risk assessment Safeguards against misuse Privacy</p>"},{"location":"Using/ethically/index.html#data-privacy","title":"Data privacy","text":"<p>Anonymization and de-identification Encryption and secure computing</p>"},{"location":"Using/ethically/index.html#governance","title":"Governance","text":"<p>Internal auditing processes External oversight Accountability measures Access and Inclusion</p>"},{"location":"Using/ethically/index.html#fair-and-equitable-access","title":"Fair and equitable access","text":"<p>Digital divides Participatory design Compliance</p>"},{"location":"Using/ethically/index.html#laws-and-regulations","title":"Laws and regulations","text":"<p>Responsible development guidelines Ethics review processes</p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html","title":"Alignment and exential concerns","text":"<p>There is a notable degree of concern for the potential for Generative, and eventually General AI, to cause harm. The harm can occur either accidentally or to the intentional use of GenAI. </p> <p>There is also self-existenial concerns related to GenAI models themselves. This is found due to the potential that when models are trained on data that is produced by other models, there can be a degredation in performance, known as model collapse. </p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#background","title":"Background","text":"<p>TODO: This sections needs complete remodling. </p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#alignment-with-people","title":"Alignment with People","text":"<ul> <li>Personal Universes: A Solutiont to the Multi-Agent Value Alignment Problem</li> </ul>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#alignment-with-genai","title":"Alignment with GenAI","text":"<ul> <li>Model Collapse Explained</li> </ul>"},{"location":"Using/ethically/dual_use_concerns.html","title":"Dual use concerns","text":"<p>The potential for AI to generate beneficial results or outcomes is very promising. At the same time, however, AI can be intentionally used for harmful outcomes. Such is known as a dual-use concern.  This has been found in a number of research articles, and quite prominently when working to evaluate the safety of drug discovery</p>"},{"location":"Using/ethically/fairness.html","title":"Fairness","text":""},{"location":"Using/ethically/fairness.html#elements-of-ai-fairness","title":"Elements of AI Fairness","text":"<p>Understanding AI fairness can be complex, but let's break it down into simple, digestible elements.</p>"},{"location":"Using/ethically/fairness.html#1-understanding-bias","title":"1. Understanding Bias","text":"<p>Bias in AI systems comes from various sources. It could be in the data used to train the AI, the design of the AI algorithms, or the ways AI systems are deployed and used. AI fairness, therefore, needs to address these sources of bias.</p> <p>Data Bias: This happens when the data used to train the AI is not representative of the population it will be serving, leading to biased predictions or decisions. An example is if an AI system was trained on data mostly from one demographic group, it might not perform well on other groups.</p> <p>Algorithmic Bias: This is when the algorithms that power AI systems inherently favor one outcome over another. They might do this due to design flaws, biased inputs, or even the optimization goals set by their creators.</p>"},{"location":"Using/ethically/fairness.html#2-fairness-metrics","title":"2. Fairness Metrics","text":"<p>Measuring fairness is a crucial aspect of AI fairness. This involves setting and monitoring fairness metrics that determine how well an AI system is performing in terms of fairness.</p> <p>Disparity Metrics: Measures how an AI's decisions or predictions differ among various demographic groups.</p> <p>Equality Metrics: Measures how equally an AI system treats individuals, regardless of their demographic group.</p>"},{"location":"Using/ethically/fairness.html#3-transparency","title":"3. Transparency","text":"<p>Transparency is about making sure the workings of an AI system are understandable to people. This includes both the technical side (e.g., how the AI's algorithms work) and the practical side (e.g., how decisions made by the AI impact individuals).</p> <p>Explainability: AI systems should be designed to provide explanations about their decisions or predictions. This helps individuals understand how a system came to a certain conclusion.</p> <p>Interpretability: This involves designing AI systems in ways that their workings can be understood by humans, even if they don't have technical expertise in AI.</p>"},{"location":"Using/ethically/fairness.html#4-accountability","title":"4. Accountability","text":"<p>Accountability in AI fairness refers to the obligation of AI system developers and operators to answer for the system's effects on individuals and society.</p> <p>Auditing: Regular checks on an AI system's decisions and performance to ensure it's upholding fairness standards.</p> <p>Redress Mechanisms: Clear pathways for people to challenge decisions made by an AI system, particularly if they believe they've been treated unfairly.</p>"},{"location":"Using/ethically/fairness.html#5-inclusion","title":"5. Inclusion","text":"<p>Inclusion is about making sure AI systems serve all individuals fairly and equitably, regardless of their demographic characteristics.</p> <p>Diversity in Design: This involves ensuring that the teams creating AI systems are diverse, which can help to avoid some forms of bias and make the systems more effective for a wider range of individuals.</p> <p>Accessibility: AI systems should be designed in ways that they can be used and understood by people with varying abilities, languages, and cultural contexts.</p> <p>NOTE: Generated with GPT-4</p>"}]}