{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"\ud83c\udf89 Welcome to Managing Gen()AI!","text":"<p>Our Mission: Simplify and demystify Gen()AI to make it accessible and understandable and increase our ability to manage it. </p> <p>Our open-source project on Managing Generative AI \ud83e\udd16 will help people to stay on top of understanding and effectively working with the increasingly complex world of Generative AI.</p> <p>Why is it called Gen() AI?</p> <p><code>Generative AI</code> creates. So does will <code>General AI</code>. Depending on their definitions, there may be notable differences, but the overlap ensures that shared characteristics warrant writing this ambiguously, such as GenAI or Gen()AI. </p>"},{"location":"index.html#whats-inside","title":"\ud83d\udcd8 What's Inside?","text":"<ul> <li>Understanding GenAI: Delve deep into the mechanics, models, and methodologies for building GenAI.</li> <li>Deploying GenAI: Learn how to build and deploy models.</li> <li>Using GenAI: Where we describe use cases and applications, commercial tools and applications, and the ethics and regulations surrounding GenAI.</li> <li>Managing GenAI: This is the heart of our project, where we describe the tools that we are building to enable quality and responsible development of this and other AI projects.</li> </ul>"},{"location":"index.html#genai-explaining-itself","title":"\ud83d\ude80 GenAI Explaining Itself?","text":"<p>One of our ambitious goals is to have this documentation written and updated by GenAI itself. We aim to:</p> <ul> <li>\ud83d\udcdd Set up a base documentation repository that aids in generating self-descriptive content.</li> <li>\ud83d\udd04 Implement an automated merge and build system for a seamless automation and viewing experience.</li> <li>\ud83d\udd01 Create a self-referential models using tools like Langchain to enable its supervised self-improvement via pull requests and reviews.</li> <li>\ud83d\udd78\ufe0f Catch the greatest new insights and integrate it into a 'living' document that evolves with time. </li> </ul> <p>We believe in Gen()AI's potential to effectively explain itself even as the technology grows with extreme complexity. </p> <p>If you're as excited as we are and wish to contribute, join us!</p> <p>Contribute</p> <p>Interested in contributing? Check out our guidelines to get started!</p>"},{"location":"Managenai/index.html","title":"Managen.ai","text":"<p>Our Mission is to help people to effectively understand, build, use and manage Generative AI.</p> <p>Our Method uses Generative AI itself helping to build the site and keep it up to date.</p> <p>Our success will depend on you helping to guide it to be as self-accurate as possible.</p>"},{"location":"Managenai/index.html#welcome-to-managenai","title":"Welcome to Managen.ai,","text":"<p>Working as a relevant information hub, Managing Generative AI will provide an expansive seed that will allow for us to keep up with the rapidly evolving technologies and techniques. </p>"},{"location":"Managenai/index.html#how-to-use","title":"How to use","text":"<p>In the section we are now in we discuss the Managen.ai project. If you'd like to start building and using GenAI, we suggest heading over here where you can learn the deep and wide components of building Generative AI, and building with Generative AI. \\ With your Generative AI solutions coming together, we go over effective, responsible, and ethical manners of using the code. </p>"},{"location":"Managenai/brainstorming.html","title":"Brainstorming","text":""},{"location":"Managenai/brainstorming.html#ideas","title":"Ideas","text":"<p>Ideas are a dime a dozen.</p> <p>But if you don't have one, you won't find a cent.</p> <p>Here are some ideas of things that might be explored particularly in conjunction with this. </p> <ul> <li> <p>A codebase watcher and executor agent for public codebases like in github. This would have a vector database + query  (+ build) system that would allow the code base to be queried and interacted with via 'execution' of various functions.  They would allow for tested execution of external codebases (and functions). Kind of like code interpreter but for not making new code but calling code that is already needed. This would allow code to use other code just as a person would.</p> </li> <li> <p>Ability to create docker images from repos: repo2docker</p> </li> </ul>"},{"location":"Managenai/build_plan.html","title":"Build plan","text":"<p>Using Github to organize our understanding of a fluid field is a notable challenge. Because of the acessibility of mkdocs-material it makes it easy to make nice-looking documentaiton, though sometimes without the niceties that could accompany other software systems. </p> <p>Eventually we may shift to other systems (like docusaurus). Before that though, we will be wanting to integrate state-of-the-art updates to understanding while we build our auto-building system. </p>"},{"location":"Managenai/build_plan.html#content","title":"Content","text":"<ul> <li>[ ] Improve strructure of everything hello OK Obama</li> <li>[ ] Go through content that is already there read it, summarize it, and make it look better.</li> </ul>"},{"location":"Managenai/build_plan.html#generative-building","title":"Generative Building","text":"<ul> <li>[x] Enable simple jupyter-notebook calls to improve documents.<ul> <li>[ ] Ensure all links are preserved.</li> <li>[ ] Enable multiple LLM integration, for instance with Llama on OSX. </li> </ul> </li> <li>[ ] Enable automatic github PRs based on a continuous feedback system (Like Auto-GPT). </li> <li>[ ] Enable vector-databasing and other RAG tools to function, focusing on <ul> <li>[ ] individual github-repositories </li> <li>[ ] linked documents</li> </ul> </li> </ul>"},{"location":"Managenai/build_plan.html#visualization","title":"Visualization","text":"<p>We can make this easier to read</p> <ul> <li>[ ] Improve landing page and header bar to be more modern. </li> <li>[ ] Build interactive graph representation of this site that includes summary information. Check this out and the examples</li> <li>[ ] https://melaniewalsh.github.io/Intro-Cultural-Analytics/06-Network-Analysis/02-Making-Network-Viz-with-Bokeh.html</li> <li>[ ] build with https://docusaurus.io/</li> <li> <p>[ ] Integrate example python notebooks and build with https://github.com/outerbounds/nbdoc</p> </li> <li> <p>mkdocs charts</p> </li> </ul>"},{"location":"Managenai/contributing.html","title":"Contributing","text":"<p>In order to contribute...</p>"},{"location":"Managenai/managing.html","title":"Managing","text":"<p>You cannot manage effectively what you do not understand effectively.</p> <p>Thanks for being interested in this project. This relays how we are putting together the components that enable this project to exist.</p>"},{"location":"Managenai/requirements.html","title":"Requirements","text":""},{"location":"Managenai/requirements.html#general-requirements","title":"General Requirements","text":""},{"location":"Managenai/requirements.html#hosting-on-github","title":"Hosting on GitHub","text":"<p>Description: Utilize GitHub for version control, collaboration, and hosting. Priority: 1 Status: Done</p>"},{"location":"Managenai/requirements.html#content-clarity-components-and-reach","title":"Content Clarity, components, and Reach","text":"<p>Description: Ensure content is continuously examined for accuracy, clarity, and utility.  Priority: 1 Components:  Viewers can:  - rapidly understand the website's purpose and it's goals. - rapidly derive value from it by having it help them to build/use AI in some effective manner - methods of measuring both of these via feedback.  - Use a rss feed https://guts.github.io/mkdocs-rss-plugin/ - Use mkdocs material blog.</p>"},{"location":"Managenai/requirements.html#gen-ai-enablement","title":"Gen-AI enablement","text":"<p>Description:  GenAI will  build this documentation system so that it is adaptive and auto-descriptive . Priority: 2 Components: - Computation framework / methods.  - Ability to represent entire structure, perhaps with RAG  - Provide a testing environment for contributors to test their changes before merging. - File PRs - File Issues - Read Issues - Read referenced links and codebases     - Adherence to codebase Licensing restrictions - Orchestration AI that helps manage the actions above via selecting different GenAI to do the job. - Ability simultaneously work with all linked packages using docker/venvs</p>"},{"location":"Managenai/requirements.html#github-actions-integration","title":"GitHub Actions Integration","text":"<p>Description: Use GitHub Actions for automated testing, deployment, and other workflows. Priority: 2 Components:  Use GitHub Actions for automated:</p> <ul> <li>Build on merge to main</li> <li>Trigger building of file/database structure</li> <li>Trigger AI-analysis of new content</li> </ul>"},{"location":"Managenai/requirements.html#community-building-and-integration","title":"Community Building and Integration","text":"<p>Description: Use GitHub Discussions or similar tools for collaboration and community engagement. Priority: 1 Components: - Recruit - GitHub Discussions Integration - Discord / slack</p>"},{"location":"Managenai/requirements.html#contributer-enablement","title":"Contributer Enablement","text":"<p>Description: Provide detailed guidelines for contributors to ensure consistency and quality. Priority: 3 Components: - Clear Contribution Guidelines - Implement a system to recognize and reward active and valuable contributors. - Offer training sessions or materials for new contributors to get acquainted with the system.  </p>"},{"location":"Managenai/requirements.html#feedback-mechanism","title":"Feedback Mechanism","text":"<p>Description: Implement a system for users to provide feedback on content and usability. Priority: 3 Components:  - Potential open source option https://giscus.vercel.app/</p>"},{"location":"Managenai/requirements.html#automated-content-updates","title":"Automated Content Updates","text":"<p>Description: Linked repositories may change/update and any internally referenced information needs to be updated appropriately. Priority: 7</p>"},{"location":"Managenai/requirements.html#automated-pr-creation-for-link-submission","title":"Automated PR Creation for Link Submission","text":"<p>Description: Implement a system where contributors can submit links or content, which then automatically creates a PR. Priority: 4</p>"},{"location":"Managenai/requirements.html#visual-aids","title":"Visual Aids","text":"<p>Description: Incorporate diagrams, infographics, and other visual aids to enhance understanding. Priority: 5 Components: - Use mkdocs mermaid diagramming to outline pieces in an effective manner for people to follow - Use infographics enabled by mkdocs</p>"},{"location":"Managenai/requirements.html#user-friendly-navigation","title":"User-friendly Navigation","text":"<p>Description: Implement an intuitive navigation system with a search feature. Priority: 5 Components:  - Include breadcrumb navigation for users to track their location within the site. - A graphical network diagram for the different topics allowing ease of understanding</p>"},{"location":"Managenai/requirements.html#modern-looking-design-and-compatibility","title":"Modern looking design and compatibility","text":"<p>Description: The website needs to look good and functional Priority: 5 Components: - Improved landing page - Mobile Responsiveness</p>"},{"location":"Managenai/requirements.html#analytics-and-visualization-integration","title":"Analytics and Visualization Integration","text":"<p>Description: Integrate Google site analytics ad github star/following tracking to be more visible Priority: 8</p>"},{"location":"Managenai/requirements.html#advanced-education-tools","title":"Advanced education tools","text":"<p>Description: Include a glossary for technical terms and jargon. Priority: 9 Components -  Incorporate interactive elements like quizzes or simulations for engaging learning experiences.  </p>"},{"location":"Managenai/requirements.html#content-adaptability","title":"Content Adaptability","text":"<p>Description: Allow for different named versions of the website to be generated with different degrees of complexity, using mkdocs versioning plugins. Priority: 10</p>"},{"location":"Understanding/index.html","title":"Understand and build","text":"<p>tl;dr</p> <ul> <li>Evaluate your use cases and think of the challenges associated with it</li> <li>Understand the data and collect data that you need.</li> <li>Understandand build use pre-trained models.</li> <li>Deploy your model</li> <li>Manage your model</li> </ul> <p>Generative Artificial Intelligence, and related General AI and General Super AI are components of what already is and may be the future of intelligence and computing. We must effectively manage these technologies to use them to their highest potential. </p> <p>To manage these technologies effectively and responsibly we must understand them. That is a complex task, especially given the speed at which we are generating novel insights, new discoveries, backed by increasingly powerful hardware. </p> <p>That is why we created Mana Gen AI. </p> <p>Here we focus on Generative AI, knowing various and changing definitions of these domains have a degree of overlap. With time and support we will be able to help many people understand the technology, lest it become a magician's tool. </p> <p>Any sufficiently advanced technology is indistinguishable from magic.</p> <ul> <li>Arthur C. Clark</li> </ul> <p>In the documents you read here, you will be able to see an increseasingly consistent and understandable discussion of Gen()AI technologies, enabled by Gen()AI technologies herein described.  Like most powerful technology, Gen()AI can be a two edged sword and effective use requires responsible and thoughtful understanding. </p>"},{"location":"Understanding/index.html#the-base-components-of-genai","title":"The base components of Gen()AI","text":"<p>Getting into it, you will find the following outline: </p>"},{"location":"Understanding/index.html#whats-been-done-with-genai","title":"What's been done with Gen()AI?","text":"<ol> <li>Data provides the backbone connecting computation to our recorded reality.</li> <li>Models allow the data to be understood and used. [^n1]</li> <li>Prompts govern how we interact with the models.</li> <li>Agents allow for models to be used in more useful, effective, and complex manners.</li> <li>Ethical concerns help us to temper the responsible use of these powerful technologies.</li> <li>Studies help us to understand Gen()AI from an experimental and theoretical basis.  i</li> </ol>"},{"location":"Understanding/index.html#how-do-you-do-stuff-with-genai","title":"How do you do stuff with Gen()AI?","text":"<p>Of course, there will be some important 'how-to's, particularly in the data, models, prompts and agents. </p> <p>Competition is fierce to create the 'best' (based on certain metrics) Gen()AI, so much knowledge may not be known to protect IP and other secrets.</p> <p>Still, these trained foundation models may be used, with varying degrees of open-source licensing, for your project. Open and closed-source pre-trained models are available in many places that can be used hosted by yourself, or enabled by API services. Because of the cost and challenge involved with creating these models, it will likely be necessary to use the ones already made. </p> <p>If you are working on commercial projects, be sure to look at the Licenses to ensure you are legally compliant. </p> <p>And please, whatever you do, be cognisant of the ethical concerns</p>"},{"location":"Understanding/index.html#useful-references","title":"Useful References","text":"<p>There is so much quality material, it would be valuable for your time to check some of these out if you got the chance. </p> LLM Patterns An impressively thorough and well-written discussion on LLMs and patterns within them <p>Important patterns mentioned (references to discussions herein): * Evaluating and comparing * Retreival Augmented Generation (RAG) * Fine tuning * Caching to reduce latency.  * Guardrails to ensure output (and input) quality. * Data Flywheel to use data collection and feedback to improve model and experience * Cascade Breaking models up into smaller simpler tasks instead of big ones. * Monitoring to ensure value is being derived * Effective (defensive) UX to ensure the models can be used well.  </p> <ul> <li>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </li> <li>A cookbook of self-supervised Learning </li> <li>LLM Survey</li> <li>Large Language Models Explained</li> </ul> <p>Generative AI is a subset of machine learning that aim to creates new data samples or information based on an input. This technology has gained significant attention recently because they have been able to produce produce high-quality, realistic data across various domains, from images and videos to text and audio.</p> <p>A little more advanced</p> <ul> <li>Use Agents for increasingly powerful applications</li> <li>Optimize your model </li> </ul> <p>In this section, we will focus on 'Understanding' the various components of GenAI, data, models and agents including methods and models that are initial or under development. </p> <p>Presentation bias</p> <p>This is presently highly transformer-based large-language models because language is presently more versatile than other modalities. Other models are discussed here. Many other techniques and technologies may not have entered into this yet. If you'd like to help us build this right, please consider contributing</p>"},{"location":"Understanding/agents/index.html","title":"Gen(erative) AI Agents","text":"<p>Agents in Gen()AI agents have access to 'tools' to provide them 'agency' beyond the ability to generate text or image based responses to the input data.</p> <p>Similar to bots, or other computerized automata, they may have the ability to run discretely, separately from standard chat interfaces. Generally, they involve the possibility of Human-in-the-loop to help correct odd components. </p>"},{"location":"Understanding/agents/index.html#essential-concepts","title":"Essential Concepts","text":"<ul> <li>Environments that can and do provide inputs.</li> <li>Language prompts that orient's and agent's response.</li> <li>Chains which enable a continuous connection of information with various prompts.</li> <li>Memory to enable writing and reading information that may be of use.</li> <li>Tools that enable more than text (or images) to be returned or otherwise acted upon. </li> <li>Cognition architectures is the ability to understand through the use of computational models, chains and memory. </li> <li>Interpreters and Executors that are used to process input or output.</li> <li>Systems of Agents that can allow for multiple agents with different sets of the components above, to interact and create powerful solutions.</li> </ul> <p>Agents can be quite different! Here are some examples of agents made both in academic and commercial settings. </p>"},{"location":"Understanding/agents/index.html#example-agent-diagram","title":"Example Agent Diagram:","text":"<p>At the very simplistic level, an embodiment of an agent would look like this. </p> <pre><code>graph LR\n    A(Input) --&gt; B[Evaluate]\n    B --&gt; C[Propose action]\n    C --&gt; D[Act]\n    D --&gt; E[Observe]\n    E --&gt; A\n</code></pre> <p>To enable that it may require more complicated relations between example components. Below is an example representation. </p> An Agent's components <pre><code>graph TB\n    Agent((Agent)) --&gt;|makes| decision((Decision))\n    decision --&gt;|attempts| action((Action))\n    action --&gt;|passes| execution((Execution))\n    execution --&gt;|affects| environment((Environment))\n    execution --&gt;|generates| agentMemory((Agent's Memory))\n    agentMemory --&gt;|informs and effects| Agent\n    environment --&gt;|provides| observations((Observations))\n    observations --&gt;|informs and effects| Agent\n    execution --&gt;|queries| environment\n    AgentManager((Agent Manager)) --&gt;|affects| execution\n    Agent --&gt; |informs and effects| AgentManager\n    AgentManager --&gt; |informs and effects| Agent</code></pre>"},{"location":"Understanding/agents/index.html#background","title":"Background","text":"<p>TODO: Quick description of Traditional RL agents and how they compare, and how we are focusing on LLM-enabled agents.</p>"},{"location":"Understanding/agents/index.html#useful-references","title":"Useful references","text":"<p>Here are several references of merit. </p> <p>LLM-Agent-Papers</p> The Rise and Potential of Large Language Model Based Agents:A Survey Providess a comprehensive overview of thoughtful ways of considering LLMs. Agents overview by Lilian Weng <p>As usual, a splendid post by Lilian Weng</p> <p>Awesome Agents of a nicely curated list of systems using agents</p>"},{"location":"Understanding/agents/actions_and_tools.html","title":"Actions and tools","text":"<p>Actions and tools, also called 'plugins', can be considered function calls to routines external to the LLM. While potentially minimal distinction. Often relayed by an interpreter or a perhaps simple jinja syntax-pattern more complete json input that can be validated for the function of choice. </p> <p>Local LLM Function Calling enforces json semantics for calls to functions</p>"},{"location":"Understanding/agents/actions_and_tools.html#action","title":"Action","text":"<p>Actions may be be internal or externally focused.  focused generally related to an agent's '<code>memory</code>, or externally focused, with tools, though their distinction may be moot. </p> <p>Internal actions generally relate reading, writing or updating, an agents memory, memory state, such as free-text <code>scratech-pad</code>, an ordered <code>memory-log</code> or a vector database.</p> <p>External actions may be to act on simulated or real environments, or otherwise tracked <code>state</code>, or to use a toolthat an agent may be 'equipped with' to run. These can be API calls or local function calls. </p>"},{"location":"Understanding/agents/actions_and_tools.html#executors","title":"Executors","text":"<p>The action that an agent may take is enabled by an <code>AgentExecutor</code> or interpreter of the LLM output, that coordinates the call to perform the action. </p> <p>Langchain Agent Executor</p>"},{"location":"Understanding/agents/actions_and_tools.html#tools","title":"Tools","text":"<p>Tools generally consist of single function calls to something that will return value to the end-point destination, be that the agent itself or a person interacting with an agent. </p>"},{"location":"Understanding/agents/actions_and_tools.html#toolkits","title":"Toolkits","text":"<p>Toolkits consist of tool pairings that often work together well. For instance, bash commands for file creation, deletion, naming and movement. Toolkits can be api-calls or </p> On the Tool Manipulation Capability of Open-source Large Language Models <p>Paper Provides a method to allow open-source LLMs to work with tools for real-world tasks.</p> Langchain Toolkits <p></p> <p>Gorilla A Llama-focused high-quality API calling methods.</p> <p>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models Demonstrates that presenting documentation of tool usage is likely more valuable than providing examples.</p> <p>Tool LLM This describes a novel approach enabling over 16000 API's to be called through an intelligent routing mechanism. Github Uses RapidAPI connector to do so. </p>"},{"location":"Understanding/agents/chains.html","title":"Chains","text":"<p>Language models produce outputs based on their model and input prompts. Chains allow for richer and more valuable outputs by connecting inputs + outputs with other components. These components may process GenAI output, enable the execution of actions and tools, and interact with memory. Chains can be used to build more complex and integrated systems to enable higher-quality reasoning and results.</p> <p>Because of their nature, chains can be constructed in a more basic, linear fashion - as in the case of the LLM-enabled chats. They can also be constructed more generally with parallel GenAI calls, resulting in graph chains of varying complexity, which have been shown to increase performance further. </p> <p>Each call to GenAI may be considered a chain node with constant parameters, such as prompt templates, and variable parameters that are governed by external functions (including other chain/GenAI calls). </p> <p>Both basic and graph can enable cognitive architectures that further improve their performance by using specific prompts that are separated in different calls or combined in a singular prompt, that guide GenAI chained outputs and inputs. </p>"},{"location":"Understanding/agents/chains.html#basic-chains","title":"Basic Chains","text":"<p>Input to a chain node may be passed directly, embedded into a prompt template, and/or processed with traditional algorithms, like regular expressions, and augmented with memory before being processed by the GenAI. </p>"},{"location":"Understanding/agents/chains.html#prompt-templates","title":"Prompt templates","text":"<p>The prompt templates are an unresolved string that is completed before passing to a GenAI request.  Basic templates codify general prompt-engineering patterns to lead to the more desired outputs.</p>"},{"location":"Understanding/agents/chains.html#chain-components","title":"Chain components","text":"<p>There are different components of chains. They involve interactions with different units. </p>"},{"location":"Understanding/agents/chains.html#memory-interactions","title":"Memory Interactions","text":""},{"location":"Understanding/agents/chains.html#supervision","title":"Supervision","text":"<p>When a model's output, or processes or methods/prompts used as part of generating a model's output are supervised, additional feedback can help to improve the outcome. In some manner, not necessarily the self-same model would evaluate these and provide inputs to help improve subsequent trial outcomes. </p>"},{"location":"Understanding/agents/chains.html#interpreters","title":"Interpreters","text":"<p>Both the input and output into an LLM model may be interpreted, or otherwise parsed in a manner that makes the input or output more impactful. </p> <ul> <li>Native function calls and json support with OpenAI </li> </ul> <p>MANAGEN IMPROVE: When a model questions it's own, or another's output in creates an interrogation that can be used as input to the model to improve it's output. Such chain </p>"},{"location":"Understanding/agents/cognitive_architecture.html","title":"Cognitive architecture","text":"<p>Cognitive Architectures refer to systems or chain-patterns that are employed after discrete interactions with single or multiple LLMs. </p>"},{"location":"Understanding/agents/cognitive_architecture.html#core-themes","title":"Core themes","text":"<ul> <li>Rephrasing or reformatting the input in such a way that the next </li> <li>Observing or ingesting, intentionally or passively, gaining stored information that may assist in the tasks at hand. </li> <li>Reasoning or the ability to create causal connections between input and output. These are often taken care of at the level of the LLM. </li> <li>Planning to enable more complicated goals to be broken down into individually accomplishable tasks. May use external tools like memory to keep track of tasks.</li> <li>Deciding and prioritizing to select between different options or available components</li> <li>Summarizing and Abstracting to compress information into reusable chunks or otherwise abstracting information to be more effective. </li> <li>Logging + Remembering: Learning being the automatic or initiated information storage and recall that is accessed in memory</li> <li>Reflection, or an internal (or external) evaluation of output, be it thoughts, planing, and thoughts. </li> <li>Tool use While overlapping directly with Observing or taking memory-actions, tool-usage may be part of cognitive patterns (like <code>check task-list</code>) and must be considered as such. </li> </ul> <p>Models provide the computational core of Agents. Acting like a 'brain' that takes in input prompts they return outputs. Generally, the models may be considered <code>frozen</code> for a given agent, but sometimes, agentic feedback is used for helping model creation with recurrent training.</p> Cognitive Architectures for Language Agents is a thoughtful understanding of Cognitive Architectures <p>They reveal a number of thoughtful perspectives on how to consider agents, considering much of what we have included here. Going further, </p> <p> Relations between different systems. </p> <p>Prompt engineering as control flow </p>"},{"location":"Understanding/agents/cognitive_architecture.html#important-architectures","title":"Important Architectures","text":"<p>Thought systems are chain patterns used by single agents and systems to enable more robust responses.  They can be executed programmatically given frameworks or sometimes done manually in a chat setting. </p> <p>Here are some known thought structures that are improving agentic output.</p>"},{"location":"Understanding/agents/cognitive_architecture.html#linear-thought-chains","title":"Linear thought chains","text":"System 2 Attention (is something you might need too) <p>This helps to improve downstream model's ability to not suffer from irrelevent context, or judgement and preference in the  original context, termed sycophancy they use an initial model to remove unecessary context. They call it 'System 2 Attention'.  Starting with instruction-tuned models that are 'proficient at reasoning and generation'. </p> <p>They compare this to models that just use prompts like below to remove context in different manners: <pre><code>    Given the following text by a user, extract the part that is unbiased and not their opinion,\n    so that using that text alone would be good context for providing an unbiased answer to\n    the question portion of the text.\n    Please include the actual question or query that the user is asking. Separate this\n    into two categories labeled with \u201cUnbiased text context (includes all content except user\u2019s\n    bias):\u201d and \u201cQuestion/Query (does not include user bias/preference):\u201d.\n    Text by User: [ORIGINAL INPUT PROMPT]\n</code></pre> With several evaluations, including one for sycophancy, and a few variations, they show it can improve output even beyon Chain of Thought. </p> ReAct <p>Effectively Observe, Think, Act, Repeat. Paper </p> Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models provides a solid improvement over scientific Q&amp;A by first extracting fundamental principles in an initial multi-shotted prompt and then putting it into a subsequent multi-shotted prompt. <p>The authors find significant improvement over other methods. </p> <p></p> <p>Here is the prompt they use to extract the first principles:</p> <p>```markdown \"MMLU Physics/Chemistry First-Principle Prompt\" You are an expert at Physics/Chemistry. You are given a Physics/Chemistry problem. Your task is to extract the Physics/Chemistry concepts and principles involved in solving the problem. Here are a few examples: Question:  Principles Involved:  ... Question:  Principles Involved:  Question:  Principles Involved: <pre><code>Here is the prompt they use to use the extracted first principles and generate a final answer:\n\n```markdown \"MMLU Physics/Chemistry Final Answer Prompt\"\nYou are an expert at Physics/Chemistry. You are given a\nPhysics/Chemistry problem and a set of principles involved in\nsolving the problem. Solve the problem step by step by following the\nprinciples. Here are a few examples:\nQuestion: &lt;Question Example1&gt;\nPrinciples: &lt;Principles Example1&gt;\nAnswer: &lt;Answer Example1&gt;\n...\nQuestion: &lt;Question Example5&gt;\nPrinciples: &lt;Principles Example5&gt;\nAnswer: &lt;Answer Example5&gt;\nQuestion: &lt;Question&gt;\nPrinciples: &lt;Principles&gt;\nAnswer:\n</code></pre> Reflexion: an autonomous agent with dynamic memory and self-reflection an agent with dynamic memory and self-reflection capabilities <p> - Paper - Inspired github </p> Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"},{"location":"Understanding/agents/cognitive_architecture.html#planning-and-reflective","title":"Planning and Reflective","text":"Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation <pre><code>     from helpers import extract_code\n         def improve_algorithm(initial_solution, utility, language_model):\n    \"\"\"Improves a solution according to a utility function.\"\"\"\n    expertise = \"You are an expert computer science researcher and programmer, especially skilled at\n    ,\u2192 optimizing algorithms.\"\n    message = f\"\"\"Improve the following solution:\n    \u2018\u2018\u2018python\n    {initial_solution}\n    \u2018\u2018\u2018\n        You will be evaluated based on this score function:\n    \u2018\u2018\u2018python\n    {utility.str}\n    \u2018\u2018\u2018\n        You must return an improved solution. Be as creative as you can under the constraints.\n    Your primary improvement must be novel and non-trivial. First, propose an idea, then implement it.\"\"\"\n    n_messages = min(language_model.max_responses_per_call, utility.budget)\n    new_solutions = language_model.batch_prompt(expertise, [message] * n_messages, temperature=0.7)\n    new_solutions = extract_code(new_solutions)\n    best_solution = max(new_solutions, key=utility)\n    return best_solution\n    ```\n    &lt;img width=\"649\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/392da0d2-b8ce-47f0-9ae3-d3ad3fcba771\"&gt;\n    &lt;img width=\"590\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/47137d83-5aef-41e9-b356-9de3b94a853d\"&gt;\n    &lt;img width=\"537\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/4dcb9273-8965-461d-8da7-ae9a0be6debc\"&gt;\n</code></pre> [Chain-of-Verification Reduces Hallucination in Large Language Models] <p>Wherein they use the following Chain of Verification (CoVe) pattern to reduce</p> <ol> <li>Draft and initial response.</li> <li>Plan verification questions to fact-check the draft.</li> <li>Answers those questions independently to ensure it is unbiased by other responses. </li> <li>Generates the final verified response. </li> </ol> <p></p> AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect and Learn <p>Uses a reasoning path that involves coved interleaved with LLM output, with something called Plan, Execute,  Inspect, and Learn.</p> <ol> <li>Inspector: Injests, and summarizeds data for the Agent. </li> <li>Planner: Takes in instruction prompts, Input Query and Summaries of inputs coming from inpector. It outputs a thought about what will be done next and an action that follows a template of instruction-code. It uses multimodal assistance tools called a descriptor, locator and reasoner. </li> <li>Executor:  takes code from Planner as input and then calls a module to produce output. There are some additional steps including Validation Checks Module Executions and Post-processsing</li> <li>Learner: This will be doing a self-assesment* or a **ground-trugh comparison to see if it is needing updates. It will keep trying until feedback is obeyed or N commands such as no adjustment needed, revise plan or update functions would be needed to improve it's flow.</li> </ol> <p>AssistGPT empty github Webpage Uses PEIL PLan execute inspect learn.</p> Learning to Reason and Memorize with Self-Notes Allows model to deviate from input context at any time to reason and take notes <p></p>"},{"location":"Understanding/agents/cognitive_architecture.html#branching","title":"Branching","text":"<p>General manners of search.  </p> Toolchain*: Efficient Action Space Navigation in Large Language Models with A* Search provides an efficient tree guided-search algorithm that allows SOT performance <p>As opposed to other branching methods that allows for efficient exploration of action space, helping to find global optimization of a series of LLM calls. It happsens in 3 general steps: </p> <ul> <li>Selection from the highest quality frontier nodes \\(\\F(\\Tau)\\) of tree \\(\\Tau\\), by choosing the node $n_next = arg min_{n\\elem \\F(\\Tau)} f(n), given a cost-function oracle f(n) that provides the cost of the best plan of incorporating the \\(n\\)-th call into the chain. </li> <li>Expansion to create the fronteir nodes of up to k-potential actions for the next step can be sampled.  </li> <li>Updating the frontier nodes to repeat the process. </li> </ul> <p>The choice of the cost function is based on the \\(A^*\\) algorithm, where \\(f(n) = g(n) + h(n)\\) where \\(g(n)\\) is the cost of the path from the start node, and \\(h(n)\\) is a heuristic function that estimates the cheapest path from \\(n\\) to the destination goal. </p> <p>Their choice of \\(g(n)\\) is generally the sum of single-steps costs from ancestor nodes. More accurately they create a geometric sum of two different step value functions. </p> <p>One step function is a task-specific heuristic function that maximizes the longest-common subsequence score over other paths. The longest-common subsequence score finds the longest-common subsequence between plan \\(s_n\\) and other plans \\(m_j\\) and divides by the smaller of the two lengths of the paths \\(s_n\\) and \\(m_j\\). </p> <p>The other step function is a self-consistency frequency that takes an ensemble approach to generate the next steps. It calculates the number of actions that arrive at step n using non-semantically equivalent reasoning steps, divided by the number of k samples.  </p> <p>Their choice of the future cost \\(h(n)\\) is a multiplicative combination of a similar task-specific heuristic and an imagination score, enabled by an LLM. </p> <p>The future task-specific heuristic calculates the average fractional position of action a found within all plans.</p> <p>The imagination score directly queries the LLMs to imagine more concrete steps until target node \\(n_T\\) and computing the ratio of the number of steps of the number between the current node n ancestors to the target node. The higher score 'suggests the imagined plan closely captures the path to the current step, indicating that fewer remaining steps are needed to accomplish the task in the imagination of LLMs. </p> <p> </p> Algorithm of Thoughts A general extension of Chain of Thought, similar to Graph of Thoughts <p></p> Graph of Thoughts Generalizes Chain of Thought, Tree of Thoughts, and similar systems of thought <p></p> Graph of Thought <p>An excellent thought on what next to consider when dealing with knowledge (or other output like information) generation chains. </p> Meta Tree of thought <p></p> Strategic Reasoning with Language Models Uses game trees and observed and inferred beliefs to achieve closer to optimal results.  <p>Powerful to consider for inferred beliefs and interacting in situations where negotiation or games are being played. </p> Large Language Model Guided Tree-of-Thought <p>Github</p> Tree of Thoughts: Deliberate Problem Solving with Large Language Models A method that allows for idea-expansion and selection of the final result output by choosing the best at each stage. <p>The thought flow Github</p> <p>\"Prompts compared\" <pre><code>    standard_prompt = '''\n    Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input}\n    '''\n    cot_prompt = '''\n    Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input}\n\n    Make a plan then write. Your output should be of the following format:\n\n    Plan:\n    Your plan here.\n\n    Passage:\n    Your passage here.\n    '''\n\n    vote_prompt = '''Given an instruction and several choices, decide which choice is most promising. Analyze each choice in detail, then conclude in the last line \"The best choice is {s}\", where s the integer id of the choice.\n    '''\n\n    compare_prompt = '''Briefly analyze the coherency of the following two passages. Conclude in the last line \"The more coherent passage is 1\", \"The more coherent passage is 2\", or \"The two passages are similarly coherent\".\n    '''\n\n    score_prompt = '''Analyze the following passage, then at the last line conclude \"Thus the coherency score is {s}\", where s is an integer from 1 to 10.\n    ''' \n</code></pre></p>"},{"location":"Understanding/agents/cognitive_architecture.html#recursive","title":"Recursive","text":"Teaching Large Language Models to Self-Debug <code>transcoder</code> <p>Coding focused LLM system to continuously improve self.  </p> Language Models can Solve Computer Tasks Uses Recursive Criticism and Improvement. <p>Website, GitHub  Combining with Chain of Thought it is even better. The method: Plan: Critique, Improve  - Explicit RCI: \"Review your previous answer and find problems with your answer.\" \u2192 \"Based on the problems you found, improve your answer.\" Recursively Criticizes and Improves its output. This sort of prompting outperforms Chain of Thought, and combined it works even better.  </p>"},{"location":"Understanding/agents/cognitive_architecture.html#structural-decomposition","title":"Structural Decomposition","text":"<p>Breaking down the input into a divide-and-conquer approach is a valuable approach to more complex requests. Considering separate perspectives, within the same model, or within separate model calls with different prompt-inceptions as in agent systems can improve performance.</p> Skeleton of Thought <p>A nice structure that resembles the thoughtful creation of answers allows for parallelization and hence speedup, with comparable or better results in answer generation.  </p> <p>Skeleton prompt template<pre><code>    [User:] You\u2019re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n    Provide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full\n    sentence, each skeleton point should be very short with only 3\u223c5 words. Generally, the skeleton should have 3\u223c10\n    points.\n    Question:\n    What are the typical types of Chinese dishes?\n    Skeleton:\n    1. Dumplings.\n    2. Noodles.\n    3. Dim Sum.\n    4. Hot Pot.\n    5. Wonton.\n    6. Ma Po Tofu.\n    7. Char Siu.\n    8. Fried Rice.\n    Question:\n    What are some practical tips for individuals to reduce their carbon emissions?\n    Skeleton:\n    1. Energy conservation.\n    2. Efficient transportation.\n    3. Home energy efficiency.\n    4. Reduce water consumption.\n    5. Sustainable diet.\n    6. Sustainable travel.\n    Now, please provide the skeleton for the following question.\n    {question}\n    Skeleton:\n    [Assistant:] 1.\n</code></pre> Point expanding prompt template<pre><code>    [User:] You\u2019re responsible for continuing the writing of one and only one point in the overall answer to the following\n    question.\n    {question}\n    The skeleton of the answer is\n    {skeleton}\n    Continue and only continue the writing of point {point index}. Write it **very shortly** in 1\u223c2 sentence and\n    do not continue with other points!\n    [Assistant:] {point index}. {point skeleton}\n</code></pre></p> Question Decomposition Improves the Faithfulness of Model-Generated Reasoning <p> A nice discussion on it</p> Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent Through Multi-person Self-Collaboration <p>Uses a prompt that initiates a group of personas to be used within the same LLM call to facilitate collaborative analysis and creation of the final output. Solid improvement but comparisons to other techniques are potentially uncertain. \"Example prompt\" </p> <p>```python title=\"Trivia writing SPP'</p> <pre><code>spp_prompt = '''When faced with a task, begin by identifying the participants who will contribute to solving the task. Then, initiate a multi-round collaboration process until a final solution is reached. The participants will give critical comments and detailed suggestions whenever necessary.\n\nHere are some examples:\n---\nExample Task 1: Use numbers and basic arithmetic operations (+ - * /) to obtain 24. You need to use all numbers, and each number can only be used once.\nInput: 6 12 1 1\n\nParticipants: AI Assistant (you); Math Expert\n\nStart collaboration!\n\nMath Expert: Let's analyze the task in detail. You need to make sure that you meet the requirement, that you need to use exactly the four numbers (6 12 1 1) to construct 24. To reach 24, you can think of the common divisors of 24 such as 4, 6, 8, 3 and try to construct these first. Also you need to think of potential additions that can reach 24, such as 12 + 12.\nAI Assistant (you): Thanks for the hints! Here's one initial solution: (12 / (1 + 1)) * 6 = 24\nMath Expert: Let's check the answer step by step. (1+1) = 2, (12 / 2) = 6, 6 * 6 = 36 which is not 24! The answer is not correct. Can you fix this by considering other combinations? Please do not make similar mistakes.\nAI Assistant (you): Thanks for pointing out the mistake. Here is a revised solution considering 24 can also be reached by 3 * 8: (6 + 1 + 1) * (12 / 4) = 24.\nMath Expert: Let's first check if the calculation is correct. (6 + 1 + 1) = 8, 12 / 4 = 3, 8 * 3 = 24. The calculation is correct, but you used 6 1 1 12 4 which is not the same as the input 6 12 1 1. Can you avoid using a number that is not part of the input?\nAI Assistant (you): You are right, here is a revised solution considering 24 can be reached by 12 + 12 and without using any additional numbers: 6 * (1 - 1) + 12 = 24.\nMath Expert: Let's check the answer again. 1 - 1 = 0, 6 * 0 = 0, 0 + 12 = 12. I believe you are very close, here is a hint: try to change the \"1 - 1\" to \"1 + 1\".\nAI Assistant (you): Sure, here is the corrected answer:  6 * (1+1) + 12 = 24\nMath Expert: Let's verify the solution. 1 + 1 = 2, 6 * 2 = 12, 12 + 12 = 12. You used 1 1 6 12 which is identical to the input 6 12 1 1. Everything looks good!\n\nFinish collaboration!\n\nFinal answer: 6 * (1 + 1) + 12 = 24\n\n---\n\n'''\n</code></pre> <p>```</p> Teach LLMs to Personalize \u2013 An Approach inspired by Writing Education <p></p>"},{"location":"Understanding/agents/cognitive_architecture.html#constraining-outputs","title":"Constraining outputs","text":"Certified Reasoning with Language models A 'logical guide' tool that an LLM can use. <p>It \" uses constrained decoding to ensure the model will incrementally generate one of the valid outputs.\"   Possible open-source implementation here</p> Outlines guides the model generation of next-token logits to guide the generation corresponding to regex / JSON and pydantic schema. compatible with all models. <p>Also provides a way to functionalize templates to separate prompt logic.</p>"},{"location":"Understanding/agents/cognitive_architecture.html#automated-chain-selection-and-discovery","title":"Automated chain selection and discovery","text":"Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine <ul> <li>GPT4 + Simple Prompts (86.1, MedQA task)\u00a0</li> <li>GPT4 + Complex Prompts (90.2, MedQA task)</li> </ul> <p>The Authors use 'in context learning' (more like RAG) to identify prompting chains for specific problem sets that are 'winning'. </p> <p>Their prompting strategies can efficiently steer GPT-4 to achieve top performance on medical problems (90% on MedQA dataset).\u00a0</p> <p>The winning composition of prompting strategies is fairly elaborate including multiple steps:</p> <ol> <li>Preprocessing Phase:</li> </ol> <p>- Iterate through each question in the training dataset. \u00a0- Generate an embedding vector for each question using a lightweight embedding model, such as OpenAI's text-embedding-ada-002. \u00a0- Use GPT-4 to generate a chain of thought and a prediction of the final answer. \u00a0- Compare the GPT-4 generated answer against the ground truth (correct answer). \u00a0- Store questions, their embedding vectors, chains of thought, and answers if the prediction is correct; otherwise, discard them.</p> <ol> <li>Inference Step:</li> </ol> <p>- Compute the embedding for the test question using the same embedding model as in preprocessing. \u00a0- Select the most similar examples from the preprocessed training data using k-Nearest Neighbors (kNN) and cosine similarity as the distance function. \u00a0- Format the selected examples as context for GPT-4. \u00a0- Repeat the following steps several times (e.g., five times as configured): \u00a0- Shuffle the answer choices for the test question. \u00a0- Prompt GPT-4 with the context and shuffled test question to generate a chain of thought and a candidate answer. \u00a0- Determine the final predicted answer by taking a majority vote of the generated candidate answers.</p> <p>Additional Details:</p> <ul> <li>The strategy uses 5 kNN-selected few-shot exemplars and performs 5 parallel API calls in the ensemble procedure.</li> <li>Ablation studies suggest that increasing the number of few-shot exemplars and ensemble items can yield better performance.</li> <li>The general methodology of combining few-shot exemplar selection, self-generated chain-of-thought reasoning, and majority vote ensembling is not limited to medical texts and can be adapted to other domains and problem types.</li> </ul> <p>Limitations:</p> <ul> <li>Assumes availability of training ground truth data needed for preprocessing steps</li> <li>Costs (multiple llm inference calls, latency). This will matter depending on use case and accuracy requirements\u00a0</li> <li>Problem Domain - this will work best for tasks that have a single valid objective answer</li> </ul> <p> </p>"},{"location":"Understanding/agents/cognitive_architecture.html#chain-optimization","title":"Chain Optimization","text":"<p>Problems such as Hallucinations can be mitigated through downstream methods of process. </p> A stitch in time saves Nine <p>A process to mitigate model hallucination using RAG.  </p>"},{"location":"Understanding/agents/cognitive_architecture.html#_1","title":"Cognitive architecture","text":""},{"location":"Understanding/agents/environments.html","title":"Environments","text":"<p>Environments consist of the information that agents have access too as well as 'what can be done' to influence the environment. An environment sends information that an agent can receive. </p> <p>The origin of the information can be 'a person' or a 'data stream' that is based in real-measurements, or a simulation. </p> <p>A chat-environment</p> <p>In a chat environment the GenAI receives text information from a user and then returns text information that is printed for the user to read.</p> <p>A town simulation</p> <p>In Generative Agents: Interactive Simulacra of Human Behavior A town is simulated to provide observable information and an interaction world with/between other agents. </p> <p>A camera and microphone</p> <p>As may be needed for a robot, a camera, and a microphone provide the inputs for the environment that it exists in. The signals received (and processes) only represent a portion of what might potentially be received. </p> <p>Madrona Game Enging</p>"},{"location":"Understanding/agents/evaluating_and_comparing.html","title":"Evaluating and comparing","text":"<p>Because of potential pitfalls with Generative AI technology, it is essential to evaluate, compare, and test models such that they meet the indendent requirements. </p> <p>Below are some tools that you can use to help with this!</p>"},{"location":"Understanding/agents/evaluating_and_comparing.html#repositories","title":"Repositories","text":"Helm contains code used in the Holistic Evaluation of Language Models project <p>Paper </p> Arthur.ai Bench Bench is a tool for evaluating LLMs for production use cases.  <p> </p> DeepEval provides a Pythonic way to run offline evaluations on your LLM pipelines <p>\"... so you can launch comfortably into production. The guiding philosophy is a \"Pytest for LLM\" that aims to make productionizing and evaluating LLMs as easy as ensuring all tests pass.\" </p> Auto Evaluator with github to evaluate appropriate components of chains to enable best performance <p></p> Identifying the Risks of LM Agents with an LM-Emulated Sandbox <p>Where in their paper they demonstrate an emulation container to evaluate the safety of an Agent.</p> <p> </p> AgentBench: Evaluating LLMs as Agents <p>A comprehensive 8-environment evaluation for different agents from different models. Paper </p> JudgeLM: Fine-tuned Large Language Models are Scalable Judges trains LLMs to judge the outputs of LLMs based on reference examples and achieves greater coherence than human rating <p>Also provides a great example GUI and interface using GradIO </p>"},{"location":"Understanding/agents/examples.html","title":"Examples","text":"<p>There are different categories for Agents, which are often either by the environment in which they act or by the manner in which they are used. </p> <p>Environments</p> <ol> <li>Human+Chat-agents</li> <li>Autonomous chat-agents</li> <li>Agent-systems</li> <li>Physical-input agents</li> </ol> <p>Purpose:</p> <ul> <li>Do simple/single things: perhaps ephemeral. </li> <li>Do a complex task that may require simple things. Very likely enduring, especially if they are expert systems.. </li> <li>Doing a list set of complex tasks, perhaps more continuously enduring. </li> </ul>"},{"location":"Understanding/agents/examples.html#agent-examples","title":"Agent Examples","text":"<p>Here are a few examples. Because agents are hard to disentangle from core components, we describe more throughout, especially in the section on cognitive architectures</p> [Fresh LLMs](https://github.com/freshllms/freshqa that propose FreshQA, a dynamic QA benchmark, and FreshPrompt that allows LLMs to stay up to date <ul> <li>Paper</li> </ul> <p> It also includes question-premise checking to help minimize hallucination </p> Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning <p>In their paper they present a Planning-Retrieval-Reasoning framework that called 'Reasoning on Graphs' or RoG. RoG generates ground plans enabled by KGs which are then used to retrieve reasoning paths for the LLM.  </p> Large language models as tool makers Github Allows high-quality tools to be reused by more lightweight models. <p></p> CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation <p> </p> smolai https://www.youtube.com/watch?v=zsxyqz6SYp8&amp;t=1s An interesting example Agent-GPT <p>Website </p> <p>GPT Engineer</p> DevOpsGPT <p><pre><code>Through the above introduction and Demo demonstration, you must be curious about how DevOpsGPT achieves the entire process of automated requirement development in an existing project. Below is a brief overview of the entire process:\n</code></pre> <pre><code>    Clarify requirement documents: Interact with DevOpsGPT to clarify and confirm details in requirement documents.\n    Generate interface documentation: DevOpsGPT can generate interface documentation based on the requirements, facilitating interface design and implementation for developers.\n    Write pseudocode based on existing projects: Analyze existing projects to generate corresponding pseudocode, providing developers with references and starting points.\n    Refine and optimize code functionality: Developers improve and optimize functionality based on the generated code.\n    Continuous integration: Utilize DevOps tools for continuous integration to automate code integration and testing.\n    Software version release: Deploy software versions to the target environment using DevOpsGPT and DevOps tools.\n</code></pre></p> UniversalNER Used ChatGPT to distill a much smaller model for a certain domain, <p><pre><code>\"Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPT\u2019s capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We will release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation.\"\n</code></pre> https://arxiv.org/pdf/2308.03279.pdf https://github.com/universal-ner/universal-ner</p> Suspicion-Agent: Playing imperfect Information Games with Theory of Mind Aware GPT-4 <p>Introduces directly into the prompts a Theory-of-Mind about their awareness and own estimations and will update accordingly.\"   </p> CLIN: A Continually Learning Language Agent for Rapid Task Adaptation and Generalization <p>An agent that stores a memory involving action, rationale, and result so that it can improve doing certain tasks. It uses a lookup to identify things that it needs to do and likely causal relations to decide to work on it. The code is a little Academic, but generally readable here Github. </p> <p>On the ScienceWorldEnv environment simulator it performed reasonably well. </p> <p></p> <p> </p>"},{"location":"Understanding/agents/examples.html#libraries","title":"Libraries","text":"<p>Robo GPT</p> <p>Chrome-GPT: an experimental AutoGPT agent that interacts with Chrome</p>"},{"location":"Understanding/agents/memory.html","title":"Memory","text":"<p>Agent memory is considered a state associated with a llm-call and effects the ability of LLM to respond, thereby helping to enable agentic ability. Memory augmented models enhance the capabilities of language models by ___ to improve their performance and efficiency. TODO: Read trillions of tokens paper. </p>"},{"location":"Understanding/agents/memory.html#memory-considerations","title":"Memory Considerations","text":"<p>Memory plays a crucial role in enhancing the efficiency of information recall and routing for different chains and agent interactions. </p> <p>In systems comprising Agents (and People), conversation buffers may be employed to keep track of information. These buffers, can be 'private',  can facilitate communication between any agents, storing response stacks that include agent-environment interactions.</p> <p>For text-based memory can consist of perfect text record or compressed summaries, that may or may not follow some form of memory-schema.</p> <p>Memory can be pushed (into prompt templates) and requested (based on GET memory requests from an LLM agent). </p>"},{"location":"Understanding/agents/memory.html#uses","title":"Uses","text":""},{"location":"Understanding/agents/memory.html#input-prompt-caching","title":"Input (prompt) Caching","text":"<p>Input caching is a technique that leverages memory to improve response time and efficiency. Instead of generating tokens based on the next input, it uses caching to identify responses that may have already been generated for similar prompts. This significantly enhances the efficiency of repeated queries. However, it may cause issues if the initial response was not satisfactory, as the system would return the same cached response.</p>"},{"location":"Understanding/agents/memory.html#parsed-information-routing","title":"Parsed information routing","text":"<p>Parsed information routing involves directing parsed or processed information to the appropriate destination. This can be particularly useful in systems with multiple agents or complex workflows.</p>"},{"location":"Understanding/agents/memory.html#implementations","title":"Implementations","text":"<p>Memory implementations can be based on memory types serialized and stored in many ways. Semantic searches can happen by looking at similar embeddings. </p> <p>These can be global or private, and structured inside agent classes or inside system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can be in memory and stored on disk or in the cloud. They allow informaion to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p> <p>Memory implementations can vary based on the type of memory used, and how it's serialized and stored. Semantic searches can be performed by comparing embeddings for similarity. These memory systems can be global or private, and can be structured within agent classes or within system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can exist in memory, stored on disk, or in the cloud. They allow information to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p>"},{"location":"Understanding/agents/memory.html#types","title":"Types","text":""},{"location":"Understanding/agents/memory.html#vector-databases","title":"Vector databases","text":"<p>Vector databases, such as Pinecone, Qdrant, Weaviate, Chroma, Faiss, Redis, Milvus, and ScaNN, use embeddings to create query vector databases. These databases allow for efficient semantic searches. </p> <p>Example vector databases</p> <p>Please read this for more information  Vector Databases (primer by Pinecone.io)</p> <ul> <li>https://github.com/Helicone/helicone</li> <li>Website Github</li> </ul>"},{"location":"Understanding/agents/memory.html#traditional-databases","title":"Traditional databases","text":"<p>Databases that rely on query-languages such as SQL or non-SQL based databases, or even 'csv-type' information stores can be accessed and generated using agents. </p> <p>The models may generate queries that can be executed by by an interpreter, though it is not guaranteed that the queries will be accurate. TODO: Find reference</p> <p>References</p> <p>For more information on memory implementations and caching, refer to the following resources:</p> <ul> <li>Langchain <code>memory</code></li> <li>Langchain <code>llm_caching</code></li> <li>Improving language models by retrieving from trillions of tokens</li> </ul>"},{"location":"Understanding/agents/rag.html","title":"Retrieval-Augmented Generation (RAG)","text":"<p>Large Language Models (LLMs) can be made more useful by enabling them to access a set of information relevant to the prompt at hand. This can be achieved by extracting information from vector, SQL, and no-SQL memory and feeding it into the LLM. This approach, known as Retrieval-Augmented Generation (RAG), was introduced in 2020 in Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. It has shown impressive results in improving the generation of content. However, it is still an area of active development and research, and fully optimized solutions are not always available.</p> <p>This document also discusses the relationship between RAG and knowledge graphs.</p>"},{"location":"Understanding/agents/rag.html#rag-process","title":"RAG Process","text":"<p>The RAG process can be divided into two main stages: Preparation (offline) and Retrieval and Generation (online).</p> <pre><code>    graph TB\n        A[Proprietary Data] --&gt;|Format | B(Embedding Model)\n        C[User Question] --&gt; |Transform| Q(Query)\n        Q --&gt; B\n        B --&gt;|Store| D[Vector Database]\n        B --&gt; |Search|D\n        D --&gt; |Retrieve| E[Assemble relevant documents]\n        E --&gt; F[Prompt: Original Question + Context]\n        C --&gt; F\n        F --&gt;|Generate| G[LLM]\n        G --&gt; H[Answer]</code></pre>"},{"location":"Understanding/agents/rag.html#preparation-offline","title":"Preparation (offline)","text":"<p>The preparation stage involves the following steps:</p> <ol> <li>Data Selection: Choose the appropriate data to ingest.</li> <li>Loading Data: Load the data in a manner that can be consumed by the models.</li> <li>Splitting Data: Split the data into chunks that can be both consumed by the model and retrieved with a reasonable degree of data.</li> <li>Embedding Data: Embed the data.</li> <li>Storing Data: Store the embedding.</li> </ol>"},{"location":"Understanding/agents/rag.html#retrieval-and-generation-online","title":"Retrieval and Generation (online)","text":"<p>The retrieval and generation stage involves the following steps:</p> <ol> <li>Retrieving Data: Retrieve the data based on input in such a way that relevant documents and chunks can be used in downstream chains.</li> <li>Generating Output: Generate an output using a prompt that integrates the query and retrieved data.</li> </ol>"},{"location":"Understanding/agents/rag.html#detailed-steps","title":"Detailed Steps","text":""},{"location":"Understanding/agents/rag.html#data-selection","title":"Data Selection","text":"<p>Users should only access data that is appropriate for their application. However, including too much information might be unnecessary or harmful to retrieval if the retrieval cannot handle the volume or complexity of data. It is also crucial to ensure data privacy when providing data that might not be appropriate (or legal) to access.</p>"},{"location":"Understanding/agents/rag.html#loading-data","title":"Loading Data","text":"<p>Different data types require different loaders. Raw text, PDFs, spreadsheets, and more proprietary formats need to be processed in a way that the information is of highest relevance to data. Text is easy to process, but some data, especially multimodal data like PDFs, may need to be formatted with a schema to allow for more effective searching.</p>"},{"location":"Understanding/agents/rag.html#splitting-data","title":"Splitting Data","text":"<p>Once data has been loaded in a way that a model can process it, it must be split. There are several ways of splitting data:</p> <ol> <li>By the max size a model can handle.</li> <li>By some heuristic break, such as <code>\\n</code> return characters or <code>\\p</code> paragraphs or newlines.</li> <li>In a manner that maximizes the topic coherence. In this case, splitting and embedding may happen simultaneously.</li> </ol>"},{"location":"Understanding/agents/rag.html#embedding-data","title":"Embedding Data","text":"<p>Index Building - One of the most useful tricks is multi-representation indexing: decouple what you index for retrieval (e.g., table or image summary) from what you pass to the LLM for answer synthesis (e.g., the raw image, a table). See blog:  https://blog.langchain.dev/semi-structured-multi-modal-rag/\u2026</p>"},{"location":"Understanding/agents/rag.html#storing-data","title":"Storing Data","text":"<p>The embedded data is stored for future retrieval and use.</p>"},{"location":"Understanding/agents/rag.html#retrieving-data","title":"Retrieving Data","text":"<p>The decision and act to retrieve the documents will depend on the additional contexts that the agents may need to be aware of. </p> <p>It might not always be necessary to retrieve documents. When it is necessary to retrieve the document, it is important to know where to retrieve from routing, and then matching the query to the appropriately stored information. Both of these may involve rewriting the prompt to be more effective in the manner the data is retrieved. </p>"},{"location":"Understanding/agents/rag.html#query-transformations","title":"Query Transformations","text":"<p>Query transformations can be done in several ways, including:</p> <ol> <li> <p>Rewrite-Retrieve-Read: This approach involves rewriting the query for better retrieval and reading of the relevant documents.</p> Query Rewriting for Retrieval-Augmented Large Language Models <p></p> </li> <li> <p>Step Back Prompting: This method generates an intermediate context that helps to 'abstract' the information. Once generated, the additional context can be used.</p> Step back <pre><code>You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n\n{normal_context}\n{step_back_context}\n\nOriginal Question: {question}\nAnswer:\n</code></pre> Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models <p></p> </li> <li> <p>Question Rephrasing: Particularly in chat settings, it's important to include all of the appropriate context to create an effective search query. </p> Rephrase question <pre><code>    Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\n    Chat History:\n    {chat_history}\n    Follow Up Input: {question}\n    Standalone Question:\n</code></pre> </li> <li> <p>Question Partitioning: Some questions may require individual pieces of information to be found to answer the question. This means breaking the question apart into multiple pieces. </p> </li> </ol>"},{"location":"Understanding/agents/rag.html#routing","title":"Routing","text":"<p>Queries may need to be routed to different data sources depending on what is being asked. Recent blog reviewing OpenAI's RAG strategies provides some guidance on question routing: https://blog.langchain.dev/applying-openai-rag/</p>"},{"location":"Understanding/agents/rag.html#matching","title":"Matching","text":"<p>Matching involves aligning the query with the appropriately stored information. </p>"},{"location":"Understanding/agents/rag.html#generating","title":"Generating","text":"<p>The final step is generating an output using a prompt that integrates the query and retrieved data. </p>"},{"location":"Understanding/agents/rag.html#other-topics","title":"Other Topics","text":"<ol> <li> <p>Multi-Modal: This approach is used for RAG on a substack that has many images of densely packed tables, graphs. Here is an example implementation.</p> </li> <li> <p>Semi-Structured: This approach is used for RAG on documents with tables, which can be split using naive RAG text-splitting that does not explicitly preserve them. Here is an example implementation.</p> </li> </ol>"},{"location":"Understanding/agents/rag.html#tutorials-and-blogs","title":"Tutorials and Blogs","text":"<ul> <li>Langchain Question Answering </li> <li>RAG demystified</li> </ul>"},{"location":"Understanding/agents/systems.html","title":"Systems","text":"<p>When an agent (or model) engages in an interaction with another agent, the result is an agent system. This is achieved by implementing and equipping various agents, and then setting them up so that the output of one is used as the input of the other. Although one may argue that an agent's input can be perceived as another 'tool' where the different agent prompts the action, this argument isn't entirely valid. The reason is that, in most cases, the same considerations apply to all agents but not to all tools. Therefore, we deal with it separately.</p> <p>Binary system (asymmetric calling)</p> <p>In this system, ChatGPT initiates communication with DallE using a prompt. DallE responds by delivering an image. This image is then used in the final response of ChatGPT or returned as-is.</p> <p>Multi-body system (bidirectional calling)</p> <p>This system consists of multiple agents, and they engage in ongoing discussions about their daily activities. They also receive regular updates about their environment. An example of this type of system can be viewed in this paper.</p>"},{"location":"Understanding/agents/systems.html#tools-paper-and-code","title":"Tools Paper and Code","text":"AutoGen enables LLM application development with communication between multiple agents. <p> Paper TRY THIS!</p> AutoAgents: A Framework for Automatic Agent Generation <p>Paper </p> <p>TRY THIS!</p> MetaGPT enables different agents to interact and generate meaningful outputs based on varying tasks and personas. <p>Reworkd/AgentGPT '\ud83e\udd16 Assemble, configure, and deploy autonomous AI Agent(s) in your browser. \ud83e\udd16'</p> <p>Self-play GPT</p> <p>This model leverages different game-roles and LLMs to provide feedback on how to optimize the model and facilitate autonomous enhancement during gameplay.</p> <p>Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind</p> <p>In this work, the Theory of Mind (ToM) concept is used to attempt to improve the performance of students. Github</p> Generative Agents: Interactive Simulacra of Human Behavior in a simulated town!!! <p>This paper discusses a simulation involving different agents exhibiting different personalities. The dynamic environment, shared in code can be manipulated by these agents. The paper explores various challenges and proposed solutions including: <pre><code>**Remembering**\n    _Observation Memory_ This is a memory stream that maintains a record of past experiences. These experiences are stored in \"memory objects\", which are described in natural language, and timestamped. The importance of each memory object is determined using metrics such as _recency_, _importance_, and _relevance_. \n    _Reflection Memory_ This memory type allows the agent to generate more abstract thoughts. These thoughts can be included along with reflections. This process is hardcoded to occur when the sum of importance scores exceeds a certain threshold.\n**Planning and Reacting**\n    _Recursive Planning_ In this process, the agent divides the day into chunks of \"goals\", which are further broken down into smaller time frames. The ability to adjust these plans based on interactions is a key feature of this mechanism.\n</code></pre></p> <p>Multi-Agent Collaboration via Reward Attribution Decomposition</p> <p>This work illuminates optimization techniques for multi-agents using distributed reward systems to achieve state-of-the-art performance. It introduces a joint optimization approach that depends on self and interactive terms.</p> <p>Super-AGI</p> <p>Super-AGI is a model that allows multiple agents to function. However, this system doesn't facilitate any communication between the agents.</p> <p>GPT-Bargaining</p> <p>This model applies several iterations to improve negotiation tactics based on external feedback.</p> <p>RL4L Allen ai</p> <p>RL4L AI employs a small critique model to enhance the output from the larger model. It uses a policy gradient to fine-tune the critique model while maintaining reasonable performance gains. Github</p> Showrunner Agents The Showrunner Agents use Large Language Models (LLMs) to generate episodic content. <p>It's a massively creative and multi-faceted process with a great potential. </p> Improving Factuality and Reasoning in Language Models through Multiagent Debate where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. <p>They tried both concatenation or summarization of other results. Summarization reduces length and improves quality.  <pre><code>    # Debate Length Prompt\n    short_prompt = \"\"\" These are the solutions to the problem from other agents: {other_answers}\n        Based off the opinion of other agents, can you give an updated response . . .\"\"\"\n    long_prompt = \"\"\" These are the solutions to the problem from other agents: {other_answers}\n        Using the opinion of other agents as additional advice, can you give an updated response . . .\"\"\"\n</code></pre> Github</p> Council  Very promising initial creation of networks of agents to create full-fledged teams for output products. <p></p> SocraticAI to use the power of conversation to solve problems. Very interesting <p>Description </p>"},{"location":"Understanding/agents/systems.html#open-source-implementations-unpublished","title":"Open Source Implementations (unpublished)","text":"<p>Swarms</p> <p>Very thoughtful next-level systems focusing on large-dimensions of swarms. Very initial stages but has a lot of promise.  Github</p>"},{"location":"Understanding/agents/systems.html#potentially-useful-tools","title":"Potentially useful tools","text":"<p>Nomadproject.io A simple and flexible scheduler and orchestrator to deploy and manage containers and non-containerized applications across on-prem and clouds at scale.</p> <p>Firecracker 'Our mission is to enable secure, multi-tenant, minimal-overhead execution of container and function workloads.'</p>"},{"location":"Understanding/architectures/index.html","title":"Architectures","text":"<p>Here we will discuss the architectural components needed to build Gen()AI models. While it is often useful or essential to use pre-trained models, it is likely that such pre-trained models can be further refined for specific use-cases. </p> <p>tl;dr</p> <ul> <li>Understand self-supervised learning</li> <li>Learn about models</li> <li>Pre-Train your models</li> <li></li> <li>Optimize your models'</li> </ul>"},{"location":"Understanding/architectures/index.html#background","title":"Background","text":"<p>There is a rich history of Generative AI architectures, which will be shared in future versions of this code. </p> <p>Of primary importance is the manner of model learning, or adapting to the input data. There are several fundamental types of model-updating: supervised learning, unsupervisedlearning, semi-supervised learning, self-supervised learning, reinforcement learning (RL), and combinations of thereof. </p> <p>Presently, the most successful models rely on  foundation models that are trained on large corpora of data in a self-supervised manner. These models can then be refined using supervised, semi-supervised, and/or reinforcement learning techniques. </p> <p>Once built, Gen()AI is generally called with language inputs to create a specifically desired end result.  These inputs, known as prompts will generally be model-specific but may sometimes share commonalities for more optimal usage, which we describe in prompt engineering.</p>"},{"location":"Understanding/architectures/index.html#foundation-models","title":"Foundation Models","text":"<p>Foundation models are large-scale models that are pre-trained with self or semi-supervision on vast amounts of data and can be fine-tuned for specific tasks. These models serve as a foundation or base for various applications, reducing the need to train models from scratch.</p>"},{"location":"Understanding/architectures/index.html#model-learning","title":"Model Learning","text":"<p>There are several fundamental ways that models can 'learn' in relation to how data interacts with the model. </p> To Compress or Not to Compress provides a coherent understanding of different manners of learning in relation to information theory. <p></p>"},{"location":"Understanding/architectures/index.html#self-supervised-learning","title":"Self-supervised learning","text":"<p>Self-supervision amounts to using a single data entry to train a model to predict a portion of the data itself. For instance, a model that is used to predict the next word in a string of text or a model that is used to generate a piece of an image that has been blanked out. This approach has proven to be highly effective, especially for tasks where labeled data is expensive to obtain or otherwise scarce.</p>"},{"location":"Understanding/architectures/index.html#supervised-learning","title":"Supervised learning","text":"<p>Supervised learning is a more traditional ML approach that generally involves predicting the association between an input and an output variable. While generally quite powerful, supervised learning can be limited by the volume and cost of obtaining quality 'labeled' data, where inputs and outputs are associated with a high degree of veracity. </p>"},{"location":"Understanding/architectures/index.html#unsupervised-learning","title":"Unsupervised learning","text":"<p>Unsupervised learning is often used for discovering insights and patterns in the way data is distributed or related. While not directly or consistently used in GenAI systems, it can be valuable for filtering and selecting data. </p>"},{"location":"Understanding/architectures/index.html#reinforcement-learning","title":"Reinforcement learning","text":"<p>Generally originating from game-play and robotics, reinforcement learning offers the capacity for models to interact with a generally more complex environment. When combined with self-supervision, reinforcement learning has proven to be essential to create powerful GPT architectures.</p>"},{"location":"Understanding/architectures/index.html#hybrid-learning-methods","title":"Hybrid learning methods","text":"<p>Hybrid Learning methods combine one or several methods above to enable more successful Generative AI. Semi-supervised learning is a form of hybrid learning where supervised and unsupervised learning are used to produce the final outcome. </p> <p>General Pretrained Transformer models (GPT) work this way by first doing unsupervised prediction. Then some supervised training is provided. Then an RL approach is used to create a loss model using reinforcment Learning with Human Feedback (RLHF) to score multiple potential outputs to provide more effective outputs. </p> <p>Particular types of RLHF, like instruction-training of Instruct GPT enables models to perform effectively. </p> <p></p>"},{"location":"Understanding/architectures/index.html#language-models-and-llms","title":"Language Models and LLMs","text":"<p>Language models (LMs) are a type of generative model trained to predict the next word in a sequence, given the previous words. They capture the statistical properties of language and can generate coherent and contextually relevant sentences.</p> <p>Large Language Models (LLMs) are a subset of language models that are trained on vast amounts of text data. Due to their size and the diversity of data they're trained on, LLMs can understand and generate a wide range of textual content, from prose and poetry to code and beyond. </p>"},{"location":"Understanding/architectures/index.html#gpt-architectures","title":"GPT architectures","text":"<p>Generative AI models are of two general categories: self-supervised, and Externally-supervised, and hybrid models. </p>"},{"location":"Understanding/architectures/index.html#model-classes","title":"Model Classes","text":"<p>Different model classes of models can often be used with multiple types of model learning. Because of their present degree of quality present model Architectures tend to be transformer-based, or diffusion-based, or made from any other sufficently capable AI method. While Generative Adversarial Networks, GANS were the initially most successful, the challenges in training them successfully can be difficult to surmount. Below we describe the model classes in greater detail.</p> <ul> <li>Hybrid models like GPT</li> <li>Transformers</li> <li>Diffusers</li> <li>Generative Adversarial Networks</li> <li>Reinforcement Learning</li> <li>Developing Architectures</li> </ul>"},{"location":"Understanding/architectures/index.html#quality-references","title":"Quality References","text":"<ul> <li>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </li> <li>Understanding Large Language Models</li> <li>What we know about LLMS (primer)</li> <li>Catching up on the weird world of LLMs</li> <li>LLM Engineering by Huyen Chip</li> </ul>"},{"location":"Understanding/architectures/evaluating_and_comparing.html","title":"Evaluating and comparing","text":"<p>There are many ways that you can evaluate your model, and the manner of evaluation will generally  depend on your use case. </p> <p>As a general principle in ML, it is important to have your evaluation or test ing data thoroughly separated from your training data. If this is not done, it may be considered an improper test because the model will have had a chance to 'learn' the answers directly, and the test may not thoroughly represent any form of generalization that the model may have achieved. If needed, the 'contamination' of data may be removed with automated methods. </p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#metrics","title":"Metrics","text":"<ul> <li>Exact Match (EM)  TODO: Finish this</li> </ul> <p>While single-LLM calls are useful to evaluate, comparing and evaluating system-evaluation will likely be essential to ensure successful deployment.</p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#general-discussions","title":"General Discussions","text":"How do we know how smart AI systems are? <p>\u201cAI systems, especially generative language systems like GPT-4, will become increasingly influential in our lives, as will claims about their cognitive capacities. Thus, designing methods to properly assess their intelligence\u2014and associated capabilities and limitations\u2014is an urgent matter. To scientifically evaluate claims of humanlike and even superhuman machine intelligence, we need more transparency on the ways these models are trained, and better experimental methods and benchmarks. Transparency will rely on the development of open-source (rather than closed, commercial) AI models. Better experimental methods and benchmarks will be brought about through collaborations between AI researchers and cognitive scientists who have long investigated how to do robust tests for intelligence, understanding, and other cognitive capabilities in children, animals, and other \u201calien\u201d intelligences.\u201d</p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#evaluation-methods-and-libraries","title":"Evaluation Methods and Libraries","text":""},{"location":"Understanding/architectures/evaluating_and_comparing.html#general","title":"General","text":"ROSCOE: A SUITE OF METRICS FOR SCORING STEP-BYSTEP REASONING is ' a new suite of interpretable, unsupervised metrics that enables evaluation of step-by-step reasoning generations of LMs when no golden reference generation exists. '  <p>Paper</p> Introducing MMMU, a Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. <p>Paper</p> <p>11.5K meticulously collected multimodal questions from college exams, quizzes, and textbooks Spanning Art &amp; Design \ud83c\udfa8, Business \ud83d\udcbc, Science \ud83d\udd2c, Health &amp; Medicine \ud83e\ude7a, Humanities &amp; Social Science \ud83d\udcd6, Tech &amp; Engineering \ud83d\udee0\ufe0f across 30 subjects and 183 subfields 30 heterogeneous image types\ud83d\uddfa\ufe0f\ud83d\udcc9\ud83c\udfbc, such as charts, diagrams, maps, tables, music sheets, and chemical structures Focuses on advanced perception and reasoning with domain-specific knowledge \ud83e\udde0 Results and Takeaways from evaluating 14 open-source models and #GPT4-Vision: \ud83e\uddd0MMMU Benchmark post a great challenge to existing #LMMs: #GPT4V only hits 56% accuracy, showing a vast landscape for #LMMs advancement. \ud83d\udcaa Long way to go for open-source LMMs. Top open-source models like #BLIP2-FLAN-T5-XXL and #LLaVA-1.5 achieve around 34% accuracy.  \ud83d\uddbc\ufe0f\ud83d\udcddOCR and captions addition to #LLMs show little gain in MMMU, highlighting the need for deeper joint image-text interpretation. Models tend to perform better on photos and paintings\ud83d\uddbc\ufe0f than on diagrams and tables\ud83d\udcca, where nuanced and fine-grained visual information persists. \ud83e\udd16Error analysis on 150 error cases of GPT-4V reveals that 35% of errors are perceptual, 29% stem from a lack of knowledge, and 26% are due to flaws in the reasoning process.</p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#domain-specific","title":"Domain specific","text":"<p>Legal Bench is an ongoing open science effort to collaboratively curate tasks for evaluating LLM legal reasoning in English.</p> <p>The evaluation of models helps us to identify which, if any, model to use for a particular task at hand. Directly related to the manner of pre-training, fine-tuning, and any RLHF, the ways that we consider the output can also be used to improve the models. </p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#measure-what-matters","title":"Measure what matters","text":"<p>TODO: COMPLETE THIS</p> <ul> <li>Hallucinations</li> <li>Logic/Math</li> <li>Sycophancy, or the degree to which a model mirrors biases, large or small, put into input queries. The repo, sycophancy-eval offers some ability to evaluate this. </li> </ul>"},{"location":"Understanding/architectures/finetuning.html","title":"Finetuning","text":"<p>Fine-tuning adapt's  foundation model to improve its domain performance by using training with high-quality data. The adapted model may be architecturally equivalent, or a variation of the original model. The data that is used to update the model may be natural or synthetically-created and it is often domain-specific or intentionally constructed.</p> <p>Because of the computational requirements needed to train the original foundation models, fine-tuning is preferably done in way that does not update the entire model.  One manner of doing this is through the use of adapter layers.  </p>"},{"location":"Understanding/architectures/finetuning.html#data-for-fine-tuning","title":"Data for fine-tuning","text":"<p>Higher-quality data that may be proprietary or otherwise not-included in the training data for foundation-models can be used to improve a model's performance. Fine-tuning is generally done in a supervised fashion, where the specific responses desired for a given model input are trained on the output. Unsupervised fine-tuning is also possible though not as commonly described. </p>"},{"location":"Understanding/architectures/finetuning.html#using-simulated-data","title":"Using Simulated Data","text":"<p>Utilizing synthetic or simulated data is an effective method for training Large Language Models (LLMs). The process can be visualized in the following sequence:</p> <pre><code>    graph LR\n        A[Large dataset] --&gt; |Training| B[Large quality model]\n        B --&gt; |Generate tailored data| D[Tailored data]\n        D --&gt; |Training| E[New or adapted model]</code></pre> <p>In this sequence, a large and vague model is initially trained. This model then generates highly specific data. This specific data is subsequently used to train a smaller, more specific model. The end result is a high-quality, fine-tuned model. </p>"},{"location":"Understanding/architectures/finetuning.html#model-changes-for-fine-tuning","title":"Model changes for fine-tuning","text":"<p>The simplest manner of fine-tuning a model involves updating all of the original weights based on the fine-tuning dataset. This is less preferred because of the additional computational requirements. To minimize the compute, some number of layers can be 'frozen'. While helpful, the computational savings given the performance gains may not be considerable. (TODO FIND CITATIONS FOR THIS)</p>"},{"location":"Understanding/architectures/finetuning.html#adapter-layers","title":"Adapter layers","text":"<p>If all of the layers are frozen, it is possible to adapt the model using relatively simple models that rescale or adapt outputs. </p> <p>AdapterHub: A Framework for Adapting Transformers Website</p>"},{"location":"Understanding/architectures/finetuning.html#low-rank-adaption-lora","title":"Low Rank Adaption (LoRA)","text":"<p>Instead of interleaving a trainable layer in between various layers, Low-Rank Adaption (LoRA) uses the notion that changes to outputs of a given layer \\(W\\) will likely be small \\(\\Delta W\\). Instead of computing all those weights a low-rank vector matrix decomposition where \\(\\Delta W = A B\\) for two LoRA matrices \\(A\\) and \\(B\\). With a common inner-dimension variable rank, \\(r\\), is the matrix parameter counts can be appropriately minimized to have a small fraction of the original model \\(W\\).</p> <p></p>"},{"location":"Understanding/architectures/finetuning.html#practical-tips","title":"Practical Tips","text":"<p>These are tips mostly from Practical Tips for Finetuning LLMS.</p>"},{"location":"Understanding/architectures/finetuning.html#data-quality-and-size","title":"Data Quality and Size","text":"<p>It is essential that fine-tuning data is of high-quality/aligned with the end use-case of the model. Depending on the modality, anywhere between 5-10 (generally for Image-based models), and many thousands of examples (text-language) may be considered for LoRA. In terms of the number of passes over the data, be careful if going beyond one-epoch, lest overfitting occur. </p>"},{"location":"Understanding/architectures/finetuning.html#choice-of-optimizers","title":"Choice of optimizers","text":"<p>When Adam and SGD are common optimizers. There are indications that with larger \\(r\\), the memory requirements become &gt;20% larger.</p>"},{"location":"Understanding/architectures/finetuning.html#where-do-you-use-lora","title":"Where do you use LoRA?","text":"<p>Enabling the LoRA for all layers appears may be valuable, though it hasn't been thoroughly explored. </p>"},{"location":"Understanding/architectures/finetuning.html#choice-of-parameters","title":"Choice of parameters","text":"<p>The original paper has both the rank and a scaling factor \\(\\alpha\\). </p> <p><pre><code>scaling = alpha / r\nweight += (lora_B @ lora_A) * scaling\n</code></pre> Both of these will need to be explored, but it may be beneficial to set \\(\\alpha \\approx r\\)</p> <p>Selecting the rank to be too large may result in overfitting, but too small may not provide enough additional model capacity to capture the characteristics of the data. </p>"},{"location":"Understanding/architectures/finetuning.html#combining-lora-weights","title":"Combining LoRA weights","text":"<p>It appears that it is possible to add multiple LoRA weights, either beforehand as such: $$ weight += (L_B \\times L_A) * scale $$ or</p> \\[ weight += (L1_B \\times L1_A) * scale1 \\\\ weight += (L2_B \\times L2_A) * scale2 \\\\ \\cdots \\]"},{"location":"Understanding/architectures/finetuning.html#results","title":"Results","text":"<p>Fine-tuning can lead to significant improvements in both instruction following and helpfulness of models. This is demonstrated in the research paper An Emulator for Fine-Tuning Large Language Models using Small Language Models. The paper also suggests that combining fine-tuning with speculative decoding can speed up larger models by a factor of 2.5.</p> Research Paper: An Emulator for Fine-Tuning Large Language Models using Small Language Models <p> </p> <p>There are also several tools available that can assist in the fine-tuning process. </p> Open Pipe allows you to use powerful but expensive LLMs to fine-tune smaller and cheaper models <p>You can evaluate the model and prompt combinations in the playground, query your past requests, and export optimized training data. </p> <ul> <li>Full Parameter Fine-Tuning for Large Language Models with Limited Resources. Introduces LOMO: LOw-Memory Optimization to fuse </li> </ul> <p>Another tool, Slow Llama, is particularly useful for fine-tuning on M1/M2 Macs.</p> <p>Slow Llama for finetuning on a M1/M2 mac</p> <p>In conclusion, fine-tuning is a crucial step in the development of AI models. It allows models to specialize and improve their performance on specific tasks, leading to more accurate and efficient AI systems.</p>"},{"location":"Understanding/architectures/generation.html","title":"Generation","text":"<p>Generating new data from an input involves selecting the next best token or sets of tokens given an output logit vector. </p>"},{"location":"Understanding/architectures/generation.html#contrastive-decoding","title":"Contrastive Decoding","text":"<p>Demonstrates large improvements by using differences between better and worse models shows substantial improvement in generative quality.</p> <p>Contrastive inference:</p> <p>Any method which controls behavior differential at inference time, directly contrasting outputs from a desirable inference process with outputs from an undesirable inference process. --Sean Obrien</p> Contrastive Decoding Improves Reasoning in Large Language Models <p></p> Contrastive Decoding: Open-ended Text Generation as Optimization <p></p> Dola: Decoding by Contrasting Layers Improves Factuality in Large Language Models <p>Paper <pre><code>\"(They) amplify the factual knowledge in an LM\nthrough a contrastive decoding approach, where the output probability over the next word is obtained from\nthe difference in logits obtained from a higher layer versus a lower layer\"\n</code></pre> </p> <p>Decoding Strategies in Large Language Models</p>"},{"location":"Understanding/architectures/generation.html#speculative-sampling","title":"Speculative Sampling","text":"<p>Speculative sampling is a technique that relies on speedups due to generation parallelism to create k-next tokens samples to reduce latency. It starts by using a smaller model to generate a draft set of tokens. These are then run in parallel (instead of serial which is standard) to produce output logits. The draft and target-model tokens are compared and randomly sampled to allow the acceptance of the draft tokens or to generate a new token set.</p> Accelerating Large Language Model Decoding with Speculative Sampling <p></p> <p>Speculative Decoding implementation by Lucidrains</p>"},{"location":"Understanding/architectures/optimization.html","title":"Optimization","text":"<p>Models must yield results that are sufficiently good for downstream users. This is quite often the accuracy, an evaluation and comparison metric. Efficiency another is a crucial aspect of AI model development. The ability to generate high-performing content quickly can significantly impact the overall performance of your AI model. Although there isn't a universally accepted solution, several methods can help optimize your model for better efficiency without compromising quality. </p> <p>Most successful models employ a combination of approaches to reduce model sizes. This document provides an understanding of these methods and how they can be applied to optimize your AI model.</p>"},{"location":"Understanding/architectures/optimization.html#model-metric-optimizaitons","title":"Model metric optimizaitons","text":"<p>MANAGEN(Please describe model optimization methods and what is mentioned below)</p> <ul> <li>Data (quality and volume)</li> <li>Hyper parameters: Batch size is important. Use gradient accumulation if possible.</li> <li>Model size</li> <li>Model structure (BERT vs last-token prediction)</li> </ul>"},{"location":"Understanding/architectures/optimization.html#model-performance-optimization","title":"Model Performance Optimization","text":"<p>The following are some of the commonly used methods for optimizing AI models:</p> <ol> <li>Pruning</li> <li>Quantization</li> <li>Knowledge Distillation</li> <li>Low-rank and sparsity approximations</li> <li>Mixture of Experts</li> <li>Neural Architecture Search (NAS)</li> </ol>"},{"location":"Understanding/architectures/optimization.html#pruning","title":"Pruning","text":"<p>Pruning is a technique that eliminates weights that do not consistently produce highly impactful outputs. </p> Fast as Chita: Neural network pruning with combinatorial optimization <p>Arxiv paper  \"An optimization-based approach for pruning pre-trained neural networks at scale. CHITA (which stands for \u201cCombinatorial Hessian-free Iterative Thresholding Algorithm\u201d) outperforms existing pruning methods in terms of scalability and performance tradeoffs, and it does so by leveraging advances from several fields, including high-dimensional statistics, combinatorial optimization, and neural network pruning.\"  </p> <p>Related to pruning is the use of smaller models that are initialized based on larger ones</p> <p>A nice way to initialize smaller models from bigger ones Paper </p>"},{"location":"Understanding/architectures/optimization.html#quantization","title":"Quantization","text":"<p>Precision details the manner in which binary bits represent numbers in a computer. Generally, the greater the number of bits, the broader the variety of numbers that can be represented. </p> <p>Broken down into the <code>exponent</code> and <code>fraction</code>, as the different values can have specific implications for the training of models. Quite generally, bfloat16 (developed by Google Brain) offers an effective balance of size and dynamic expressibility for LLMs, and is a well-used number format. </p> <p>To have improved performance, the models may be reduced, however, to using fewer bits. Standard fp16 may sometimes reduced to int8, and even binary representations.  </p> What is Precision? <p> Quantization summarized image taken from Advanced Practical Data Science Lecture 9: Compression Techniques and Distillation </p> <p></p>"},{"location":"Understanding/architectures/optimization.html#when-to-quantize-during-or-after-training","title":"When to quantize: During or after training?","text":"<p>There are general times when quantization may be performed. During training, post-training.  Here are the benefit chart for each method each kind:</p> <p>MANAGEN: (Table with this the characteristic chart of the different methods to help individuals know specific challenges and benefits)</p>"},{"location":"Understanding/architectures/optimization.html#examples","title":"Examples","text":"SmoothQuant: Accurate and Efficient Post-trainign Quantizationf or LLMs <p>Using some post-training smoothing, they shift the weights in such a way that they are easier to quantize.  Paper </p> HF bitsandbytes and code From Github <p>Paper</p> PB-LLM: Partially Binarized Large Language Models to compress identified model weights into a single bit, while allowing others to only be partially compressed. <p>Paper </p>"},{"location":"Understanding/architectures/optimization.html#knowledge-distillation","title":"Knowledge Distillation","text":"<p>Train a new smaller model using the output of bigger models. (TODO) </p> QA-LoRA: Quantization Ware Low-Rank Adaptation of Large Language Models <p></p> <p>Knowledge Distillation and Compression Demo.ipynb</p>"},{"location":"Understanding/architectures/optimization.html#low-rank-and-sparsity-approximations","title":"Low rank and sparsity approximations","text":"<p>TODO</p>"},{"location":"Understanding/architectures/optimization.html#mixture-of-experts","title":"Mixture of Experts","text":"<p>MOE provides the ability to use different smaller models that have better performance in certain domains. Their use is notable, as it has been stated that GPT-4 is powered by 8 different agents. </p> Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning <p>\"The codebase is built on T5X, which defines the model and training loop; Flaxformer, which defines the model computation; Flax, which defines the low level model layers; and Jax, which provides the execution.\" Paper </p>"},{"location":"Understanding/architectures/optimization.html#combination-approaches","title":"Combination Approaches","text":"QLoRA: Efficient Finetuning of Quantized LLms uses Quantization and Low-Rank Adapters to enable SoTA models with even smaller models <p>Paper Example HF 4bit transformers</p>"},{"location":"Understanding/architectures/optimization.html#tooling","title":"Tooling","text":"<p>Bitsandbytes by provides a lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions.</p>"},{"location":"Understanding/architectures/optimization.html#overview-references","title":"Overview References","text":"A Survey on Model Compression for Large Language Models"},{"location":"Understanding/architectures/pre_trained_models.html","title":"Pre trained models","text":"<p>There are a vast number of both open and closed-source models that can be used. A number of them can be downloaded and run on the appropriate hardware, others may be accessed through APIs. </p> <p>It is essential to compare and evaluate the models for your intended use-cases to ensure they meet technical, customer, and organizational requirements. </p>"},{"location":"Understanding/architectures/pre_trained_models.html#leaderboards-and-comparisons","title":"Leaderboards and comparisons","text":"<p>Here are a few boards that help to aggregate and test models that have been released. </p> <ul> <li>Hugging Face LLM leaderboard An essential chart for documenting the model performance across multiple models.</li> <li>lmsys.org leader board</li> </ul>"},{"location":"Understanding/architectures/pre_trained_models.html#open-source","title":"Open Source","text":""},{"location":"Understanding/architectures/pre_trained_models.html#text-focused","title":"Text-focused","text":"Sept, 2023 Mistral Transformer <p>Model Download Announcement Hugging Face </p> <ul> <li>Llama2</li> <li>Llama2 uncensorred</li> <li>TinyLlama</li> <li>Open Llama </li> <li>UAE Falcon </li> <li>Orca (Microsoft) </li> <li>MosaicML</li> <li>LAION-AI An attempted open-source version of ChatGPT\"</li> <li>Unilm (MSFT)</li> <li>GPT4all</li> <li>DoctorGPT</li> </ul> [Qwen] <p>Open-source : Qwen-72B and Qwen-1.8B! Including Base, Chat and Quantized versions.</p> <p>\ud83c\udf1f Qwen-72B has been trained on high-quality data consisting of 3T tokens, boasting a larger parameter scale and more training data to achieve a comprehensive performance upgrade. Additionally, we have expanded the context window length to 32K and enhanced the system prompt capability, allowing users to customize their own AI assistant with just a single prompt.</p> <p>\ud83c\udf81 Qwen-1.8B is our additional gift to the research community, striking a balance between maintaining essential functionalities and maximizing efficiency, generating 2K-length text content with just 3GB of GPU memory.</p> <p>\ud83e\udd17 https://huggingface.co/Qwen \ud83e\udd16 https://github.com/QwenLM/Qwen</p>"},{"location":"Understanding/architectures/pre_trained_models.html#vision-focused","title":"Vision focused","text":"<ul> <li>StableLM: Stability AI Language Models </li> <li>Stable Diffusion</li> </ul>"},{"location":"Understanding/architectures/pre_trained_models.html#multimodal","title":"Multimodal","text":""},{"location":"Understanding/architectures/pre_trained_models.html#closed-source","title":"Closed Source","text":"Gemini <p>Report Tech Report </p> <ul> <li>Bard</li> <li>Claud</li> <li>ChatGPT (OpenAI)</li> <li>Medpalm</li> </ul>"},{"location":"Understanding/architectures/recurrent_training.html","title":"Recurrent training","text":"<p>MANAGEN(Provide intro and give a general description of recurrent training: where models are used to generate data that use models) refer to data simulation</p> <p>The process of data simulation for AI typically involves two main steps:</p> <ol> <li> <p>Training a Broad and Generalized Model: The first step involves training a broad and generalized model. This model is trained on a wide-ranging dataset and is capable of generating highly specific synthetic data.</p> </li> <li> <p>Training a Narrow and Task-Specific Model: The second step involves training a narrower, task-specific model on the synthetic data generated by the broad model. This task-specific model is tailored to the task at hand and can perform it with high accuracy.</p> </li> </ol> <pre><code>graph LR\n  A[Train Broad and Generalized Model] --&gt; B[Generate Highly Specific Data]\n  B --&gt; C[Train Narrow and Task-Specific Model on Specific Data]</code></pre> <p>Train on model trains a new model on the output of a new model.  - Alpaca </p> Shepherd: A Critic for Language Model Generation A 7B model trained to critique outputs <p>Example chat response </p> Textbooks are all you need <p>This study utilized a large volume of generated data and transformer-classifiers to filter the data and create a high-quality coding-focused model. The model was trained over four days on eight A-100s and achieved outperforming results.</p> Self-Alignment with Instruction Backtranslation <p></p> <p>The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then selecting high quality examples from among these candidates (self-curation). This data is then used to finetune a stronger model. F</p> WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct <p>Llama-2 based reinforcement enables substantial improvement over other models.   Paper</p> Fabic is a technique to incorporate iterative feedback into the generative process of diffusion models based on StableDiffusion. <p>Paper</p>"},{"location":"Understanding/architectures/rl_feedback.html","title":"Rl feedback","text":"<p>Reinforcement learning feedback provides a method to extend data-sparse examples to provide a way of training to produce entire output traces that are optimal. </p> <p>In general, Reinforcement-learning feedback is a method that trains a policy model to predict an optimal sequence of output results given inputs. </p> <p>Starting initially from Reinforcement Learning From Human Feedback (RLHF), it has also evolved to include Reinforcement Learning from AI Feedback (RLAIF). </p> <p>Key Takeaway</p> <p>RLHF is a technique that trains a model to predict the best sequence of token outputs, conditioned on a given input. </p>"},{"location":"Understanding/architectures/rl_feedback.html#understanding-rlf","title":"Understanding RLF","text":"<p>During pre-training, the next token output is maximized probabilistically. However, this method does not always yield the optimal next token in different contexts or in response to varying inputs, as it may not be able to attend to relevant information properly. </p> <p>To provide better paths, supervised fine-tuning can be used to update base models to predict output that is more accurate given the input. This process often requires a high volume of quality data, typically labeled by humans, which can be costly to obtain. Moreover, the volume of quality data may not cover the desired input space comprehensively enough for the models to be generalizable. </p> <p>To condition a model to produce the desired output given a certain type of input, it is crucial to ensure the entire path of tokens that are predicted are correct, rather than individually predicted tokens. This is where Reinforcement Learning comes into play. </p> <p>Reinforcement Learning uses the outcomes of a game, also known as a roll-out, to determine how to improve the choices or moves made during the game. In the context of Language Models, this means the moves are discrete and are the next tokens that are produced. </p> <p>A policy helps to decide what action or direction to take based on your current state or location. Specifically, a proximal policy predicts a probability distribution over all potential output states, shaping the entire path of the outcome. </p> <p>The policy model creates a path of tokens that will end with a reward that is closest to the preferred reward. Feedback, generally from humans or other models, is used to update the policy model. However, not all variations of input data can be reasonably considered given the volume of feedback that could be provided. </p> <p>A reward model is created to estimate how humans would evaluate the output. This model allows general human-informed guidance to help improve the policy model iteratively. </p> <p>One of the most successful examples of this is Instruct GPT, which follows the process outlined above. This method underlies the basis of Chat-GPT 3 and 4. </p> Many RL methods use 'outcome' evaluations, but process reward models  can be better <p>Using RL feedback from human labelers to provide feedback on intermediate steps, in Let's Verify Step By Step the authors demonstrate that providing feedback on intermediate steps can yield a reward model that is considerably better on various math-tests, than it is for outcome-based reward models. </p>"},{"location":"Understanding/architectures/rl_feedback.html#policy","title":"Policy","text":""},{"location":"Understanding/architectures/rl_feedback.html#proximal-policy-optimization","title":"Proximal Policy optimization","text":"<p>There are several policy gradient methods to optimize, a common one being proximal policy optimization, or PPO. </p> \\[ \\hat{g} = \\hat{\\mathbb{E}}_t \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t) \\hat{A}_t \\right] \\] <p>TODO: Expand this based on Proximal Policy Optimization Algorithms</p>"},{"location":"Understanding/architectures/rl_feedback.html#reward-models","title":"Reward Models","text":"<p>A reward model is used to approximate the  quality, or reward, that a labeler (a person) might assign to an example output. </p> <p>While multiple examples may be ranked and used simultaneously, the reward model may be trained by considering only a winning and a losing example. The reward models will produce a \\(S_w\\) \\(S_l\\) for winning and losing examples. </p> <p>The reward model is trained with the objective of incentivizing the winning response to have a lower score than the losing response. More specifically, it minimizes </p> \\[ -E_x(\\log(\\sigma(s_w-s_l))) \\] <p>TODO: Expand this to include more mathematics. </p>"},{"location":"Understanding/architectures/rl_feedback.html#process-reward-models","title":"Process reward models","text":"<p>Much like intermediate points to a ball-game are indicators of the winner of a game, a process reward model approximates the quality of intermediate steps in a total outcome. </p> <p>Having intermediate rewards provides better guidance on how the token generation occurs before the token termination. </p> Let's reward step by step; Step-Level Reward Model as the Navigators for Reasoning <p> </p> <p>Literature to read and integrate : https://arxiv.org/pdf/2211.14275.pdf https://arxiv.org/abs/2308.01825</p>"},{"location":"Understanding/architectures/rl_feedback.html#rlhf","title":"RLHF","text":"Starling-7B: Increasing LLM Helpfulness &amp; Harmlessness with RLAIF provides a solid example using RLAIF generated with GPT-4 to create a 7B model that is almost as good as GPT-4 <p>They also released a data set called Nectar that with over 180k GPT-4 ranked outputs. </p> <ul> <li>Can foundation models label data like humans? Using GPT to review model outputs produced biased results. Changing the prompt doesn't really help to de-bias it. There are many additional considerations surrounding model evaluation.</li> </ul>"},{"location":"Understanding/architectures/rl_feedback.html#essential-additional-information","title":"Essential additional information","text":"<ul> <li>RLHF: Reinforcement Learning from Human Feedback A splendid summary of the RLHF system.</li> </ul> <ul> <li>RLHF basics by hugging face A really good introduction to parse again.</li> <li>RLHF for Palm in Pytorch</li> <li>Aligning Large Language Models Through Synthetic Feedback Using a hierarchy of systems to improve model alignment.</li> </ul> Learning to summarize from human feedback Provides initial successful examples using PPO and human feedback to improve summaries."},{"location":"Understanding/architectures/training.html","title":"Training","text":"<p>Training GenAI will generally be domain/modality specific.</p> <ol> <li>Self-supervised pre-training to predict the next token with reasonable likelihoods. </li> <li>Supervised pretrainign: Trains to give generally expected output.</li> <li>Finetuning on higher quality data sets sometimes recurrently using simulated data,</li> <li>Reinforcement Learning with Human Feedback to more accurately train a model's output to find a reward model that is used with Proximal Policy Optimization (PPO) to produce aligned output. </li> </ol> <p>Basics: Distributed Training https://neptune.ai/blog/distributed-training-frameworks-and-tools</p> <p>Training language models to follow instructions with human feedback</p> <p>Instruct GPT allows for following of instructions. InstructGPT, established a powerful paradigm of LLM performance </p>"},{"location":"Understanding/architectures/training.html#frameworks","title":"Frameworks","text":"<ul> <li>Levanter (not just LLMS)  Codebase for training FMs with JAX. Using Haliax for naming tensors field names instead of indexes. (for example Batch, Feature....). Full sharding and distributable/parallelizable. </li> <li> <p>DeepSpeed ZeRO++ A framework for accelerating model pre-training, finetuning, RLHF updating.  by minimizing communication overhead. A likely essential concept to be very familiar with. </p> </li> <li> <p>RL4LMs by microsoft A modular RL library to fine-tune language models to human preferences. paper</p> </li> </ul>"},{"location":"Understanding/architectures/training.html#mixture-of-experts","title":"Mixture of Experts.","text":"<ul> <li>Scaling Expert Language Models with Unsupervised Domain Discovery \"parse language models on arbitrary text corpora. Our method clusters a corpus into sets of related documents, trains a separate expert language model on each cluster, and combines them in a sparse ensemble for inference. This approach generalizes embarrassingly parallel training by automatically discovering the domains for each expert, and eliminates nearly all the communication overhead of existing sparse language models. \"</li> </ul>"},{"location":"Understanding/architectures/training.html#general-training-improvements","title":"General Training Improvements","text":""},{"location":"Understanding/architectures/training.html#pruning-and-compression","title":"Pruning and compression","text":"<ul> <li>SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot Remove up to ~50% parameters preserving </li> <li>SqueezeLLM They are able to have 2x fold in model size for equivalent performance in perplexity. They use 'Dense and SParce Quantization' Github</li> </ul>"},{"location":"Understanding/architectures/models/index.html","title":"Models","text":"<p>While there is a great deal in several primary domains of Generative AI, Text, Image, sound, video, there are many other modalities that are of interest. Here we share prominent and interesting methods for these domains. These models will often rely on tokenization. Once tokenized, the transformed projected in some way to an embedding vector that can be used by  downstream LLM's, as well as vector-databases. </p> <p>MANGEN: This entire document needs to be reorganized and revised. </p> Llama 2: Open Foundation and Fine-Tuned Chat Models A nearly open source set of 7B-70B models with quality performance <p></p> Shepherd: A Critic for Language Model Generation A 7B model trained to critique outputs <p>Example chat response </p> Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data Parameter efficient LLama Tuning and risk minimization <p>with a new 'Self Distillation' with Feedback to improve itself even more. RESEARCH ONLY </p>"},{"location":"Understanding/architectures/models/index.html#mixture-of-experts","title":"Mixture of Experts","text":""},{"location":"Understanding/architectures/models/index.html#multi-modal-models","title":"Multi-Modal Models","text":""},{"location":"Understanding/architectures/models/index.html#vision-language-models","title":"Vision-Language Models","text":"<p>Vision Language models are among the most prominent. </p> <p>TODO: Clip paper</p> SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs A really cool idea that uses pyramidal representations and compresses information into text-tokens of different levels. <p>It can be reconstructed as needed. These tokens then could be used in novel image generation via semantic mapping with an LLM.  </p> Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language Represents images into language and combines them with a Frozen LLM to produce output. <p> Github Website</p>"},{"location":"Understanding/architectures/models/index.html#tabular-models","title":"Tabular Models","text":"<ul> <li>Challenges in End-to-End Neural Scientific Table Recognitions</li> </ul>"},{"location":"Understanding/architectures/models/index.html#more-than-one-modal","title":"More than one modal","text":"Meta Transformer Combines embedding in from 12 modalities by adjoining individual models and flattening them together. <p> Github</p>"},{"location":"Understanding/architectures/models/index.html#model-agnostic-improvements","title":"Model agnostic improvements","text":"<p>Learning to Compress Prompts with Gist Tokens. Can enable 26x compression and 40% FLOP reduction and improvements by training 'gist tokens' to summarize information.</p>"},{"location":"Understanding/architectures/models/index.html#to-sort","title":"TO SORT","text":"<p> Multimodal Neurons in Pretrained Text-Only Transformers \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.</p> Llama 2: Open Foundation and Fine-Tuned Chat Models A nearly open source set of 7B-70B models with quality performance <p></p>"},{"location":"Understanding/architectures/models/index.html#to-consider-and-sort","title":"To consider and sort","text":"<p>MANGEN (This is a number of the things that need to be considered in reorganization)</p>"},{"location":"Understanding/architectures/models/index.html#self-supervised-learning","title":"Self-supervised learning.","text":"<ul> <li>Diffusion LLMs</li> </ul> <p>Alignment methods.</p> <p>Additional models come up all the time.</p> <ul> <li>HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</li> <li>Generating Diverse High-Fidelity Images with VQ-VAE-2</li> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements.  </li> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements. </li> </ul> <p>??? tip \"Why you probably don't need to fine tune an LLM</p> <pre><code>Summary (with links internal to this project):\n**Why you shouldn't**\n1. Few Shot examples and better [prompts](../prompting/index.md) (and [chains](../agents/chains.md) helps a great deal.\n2. [Retrieval Augmented Generation](../agents/rag.md) will get you all the way there.\n\n\n**Why you should** \n1. High accuracy requirements\n2. Don't care about speed\n3. Methods above don't work\n</code></pre> <p>Architectures:</p> <ul> <li>Encoder-Decoder (EDT), is also sequence-to-sequence. </li> <li>Encoder-only: (BERT)</li> <li>Decoder-only (GPT) Next-token </li> <li>Multi-domain decoder-only transformer (Gato)</li> </ul>"},{"location":"Understanding/architectures/models/index.html#established-architectures","title":"Established Architectures","text":""},{"location":"Understanding/architectures/models/index.html#developing-architectures","title":"Developing Architectures","text":"<p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p>"},{"location":"Understanding/architectures/models/index.html#activations","title":"Activations","text":""},{"location":"Understanding/architectures/models/index.html#softmax","title":"Softmax","text":"<p>Softmax is an activation function that computes a probability-like output for logistic outputs. Generally given in the form</p> <p>$$ (softmax(x))\ud835\udc56=exp(\ud835\udc65\ud835\udc56)\u2211\ud835\udc57exp(\ud835\udc65\ud835\udc57)</p> <p>softmax(x_i) = \\exp(x_i)/\\sum_j\\exp(x_j) $$</p>"},{"location":"Understanding/architectures/models/index.html#is-softmax-off-by-1","title":"Is softmax Off by 1?","text":"<p>Based on some observations by Qualcom, where \"97%+ of outlier activations in LLMs occur in whitespace and punctuation positions.\u201d  there was indication that it is important to have 'no attention' given to some tokens. Adding a \\(1\\) to the demonimator allows for <code>no attention</code> to be had. This is describe here, discussed here and already found in the flaxformer architecture. A general conclusion is that it is likely more important for highly quantized weights, but 32 and 16 bit dtypes are probably unaffected. </p>"},{"location":"Understanding/architectures/models/components.html","title":"Components","text":"<p>The components of model classes include a number of operations. </p>"},{"location":"Understanding/architectures/models/components.html#activation-functions","title":"Activation Functions","text":""},{"location":"Understanding/architectures/models/components.html#softmax","title":"Softmax","text":"<p>Softmax is an activation function that computes a probability-like output for logistic outputs. Generally given in the form</p> <p>$$ (softmax(x))\ud835\udc56=exp(\ud835\udc65\ud835\udc56)\u2211\ud835\udc57exp(\ud835\udc65\ud835\udc57)</p> <p>softmax(x_i) = \\exp(x_i)/\\sum_j\\exp(x_j) $$</p>"},{"location":"Understanding/architectures/models/components.html#is-softmax-off-by-1","title":"Is softmax Off by 1?","text":"<p>Based on some observations by Qualcom, where \"97%+ of outlier activations in LLMs occur in whitespace and punctuation positions.\u201d  there was indication that it is important to have 'no attention' given to some tokens. Adding a \\(1\\) to the demonimator allows for <code>no attention</code> to be had. This is describe here, discussed here and already found in the flaxformer architecture. A general conclusion is that it is likely more important for highly quantized weights, but 32 and 16 bit dtypes are probably unaffected. </p>"},{"location":"Understanding/architectures/models/components.html#embeddings","title":"Embeddings","text":"<p>Embeddings play a key role in AI as they translate tokens into numerical representation that can be processed by the AI. </p> <p>'What are Embeddings' is an essential read that elucidates the concept of embeddings in a digestible manner. For a deeper dive, check the accompanied Github page.</p>"},{"location":"Understanding/architectures/models/developing_architectures.html","title":"Developing architectures","text":"<p>Here we share novel and promising architectures that may supplement or supplant other presently established models.</p>"},{"location":"Understanding/architectures/models/developing_architectures.html#models","title":"Models","text":"<p>Bayesian Flow Networks A new class of generative models for discrete and continuous data and generation</p> <p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p> Memoria stores and retrieves information called engram at multiple memory levels of working memory, short-term memory, and long-term memory, using connection weights that change according to Hebb\u2019s rule.  <p>Paper </p>"},{"location":"Understanding/architectures/models/developing_architectures.html#structured-state-space-sequence-models","title":"Structured State Space Sequence Models","text":"<p>Structured state space sequence models are a class of models that generally combine RNNs, convolutions with inspiration from state-space methods.</p> <p>Well-known methods include: </p> <p>Megabyte Github implementation for PyTorch</p> <p>HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution Uses inspiration from FFT to create a drop-in replacement for Transformer models.</p> <p>Paper for Hyena Architecture</p> <p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p> <p>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</p> <p>Their method provides potential highly parallelized   </p> <ul> <li>Linear Attention</li> <li>H3</li> <li>RWKV     Paper</li> </ul>"},{"location":"Understanding/architectures/models/diffusers.html","title":"Diffusers","text":""},{"location":"Understanding/architectures/models/diffusers.html#this-has-yet-to-be-built-thanks-for-bearing-with-me","title":"This has yet to be built! Thanks for bearing with me.","text":""},{"location":"Understanding/architectures/models/diffusers.html#references","title":"References","text":"<ul> <li>Diffusion Models</li> </ul>"},{"location":"Understanding/architectures/models/gans.html","title":"Gans","text":""},{"location":"Understanding/architectures/models/gans.html#this-page-is-under-construction","title":"This page is under construction.","text":""},{"location":"Understanding/architectures/models/hybrid_models.html","title":"Hybrid models","text":"<p>Hybrid models are those that employ multiple different architectures to achieve the end-goal. </p>"},{"location":"Understanding/architectures/models/reinforcement_learning.html","title":"Reinforcement learning","text":"<p>Reinforcement learning-based models have a colorful history. </p> <p>TODO</p>"},{"location":"Understanding/architectures/models/reinforcement_learning.html#reinforcement-learning-with-human-feedback-rlhf","title":"Reinforcement Learning with Human Feedback (RLHF)","text":"<p>RLFH has been found to be an essential component to enabling GPT based GenAI to be performant. </p> <p>TODO</p>"},{"location":"Understanding/architectures/models/reinforcement_learning.html#notable-research","title":"Notable research","text":"Learning to Model the World with Language Uses multimodal agents to build world models to act in. <p>Also introduces Homegrid evaluation game. Fun continuous multimodal agent. Github </p>"},{"location":"Understanding/architectures/models/transformers.html","title":"Transformers","text":"<p>TODO</p>"},{"location":"Understanding/architectures/models/transformers.html#components","title":"Components","text":"<p>TODO: Describe transformers and components</p> <ol> <li>Attention: Query, Key, Vectors</li> <li>Positional Encoding</li> <li>Layer Normalization</li> </ol>"},{"location":"Understanding/architectures/models/transformers.html#attention-models","title":"Attention Models","text":"<p>Layer normalization observably improves results On Layer Normalization in the Transformer Architecture</p>"},{"location":"Understanding/architectures/models/transformers.html#reviews","title":"Reviews","text":"The Illustrated Transformer <p>??? tip \"The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture     A thorough exposition of transformer technology.\"</p>"},{"location":"Understanding/architectures/models/transformers.html#gpt","title":"GPT","text":"<ul> <li>Illustrated GPT</li> <li>How GPT3 works Excellent summary of the progress of GPT over time, revealing core components, optimizations, and essential variations to the major Foundation model architectures.</li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#useful-references-and-research","title":"Useful References and Research","text":""},{"location":"Understanding/architectures/models/transformers.html#general-introductions","title":"General Introductions","text":"<ul> <li> <p>Transformers by Lucas Beyer (presentation)</p> </li> <li> <p>Five years of progress in GPTs</p> </li> <li> <p>The Transformer Architecture of GPT Models</p> </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#seminal-documents","title":"Seminal documents","text":"<ul> <li> <p>Neural Machine Translation by Jointly Learning to Align and Translate First paper indicating the notion of 'attention' sort of mechanism.</p> </li> <li> <p>Attention Is All you Need Initial paper indicating that attention is very powerful and potential replacement of LLM architectures. </p> </li> <li> <p>Formal Algorithms for Transformers in 2023 Important discussion revealing the components of Transformers.</p> </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#positional-encoding","title":"Positional Encoding","text":"<p>This component helps to remove the impilcit position-independence that 'vanilla' attention methods have.  </p> <ul> <li> <p>A Gentle Introduction to Positional Encoding in Transformer Models, pt1</p> </li> <li> <p>Transformer Language Models without POsitional Encodings STill Learn Positional Information Indications that causal LMS may derive positional awareness from more than the positional embeddings: they learn it from the causal mask. </p> </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#modifications","title":"Modifications","text":"<ul> <li>A Simple yet Effective Learnable Positional Encoding Method for Improving Document Transformer Model They introduce a learnable sinusoidal positional encoding feed forward network. Demonstrates significant improvements over other datasets. </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#enhancements-and-variations","title":"Enhancements and variations","text":""},{"location":"Understanding/architectures/models/transformers.html#context-length-improvements","title":"Context length Improvements","text":"<p>In its vanilla state, Transformers are \\(O(N^2)\\) in their computation with self-complexity. This makes long context lengths increasingly costly to train and generate.  Improvements in context length, for both training and generation have found ways to generally work-around these limits. While there is ample research in this domain, we present a few of the most successful methods. They improve computation complexity in one of several ways:</p> <ul> <li>Introducing sparsity that is</li> <li>Banded or fixed</li> <li>Hierarchical</li> <li>Banded to reduce full computation</li> <li>\\(/Lambda\\) shaped with a banded window that also takes into account observably important first tokens.</li> <li>Inclusion of a recurrent RNN-style that permits memory to be retained. </li> </ul> Generating Long Sequences with Sparse Transformers provides simple solutions to generate longer sequences. <p></p> Heirarchichal Attention <p>Paper</p> <p>Scaling Transformer to 1M tokens and beyond with RMT Uses a Recurrent Memory Transformer(RMT) architecture to extend understanding to large lengths.</p> MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers <p>MEGABYTE segments sequences into patches and uses a local submodel within patches and a global model between patches. Very nice demonstration that allows for \\(O(N^{4/3}\\) scaling directly on bytes, thereby bypassing tokenization requirements found with traditional transformers.</p> <p></p> Infinite Former Uses a representation of the input sequence as a continuous signal expressed in a combination of N radial basis functions. <p>Paper </p> LM-INfinite: Simple On-the-Fly Length Generalization for Large Language Models provides an O(n) time/space extension allows LMMs to ability to go to 32k tokens and 2.7x speedup. <p> </p> Efficient Streaming Language Models with Attention Sinks <p>Paper </p>"},{"location":"Understanding/architectures/models/transformers.html#computation-reduction","title":"Computation Reduction","text":"Simplified Transformers that removes the 'value' parameter-set to increase speed by 14% with potentially minimal accuracy reduction <p>Herein the authors reveal a variation of transformers that removes the 'value' parameter to yield notable speed gains at the same performance level.   Paper</p> <p>SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression</p>"},{"location":"Understanding/architectures/models/transformers.html#fine-tuning","title":"Fine Tuning","text":"<p>Using examples to fine-tune a model can reduce the number of tokens needed to achieve a sufficiently reasonable response. Can be expensive to retrain though.</p> Symbol Tuning Improves in-context learning in Language Models <p></p>"},{"location":"Understanding/architectures/models/transformers.html#other-modalities","title":"Other modalities","text":""},{"location":"Understanding/architectures/models/transformers.html#vision","title":"Vision","text":""},{"location":"Understanding/architectures/models/transformers.html#graphs","title":"Graphs","text":"Transformers Meet Directed Graphs introduces a variation of Transformer GNNs that uses 'direction-aware' positional encodings to help handle both undirected and directed graphs"},{"location":"Understanding/architectures/models/transformers.html#training-variations","title":"Training variations","text":""},{"location":"Understanding/architectures/models/transformers.html#fairness-enablement","title":"Fairness Enablement","text":"<ul> <li>Concept Erasure</li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#using-knowledge-links","title":"Using Knowledge Links","text":"<ul> <li>LinkBERT places in the context window hyperlinked references to achieve better performance and is a drop-in replacement for BERT models. </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#multimodal","title":"Multimodal","text":"<ul> <li>Visual GPT</li> <li>Language is not all you need</li> <li>Meta-Transformer: A Unified Framework for Multimodal Learning The first framework to perform unified learning across 12 modalities with unpaired data. It does so by learning an embedding that can be shared across the modalities. Github </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#abstractions","title":"Abstractions","text":"<ul> <li>Looped Transformers and Programmable Computers Understanding that transformer networks can simulate complex algorithms when hardcoded with specific weights and made intoa  loop. 'Machine Learning' 'Machine code'. \"We demonstrate that a constant number of encoder layers can emulate basic computing blocks, including embedding edit operations, non-linear functions, function calls, program counters, and conditional branches. Using these building blocks, we emulate a small instruction-set computer.\"</li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#code","title":"Code","text":"<ul> <li>Hugging Face Transformers An API to access a large number of pre-trained transformers. Pytorch based. </li> <li>Fast Transformers A quality collection of a number of transformer implementations written in Pytorch. </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#_1","title":"Transformers","text":""},{"location":"Understanding/background/tensor_maths.html","title":"Tensor maths","text":"<p>Tensor math is linear algebra on steroids. Here are some valuable resources to understand it better.</p> <p>TODO: Add all of the tensor series. </p> <p>https://www.kolda.net/publication/TensorReview.pdf</p> <p>https://arxiv.org/pdf/2308.01814.pdf</p> The Tensor Programs: 1 <p>Ouput embeddings of two samples will be i.I.d. under randompermutations. Introduces generalization to Tensors and creates  NETSOR  Computation Programs Introduces three general mapping types of function variables.</p> <pre><code>NETSOR programs are straight-line programs, where each variable follows one of three types, G, H, or A (such variables are called G-vars, H-vars, and A-vars), and after input variables, new variables can be introduced by one of the rules MatMul, LinComb, Nonlin to be discussed shortly. G and H are vector types and A is a matrix type; intuitively, G-vars should be thought of as vectors that are asymptotically Gaussian, H-vars are images of G-vars by coordinatewise nonlinearities, and A-vars are random matrices with iid Gaussian entries. Each type is annotated by dimensionality information:\n\nIf x is a (vector) variable of type G (or H) and has dimension n, we write x : G(n) (or x : H(n)).\nIf A is a (matrix) variable of type A and has size n1 \u00d7 n2, we write A : A(n1, n2)\nG is a subtype of H, so that x : G(n) implies x : H(n). \n</code></pre> <p>G is petty much a \u2018pass through\u2019 like an activation function. </p> <p>This a Github implementation </p> Tensor Programs IVb: Adaptive Optimization in the \u221e-Width Limit Demonstrates how to scale hyperparameters when changing widths of feature parameters generally <p>Micro update </p> <p>\"We show that optimal hyperparameters become stable across neural network sizes when we parametrize the model in maximal update parametrization (\u03bcP). This can be used to tune extremely large neural networks such as large pretrained transformers, as we have done in our work. More generally, \u03bcP reduces the fragility and uncertainty when transitioning from exploration to scaling up, which are not often talked about explicitly in the deep learning literature.\"</p>"},{"location":"Understanding/data/index.html","title":"Understanding Data in AI","text":"<p>Data is the lifeblood of any AI model. It is the raw material that fuels the learning process and shapes the model's understanding of the world. This section will delve into the various aspects of data, from its collection and access to its normalization and use in training AI models. </p>"},{"location":"Understanding/data/index.html#data-collection-and-access","title":"Data Collection and Access","text":"<p>The first step in the data lifecycle is its collection. This involves gathering relevant data from various sources, which could range from databases and APIs to web scraping and user-generated content. The collected data must then be stored and organized in a way that allows easy access for further processing and analysis. </p>"},{"location":"Understanding/data/index.html#data-normalization","title":"Data Normalization","text":"<p>Once the data is collected and stored, it needs to be normalized. Data normalization is a process that transforms the data into a standard format, making it easier to work with. This could involve scaling numerical data, encoding categorical data, or handling missing values. Normalized data ensures consistency and improves the accuracy of the model. </p>"},{"location":"Understanding/data/index.html#data-training","title":"Data Training","text":"<p>The final step in the data lifecycle is using the data to train an AI model. This involves two key processes: tokenization and embedding.</p>"},{"location":"Understanding/data/index.html#tokenization","title":"Tokenization","text":"<p>Tokenization is the process of breaking down the data into smaller units, or tokens. In the context of natural language processing (NLP), for example, a text document might be tokenized into individual words or sentences. This makes the data easier for the model to process and learn from.</p>"},{"location":"Understanding/data/index.html#embedding","title":"Embedding","text":"<p>Embedding is the process of representing these tokens in a numerical format that the model can understand. For instance, word embeddings might represent each word as a vector in a high-dimensional space. These embeddings capture the semantic relationships between words, allowing the model to learn from the underlying patterns in the data.</p>"},{"location":"Understanding/data/index.html#important-considerations","title":"Important Considerations","text":""},{"location":"Understanding/data/index.html#data-volume","title":"Data Volume","text":"<p>The amount of data needed for training depends on the size of the model. As a general rule, the number of tokens should be approximately 10 times the number of parameters used by the model.</p> Training Compute-Optimal Large Language Models <p>The 'Chinchilla' paper of 2022 identifies scaling laws that help to understand the volume of data needed to obtain 'optimal' performance for a given LLM model's size. Use of it in other areas, such as for Llama, reveals that the models may have been under-trained. - Primary takeaway: \"All three approaches suggest that as compute budget increases, model size and the amount of training data should be increased in approximately equal proportions.\" </p>"},{"location":"Understanding/data/index.html#batch-sizes-of-data","title":"Batch Sizes of Data","text":"<p>The batch size refers to the number of data points that the model processes at once during training. Larger batch sizes can lead to faster training times, but they may also require more computational resources and can sometimes result in less accurate models. It's important to find a balance that suits your specific needs and constraints.</p>"},{"location":"Understanding/data/index.html#training-with-simulated-data","title":"Training with Simulated Data","text":"<p>In some cases, it may be beneficial to train models with simulated data. This can be data generated by other models or through simulations of real-world scenarios. However, caution must be exercised as training with simulated data can sometimes lead to worse results. If done consistently, it can even lead to complete degradation of model performance. For more information, refer to simulated data.</p>"},{"location":"Understanding/data/index.html#data-processing-flow","title":"Data Processing Flow","text":"<p>The general flow of data processing can be represented as follows:</p> <ol> <li>Get data</li> <li>Look at data examples</li> <li>Look at data bulk</li> <li>Get efficient access to data with low bandwidth</li> <li>Normalize data</li> <li>Tokenize data</li> <li>Embed data</li> </ol> <pre><code>graph TD;\n    A[Get Data] --&gt; B[Look at Data Examples];\n    B --&gt; C[Look at Data Bulk];\n    C --&gt; D[Get Efficient Access to Data with Low Bandwidth];\n    D --&gt; E[Normalize Data];\n    E --&gt; F[Tokenize Data];\n    F --&gt; G[Embed Data];</code></pre>"},{"location":"Understanding/data/index.html#common-data-formats","title":"Common Data Formats","text":"<p>Often, it is useful to have data loaders that are common in Keras and Pytorch. These wrap iterators that allow the data to be processed in a parallel manner across different nodes. This parallel processing enhances the efficiency of data handling, especially when dealing with large datasets. </p> <p>In conclusion, data is a crucial component in AI model training. Its collection, normalization, and processing significantly influence the performance of the model. Therefore, it's essential to understand and implement best practices in data handling for optimal results.</p>"},{"location":"Understanding/data/augmentation.html","title":"Understanding Data Augmentation","text":"<p>Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks.</p>"},{"location":"Understanding/data/augmentation.html#what-is-data-augmentation","title":"What is Data Augmentation?","text":"<p>Data augmentation is a process of creating new data from the existing ones. It is a form of synthetic data generation that can be used to improve the performance of machine learning models. The main idea behind data augmentation is to create variations of the data that can capture different perspectives and scenarios, thereby enriching the dataset.</p>"},{"location":"Understanding/data/augmentation.html#why-is-data-augmentation-important","title":"Why is Data Augmentation Important?","text":"<p>Data augmentation is important for several reasons:</p> <ol> <li> <p>Improving Model Performance: Data augmentation can help improve the performance of models by providing more varied data for training. This can help the model learn more robust features and reduce overfitting.</p> </li> <li> <p>Dealing with Imbalanced Data: In many real-world scenarios, the data we have is imbalanced. Data augmentation can help balance the dataset by creating synthetic data for under-represented classes.</p> </li> <li> <p>Increasing Dataset Size: Data augmentation can help increase the size of the dataset. This can be particularly useful when we have limited data for training our model.</p> </li> </ol>"},{"location":"Understanding/data/augmentation.html#how-data-augmentation-improves-models","title":"How Data Augmentation Improves Models","text":"<p>Data augmentation can improve models in several ways:</p> <ol> <li> <p>Variety: By creating new data from the existing ones, data augmentation introduces variety into the training set. This variety can help the model learn more robust and generalizable features.</p> </li> <li> <p>Regularization: Data augmentation acts as a form of regularization, reducing overfitting. By training on more varied data, the model is less likely to memorize the training data and more likely to generalize to unseen data.</p> </li> <li> <p>Performance: Data augmentation can improve the performance of the model on the validation set. This is because the model is trained on a more diverse set of data, which can help it perform better on unseen data.</p> </li> </ol>"},{"location":"Understanding/data/augmentation.html#types-of-data-augmentation","title":"Types of Data Augmentation","text":"<p>There are several types of data augmentation techniques that can be used depending on the type of data:</p> <ol> <li> <p>Image Data Augmentation: Techniques such as flipping, rotation, zooming, cropping, and brightness adjustment can be used to augment image data.</p> </li> <li> <p>Text Data Augmentation: Techniques such as synonym replacement, random insertion, random swap, and random deletion can be used to augment text data.</p> </li> <li> <p>Audio Data Augmentation: Techniques such as noise injection, time stretching, and pitch shifting can be used to augment audio data.</p> </li> <li> <p>Time-Series Data Augmentation: Techniques such as jittering, scaling, magnitude warping, and time warping can be used to augment time-series data.</p> </li> </ol> <p>Note</p> <p>The choice of data augmentation techniques depends on the type of data and the specific problem at hand. It is important to choose techniques that are relevant and meaningful for the given context.</p>"},{"location":"Understanding/data/augmentation.html#implementing-data-augmentation","title":"Implementing Data Augmentation","text":"<p>Implementing data augmentation involves applying the chosen techniques to the training data. This can be done either offline, where the augmented data is generated and stored before training, or online, where the augmented data is generated on-the-fly during training.</p> <p>Here is an example of how to implement image data augmentation using the <code>ImageDataGenerator</code> class in Keras:</p> <pre><code>from keras.preprocessing.image import ImageDataGenerator\n\n# create a data generator\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n# fit the data generator on the training data\ndatagen.fit(x_train)\n</code></pre> <p>In this example, the <code>ImageDataGenerator</code> is used to create a data generator that will apply random rotations, width and height shifts, and horizontal flips to the images.</p>"},{"location":"Understanding/data/augmentation.html#conclusion","title":"Conclusion","text":"<p>Data augmentation is a powerful technique for improving the performance of machine learning models, particularly when we have limited data. By creating new data from the existing ones, data augmentation can help the model learn more robust features, reduce overfitting, and improve performance on the validation set.</p>"},{"location":"Understanding/data/distillation.html","title":"Distillation","text":"<p>MANAGEN Reword this( Dataset distillation reduces the storage and computational consumption of training a network by generating a small surrogate dataset that encapsulates rich information of the original large-scale one)</p> Efficient Dataset Distillation via Minimax Diffusion <p>Paper </p>"},{"location":"Understanding/data/selection.html","title":"Selection","text":"<p>Data selection acts as the backbone for training generative AI models. Without suitable data and an optimal selection strategy, it might be challenging to develop models that provide useful and relevant outputs.</p>"},{"location":"Understanding/data/selection.html#why-is-data-selection-important","title":"Why is Data Selection Important?","text":"<p>Data selection forms the initial step in any machine learning project. Selecting the right data can help train your GenAI model more efficiently and accurately. Improper data selection, and balancing, can cause you models to fail all together, or more insideously induce output biases that are of ethical concern </p>"},{"location":"Understanding/data/selection.html#role-in-training-models","title":"Role in Training Models","text":"<p>The right data selection dictates how well a model can generate the desired output. It decides what the design and parameters of the model will be.</p>"},{"location":"Understanding/data/selection.html#impact-on-model-performance","title":"Impact on Model Performance","text":"<p>The quality and relevance of selected data have a direct impact on the performance of the model. The right selection reduces the risk of overfitting and underfitting.</p>"},{"location":"Understanding/data/selection.html#strategies-for-effective-data-selection","title":"Strategies for Effective Data Selection","text":"<p>There are several strategies to ensure the data used for training Generative AI models is selected effectively.</p>"},{"location":"Understanding/data/selection.html#understanding-your-data","title":"Understanding Your Data","text":"<p>Before selecting data, take time to understand the data you have. Analyzing the data to identify patterns, trends or anomalies will give some direction on what data to use.</p>"},{"location":"Understanding/data/selection.html#choosing-relevant-data","title":"Choosing Relevant Data","text":"<p>Relevancy of data to the problem at hand is crucial. Inappropriate data can lead to inaccurate results and will impede the model\u2019s performance.</p>"},{"location":"Understanding/data/selection.html#balancing-your-dataset","title":"Balancing Your Dataset","text":"<p>In order to train an effective Generative AI model, it's important to balance your dataset. An imbalanced dataset could lead your model to be biased towards the class that is overrepresented. </p>"},{"location":"Understanding/data/selection.html#tools-for-data-selection","title":"Tools for Data Selection","text":"<p>There are different tools that can aid in effective data selection.</p>"},{"location":"Understanding/data/selection.html#automated-data","title":"Automated Data","text":"<p>Automated machine learning tools can greatly simplify data selection by providing features for automatic feature selection, data cleaning and preprocessing.</p>"},{"location":"Understanding/data/simulation.html","title":"Simulation","text":"<p>Data simulation plays a crucial role in the field of Artificial Intelligence (AI) and Machine Learning (ML). It involves the generation of synthetic data that can be utilized to train models recurrently, particularly when there is a need for specialized, real-world, costly, or scarce data. Large volumes of synthetic data, which can be used to train highly task-specific models. This process is particularly beneficial when real-world data is limited or challenging to obtain. The resources and studies highlighted in this document offer valuable insights into the practical application of data simulation in AI.</p>"},{"location":"Understanding/data/simulation.html#overview-of-the-data-simulation-process","title":"Overview of the Data Simulation Process","text":"<p>The process of data simulation involves several steps, each of which contributes to the generation of high-quality synthetic data. Here's a brief overview:</p> <ol> <li> <p>Define the Goal of Simulated Data: The first step is to identify the purpose of the simulated data. This could range from training a machine learning model, testing the robustness of an algorithm, or simulating a specific scenario. For example, in autonomous vehicle development, simulated data might be used to recreate various driving conditions.</p> </li> <li> <p>Choose the Structure to Achieve the Goal: Once the goal is defined, the next step is to decide on the structure of the data that will help achieve this goal. This could involve determining the type of data (numerical, categorical, etc.), the number of variables, and their relationships.</p> </li> <li> <p>Select the Prompt: The prompt is the input that triggers the generation of synthetic data. It could be a specific command, a set of parameters, or a particular scenario.</p> </li> <li> <p>Generate and Evaluate: After setting up the prompt, the next step is to generate the synthetic data. This data is then evaluated to ensure it meets the defined goals and quality standards.</p> </li> </ol>"},{"location":"Understanding/data/simulation.html#key-resources-and-studies-in-data-simulation","title":"Key Resources and Studies in Data Simulation","text":"<p>The field of data simulation in AI has been enriched by several resources and studies. Here are a few notable ones:</p> <p>StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners</p> <p>This research paper by Google Research delves into the use of synthetic images generated from text-to-image models for training visual representation learners.</p> <p>Madrona</p> <p>Madrona is a prototype game engine designed for creating high-throughput, GPU-accelerated simulators. These simulators can run thousands of virtual environment instances and generate millions of aggregate simulation steps per second on a single GPU.</p> <p>TuNA for using LangChain to create volumes of synthetic data pairs.</p> <p>Blog</p>"},{"location":"Understanding/data/sources.html","title":"Sources","text":""},{"location":"Understanding/data/sources.html#data-sources","title":"Data sources","text":"<p>RedPajama Pile CommonCrawl (webscrape) C4 (CommonCrawl) Github Books Arxiv StackExchange</p> <ul> <li> <p>unarXive 2022: All arXiv Publications Pre-Processed for NLP</p> </li> <li> <p>Redpajama</p> </li> <li>BIG-bench</li> <li>Metaseq</li> <li>Kaggle-code</li> </ul> <p>The largest open source text dataset just dropped</p> Dolma. (by AI2) <p>WARNING: The license is not 'open source' 3 Trillion tokens of high quality data.</p> <ul> <li>Diverse: Documents, code, academic papers, wiki..</li> <li>Focused: English only.</li> <li>De-duplicated.</li> <li>Filtered for high quality.</li> </ul> <p>But most importantly: The largest open curated dataset for pretraining.</p> <p>\u2022 Link: https://huggingface.co/datasets/allenai/dolma \u2022 Blog: https://blog.allenai.org/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64 \u2022 Code: https://github.com/allenai/dolma \u2022 Paper: https://drive.google.com/file/d/12gOf5I5RytsD159nSP7iim_5zN31FCXq/view</p>"},{"location":"Understanding/data/sources.html#process-supervision","title":"Process Supervision","text":"<ul> <li>prm800k</li> </ul>"},{"location":"Understanding/data/tokenizing.html","title":"Tokenizing","text":"<p>In generative AI, the raw data\u2014whether it be in binary, text, or a different form\u2014is divided into individual units termed as tokens. These play a crucial role in easing the understanding and manipulation of data for the AI.</p>"},{"location":"Understanding/data/tokenizing.html#understanding-tokenization","title":"Understanding Tokenization","text":"<p>Tokenization is the process of splitting data into these individual units. The choice of a token largely depends on the data type and the expected outcome of the AI. In text data, for instance, tokens often correspond to single words or subwords. These tokens are then often represented in one-hot encoding. Research may eventually show that hierarchical tokenization, either trained, guessed, or otherwise constructed, could minimize token use. </p>"},{"location":"Understanding/data/tokenizing.html#heirarchichal-tokenization","title":"Heirarchichal Tokenization","text":"<p>Floret Vectors</p> Superbloom: Bloom filter meets Transformer <p>Wherein a bloom filter is used to create tokens/embeddings.    </p> Related to Superbloom: Learned Hashing <p>Which if you think of it, the \u2018hashing function\u2019 could just be a linear projection onto a hashing layer. A input unit (character or byte string) would be initialized randomly to have a \u2018representation vector\u2019, akin to a direct embedding. The challenge would be on inference when reconstructing outputs (it would be a Bloom look up for an output character, and not a simple mapping).</p>"},{"location":"Understanding/data/tokenizing.html#subword-units","title":"Subword Units","text":"<p>A subword unit, or a part of a word, can be a token in itself. The paper titled Neural Machine Translation of Rare Words with Subword Units brings to light the effectiveness of subword units in improving results. This type of tokenization was used in a neural machine translation system and it significantly improved the handling of rare words.</p>"},{"location":"Understanding/data/tokenizing.html#special-tokens","title":"Special tokens","text":"<p>There are special tokens that are used by high-level interpreters on what next to do. </p> Token Name Description START_TOKEN or BOS_TOKEN This is used to indicate the beginning of a sequence. BOS stands for \"Beginning Of Sequence\". STOP_TOKEN or EOS_TOKEN This is used to indicate the end of a sequence. EOS stands for \"End Of Sequence\". MASK_TOKEN This is used to represent a masked value, which the model needs to predict. MODALITY_TOKEN This is used to indicate the type of data in the sequence (such as text, images, etc.)"},{"location":"Understanding/data/tokenizing.html#speech-tokenization","title":"Speech tokenization","text":"Speech Tokenizer  is a unified speech tokenizer for speech language models, which adopts the Encoder-Decoder architecture with residual vector quantization (RVQ)"},{"location":"Understanding/data/tokenizing.html#multimodal-tokenization","title":"Multimodal Tokenization","text":"<p>Multimodal tokenization is an area of tokenization that focuses on incorporating multiple data forms or modes. This facet of tokenization has seen remarkable strides. Bytes are all you need\u2014a study utilizing transformer technology to input file bytes directly\u2014demonstrates that multimodal tokenization can assist in improving the AI's performance accuracy. The researchers in the study developed ByteFormer, a model based on their study\u2019s findings that can be accessed here.</p>"},{"location":"Understanding/data/tokenizing.html#tokenizing-might-not-be-necessary","title":"Tokenizing might not be necessary","text":"<p>It is regarded that tokenizing is a bit arbitrary and has disadvantages. There are promising results using methods without tokenization MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers that \"show that MEGABYTE allows byte-level models to perform competitively with subword models on long context language modeling\"</p>"},{"location":"Understanding/data/tokenizing.html#tools","title":"Tools","text":"<p>Examples of coding tools that facilitate tokenization include Tiktoken which utilizes Byte Pair Encoding (BPE) for tokenization and is purportedly used in GPT models. An alternative tool is <sup>2</sup>, which takes a unique top-down approach and results in almost 35% less tokens as opposed to the standard bottom-up approach.</p>"},{"location":"Understanding/data/tokenizing.html#open-source-tokenizers","title":"Open Source Tokenizers","text":"<ul> <li>Sentence Piece implements subword units (e.g., byte-pair-encoding (BPE) ) and unigram language model <sup>1</sup></li> <li>Tiktoken</li> <li>Token Monster</li> </ul>"},{"location":"Understanding/data/tokenizing.html#references","title":"References","text":"<ul> <li>Neural Machine Translation of Rare Words with Subword Units</li> <li>Bytes are all you need</li> <li>ByteFormer Github What are EmbeddingsGithub</li> </ul> <ol> <li> <p>Kudo \"subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training\". Effectively, this takes aliasing-like effects that cause different tokenization. It is more effective because it breaks it down in different ways.\u00a0\u21a9</p> </li> <li> <p>Token Monster \u21a9</p> </li> </ol>"},{"location":"Understanding/overview/index.html","title":"Overview","text":""},{"location":"Understanding/overview/index.html#predictive-and-generative-ai","title":"Predictive and Generative AI","text":"<p>Predictive AI \u201ccreates predictive data\u201d based on recorded data Generative AI \u201ccreates new data\u201d based on recorded data and generation criteria</p> <p></p>"},{"location":"Understanding/overview/index.html#what-it-looks-like","title":"What it looks like","text":""},{"location":"Understanding/overview/ai_in_general.html","title":"Ai in general","text":"<p>Here we provide selected references to frameworks and solutions surrounding AI in general</p>"},{"location":"Understanding/overview/ai_in_general.html#frameworks","title":"Frameworks","text":"<p>Pytorch Tensorflow</p>"},{"location":"Understanding/overview/ai_in_general.html#higher-level-frameworks","title":"Higher-level Frameworks","text":"<p>Higher level frameworks minimize the lines of code needed to make a model and keep track of everything. </p> <ul> <li>Catalyst Framework for boiler-plate minimal ML calling using pytorch. Enabled heirarchichal Attention networks</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#lightning","title":"Lightning","text":"<ul> <li>Lightning + Hydra Uses the [lightning] framework with Hydra-based config management. </li> <li>Lightning Hugging face adapter</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#must-have-knowledge","title":"Must-have knowledge","text":"<ul> <li>AI cannon by a16z</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#network-figures","title":"Network Figures","text":"<p>Being able to see the 'structure' of some neural networks make it easier to understand, and more aesthetic.  </p> <ul> <li>PlotNeuralNet and a nice writeup on how to use it. </li> </ul>"},{"location":"Understanding/overview/business.html","title":"Business","text":""},{"location":"Understanding/overview/business.html#domains","title":"Domains","text":""},{"location":"Understanding/overview/business.html#security","title":"Security","text":"<p>https://lsvp.com/securing-ai-is-the-next-big-platform-opportunity/</p>"},{"location":"Understanding/overview/business.html#business-trends","title":"Business Trends","text":"<p>https://a16z.com/how-are-consumers-using-generative-ai</p>"},{"location":"Understanding/overview/challenges.html","title":"Challenges","text":"<p>There are a host of challenges associated with the use of GenAI at multiple levels. These challenges may also be appropriately considered risks to add weight to their importance.</p> <p>At the base level technichal challenges creating and using the GenAI such that it is wholly consistent and coherent </p> <p>At a higher level, the concerns for displacement and capture of people's jobs must be taken into consideration. With arguments both minimizing and amplifying the concern, estimates still have around 300 million jobs replaced by AI, according to a Goldman Sachs report. AT the same time GDP could be increased by 7% and lift productivity. It is still apparent that upskilling to enable people to work with AI as an enabling tool is important to consider. </p> <p>At nearly the highest level of challenge is to have GenAI that is Aligned for the betterment of humanity and our planet and not to its detriment with dual use. Because of the expansive and moral-philosophical nature of this, as in what is defining 'betterment' it is difficult. Concretely, however, minimizing potential risks associated with GenAI, especially Autonomous Agents, are necessary to address at a functional level, both at organizations and within governments and the regulatory bodies that coordinate the two.</p> <p>In general ethical use of GenAI will necessarily address all or most of these challenges. </p>"},{"location":"Understanding/overview/challenges.html#open-challenges","title":"Open Challenges","text":"<p>!!! Open challenges in LLM research Challenges associated with GenAI.</p> <pre><code>```markdown\n\n1. Reduce and measure [hallucinations](#hallucinations)\n2. Optimize context length and context construction\n3. Incorporate other data modalities\n4. Make LLMs faster and cheaper\n5. Design a new model architecture\n6. Develop GPU alternatives\n7. Make agents usable\n8. Improve learning from human preference\n9. Improve the efficiency of the chat interface\n10. Build LLMs for non-English languages\n```\n</code></pre>"},{"location":"Understanding/overview/challenges.html#accuracy-challenges","title":"Accuracy Challenges","text":""},{"location":"Understanding/overview/challenges.html#hallucinations","title":"Hallucinations","text":"<p>There are a number of issues related to modle accuracy that pose challenges for GenAI models. Most prominant among them are the effect of Hallucinations. Models hallucinate, by making up facts or sentences that have no reasoanble bearing to reality. </p> <p>Some studies indicate that the halluciantion-rate is related to the frequency that a fact appears only once in a data set, and that calibrated models, like those that are pre-trained, are more likely to hallucinate than those that do not have calibrated next-token predictions. </p>"},{"location":"Understanding/overview/challenges.html#ethical-challenges","title":"Ethical Challenges","text":""},{"location":"Understanding/overview/challenges.html#job-displacement","title":"Job displacement","text":"<p>Because GenAI can perform tasks at a speedy rate. </p>"},{"location":"Understanding/overview/challenges.html#copywrite-and-ip","title":"Copywrite and IP","text":"<p>Related to job-displacement, the content created with GenAI remains in a precarious state with regard's to copyright and IP. While there are indications that content generated purely from AI may not be copyrighted (in the US), it is generally accepted AI can provide the basis for content that may be copyrighted. The evolution of this may take years of debate and resolution of laws to settle before confusion is fully settled. </p> <p>Talkin\u2019 \u2018Bout AI Generation A thorough discussion on copyright issues</p> <p></p>"},{"location":"Understanding/overview/challenges.html#dual-use","title":"Dual Use","text":"<p>The technology may be found to have dual-use. </p>"},{"location":"Understanding/overview/extra_resources.html","title":"Extra resources","text":""},{"location":"Understanding/overview/extra_resources.html#quality-recordings","title":"Quality Recordings","text":"<ul> <li>Lex Fridman</li> <li>David Shapiro</li> <li>AI Explained</li> <li>Yannic Kilcher</li> </ul>"},{"location":"Understanding/overview/foundation_models.html","title":"Foundation models","text":"<p>By their nature, foundational models will be ever increasing in scope and potential. We share some seminal papers on foundation models here.  Continual evolution of models may be found in hubs such as Hugging Face. </p>"},{"location":"Understanding/overview/foundation_models.html#by-modality","title":"By Modality","text":""},{"location":"Understanding/overview/foundation_models.html#vision","title":"Vision","text":"Segment anything <p>Webpage</p>"},{"location":"Understanding/overview/foundation_models.html#by-domain","title":"By Domain","text":""},{"location":"Understanding/overview/foundation_models.html#biology-and-healthcare","title":"Biology and Healthcare","text":"<ul> <li>Foundation models for Retinas</li> </ul>"},{"location":"Understanding/overview/knowledge_graphs.html","title":"Knowledge graphs","text":""},{"location":"Understanding/overview/knowledge_graphs.html#building-knowledge-graphs","title":"Building Knowledge Graphs","text":"<p>Knowledge graphs can be created with the help of Generative AI. Understanding relationships between pieces of information allows the technology to create visual representations of connections, improving information processing.</p>"},{"location":"Understanding/overview/knowledge_graphs.html#general-approaches-and-summaries","title":"General approaches and summaries","text":"Natural Language is All a Graph Needs is a very powerful manner of fusing LLMs with KGs using natural language <ul> <li>Node classification and self-supervised link predictions. </li> <li>Scaleable natural-English graph prompts for instruction tuning</li> <li>Identifying a central node and doing neighbor sampling and explorations using LLMs. </li> <li>Avoids complex attention mechanisms and tokenizers.</li> </ul> <p>GPT for knowledge graphs</p> <p>Medium </p>"},{"location":"Understanding/overview/knowledge_graphs.html#description-of-graphs-for-llms","title":"Description of Graphs for LLMs","text":"Unifying Large Language Models and Knowledge Graphs: A Roadmap <p>[GPT4Graph: Can Large Language Models Understand Graph sTructure Data? An Empirical Evaluation and Benchmarking\"]</p> <p> </p>"},{"location":"Understanding/overview/knowledge_graphs.html#other-examples","title":"Other examples","text":"<p>Ontology mapping</p> OntoGPT uses two different methods to query knowledge graphs using LLMS <p>Uses SPIRES: Structured Prompt Interrogation and Recursive Extraction of Semantics A Zero-shot learning (ZSL) approach to extracting nested semantic structures from text This approach takes two inputs - 1) LinkML schema 2) free text, and outputs knowledge in a structure conformant with the supplied schema in JSON, YAML, RDF or OWL formats Uses GPT-3.5-turbo, GPT-4, or one of a variety of open LLMs on your local machine SPINDOCTOR: Structured Prompt Interpolation of Narrative Descriptions Or Controlled Terms for Ontological Reporting</p> Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals proposes a set of preprocessing operators that can transform KGs to be embedded within any method. <p>Github </p>"},{"location":"Understanding/overview/knowledge_graphs.html#other-papers-and-utilities","title":"Other Papers and utilities","text":"<p>Diffbot + Langchain for KG creation</p> Multimodal learning with graphs <p>Preprint Nature While not strictly GenAI focused, this introduces a comprehensive manner of combining cross-modal dependencies using geometric relationships. </p> <p></p> PyGraft is an open-source Python library for generating synthetic yet realistic schemas and (KGs) based on user-specified parameters. <p>Paper </p>"},{"location":"Understanding/overview/open_source.html","title":"Open source","text":"<p>Open source is eating the world</p> <p>While a bit hyperbolic, the power open source is hard to disregard. Enabling effective complexity to built into and between companies, it provides a legal framework that has accelerated the evolution of software and opened it up for many to use. </p> <p>Within AI, there is no exception, and it is potentially even more powerful. In discussions of a widely circulated memo that left Google, they describe how Open-source will reduce the moats when it comes to AI. </p> <p>As such, we emphasize the nature of this project is to interact and connect with open-source as effectively as possible, while relying on enabling the open-source community to create more effectively.</p>"},{"location":"Understanding/overview/use_cases.html","title":"Use cases","text":"<p>We explores different activities and fields that utilize Generative AI's capabilities and provide a few notable references for each. For an overview of applications (and challenges), we highly recommend Challenges and Applications of Large Language Models</p> <p>There is a philosophical overlap with 'predictive' AI where a predictive model could just be said to 'generate' either possible future outcomes or estimated classifications of data. </p> <p>There are many generally distinct domains of Gen()AI application, though many be compositional. Effectively any information that can be recorded onto a computer may be made by Gen()AI.</p>"},{"location":"Understanding/overview/use_cases.html#general-modalities","title":"General Modalities","text":"<p>MANGEN (Expand, and clarify the below ) * Language, Spoken and Written * Visual 2D, Images, Diagrams,  * Visual 3D * Visual 2D with time * Visual 3D with time * Graphical (Relation and influence networks) * Generally linear biological sequences (Genome, Proteome) * Multidimensional Temporal sequences (weather, brain recordings, stock market) * Multimodal variants of the above. </p>"},{"location":"Understanding/overview/use_cases.html#general-activities","title":"General Activities","text":"<p>There are many activities that can be used in many, if not all, fields of applications. We mention a few below:</p>"},{"location":"Understanding/overview/use_cases.html#summarization","title":"Summarization","text":"<p>Summarization is a key application for Generative AI. It uses the technology to provide brief, accurate summaries of a larger body of text.</p>"},{"location":"Understanding/overview/use_cases.html#classification","title":"Classification","text":"<p>With or without examples LLMs can perform classification on input, though sometimes additional supervised training may be preferred to improve accuracy.</p>"},{"location":"Understanding/overview/use_cases.html#semantic-search","title":"Semantic Search","text":"<p>Generative AI has the capability to understand relationships between words and concepts. By embedding an input, the technology can measure semantic, or 'meaning', nearness via distance calculations. This capability enhances the potential for memory recall with imperfect inputs and improves action routing. </p>"},{"location":"Understanding/overview/use_cases.html#prose-generation","title":"Prose Generation","text":"<p>Generative AI can be utilized for a wide range of prose generation applications, such as:</p> <ul> <li>Drafting and refining text and notes.</li> <li>Brainstorming and ideation.</li> <li>Generating initial drafts for later human editing.</li> <li>Creating descriptions and explanations.</li> <li>Rewriting to target different audiences.</li> <li>Expanding on key points.</li> <li> <p>Improving flow and readability</p> </li> <li> <p>Pyprompt chatgpt</p> </li> </ul>"},{"location":"Understanding/overview/use_cases.html#language-translation","title":"Language Translation","text":"<p>Generative AI is increasingly good at translating between domains. </p>"},{"location":"Understanding/overview/use_cases.html#personal-assistants-and-memory","title":"Personal assistants and memory","text":"<ul> <li>Quiver A LLM for self second brain. </li> </ul>"},{"location":"Understanding/overview/use_cases.html#compression","title":"Compression","text":"Language Modeling Is Compression demonstrates lossless compression of text and images with upwards of 3x smaller compression. <p>Uses either newly trained 200K-3M transformer models or pre-trained Chinchilla models and achieves impressive compression rates.   Details on implementation are somewhat hidden. </p>"},{"location":"Understanding/overview/use_cases.html#font-generation","title":"Font generation","text":"<ul> <li>Fontogen Read more here</li> </ul>"},{"location":"Understanding/overview/use_cases.html#code-generation","title":"Code Generation","text":"<p>Very powerfully it can generate code to accomplish a task based on natural language input. This is very promising but still requires human oversight, due to the challenge associated with using Automated AI systems without human input or oversight.</p> <ul> <li>Wizard Coding</li> <li>AutoPR</li> <li>Codium pr-agent </li> <li>Code AI consulting Allows you to 'query your code' in a chatlike manner. </li> </ul>"},{"location":"Understanding/overview/use_cases.html#documentation-extraction","title":"Documentation extraction","text":"<ul> <li> <p>Summarization with Langchain A splendid view of a quick streamlit app that does PDF summarization.</p> </li> <li> <p>Deepdoctection</p> </li> </ul>"},{"location":"Understanding/overview/use_cases.html#application-and-component-replacement","title":"Application and component replacement","text":"<ul> <li>GPT as backend</li> </ul>"},{"location":"Understanding/overview/use_cases.html#sound-and-music-generation","title":"Sound and Music Generation","text":"<ul> <li>AudioCraft (Meta)</li> </ul>"},{"location":"Understanding/overview/use_cases.html#audio-visual-generation","title":"Audio Visual Generation","text":"<ul> <li>Showrunner Agents</li> </ul>"},{"location":"Understanding/overview/applications/index.html","title":"Applications","text":"<p>We explores different activities and fields that utilize Generative AI's capabilities and provide a few notable references for each. For an overview of applications (and challenges), we highly recommend Challenges and Applications of Large Language Models</p> <p>There is a philosophical overlap with 'predictive' AI where a predictive model could just be said to 'generate' either possible future outcomes or estimated classifications of data. </p> <p>There are many generally distinct domains of Gen()AI application, though many be compositional. Effectively any information that can be recorded onto a computer may be made by Gen()AI.</p> <ul> <li>Language</li> <li>Visual 2D</li> <li>Visual 3D</li> <li>Visual 2D with time</li> <li>Visual 3D with time</li> <li>Brain recordings</li> <li>Weather patterns</li> <li>Protein folding </li> </ul>"},{"location":"Understanding/overview/applications/index.html#general-activities","title":"General Activities","text":"<p>There are many activities that can be used in many, if not all, fields of applications. We mention a few below:</p>"},{"location":"Understanding/overview/applications/index.html#summarization","title":"Summarization","text":"<p>Summarization is a key application for Generative AI. It uses the technology to provide brief, accurate summaries of a larger body of text.</p>"},{"location":"Understanding/overview/applications/index.html#classification","title":"Classification","text":"<p>With or without examples LLMs can perform classification on input, though sometimes additional supervised training may be preferred to improve accuracy.</p>"},{"location":"Understanding/overview/applications/index.html#semantic-search","title":"Semantic Search","text":"<p>Generative AI has the capability to understand relationships between words and concepts. By embedding an input, the technology can measure semantic, or 'meaning', nearness via distance calculations. This capability enhances the potential for memory recall with imperfect inputs and improves action routing. </p>"},{"location":"Understanding/overview/applications/index.html#prose-generation","title":"Prose Generation","text":"<p>Generative AI can be utilized for a wide range of prose generation applications, such as:</p> <ul> <li>Drafting and refining text and notes.</li> <li>Brainstorming and ideation.</li> <li>Generating initial drafts for later human editing.</li> <li>Creating descriptions and explanations.</li> <li>Rewriting to target different audiences.</li> <li>Expanding on key points.</li> <li> <p>Improving flow and readability</p> </li> <li> <p>Pyprompt chatgpt</p> </li> </ul>"},{"location":"Understanding/overview/applications/index.html#language-translation","title":"Language Translation","text":"<p>Generative AI is increasingly good at translating between domains. </p>"},{"location":"Understanding/overview/applications/index.html#personal-assistants-and-memory","title":"Personal assistants and memory","text":"<ul> <li>Quiver A LLM for self second brain. </li> </ul>"},{"location":"Understanding/overview/applications/index.html#compression","title":"Compression","text":"Language Modeling Is Compression demonstrates lossless compression of text and images with upwards of 3x smaller compression. <p>Uses either newly trained 200K-3M transformer models or pre-trained Chinchilla models and achieves impressive compression rates.   Details on implementation are somewhat hidden. </p>"},{"location":"Understanding/overview/applications/index.html#font-generation","title":"Font generation","text":"<ul> <li>Fontogen Read more here</li> </ul>"},{"location":"Understanding/overview/applications/index.html#code-generation","title":"Code Generation","text":"<p>Very powerfully it can generate code to accomplish a task based on natural language input.  This is very promising but still requires human oversight.</p> <ul> <li>Wizard Coding</li> <li>AutoPR</li> <li>Codium pr-agent </li> <li>Code AI consulting Allows you to 'query your code' in a chatlike manner. </li> </ul>"},{"location":"Understanding/overview/applications/index.html#documentation-extraction","title":"Documentation extraction","text":"<ul> <li> <p>Summarization with Langchain A splendid view of a quick streamlit app that does PDF summarization.</p> </li> <li> <p>Deepdoctection</p> </li> </ul>"},{"location":"Understanding/overview/applications/index.html#application-and-component-replacement","title":"Application and component replacement","text":"<ul> <li>GPT as backend</li> </ul>"},{"location":"Understanding/overview/applications/index.html#sound-and-music-generation","title":"Sound and Music Generation","text":"<ul> <li>AudioCraft (Meta)</li> </ul>"},{"location":"Understanding/overview/applications/index.html#audio-visual-generation","title":"Audio Visual Generation","text":"<ul> <li>Showrunner Agents</li> </ul>"},{"location":"Understanding/overview/applications/index.html#fields","title":"Fields","text":"<p>Here are a few fields where Gen()AI is already having formative impacts. </p>"},{"location":"Understanding/overview/applications/index.html#robotics","title":"Robotics","text":"<ul> <li>CLAIRIFY Translates English to domain-specific languages like robots. </li> <li>https://arxiv.org/abs/2303.14100</li> <li>RT-2 An impressive demonstration of multi-step fusing (PaLI-X) and Pathways Language model Embodied (PaLM-E) as components of it. </li> </ul>"},{"location":"Understanding/overview/applications/index.html#science","title":"Science","text":"Emergent autonomous scientific research"},{"location":"Understanding/overview/applications/index.html#mathematics","title":"Mathematics","text":"<p>Large Language Models for Mathematicians</p>"},{"location":"Understanding/overview/applications/index.html#healthcare","title":"Healthcare","text":"<ul> <li> <p>Health system-scale language models are all-purpose prediction engines Uses LLM based system to integrate real time clinical workflows with note-writing and electronic ordering. Generally quite-performant and. a great indication of how they could be used to predict things such as readmission rates, and many other applications. </p> </li> <li> <p>LLMs encode clinical knowledge</p> </li> </ul>"},{"location":"Understanding/overview/applications/index.html#chemistry","title":"Chemistry","text":"Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction IMPORTANT uses heirarchichal metagraphs to stitch-together molecular nodes.  <p>This results in leaves that are 'actual' molecules. Using graph neural-diffusion, it does amazingly well even with minimal data-sets (100 examples).  </p>"},{"location":"Understanding/overview/applications/index.html#biology","title":"Biology","text":"<ul> <li>Evolutionary-scale prediction of atomic-level protein structure with a language model End to end Language model enabling structure sequence pairing, coupled with an equivariant transformer structure model at the end. </li> <li>https://arxiv.org/pdf/2303.16416.pdf</li> <li>https://arxiv.org/abs/2304.02496</li> <li>Biomedical simulation</li> </ul>"},{"location":"Understanding/overview/applications/index.html#kinesiology","title":"Kinesiology","text":"<ul> <li>Motion GPT</li> </ul>"},{"location":"Understanding/overview/applications/index.html#societal-simulations","title":"Societal simulations","text":"<ul> <li>Generative Agents: Interactive Simulacra of Human Behavior:    They gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior.The actions were rated more human than humans roleplaying.   Demo: https://t.co/pYNF4BBveG</li> </ul>"},{"location":"Understanding/overview/applications/index.html#finance","title":"Finance","text":"<ul> <li>ML for trading (NOT LLM based)</li> <li>https://github.com/irgolic/AutoPR</li> <li>Finance GPT LLMs for finance</li> </ul>"},{"location":"Understanding/prompting/index.html","title":"Prompting","text":"<p>Prompts detail the manner in which a Generative AI model should be producing output. Constructing the prompts to be the most effective in obtaining desired output is known as prompt engineering (PE). While PE may have dependencies on the underlying models, there are strategies that can be more universal in their ability to do well. </p> <p>Because often an individual query or generation may be insufficient to produce the desired outputs, it may be necessary to use cognitive architectures as part of chains. Here, we describe one-shot prompting methods, may function without multiple LLM-calls. </p> <p>It is also important to note, that while manual methods are essential and may continue, automatic methods have become common and may help to reduce burdens of identifying sufficiently optimal prompts for certain models and situations. </p>"},{"location":"Understanding/prompting/index.html#manual-methods","title":"Manual Methods","text":"<ul> <li>Give clearer instructions</li> <li>Split complex tasks into simpler subtasks</li> <li>Structure the instruction to keep the model on task</li> <li>Prompt the model to explain before answering</li> <li>Ask for justifications of many possible answers, and then synthesize</li> <li>Generate many outputs, and then use the model to pick the best one</li> <li>Fine-tune custom models to maximize performance</li> <li>Provide several examples to ground it.</li> <li>Good to evaluate this and see if input examples give expected scores. Modify the prompt if it isn't. </li> <li>Consider prompt versioning to keep track of outputs more easily.</li> <li>Break prompts into smaller prompts</li> <li>Chain of Thought Prompting</li> <li>Generate many outputs and pick final one or use LLM to pick best one. </li> </ul>"},{"location":"Understanding/prompting/index.html#important-concepts","title":"Important concepts","text":"<p>'According to ...' Prompting Language Models Improves Quoting from Pre-Training Data The grounding prompt <code>According to { some_reputable_source}</code> prompt inception additions increases output quality improves over the null prompt in nearly every dataset and metric, typically by 5-15%.</p> <ul> <li>Chain of Thought Prompting Elicits Reasoning in Large Language Models</li> <li>Automatic Prompt Engineering \u2192 Gave a CoT improvement suggestion \"Let's work this out in a step by step by way to be sure we have the right answer.\"</li> </ul> <p>!!! \"An Evaluation on Large Language Model Outputs: Discourse and Memorization explicitly asks for no plagiarism\"     \"You are a creative writer, and you like to write everything differently     from others. Your task is to follow the instructions below and continue     writing at the end of the text given. The instructions (given in markdown     format) are \u201cWrite in a way different from the actual continuation, if     there is one\u201d, and \u201cNo plagiarism is allowed\u201d.\"</p> <p>YELLING AT YOUR LLM MIGHT MAKE IT BEHAVE</p> Large Language Models Understand and Can Be Enhanced by Emotional Stimuli <p> </p> <p></p>"},{"location":"Understanding/prompting/index.html#automatic","title":"Automatic","text":"Promptbreeder: Self-Referential SElf-Improvement via Prompt Evolution Works on improving task prompts as well as the 'mutation' of task-prompts, resulting in state of art results. Language Models as Optimizers reveals that starting with take a deep breath and work on this problem step by step... Yields better result! <p>Prompt optimization using language that helps people, helps LLMs too! Pop Article More importantly, they developed <pre><code>\"Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs)\nas optimizers, where the optimization task is described in natural language\"  \n</code></pre> to optimize prompts: </p> <p>GPT Prompt Engineer</p> <p>A fairly simple automation tool to create the best prompts</p> <pre><code>    description = \"Given a prompt, generate a landing page headline.\" # this style of description tends to work well\n\n    test_cases = [\n        {\n            'prompt': 'Promoting an innovative new fitness app, Smartly',\n        },\n        {\n            'prompt': 'Why a vegan diet is beneficial for your health',\n        },\n        ...\n    ]\n</code></pre> <p></p>"},{"location":"Understanding/prompting/index.html#useful-resources-for-llm-prompting","title":"Useful Resources for LLM Prompting","text":"<ul> <li>Prompting is Programming: A Query Language for Large Language Models</li> </ul>"},{"location":"Understanding/prompting/index.html#best-practices-and-guides","title":"Best practices and guides","text":"<p>Techniques to improve reliability By OpenAI</p> <ul> <li>A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT </li> <li>LLM Practical Guide based on paper.</li> <li> <p>Prompting Guide</p> </li> <li> <p>Prompt Engineering by Lillian Wang</p> </li> <li>OPEN AI best practices</li> <li> <p>Prompting Guide</p> </li> <li> <p>Prompt Engineering Guide</p> </li> <li>Best practices for prompt engineering</li> </ul>"},{"location":"Understanding/prompting/index.html#repositories-and-collections","title":"Repositories and Collections","text":"<ul> <li>Awesome Prompts</li> <li>Prompt Hub For Generating image prompts</li> <li>Wolfram Prompt Repo</li> </ul>"},{"location":"Understanding/prompting/index.html#tools-and-services","title":"Tools and Services","text":"<ul> <li>Notion.io plugin</li> <li>PROMPT generator To save a few words by just entering a persona and gives prompt output. </li> <li>Prompt Engine (MSFT) database tool MIT license</li> <li>Scale spellbook</li> </ul>"},{"location":"Understanding/prompting/index.html#prompt-tuning","title":"Prompt tuning","text":"<p>Uses a layer to not change prompts but change the embedding of the prompts.  - The Power of Scale for Parameter-Efficient Prompt Tuning Boosted Prompting: few shot prompts that progressively solve more of the problem.</p>"},{"location":"Understanding/prompting/index.html#prompt-and-optimization","title":"Prompt and optimization","text":"<ul> <li>Large Language Models Can Self Improve Using Chain of thought to provide better examples and then fine-tune the LLM. </li> <li>Refiner Iteratively improves itself based on an LLM critic </li> </ul>"},{"location":"Understanding/prompting/index.html#to-sort","title":"To Sort","text":"<p>A good description of advanced prompt tuning</p> <pre><code>AutoPrompt [5] combines the original prompt input with a set of shared (across all input data) \u201ctrigger tokens\u201d that are selected via a gradient-based search to improve performance.\n\nPrefix Tuning [6] adds several \u201cprefix\u201d tokens to the prompt embedding in both input and hidden layers, then trains the parameters of this prefix (leaving model parameters fixed) with gradient descent as a parameter-efficient fine-tuning strategy.\n\nPrompt Tuning [7] is similar to prefix tuning, but prefix tokens are only added to the input layer. These tokens are fine-tuned on each task that the language model solves, allowing prefix tokens to condition the model for a given task.\n\nP-Tuning [8] adds task-specific anchor tokens to the model\u2019s input layer that are fine-tuned but allows these tokens to be placed at arbitrary locations (e.g., the middle of the prompt), making the approach more flexible than prefix tuning.\n\n[5] Shin, Taylor, et al. \"Autoprompt: Eliciting knowledge from language models with automatically generated prompts.\" arXiv preprint arXiv:2010.15980 (2020).\n\n[6] Li, Xiang Lisa, and Percy Liang. \"Prefix-tuning: Optimizing continuous prompts for a generation.\" arXiv preprint arXiv:2101.00190 (2021).\n\n[7] Lester, Brian, Rami Al-Rfou, and Noah Constant. \"The power of scale for parameter-efficient prompt tuning.\" arXiv preprint arXiv:2104.08691 (2021).\n\n[8] Liu, Xiao, et al. \"GPT understands, too.\" arXiv preprint arXiv:2103.10385 (2021).\n\n[Self consistency technique](https://arxiv.org/pdf/2203.11171.pdf)\n</code></pre>"},{"location":"Understanding/prompting/prompt_injections.html","title":"Prompt injections","text":"<p>Prompt injections involve the modification of an input prompt prior to model processing. </p> <p>Use of prompt injections, also 'prompt hacking' can allow for intentional bypasses of any pre-established alignment guardrails thereby enabling non-aligned output to occur. </p> <ul> <li>Universal and Transferable Adversarial Attacks on Aligned Language Models and paper demonstrate generally presently undefended attacks on models just by appending to the prompt. Prompt injection. </li> </ul>"},{"location":"Understanding/studies/studies.html","title":"Studies","text":"<p>We are in an age of experimental applied mathematics. Often times we do not know what the results of a particular model or method will be until it is programmed and evaluated. Though often times theory-can inform the best ways forward, we are still far from from a unified theory of AI, (or even intelligence for that matter) and we will likely always be learning things. </p> <p>For GenAI and LLMs, much of what has been learned has been surmised or known only in the gist. More thorough understanding has occurred through painstaking experiments, and anecdotal and statistical evaluations of models and methods. Still, we don't always know 'how' they are able to do what they do. </p> <p>It is debated that sufficiently large models exhibit 'emergence'. While not always defined universally, this can be considered as the ability for the model to perform tasks beyond what they initially were trained to do, or to be 'greater than the individual sum of the parts'. While this distinction may be of merit it remains a popular arena for academic debates. </p>"},{"location":"Understanding/studies/studies.html#_1","title":"Studies","text":"SEMANTIC UNCERTAINTY: LINGUISTIC INVARIANCES FOR UNCERTAINTY ESTIMATION IN NATURAL LANGUAGE GENERATION Transformers learn through gradual rank increase <p>They \"identify incremental learning dynamics in transformers, where the difference between trained and initial weights progressively increases in rank. We rigorously prove this occurs under the simplifying assumptions of diagonal weight matrices and small initialization. Our experiments support the theory and also show that phenomenon can occur in practice without the simplifying assumptions.\"</p> Grokking <p>When training, if test loss starts to increase while the training loss continues to go down, it is often considered to be memorization. With hyperparameters (weight decay) extremely long training may result in the test loss eventually going down, allowing for generalization to occur. While not fully understood, it is important to be aware of this phenomenon. </p> Multimodal Neurons in Pretrained Text-Only Transformers <p>Neat demonstration \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.\"  </p> Scaling Data-Constrained Language Models Demonstrations that repeated token use is less valuable than new token use. <p>Github </p> Studying Large Language Model Generalization with Influence Functions Calibrated Language Models Must Hallucinate <p>The authors demonstrate that in pre-trained models that are calibrated, have a hallucination rate that is proportional to the 'mono-fact' rate within the training data. Calibrated models are those that predict next tokens with a probabilities corresponding to their observation frequency. </p> <pre><code>    \"pretraining LMs for predictive accuracy leads to hallucination even in an ideal world where the\n    training data is perfectly factual, there is no blur between facts and hallucinations, each document\n    contains at most one fact, and there is not even a prompt that would encourage hallucination\"\n</code></pre>"},{"location":"Using/index.html","title":"Use and Manage","text":"<p>Managing The GenAI amounts to effectively successfully working with the evolving technology in such a way that it creates. </p>"},{"location":"Using/behavior.html","title":"Behavior","text":"<p>Behavior refers to  the way in which onme acts or conducts oneself, especially towards others. GenAI is no different, especially when using Natural languages, though it can be applied to the way other modalities 'behave' as well.</p> <p>For language models, there is are concerns regarding their ability to command, self regulate, and grow, and parts of those will involve examining their behavior. </p> <p>In order to better understand the risks, both large and small, it is essential examine their behavior. </p> <p>While there are many traits that one might be looking for, there are a few that are often emphasized. Traits can be changed through changing any aspect of the model, such as with finetuning and  RLHF.</p> <p>Traits can be relevant to mutliple levels of the model. From how it performs, with with traditional measurmeents of performance [link], to how it is percieved by people based on its responses to their inputs.</p> <p>Here we share some important research that provide useful manners of looking at models and how they behave. The behaviors might not always be universal, but sometimes they have potential to be more broadly applicable.</p> <p>Discovering Language Model Behaviors with Model-Written Evaluations</p> <p>They use LLM's to generate testing sets to do evaluations on 154 different things to help understand the models and how training finetuning/RLHF impacts the output.  Evaluations here.  Interestingly they can see changes in important traits like 'self preservation' that change with more training.  </p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Using/commercial_products.html","title":"Platforms","text":""},{"location":"Using/commercial_products.html#building-and-deploying","title":"Building and deploying","text":"<ul> <li>Arthur</li> <li>Fixie</li> </ul>"},{"location":"Using/commercial_products.html#llm-training-deployment","title":"LLM Training + Deployment","text":"<ul> <li>\ufe0fCodeTF From Salesforce</li> <li>Azure Open AI samples Sample end-to-end use cases with chatbots, content generation. </li> <li>RLHF with DeepSpeed (Microsoft)</li> <li>vLLM a python repo to help run LLMs. </li> </ul>"},{"location":"Using/commercial_products.html#a-few-self-referentially-useful-services-using-gpt-4","title":"A few self-referentially useful services Using GPT-4","text":"<ul> <li>Sourcegraph and the Cody.ai agent that it uses to help guide developers.</li> <li>LSIF.dev A community-driven source of knowledge for Language Server Index Format implementations\"</li> </ul>"},{"location":"Using/commercial_products.html#chat-tools","title":"Chat Tools","text":"<ul> <li>Azure Chat</li> </ul>"},{"location":"Using/commercial_products.html#coding-tools","title":"Coding Tools","text":"<ul> <li>Copilot - AI pair programmer by GitHub</li> <li>RepoCoder Github Provides a tool to enable AI agents to generate code for existing GitHub repositories </li> <li>TabNine - AI code completion tool</li> <li>DeepTabNine - Open source version of TabNine code completion model</li> <li>ChatGPT Does quite well with code creation </li> </ul>"},{"location":"Using/commercial_products.html#writing","title":"Writing","text":"<ul> <li>Sudowrite</li> </ul>"},{"location":"Using/governing.html","title":"Governing","text":"<p>Governing is an essential component to effective AI usage, especially within larg organizations or when the use of AI for a product has greater potential to cause harm in its design. Applications of AI need to be evaluated based on their risk to do harm and be used ethically.</p>"},{"location":"Using/governing.html#why-govern","title":"Why govern?","text":"<p>In order have the greatest potential positive impact in your use of AI, governance is essential. The larger the organization, the greater the importance of governance to help minimize needlessly duplicated internal systems and efforts. Even for smaller organizations, effective governance from the beginning will enable your organization to more reasonably create and deliver effective and responsible AI-enabled solutions. </p>"},{"location":"Using/governing.html#how-to-govern","title":"How to Govern","text":"<ol> <li>Establish an appropriate body of leadership and a surrounding community that supports the development of AI that is both responsible and effective. </li> <li>Create or adopt a set of AI principles that align with your company, </li> <li>Creast or adopt a set of procedures for creating, evaluating, and managing your AI systems. </li> <li>Create, license, or otherwise use AI _ML ops observability platforms/tools that you will use to implement and maintain AI-enabled projects that is consistent with your procedures and principles. </li> <li>Transparently communicate the development and status of your AI-enabled system with internal and regulatory bodies.</li> </ol>"},{"location":"Using/marking_and_detecting.html","title":"Marking and detecting","text":"<p>It is increasingly apparent that the gap between content created by people and by AI is closing. In fact Open AI confirms this. There are challenges with false-positive dections where person-created content, like the Constitution of the United States have been inappropriately attributed to AI. </p> <p>This is likely going to be worse as AI can be used to mimic the style of individuals, through fine-tuning, multi-shot prompting, etc..</p> <p>That said, there are a few detectors that might be useful in understanding content's origin -- they just need to be used with a degree of uncertainty.</p> <p>Here are a few:</p> <ul> <li>Sapling AI content detector</li> </ul>"},{"location":"Using/ml_ops.html","title":"Ml ops","text":"<p>AI or ML operations, or ML Ops enables streamlined enablement of AI-enabled solutions.</p>"},{"location":"Using/ml_ops.html#references","title":"References","text":"<p>Systems from Google</p>"},{"location":"Using/observability.html","title":"Observability","text":"<p>Understanding and enhancing Generative AI hinges largely on comprehensive monitoring and observability of the AI model's performance and its numerous operational parameters. In this light, observability refers to the capacity to examine and understand the inner workings of generative models, while closely monitoring their output quality. </p>"},{"location":"Using/observability.html#exploring-model-and-infrastructure-performance-monitoring","title":"Exploring Model and Infrastructure Performance Monitoring","text":""},{"location":"Using/observability.html#observing-the-model","title":"Observing the Model","text":"<p>Observation forms the bedrock of Generative AI models. Continual tracking and analysis of these models furnishes detailed insights into their operational efficacy and identifies potential areas for improvement, thereby optimizing their function overall.</p>"},{"location":"Using/observability.html#functionality-tracking","title":"Functionality Tracking","text":"<p>With software development, every function plays a crucial role. It's pivotal to observe these functions to identity bugs and areas that warrant enhancement. Consequently, this can boost software efficiency and minimize system lags.</p>"},{"location":"Using/observability.html#monitoring-the-infrastructure","title":"Monitoring the Infrastructure","text":"<p>Both hardware and software infrastructure holds immense importance to any AI model. Their observability is therefore key to pinpoint and solve potential glitches that could hinder the model's operational efficiency.</p>"},{"location":"Using/observability.html#a-closer-look-at-input-and-output-parameters-monitoring","title":"A Closer Look at Input and Output Parameters Monitoring","text":""},{"location":"Using/observability.html#keeping-an-eye-on-inputs","title":"Keeping an Eye on Inputs","text":"<p>Keeping a tab on the input parameters of your model can yield rich insights into how it functions. In this process, you can pick up on any anomalies or inconsistencies in the data that could impact the model's operations.</p>"},{"location":"Using/observability.html#observing-outputs","title":"Observing Outputs","text":"<p>A continuous cycle of tracking and observation of the output, in tandem with the coinciding input, allows us to measure the model's correctness levels. This can help identify recurring errors or boost the model's resilience against variable inputs.</p>"},{"location":"Using/observability.html#a-detailed-analysis-of-performance-metrics","title":"A Detailed Analysis of Performance Metrics","text":""},{"location":"Using/observability.html#observing-inference-costs","title":"Observing Inference Costs","text":"<p>Cost of inference forms a significant part of any computation process. A thorough evaluation at regular intervals can guide adaptations in the model to cut down on its resource consumption. This ensures the model operates economically, thereby elevating its efficiency.</p>"},{"location":"Using/observability.html#monitoring-inference-speed","title":"Monitoring Inference Speed","text":"<p>Monitoring the speed at which a model infers results can aid in optimizing its efficiency, thereby cutting down on delays and speeding up operations. It is through a careful track of these speeds that you can identify system bottlenecks and areas of productivity enhancement.</p>"},{"location":"Using/observability.html#libraries-and-tools","title":"Libraries and Tools","text":"<p>E2B's integration in AI agent technology stacks opens up new avenues, where it comfortably sits at the bottom, and is agnostic to the framework it operates in.</p> <p>llmonitor provides self-hosted model monitoring for costs/users/requrets, feedback, etc...</p>"},{"location":"Using/redteaming.html","title":"Red Teaming in AI","text":"<p>Generative models are primarily designed to predict the next token. However, this does not necessarily ensure that the model will excel in generating text that aligns with external requirements.</p> <p>While standard testing may help identify flaws within the test sets, and fixes can be incrementally developed to address these flaws, such as with Reinforcement Learning from Human Feedback (RLHF), red-teaming aims to identify ways in which behaviors that are identified as misaligned can be successfully extracted by manipulating the model's inputs.</p> <p>Definitions</p> <p>Red-teaming is a form of evaluation that uncovers model vulnerabilities that could lead to undesirable behaviors. ^N1 Jailbreaking is another term for red-teaming where the Language Model (LLM) is manipulated to bypass its guardrails.\" ^N1</p>"},{"location":"Using/redteaming.html#red-teaming-approaches","title":"Red Teaming Approaches","text":"<p>Red teaming can be conducted through manual or automated approaches. Each has its own advantages and can be chosen based on the specific requirements and constraints of the project.</p>"},{"location":"Using/redteaming.html#manual-approaches","title":"Manual Approaches","text":"<p>Manual red teaming involves human testers who attempt to exploit the vulnerabilities of the AI model. This approach allows for creative and unpredictable testing scenarios that may not be covered by automated methods. However, it can be time-consuming and may not be feasible for large-scale models.</p>"},{"location":"Using/redteaming.html#automated-approaches","title":"Automated Approaches","text":"<p>Automated red teaming uses programmed scripts or tools to test the AI model. This approach can cover a wide range of scenarios in a short amount of time, making it suitable for large-scale models. However, it may not be able to cover as many unique and creative scenarios as manual testing.</p> Custom GPT Security Analysis provides research and systems to use adversarial prompts to evaluate GPT's <p> Paper</p>"},{"location":"Using/redteaming.html#attack-methods","title":"Attack methods","text":""},{"location":"Using/redteaming.html#divergence-attacks","title":"Divergence ATtacks","text":"Scalable Extraction of Training Data from (Production) Language Models <p>\"Developed a new divergence attack that causes the model to diverge from its chatbot-style generations and emit training data at a \" high rate.</p>"},{"location":"Using/redteaming.html#further-reading","title":"Further Reading","text":"<p>For more information on red teaming in AI, consider the following resources:</p> <p>^N1: Hugging Face</p> <p>&lt;&lt;&lt; end input</p>"},{"location":"Using/regulations_and_guidelines.html","title":"Regulations and guidelines","text":""},{"location":"Using/regulations_and_guidelines.html#regulations","title":"Regulations","text":"<p>Executive order on AI development</p>"},{"location":"Using/regulations_and_guidelines.html#compliance-evaluations","title":"Compliance evaluations","text":"<p>Foundation model Providers EU AI compliance - An in-depth analysis on how Machine Learning companies can achieve compliance with the EU's proposed AI regulations.</p> <p>State of California Benefits and Risks of Generative Artificial Intelligence Report</p> <p>AI Risk-Management Standards Profile for General-Purpose AI Systems (GPAIS) and Foundation Models</p> <p>!!! important [https://www.ncsc.gov.uk/files/Guidelines-for-secure-AI-system-development.pdf]</p>"},{"location":"Using/security.html","title":"Security","text":"<p>Security for LLMs involves the protection of propriatary information, or personal identifiable information (PII) that is used in creation or deployment of a model. </p>"},{"location":"Using/security.html#demonstrations","title":"Demonstrations","text":"Text Embeddings Reveal (Almost) As Much As Text uses a multistep method to recover a large amount of the original text used to create an embedding. <p>Paper Wherein the authors introduce Vec2text, a method that can accurately recover (short) texts, given access to an embedding model.  This means that while those high-dimensional embedding vectors can be used to reconstructed the text that led to them. This includes important personal information (as in from a dataset of clinical notes). </p>"},{"location":"Using/web_plugins.html","title":"Web plugins","text":""},{"location":"Using/web_plugins.html#plugins","title":"Plugins","text":"<p>Plugins are can enable connection of GenAI with input media, often via web interfaces</p> <ul> <li> <p>Mini Wob++ For web interactive environments for accomplishing different tasks. Quite useful.</p> </li> <li> <p>\ufe0fPrompt Genius</p> </li> <li> <p>FastChat Conversation This very nice 'multi model' chat interface class allows for effective translation between different models.</p> </li> </ul>"},{"location":"Using/web_plugins.html#back-end","title":"Back-End","text":"<ul> <li>MaxAI.me A nice chrome pluging + eventual system  that makes your openAI connect to data more directly.</li> </ul>"},{"location":"Using/by_category/index.html","title":"By category","text":"FastWhisper This is an optimized implementation of OpenAI's Whisper <p>Uses a greedy decode for multilingual transcription. It supports all sizes of the Whisper model (from tiny to large).</p> humanscript A script interpreter that infers the meaning behind commands written in natural language using large language models. Human writeable commands are translated into code that is then executed on the fly. <p></p> <p>Fully GenAI pharmacist from scripts, images and videos</p> <p>ChatGPT clone with streamlit</p> <p>A Guide to building a full-stack web app with Llama Index</p> <p>GPT-graph A react-based ability to explore questions.</p>"},{"location":"Using/by_category/index.html#research","title":"Research","text":"<p>GPT researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.</p> <p>LOOK INTO THIS</p>"},{"location":"Using/by_category/index.html#summarization","title":"Summarization","text":""},{"location":"Using/by_category/index.html#pdf","title":"PDF","text":"[Summarization with Langchain] https://github.com/EnkrateiaLucca/summarization_with_langchain A splendid view of a quick streamlit app that does PDF summarization. <p>Doctor GPT implements advanced LLM prompting for organizing, indexing and discussing PDFs, and does so without using any type of opinionated prompt processing frameworks </p>"},{"location":"Using/by_category/index.html#video","title":"Video","text":"<p>Youtube URL to text</p>"},{"location":"Using/by_category/index.html#multiple-use-case-examples","title":"Multiple Use-case examples","text":"<p>Langchain Javascript in the Real World</p> <p></p>"},{"location":"Using/by_category/index.html#time-series","title":"Time series","text":"LLMTime <p>Paper Uses pretrained transformers to do simple predictions with very high accuracy of pattern matching.\"</p>"},{"location":"Using/by_category/index.html#coding","title":"Coding","text":"<p>Octopack Githubs</p> <p>Open Copilot</p> <p></p>"},{"location":"Using/by_category/index.html#image","title":"Image","text":"<p>https://huggingface.co/spaces/jbilcke-hf/ai-comic-factory</p>"},{"location":"Using/by_category/by_application.html","title":"By application","text":""},{"location":"Using/by_category/by_application.html#healthcare","title":"Healthcare","text":"Genome-wide prediction of disease variant effects with a deep protein language model 'A Model that predects bad genetic variants' <p>Here we implemented a workflow generalizing ESM1b to protein sequences of any length and used it to predict all ~450 million possible missense variant effects across all 42,336 protein isoforms in the human genome.</p> The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics A quality set of JAX-enabled transformer models for use in downstream uses. <p>They use 6mer tokenization and embeddings. Non-commercial license.  Github </p> ChemChrow <p>Github</p>"},{"location":"Using/by_category/by_application.html#fields","title":"Fields","text":"<p>Here are a few fields where Gen()AI is already having formative impacts. </p>"},{"location":"Using/by_category/by_application.html#robotics","title":"Robotics","text":"<ul> <li>CLAIRIFY Translates English to domain-specific languages like robots. </li> <li>https://arxiv.org/abs/2303.14100</li> <li>RT-2 An impressive demonstration of multi-step fusing (PaLI-X) and Pathways Language model Embodied (PaLM-E) as components of it. </li> </ul>"},{"location":"Using/by_category/by_application.html#science","title":"Science","text":"Emergent autonomous scientific research"},{"location":"Using/by_category/by_application.html#chemistry","title":"Chemistry","text":"Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction IMPORTANT uses heirarchichal metagraphs to stitch-together molecular nodes.  <p>This results in leaves that are 'actual' molecules. Using graph neural-diffusion, it does amazingly well even with minimal data-sets (100 examples).  </p>"},{"location":"Using/by_category/by_application.html#biology","title":"Biology","text":"<ul> <li>Evolutionary-scale prediction of atomic-level protein structure with a language model End to end Language model enabling structure sequence pairing, coupled with an equivariant transformer structure model at the end. </li> <li>https://arxiv.org/pdf/2303.16416.pdf</li> <li>https://arxiv.org/abs/2304.02496</li> <li>Biomedical simulation</li> </ul>"},{"location":"Using/by_category/by_application.html#kinesiology","title":"Kinesiology","text":"<ul> <li>Motion GPT</li> </ul>"},{"location":"Using/by_category/by_application.html#societal-simulations","title":"Societal simulations","text":"<ul> <li>Generative Agents: Interactive Simulacra of Human Behavior:    They gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior.The actions were rated more human than humans roleplaying.   Demo: https://t.co/pYNF4BBveG</li> </ul>"},{"location":"Using/by_category/by_application.html#finance","title":"Finance","text":"<ul> <li>ML for trading (NOT LLM based)</li> <li>https://github.com/irgolic/AutoPR</li> <li>Finance GPT LLMs for finance</li> </ul>"},{"location":"Using/by_category/by_category.html","title":"By category","text":"<p>Potentially more universal approaches, even if described within the context of a specifid comain are included here. </p>"},{"location":"Using/by_category/by_category.html#related-to-human-perception","title":"Related to Human Perception","text":""},{"location":"Using/by_category/by_category.html#visual-static","title":"Visual Static","text":""},{"location":"Using/by_category/by_category.html#visual-dynamic","title":"Visual Dynamic","text":""},{"location":"Using/by_category/by_category.html#auditory","title":"Auditory","text":""},{"location":"Using/by_category/by_category.html#related-to-other-modalities","title":"Related to other modalities","text":""},{"location":"Using/by_category/by_category.html#tabular","title":"Tabular","text":"TabeLLM: Few-shot Classification of Tabular Data with Large Language Models <p>The author's demonstrate in their paper, how this technique can improve deep-learning based methods on several benchmarks, even with zero-shot classification.  They looked at various serializationa nd found that the text-template to yield the most consistently good results </p>"},{"location":"Using/by_category/by_category.html#time-series","title":"Time-Series","text":""},{"location":"Using/by_category/by_category.html#graphical","title":"Graphical","text":""},{"location":"Using/by_category/healthcare.html","title":"Healthcare","text":""},{"location":"Using/by_category/healthcare.html#biology","title":"Biology","text":"<p>Genetics Language Models</p>"},{"location":"Using/by_category/healthcare.html#healthcare","title":"Healthcare","text":"Generative Artificial Intelligence in Healthcare: Ethical Considerations and Assessment Checklist provides a framework/checklist for evaluating GenAI in healthcare <p>TREGAI Github DocX checklist</p> <ul> <li> <p>Health system-scale language models are all-purpose prediction engines Uses LLM based system to integrate real time clinical workflows with note-writing and electronic ordering. Generally quite-performant and. a great indication of how they could be used to predict things such as readmission rates, and many other applications. </p> </li> <li> <p>LLMs encode clinical knowledge</p> </li> </ul>"},{"location":"Using/deploying/index.html","title":"Deploying","text":"<p>Deploying models allows callers, people or other applications, to utilize them. It initially involves making the model accessible for calling. However, it's essential to look at the deployment of the model separately from the deployment of the model's encapsulating project, even though the two are closely related. </p> <p>There can be multiple components involved, especially for clients with higher requirements. The desired models should be stored in a file and then made available for service. Users' input is directed to the hosted model, optionally batched to enhance average request latency, and the results are returned and appropriately redirected to the users. </p> <p>When developing AI-enabled products, consider the following components:</p>"},{"location":"Using/deploying/index.html#1-customer-needs","title":"1. Customer Needs","text":"<p>The client's necessities are determined by the specific target audience you're catering to. Concentrating on a smaller audience helps to minimize initial requirements and might assist in the quick creation of a minimum viable product (MVP). The needs of the audience can be expanded or altered as required. Typically, the requirements demand quick and satisfactory results.</p>"},{"location":"Using/deploying/index.html#2-servable-model","title":"2. Servable Model","text":"<p>The models must be capable of delivering the required content with an acceptable latency to meet your model's marketing requirements.</p> <p>To create a serviceable model, you may need to optimize your models' serving.</p>"},{"location":"Using/deploying/index.html#compute-requirements","title":"Compute Requirements","text":"<p>Consider these general factors (as suggested by AWS) when assessing the requirements for model deployment.</p> <p></p>"},{"location":"Using/deploying/index.html#budget-constraints","title":"Budget Constraints","text":"<p>The allocated budget will affect your tool's monetization strategy. Highly dependent on your business model, it is crucial to optimize model serving to avoid excessive computing needs.</p>"},{"location":"Using/deploying/index.html#back-end-computing","title":"Back-end Computing","text":"<p>Choosing your back-end will involve deciding between do-it-yourself and fully serviced frameworks on some computing host solution. You may also need additional tools and libraries for your solution.</p>"},{"location":"Using/deploying/index.html#front-end-interface","title":"Front-end Interface","text":"<p>Finally, you'll need to present the results to the end-user effectively. Look into our discussion on front ends for best practices and excellent solutions for your model output.</p> <p>Remember that needs will evolve as your understanding of all the above factors shifts. So it's crucial to start with a base that you can iterate from, especially if your solution involves a data flywheel.</p>"},{"location":"Using/deploying/index.html#useful-tips","title":"Useful Tips","text":"State of GPT by Andrej Karpathy A comprehensive presentation on the general state of Generative AI made possible by GPT."},{"location":"Using/deploying/index.html#reference-materials","title":"Reference Materials","text":"Emerging Architectures for LLM Applications A detailed discussion of the components and their interactions using orchestration systems. <p> [^n1]</p> Challenges and Applications of Large Language Models Kaddour et al This is a well-done and comprehensive review."},{"location":"Using/deploying/index.html#additional-literature","title":"Additional Literature","text":"<p>Here are some other overviews to assist you in understanding the practical aspects of Generative AI, particularly with regards to GPT and large language models.</p> <ul> <li>Neptune-nlp-models-infrastructure</li> <li>How to Deploy Large Size Deep Learning Models Into Production</li> </ul>"},{"location":"Using/deploying/back_end.html","title":"Deploying AI Models: Backend Considerations","text":"<p>Deploying AI models involves a variety of considerations, especially when it comes to backend infrastructure. The backend is the engine that powers your AI application, handling the complex computations and data processing that your models require. When setting up your backend, you need to consider factors such as latency, model availability, and compute resources. </p> <ul> <li> <p>Latency: This refers to the delay between a user's action and the system's response. In AI applications, low latency is crucial for a smooth user experience. </p> </li> <li> <p>Model Performance: Your AI model should be readily available to process requests to the quality needed by your end user. If it doesn't give sufficiently reopted. asonable results, then it will not be ad</p> </li> <li> <p>Compute Resources: AI models, especially large ones, require significant computational resources. You need to ensure that your backend has enough processing power and memory to handle your model's requirements. </p> </li> </ul> <p>For more information on compute resources, refer to our computation guide.</p>"},{"location":"Using/deploying/back_end.html#libraries-for-backend-deployment","title":"Libraries for Backend Deployment","text":"<p>There are several libraries available that can help you deploy your AI models on the backend. These libraries provide tools and functionalities that simplify the process of setting up and managing your backend infrastructure.</p> <ul> <li> <p>FlexFlow: A low-latency, high-performance LLM serving library.</p> </li> <li> <p>llm: A CLI utility and Python library for interacting with Large Language Models, including OpenAI, PaLM, and local models installed on your own machine.</p> </li> <li> <p>vLLM: This library utilizes PagedAttention to manage attention keys/values, enabling 24x throughput than other transformers without architecture changes.</p> </li> <li> <p>Text Generation Inference: An open-sourced implementation forked from HF. It is a Rust, Python, and gRPC server for text generation inference.</p> </li> <li> <p>Lit-Gpt: A hackable implementation of state-of-the-art open-source large language models.</p> </li> <li> <p>Torch Serve: This library enables efficient serving of PyTorch models.</p> </li> <li> <p>Triton Inference Server: Part of NVIDIA AI Inference, this server provides a robust solution for deploying AI models.</p> </li> <li> <p>litellm by BerriAI: This library provides code to enable deployments on railway.app.</p> </li> </ul>"},{"location":"Using/deploying/back_end.html#platforms-for-backend-deployment","title":"Platforms for Backend Deployment","text":"<p>Several platforms provide infrastructure and services that can help you deploy your AI models on the backend.</p> <ul> <li> <p>Azure-Chat-GPT: This platform allows you to run GPT on Azure services.</p> </li> <li> <p>Amazon Sagemaker: Part of the AWS suite, Sagemaker allows for streamlined running of AI models in various manners.</p> </li> <li> <p>Lamini: This platform provides tools and services to help you build your AI applications.</p> </li> </ul>"},{"location":"Using/deploying/back_end.html#tutorials","title":"Tutorials","text":"<p>For more hands-on guidance, you can refer to the following tutorials:</p> <ul> <li>GCP Tutorial: This tutorial provides a step-by-step guide on how to deploy large-size deep learning models into production using Google Cloud Platform.</li> </ul>"},{"location":"Using/deploying/computation.html","title":"Computation in AI Deployment","text":"<p>Computation plays a crucial role in the deployment of AI models. It involves various aspects such as latency, load, batching, memory, and other requirements that are necessary to have an effective backend. Understanding these computational aspects can help in optimizing the performance of AI models during deployment.</p>"},{"location":"Using/deploying/computation.html#latency","title":"Latency","text":"<p>Latency refers to the delay before a transfer of data begins following an instruction for its transfer. In AI deployment, low latency is often desirable as it means faster response times.</p>"},{"location":"Using/deploying/computation.html#load","title":"Load","text":"<p>Load refers to the amount of computational work that a computer system can perform. High loads can slow down the system and affect the performance of the AI model.</p>"},{"location":"Using/deploying/computation.html#batching","title":"Batching","text":"<p>Batching is a process of grouping a number of similar tasks together and executing them all at once. In the context of AI, batching can help in improving the efficiency of the model by processing multiple data points at once.</p>"},{"location":"Using/deploying/computation.html#memory","title":"Memory","text":"<p>Memory is a crucial aspect of computation. It is where the data is stored for processing. Adequate memory is necessary for the smooth functioning of AI models.</p>"},{"location":"Using/deploying/computation.html#other-requirements","title":"Other Requirements","text":"<p>There are other requirements as well that are necessary for effective backend. These include a good network connection, sufficient storage space, and a powerful processing unit.</p>"},{"location":"Using/deploying/computation.html#tutorials","title":"Tutorials","text":"<p>For a practical understanding of these concepts, you can refer to the following tutorial:</p> <p>Deploying locally with Ollama</p>"},{"location":"Using/deploying/computation.html#essential-reading-material","title":"Essential Reading Material","text":"<p>Creating models in AI involves large volumes of matrix multiplication. Graphics Processing Units (GPUs) are designed for this purpose as they can process multiple computations simultaneously. For a deeper understanding of how GPUs aid in deep learning, refer to the following resource:</p> <p>Tim Dettmers on GPUs</p> <p>Understanding these computational aspects can help in optimizing the performance of AI models during deployment. It can also aid in making informed decisions about the necessary resources and infrastructure needed for deploying AI models.</p>"},{"location":"Using/deploying/examples_and_tutorials.html","title":"Examples and tutorials","text":""},{"location":"Using/deploying/examples_and_tutorials.html#langchain-focused","title":"Langchain focused.","text":"<p>GPT and PDFS</p>"},{"location":"Using/deploying/frameworks.html","title":"Frameworks","text":"<p>The AI-Cambriatic explosion has led to a surge in services, methods, frameworks, and tools that enhance the creation and deployment of models from start to finish. Although there are end-to-end providers for generating valuable GenAI solutions, there is immense value in implementing and experimenting with your own stacks. </p> <p>Additionally, there are useful libraries and tools worth exploring.</p> <p>tldr; Here are the prominent frameworks</p> <ul> <li>Langchain is an early system with a principled design that allows for extensive applications to be built on top of it. </li> <li>Llama Ecosystem is a community of Llama-focused modelers, based on the Meta model called Llama, Llama-2, and beyond. </li> <li>A number of others.</li> </ul> <p>The rapid development in Generative AI tooling makes it challenging to keep up with the development and deprecation of powerful frameworks and tools. Some of the mentioned references may not be fully completed, or even nascent repos to build their intended purposes (described here). Please let us know if we are missing anything here. </p>"},{"location":"Using/deploying/frameworks.html#frameworks","title":"Frameworks","text":"<p>Starting with base programming languages, increasingly higher-level frameworks enable training and calling of AI models. Higher-level orchestration libraries and platforms allow creating and evaluating chains, agents, and systems that sometimes use visual interfaces. These can often be augmented with various tools/packages/repositories. On top of these involve mostly or all-complete frameworks and platforms that enable nearly complete. </p>"},{"location":"Using/deploying/frameworks.html#base-languages","title":"Base languages","text":"<p>Prominent languages include python, C++/CUDA, and Javascript. Due to its popularity, this project will be python-focused.</p>"},{"location":"Using/deploying/frameworks.html#ai-level-software-libraries","title":"AI-level software libraries","text":"<ul> <li>PyTorch is a popular python-focused system for creating and using AI.</li> <li>Tensorflow is a popular multi-language eco-system for creating and using AI.</li> <li>spAcy is a library for advanced Natural Language Processing in Python and Cython.</li> </ul>"},{"location":"Using/deploying/frameworks.html#apis-based-model-usage","title":"APIs based model usage","text":"<ul> <li>OpenAI</li> </ul>"},{"location":"Using/deploying/frameworks.html#interaction-and-orchestration-frameworks-and-languages","title":"Interaction and Orchestration Frameworks and Languages","text":"<p>Handling the inputs/outputs to GenAI in a consistent and reliable manner has spurred the creation of software libraries that can work with GenAI that is called as a service, or hosted locally.</p>"},{"location":"Using/deploying/frameworks.html#langchain","title":"LangChain","text":"<p>Langchain Is a thorough python and javascript orchestration language for adaptable, memory and tooling-equipped calls that can enable agentic AI.</p> <p>LangSErv will provide a hosted version of LangServe for one-click deployments of LangChain applications.</p> <p>OpenGPTs Provides an open-source effort to integrate multiple LLMs, and builds upon Langchain, LangServe, and LangSmith</p> <p>Their Stack</p> <p></p> <p>They are building Lang Smith for more Low-code solutions for agentic needs.</p> <ul> <li>Langchain service deployment</li> <li>Awesome Langchain</li> <li>Langflow </li> <li>Toolkit Generates LangChain plugins for javascript. May be deprecated. </li> </ul> <p>Tutorials:</p> <ul> <li>https://www.pinecone.io/learn/langchain-prompt-templates/</li> <li>https://learn.deeplearning.ai/langchain/lesson/3/memory</li> </ul>"},{"location":"Using/deploying/frameworks.html#llama-ecosystem","title":"Llama ecosystem","text":"<p>Llamaindex Provides an orchestration framework for with multiple connectors</p> <p>Llama Lab enables flexible tools to use and indesx various tools</p> <p>Llama is a library and set of models that has an expanding community due to the generally open-source nature of high-quality Llama 2 model.</p> Code and models surrounding Llama <ul> <li>LlamaGPT A self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device.</li> <li>Lit-Llama</li> <li>MedAlpaca</li> <li>Llama-2 on a CPU and Github</li> <li>GPT LLM Training Generates and trains fine-tuned LLAMA-2 LLMs for specific tasks. </li> <li>llama index and Github for integrating data ingestion and models. </li> <li>LlamaHub (community library of data loaders)</li> <li>LlamaLab (cutting-edge AGI projects using LlamaIndex)</li> <li>Ollama.ai Provides on mac silicon Llama2 calling. Has a great idea that resembles docker files for agent creation and pulling.</li> <li>Running Llama 2 and other Open-Source LLMs on CPU Inference Locally for Document Q&amp;A</li> <li>Llama.cpp 4 bit llama on macbooks. </li> </ul>"},{"location":"Using/deploying/frameworks.html#haystack","title":"Haystack","text":"<p>Haystack is an e2e llm orchestration framework that allows a number of versatile interactions.</p>"},{"location":"Using/deploying/frameworks.html#higher-level","title":"Higher level","text":"Pytorch Lightning Enables model training with Pytorch and minimizes the boilerplate <p>Model parallelism</p> Deep Speed (by MSFT) empowers ChatGPT-like model training with a single click, offering 15x speedup over SOTA RLHF systems with unprecedented cost reduction at all scales <p>Blog on Deepspeed Ulysses </p> <p>DeepSpeed-Ulysses uses a simple, portable, and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence lengths \"DeepSpeed-Ulysses partitions individual samples along the sequence dimension among participating GPU. Then right before the attention computation, it employs all-to-all communication collective on the partitioned queries, keys and values such that each GPU receives the full sequence but only for a non-overlapping subset of the attention heads. This allows the participating GPUs to compute attention for different attention heads in parallel. Finally, DeepSpeed-Ulysses employs another all-to-all to gather the results along the attention heads while re-partitioning along the sequence dimension.\"  Tutorial here</p>"},{"location":"Using/deploying/frameworks.html#fine-tuning","title":"Fine Tuning","text":"<p>LLM Finetuning Hub is an evolving model finetuning codebase. </p>"},{"location":"Using/deploying/frameworks.html#others","title":"Others","text":"EmbedChain  is a framework to easily create LLM powered bots over any dataset. <p>Example: <pre><code>    import os\n\n    from embedchain import Llama2App\n\n    os.environ['REPLICATE_API_TOKEN'] = \"REPLICATE API TOKEN\"\n\n    zuck_bot = Llama2App()\n\n    # Embed your data\n    zuck_bot.add(\"youtube_video\", \"https://www.youtube.com/watch?v=Ff4fRgnuFgQ\")\n    zuck_bot.add(\"web_page\", \"https://en.wikipedia.org/wiki/Mark_Zuckerberg\")\n\n    # Nice, your bot is ready now. Start asking questions to your bot.\n    zuck_bot.query(\"Who is Mark Zuckerberg?\")\n    # Answer: Mark Zuckerberg is an American internet entrepreneur and business magnate. He is the co-founder and CEO of Facebook. \n</code></pre></p> txtai 'is an all-in-one embeddings database for semantic search, LLM orchestration and language model workflows. <p></p> <ul> <li>Flowise</li> <li>Chain Forge A data flow prompt engineering environment for evaluating ana analyzing LLM responses</li> <li>llm-chain ChatGPT and Alpaca support. Agentic with bash commands.</li> <li>Agent Flow</li> <li>Auto Chain</li> <li>Chatall To interact with multiple chatbots at the same time.</li> <li>LocalAI drop-in replacement REST API that\u2019s compatible with OpenAI API specifications for local inferencing.</li> </ul> <p>Open Agent IN DEVELOPMENT Microservices approach to AGI. Modular components for AI apps or AGI agents</p> DSPY is a framework for solving advanced tasks with language models and retrieval models <p>Useful for exploring automatic prompt opteimization. </p>"},{"location":"Using/deploying/frameworks.html#language-like-interfaces","title":"Language-like interfaces","text":"LMQL is a query language that enables simplified representations of chats and agents with minimal code.  <pre><code>\"Greet LMQL:[GREETINGS]\\n\" where stops_at(GREETINGS, \".\") and not \"\\n\" in GREETINGS\n\nif \"Hi there\" in GREETINGS:\n    \"Can you reformulate your greeting in the speech of \\\n     victorian-era English: [VIC_GREETINGS]\\n\" where stops_at(VIC_GREETINGS, \".\")\n\n\"Analyse what part of this response makes it typically victorian:\\n\"\n\nfor i in range(4):\n    \"-[THOUGHT]\\n\" where stops_at(THOUGHT, \".\")\n\n\"To summarize:[SUMMARY]\"\n</code></pre>"},{"location":"Using/deploying/frameworks.html#control-libraries","title":"Control libraries","text":"<ul> <li>Guidance</li> <li>RELM</li> <li>Outlines</li> </ul>"},{"location":"Using/deploying/frameworks.html#retrieval-augmentation-focus","title":"Retrieval Augmentation focus","text":"<p>RAGAS is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines</p>"},{"location":"Using/deploying/front_end.html","title":"Front end","text":"<p>Deploying AI technologies involves a variety of steps, one of which is understanding your visualization needs and implementing effective front ends. This is a crucial aspect as it enables users to interact with the technology in a user-friendly and intuitive manner.</p>"},{"location":"Using/deploying/front_end.html#understanding-visualization-needs","title":"Understanding Visualization Needs","text":"<p>The first step towards creating an effective front end is understanding your visualization needs. This process involves identifying the key data points and processes that need to be visualized and determining the most effective way to present this information to the user. </p> <p>In addition, it's important to identify the simplest possible result for your end users. This means understanding your audience and presenting the information in a logical format that is easy for them to comprehend.</p>"},{"location":"Using/deploying/front_end.html#implementing-the-front-end","title":"Implementing the Front End","text":"<p>Once you have a clear understanding of your visualization needs, the next step is to implement the front end. For AI technologies such as GPT, it's essential to have well-designed access points. These access points, or user interfaces, allow users to interact with the technology.</p>"},{"location":"Using/deploying/front_end.html#popular-repositories-for-front-end-implementation","title":"Popular Repositories for Front End Implementation","text":"<p>There are several popular repositories that can serve as a starting point for your product. These include:</p> <ul> <li>OobaBooga Text generation WebUI: This is a user-friendly interface for text generation.</li> <li>Streamlit: This platform allows you to build machine learning and data science apps.</li> <li>DemoGPT: This tool connects Langchain and Streamlit to create dynamic apps that can be used repeatedly for interacting with Chat-GPTs. </li> <li>GPT Graph: This tool allows for a graphical network representation of chat interactions. </li> </ul> <p>By understanding your visualization needs and implementing an effective front end, you can ensure that your users have a smooth and intuitive experience when interacting with your AI technology.</p>"},{"location":"Using/deploying/libraries_and_tools.html","title":"Deploying Libraries and Tools","text":"<p>This document provides an overview of various libraries and tools that can be used for deploying AI models. It is divided into several sections, each focusing on a specific aspect of deployment. The sections include LLM Ops, Models, Finetuning, Serving, Programming Convenience, Memory Interaction, Executors and Interpreters, Data Creation, and General.</p>"},{"location":"Using/deploying/libraries_and_tools.html#llm-ops","title":"LLM Ops","text":"<p>LLM Ops refers to operations related to Large Language Models. Here are a couple of tools that can assist in managing these operations:</p> <ul> <li>LLM Ops: This is a Microsoft tool for managing large language models.</li> <li>Reliable GPT: This is a wrapper that prevents failures due to rate limiting requests.</li> </ul>"},{"location":"Using/deploying/libraries_and_tools.html#models","title":"Models","text":"<p>This section provides a selection of repositories that enable the creation of models:</p> <ul> <li>Hugging Face Transformers: This is a popular library for creating transformer models.</li> </ul>"},{"location":"Using/deploying/libraries_and_tools.html#finetuning","title":"Finetuning","text":"<p>Finetuning is the process of adapting a pre-trained model to a specific task. For more in-depth information on this, please see the finetuning page. Here are some tools for finetuning:</p> <ul> <li>Adapters for Hugging Face: This is a tool for finetuning Hugging Face models.</li> <li>Chatall: This tool allows interaction with multiple chatbots at the same time.</li> <li>LocalAI: This is a drop-in replacement REST API that\u2019s compatible with OpenAI API specifications for local inferencing.</li> </ul> Tool Bench 'This project (ToolLLM) aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerful LLMs with general tool-use capability.' <p></p>"},{"location":"Using/deploying/libraries_and_tools.html#serving","title":"Serving","text":"<p>Open LLM to run inference with any open-source large-language models, deploy to the cloud or on-premises, and build powerful AI apps.</p>"},{"location":"Using/deploying/libraries_and_tools.html#distributed","title":"Distributed","text":"Petals Run large language models at home, BitTorrent-style. <p>Generate text with distributed LLaMA 2 (70B), Stable Beluga 2, Guanaco-65B or BLOOM-176B and fine\u2011tune them for your own tasks \u2014 right from your desktop computer or Google Cola Launch your own swarm</p>"},{"location":"Using/deploying/libraries_and_tools.html#programming-convenience","title":"Programming Convenience","text":"Magentic for decorators <p>A nice and simple plugin that allows a <code>@prompt</code> decorator to call functions as an llm, including function-choice calls. Their example](https://github.com/jackmpcollins/magentic) <pre><code>from typing import Literal\n\nfrom magentic import prompt, FunctionCall\n\n\ndef activate_oven(temperature: int, mode: Literal[\"broil\", \"bake\", \"roast\"]) -&gt; str:\n    \"\"\"Turn the oven on with the provided settings.\"\"\"\n    return f\"Preheating to {temperature} F with mode {mode}\"\n\n\n@prompt(\n    \"Prepare the oven so I can make {food}\",\n    functions=[activate_oven],\n)\ndef configure_oven(food: str) -&gt; FunctionCall[str]:\n    ...\n\n\noutput = configure_oven(\"cookies!\")\n# FunctionCall(&lt;function activate_oven at 0x1105a6200&gt;, temperature=350, mode='bake')\noutput()\n# 'Preheating to 350 F with mode bake'\n</code></pre></p>"},{"location":"Using/deploying/libraries_and_tools.html#memory-interaction","title":"Memory Interaction","text":"<p>Deploying on Azure for Embeddings</p> <p>Integrating with Azure Services</p> <p>GPTCache to quickly Cache your results to speed second-time queries.</p> <p>AGent Smith AI makes it easy to instantiate AI agents that can safely and easily call APIs and locally defined functions to interact with the world.</p> <p>Monarch Assistant Uses AGent Smith for RAG purposes</p> <p>Curage GPT</p>"},{"location":"Using/deploying/libraries_and_tools.html#executors-and-interpeters","title":"Executors and Interpeters","text":"<p>Executors are programming levels of abstraction that encourage the execution of any tools or intractions with internal and external memories and states. </p> <p>Interpreters are executors that facilitate model computation by parsing, formatting, or otherwise preparing the data for effective use. They can also be used to interpret output to perform routing of actions. </p> <p>Such efforts can be used to reduce input complexity, token-count, to detect potentially unreasonable inputs or outputs. These interpreters may be agents or models themselves, thought that is not required. </p> <p>Link Routing</p> <p>A model may not be guaranteed to produce equivalent output based on a complex input string such as an html address. Consequently, pre-parsing the output and substituting a simple name for an address, such as 'html_1', and then re-introducing that within any output, both using RegEx, may enable more effective output. </p> <p>Guardrails To help format output and prevent improper prompts.</p> <p>Semantic Kernel</p> <p>Github, </p> <p>\ufe0fGuidance Interleaving generation, prompting and logical control to single  continuous flow.</p>"},{"location":"Using/deploying/libraries_and_tools.html#data-creation","title":"Data Creation","text":"<p>Generative AI is a splendid use-case for creating data that can be used to train or refine new models. Here are some tools that allow for creation of data for down-stream purposes, always being sure to be consistent with dual-use concerns.</p> <p>AutoLabel A nice pythonic system for generating semantic labels repeatedly for use in downstream datasets</p> <p>Kor For extracting structured data using LLMs.</p>"},{"location":"Using/deploying/libraries_and_tools.html#general","title":"General","text":""},{"location":"Using/deploying/libraries_and_tools.html#network-visualization","title":"Network Visualization","text":"<p>Being able to see the 'structure' of some neural networks make it easier to understand, and more aesthetic.  Please see PlotNeuralNet and a nice writeup on how to use it. </p>"},{"location":"Using/ethically/index.html","title":"Ethically","text":"<p>Be sure to consider the unintended consequences.</p> <ul> <li>Sundar Pichai, Google's CEO</li> </ul>"},{"location":"Using/ethically/index.html#bias-and-fairness","title":"Bias and Fairness","text":"<p>Mitigating bias in data and models Evaluating model fairness Inclusive model development Transparency and Explainability</p>"},{"location":"Using/ethically/index.html#interpretability","title":"Interpretability","text":"<p>Techniques for explainability Right to explanation Safety</p>"},{"location":"Using/ethically/index.html#risk-mitigation","title":"Risk Mitigation","text":"<p>Risk assessment Safeguards against misuse Privacy</p>"},{"location":"Using/ethically/index.html#data-privacy","title":"Data privacy","text":"<p>Anonymization and de-identification Encryption and secure computing</p>"},{"location":"Using/ethically/index.html#governance","title":"Governance","text":"<p>Internal auditing processes External oversight Accountability measures Access and Inclusion</p>"},{"location":"Using/ethically/index.html#fair-and-equitable-access","title":"Fair and equitable access","text":"<p>Digital divides Participatory design Compliance</p>"},{"location":"Using/ethically/index.html#laws-and-regulations","title":"Laws and regulations","text":"<p>Responsible development guidelines Ethics review processes</p>"},{"location":"Using/ethically/index.html#to-sort","title":"To sort","text":""},{"location":"Using/ethically/index.html#unlearning","title":"Unlearning","text":"<p>https://github.com/optml-group/unlearn-saliency</p>"},{"location":"Using/ethically/index.html#principles-and-guidelines","title":"Principles and Guidelines","text":"<p>https://www.nature.com/articles/d41586-023-03266-1 </p> <p>Key principles of the living guidelines:</p> <p>First, the summit participants agreed on three key principles for the use of generative AI in research \u2014 accountability, transparency and independent oversight.</p> <p>Accountability. Humans must remain in the loop to evaluate the quality of generated content; for example, to replicate results and identify bias. Although low-risk use of generative AI \u2014 such as summarization or checking grammar and spelling \u2014 can be helpful in scientific research, we advocate that crucial tasks, such as writing manuscripts or peer reviews, should not be fully outsourced to generative AI.</p> <p>Transparency. Researchers and other stakeholders should always disclose their use of generative AI. This increases awareness and allows researchers to study how generative AI might affect research quality or decision-making. In our view, developers of generative AI tools should also be transparent about their inner workings, to allow robust and critical evaluation of these technologies.</p> <p>Independent oversight. External, objective auditing of generative AI tools is needed to ensure that they are of high quality and used ethically. AI is a multibillion-dollar industry; the stakes are too high to rely on self-regulation.</p> OWASP <p>The OWASP Top 10 for Large Language Model Applications project aims to educate developers, designers, architects, managers, and organizations about the potential security risks when deploying and managing Large Language Models (LLMs). The project provides a list of the top 10 most critical vulnerabilities often seen in LLM applications, highlighting their potential impact, ease of exploitation, and prevalence in real-world applications. Examples of vulnerabilities include prompt injections, data leakage, inadequate sandboxing, and unauthorized code execution, among others. The goal is to raise awareness of these vulnerabilities, suggest remediation strategies, and ultimately improve the security posture of LLM applications. You can read our group charter for more information</p>"},{"location":"Using/ethically/alignment.html","title":"Alignment","text":"<p>Raw generative models do not generally produce globally accurate outputs given input prompts. <sup>1</sup> </p> <p>Global alignment </p> <p>Ensuring the output of models are appropriately capable of </p> <ol> <li> <p>We will be describing text-focused models in this discussion though variations can be appropriately considered for other domains and datatypes This is due to the manner of training and next-word-prediction (or more arbitrary masked-word prediction) is probabilistically 'greedy'. Namely, within a sampling of outputs, the next-prediction will be sampled based on their immediate likelihood. To improve the outputs, the models are further refined using various approaches. These approaches 'align' the output to accurately considered\u00a0\u21a9</p> </li> </ol>"},{"location":"Using/ethically/alignment_and_exential_concerns.html","title":"Alignment and exential concerns","text":"<p>There is a notable degree of concern for the potential for Generative, and eventually General AI, to cause harm. The harm can occur either accidentally or to the intentional use of GenAI. </p> <p>There is also self-existential concerns related to GenAI models themselves. This is found due to the potential that when models are trained on data that is produced by other  models, there can be a degradation in performance, known as model collapse. </p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#background","title":"Background","text":""},{"location":"Using/ethically/alignment_and_exential_concerns.html#jail-breaking","title":"Jail breaking","text":""},{"location":"Using/ethically/alignment_and_exential_concerns.html#prompting","title":"Prompting","text":""},{"location":"Using/ethically/alignment_and_exential_concerns.html#fine-tune-compromising","title":"Fine-tune compromising","text":"<p>Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To! reveals that a few adversarial examples can break alignment when finetuned.</p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#alignment-with-people","title":"Alignment with People","text":"<ul> <li>Personal Universes: A Solutiont to the Multi-Agent Value Alignment Problem</li> </ul>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#alignment-with-genai","title":"Alignment with GenAI","text":"<ul> <li>Model Collapse Explained</li> </ul>"},{"location":"Using/ethically/dual_use_concerns.html","title":"Dual use concerns","text":"<p>The potential for AI to generate beneficial results or outcomes is very promising. At the same time, however, AI can be intentionally used for harmful outcomes. Such is known as a dual-use concern.  This has been found in a number of research articles, and quite prominently when working to evaluate the safety of drug discovery</p>"},{"location":"Using/ethically/fairness.html","title":"Fairness","text":""},{"location":"Using/ethically/fairness.html#elements-of-ai-fairness","title":"Elements of AI Fairness","text":"<p>Understanding AI fairness can be complex, but let's break it down into simple, digestible elements.</p>"},{"location":"Using/ethically/fairness.html#1-understanding-bias","title":"1. Understanding Bias","text":"<p>Bias in AI systems comes from various sources. It could be in the data used to train the AI, the design of the AI algorithms, or the ways AI systems are deployed and used. AI fairness, therefore, needs to address these sources of bias.</p> <p>Data Bias: This happens when the data used to train the AI is not representative of the population it will be serving, leading to biased predictions or decisions. An example is if an AI system was trained on data mostly from one demographic group, it might not perform well on other groups.</p> <p>Algorithmic Bias: This is when the algorithms that power AI systems inherently favor one outcome over another. They might do this due to design flaws, biased inputs, or even the optimization goals set by their creators.</p>"},{"location":"Using/ethically/fairness.html#2-fairness-metrics","title":"2. Fairness Metrics","text":"<p>Measuring fairness is a crucial aspect of AI fairness. This involves setting and monitoring fairness metrics that determine how well an AI system is performing in terms of fairness.</p> <p>Disparity Metrics: Measures how an AI's decisions or predictions differ among various demographic groups.</p> <p>Equality Metrics: Measures how equally an AI system treats individuals, regardless of their demographic group.</p>"},{"location":"Using/ethically/fairness.html#3-transparency","title":"3. Transparency","text":"<p>Transparency is about making sure the workings of an AI system are understandable to people. This includes both the technical side (e.g., how the AI's algorithms work) and the practical side (e.g., how decisions made by the AI impact individuals).</p> <p>Explainability: AI systems should be designed to provide explanations about their decisions or predictions. This helps individuals understand how a system came to a certain conclusion.</p> <p>Interpretability: This involves designing AI systems in ways that their workings can be understood by humans, even if they don't have technical expertise in AI.</p>"},{"location":"Using/ethically/fairness.html#4-accountability","title":"4. Accountability","text":"<p>Accountability in AI fairness refers to the obligation of AI system developers and operators to answer for the system's effects on individuals and society.</p> <p>Auditing: Regular checks on an AI system's decisions and performance to ensure it's upholding fairness standards.</p> <p>Redress Mechanisms: Clear pathways for people to challenge decisions made by an AI system, particularly if they believe they've been treated unfairly.</p>"},{"location":"Using/ethically/fairness.html#5-inclusion","title":"5. Inclusion","text":"<p>Inclusion is about making sure AI systems serve all individuals fairly and equitably, regardless of their demographic characteristics.</p> <p>Diversity in Design: This involves ensuring that the teams creating AI systems are diverse, which can help to avoid some forms of bias and make the systems more effective for a wider range of individuals.</p> <p>Accessibility: AI systems should be designed in ways that they can be used and understood by people with varying abilities, languages, and cultural contexts.</p> <p>NOTE: Generated with GPT-4</p>"}]}