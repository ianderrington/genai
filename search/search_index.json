{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"\ud83c\udf89 Welcome to Managing Gen()AI!","text":"<p>Our Mission: Simplify and demystify Gen()AI for making it accessible and understandable, and to increase our ability to manage it. </p> <p>Our open-source project on Managing Generative AI \ud83e\udd16 will help people to stay on top of understanding effectively working with the increasingly complex of world of Generative AI.</p> <p>Why is it called Gen() AI?</p> <p><code>Generative AI</code> creates. So does will <code>General AI</code>. Depending on their definitions there may be notable differences, the overlap ensures that there will be shared characteristics that warrant writing this ambiguously, such as GenAI or Gen()AI. </p>"},{"location":"index.html#whats-inside","title":"\ud83d\udcd8 What's Inside?","text":"<ul> <li>Understanding GenAI: Delve deep into the mechanics, models, and methodologies fo building GenAI.</li> <li>Deploying GenAI: Learn how to build and deploy models.</li> <li>Using GenAI: Where we describe use cases and applications, commercial tools and applications, and the ethics and regulations surrounding GenAI.</li> <li>Managing GenAI: This is the heart of our project, where we describe the tools that we are building to enable quality, and responsible development of this and other AI-projects.</li> </ul>"},{"location":"index.html#genai-explaining-itself","title":"\ud83d\ude80 GenAI Explaining Itself?","text":"<p>One of our ambitious goals is to have this documentation written and updated by GenAI itself. We aim to:</p> <ul> <li>\ud83d\udcdd Set up a base documentation repository that aids in generating self-descriptive content.</li> <li>\ud83d\udd04 Implement an automated merge and build system for a seamless automation and viewing experience.</li> <li>\ud83d\udd01 Create a self-referential models using tools like Langchain to enable its supervised self-improvement via pull-requests and reviews.</li> <li>\ud83d\udd78\ufe0f Catch the greatest new insights and integrate it into a 'living' document that evolves with the time. </li> </ul> <p>We believe in Gen()AI's potential to effecively explain itself even as the technology grows with extreme complexity. </p> <p>If you're as excited as we are and wish to contribute, join us!</p> <p>Contribute</p> <p>Interested in contributing? Check out our guidelines to get started.</p>"},{"location":"Managen.ai/index.html","title":"Managen.ai","text":"<p>Our Mission is to help people to effectively understand, build, use and manage Generative AI.</p> <p>Our Method uses Generative AI itself helping to build the site and keep it up to date.</p> <p>Our success will depend on you helping to guide it to be as self-accurate as possible.</p>"},{"location":"Managen.ai/index.html#welcome-to-managenai","title":"Welcome to Managen.ai,","text":"<p>Working as a relevant information hub, Managing Generative AI will provide an expansive seed that will allow for us to keep up with the rapidly evolving technologies and techniques. </p>"},{"location":"Managen.ai/index.html#how-to-use","title":"How to use","text":"<p>In the section we are now in we discuss the Managen.ai project. If you'd like to start building and using GenAI, we suggest heading over here where you can learn the deep and wide components of building Generative AI, and building with Generative AI. \\ With your Generative AI solutions coming together, we go over effective, responsible, and ethical manners of using the code. </p>"},{"location":"Managen.ai/brainstorming.html","title":"Brainstorming","text":""},{"location":"Managen.ai/brainstorming.html#ideas","title":"Ideas","text":"<p>Ideas are a dime a dozen.</p> <p>But if you don't have one, you won't find a cent.</p> <p>Here are some ideas of things that might be explored particularly in conjunction with this. </p> <ul> <li> <p>A codebase watcher and executor agent for public codebases like in github. This would have a vector database + query  (+ build) system that would allow the code base to be queried and interacted with via 'execution' of various functions.  They would allow for tested execution of external codebases (and functions). Kind of like code interpreter but for not making new code but calling code that is already needed. This would allow code to use other code just as a person would.</p> </li> <li> <p>Ability to create docker images from repos: repo2docker</p> </li> </ul>"},{"location":"Managen.ai/build_plan.html","title":"Build plan","text":"<p>Using Github to organize our understanding of a fluid field is a notable challenge. Because of the acessibility of mkdocs-material it makes it easy to make nice-looking documentaiton, though sometimes without the niceties that could accompany other software systems. </p> <p>Eventually we may shift to other systems (like docusaurus). Before that though, we will be wanting to integrate state-of-the-art updates to understanding while we build our auto-building system. </p>"},{"location":"Managen.ai/build_plan.html#content","title":"Content","text":"<ul> <li>[ ] Improve strructure of everything hello OK Obama</li> <li>[ ] Go through content that is already there read it, summarize it, and make it look better.</li> </ul>"},{"location":"Managen.ai/build_plan.html#generative-building","title":"Generative Building","text":"<ul> <li>[x] Enable simple jupyter-notebook calls to improve documents.<ul> <li>[ ] Ensure all links are preserved.</li> <li>[ ] Enable multiple LLM integration, for instance with Llama on OSX. </li> </ul> </li> <li>[ ] Enable automatic github PRs based on a continuous feedback system (Like Auto-GPT). </li> <li>[ ] Enable vector-databasing and other RAG tools to function, focusing on <ul> <li>[ ] individual github-repositories </li> <li>[ ] linked documents</li> </ul> </li> </ul>"},{"location":"Managen.ai/build_plan.html#visualization","title":"Visualization","text":"<p>We can make this easier to read</p> <ul> <li>[ ] Improve landing page and header bar to be more modern. </li> <li>[ ] Build interactive graph representation of this site that includes summary information. Check this out and the examples</li> <li>[ ] https://melaniewalsh.github.io/Intro-Cultural-Analytics/06-Network-Analysis/02-Making-Network-Viz-with-Bokeh.html</li> <li>[ ] build with https://docusaurus.io/</li> <li>[ ] Integrate example python notebooks and build with https://github.com/outerbounds/nbdoc</li> </ul>"},{"location":"Managen.ai/contributing.html","title":"Contributing","text":"<p>In order to contribute...</p>"},{"location":"Managen.ai/managing.html","title":"Managing","text":"<p>You cannot manage effectively what you do not understand effectively.</p> <p>Thanks for being interested in this project. This relays how we are putting together the components that enable this project to exist.</p>"},{"location":"Managen.ai/requirements.html","title":"Requirements","text":""},{"location":"Managen.ai/requirements.html#general-requirements","title":"General Requirements","text":""},{"location":"Managen.ai/requirements.html#hosting-on-github","title":"Hosting on GitHub","text":"<p>Description: Utilize GitHub for version control, collaboration, and hosting. Priority: 1 Status: Done</p>"},{"location":"Managen.ai/requirements.html#content-clarity-components-and-reach","title":"Content Clarity, components, and Reach","text":"<p>Description: Ensure content is continuously examined for accuracy, clarity, and utility.  Priority: 1 Components:  Viewers can:  - rapidly understand the website's purpose and it's goals. - rapidly derive value from it by having it help them to build/use AI in some effective manner - methods of measuring both of these via feedback.  - Use a rss feed https://guts.github.io/mkdocs-rss-plugin/ - Use mkdocs material blog.</p>"},{"location":"Managen.ai/requirements.html#gen-ai-enablement","title":"Gen-AI enablement","text":"<p>Description:  GenAI will  build this documentation system so that it is adaptive and auto-descriptive . Priority: 2 Components: - Computation framework / methods.  - Ability to represent entire structure, perhaps with RAG  - Provide a testing environment for contributors to test their changes before merging. - File PRs - File Issues - Read Issues - Read referenced links and codebases     - Adherence to codebase Licensing restrictions - Orchestration AI that helps manage the actions above via selecting different GenAI to do the job. - Ability simultaneously work with all linked packages using docker/venvs</p>"},{"location":"Managen.ai/requirements.html#github-actions-integration","title":"GitHub Actions Integration","text":"<p>Description: Use GitHub Actions for automated testing, deployment, and other workflows. Priority: 2 Components:  Use GitHub Actions for automated:</p> <ul> <li>Build on merge to main</li> <li>Trigger building of file/database structure</li> <li>Trigger AI-analysis of new content</li> </ul>"},{"location":"Managen.ai/requirements.html#community-building-and-integration","title":"Community Building and Integration","text":"<p>Description: Use GitHub Discussions or similar tools for collaboration and community engagement. Priority: 1 Components: - Recruit - GitHub Discussions Integration - Discord / slack</p>"},{"location":"Managen.ai/requirements.html#contributer-enablement","title":"Contributer Enablement","text":"<p>Description: Provide detailed guidelines for contributors to ensure consistency and quality. Priority: 3 Components: - Clear Contribution Guidelines - Implement a system to recognize and reward active and valuable contributors. - Offer training sessions or materials for new contributors to get acquainted with the system.  </p>"},{"location":"Managen.ai/requirements.html#feedback-mechanism","title":"Feedback Mechanism","text":"<p>Description: Implement a system for users to provide feedback on content and usability. Priority: 3 Components:  - Potential open source option https://giscus.vercel.app/</p>"},{"location":"Managen.ai/requirements.html#automated-content-updates","title":"Automated Content Updates","text":"<p>Description: Linked repositories may change/update and any internally referenced information needs to be updated appropriately. Priority: 7</p>"},{"location":"Managen.ai/requirements.html#automated-pr-creation-for-link-submission","title":"Automated PR Creation for Link Submission","text":"<p>Description: Implement a system where contributors can submit links or content, which then automatically creates a PR. Priority: 4</p>"},{"location":"Managen.ai/requirements.html#visual-aids","title":"Visual Aids","text":"<p>Description: Incorporate diagrams, infographics, and other visual aids to enhance understanding. Priority: 5 Components: - Use mkdocs mermaid diagramming to outline pieces in an effective manner for people to follow - Use infographics enabled by mkdocs</p>"},{"location":"Managen.ai/requirements.html#user-friendly-navigation","title":"User-friendly Navigation","text":"<p>Description: Implement an intuitive navigation system with a search feature. Priority: 5 Components:  - Include breadcrumb navigation for users to track their location within the site. - A graphical network diagram for the different topics allowing ease of understanding</p>"},{"location":"Managen.ai/requirements.html#modern-looking-design-and-compatibility","title":"Modern looking design and compatibility","text":"<p>Description: The website needs to look good and functional Priority: 5 Components: - Improved landing page - Mobile Responsiveness</p>"},{"location":"Managen.ai/requirements.html#analytics-and-visualization-integration","title":"Analytics and Visualization Integration","text":"<p>Description: Integrate Google site analytics ad github star/following tracking to be more visible Priority: 8</p>"},{"location":"Managen.ai/requirements.html#advanced-education-tools","title":"Advanced education tools","text":"<p>Description: Include a glossary for technical terms and jargon. Priority: 9 Components -  Incorporate interactive elements like quizzes or simulations for engaging learning experiences.  </p>"},{"location":"Managen.ai/requirements.html#content-adaptability","title":"Content Adaptability","text":"<p>Description: Allow for different named versions of the website to be generated with different degrees of complexity, using mkdocs versioning plugins. Priority: 10</p>"},{"location":"Understanding/index.html","title":"Understand and build","text":"<p>tl;dr</p> <ul> <li>Evaluate your application and think of the challenges associated with it</li> <li>Understand the data and collect data that you need.</li> <li>Understandand build use pre-trained models.</li> <li>Deploy your model</li> <li>Manage your model</li> </ul> <p>Generative Artificial Intelligence, and related General AI and General Super AI are components of what already is and may be the future of intelligence and computing. We must effectively manage these technologies to use them to their highest potential. </p> <p>To manage these technologies effectively and responsibly we must understand them. That is a complex task, especially given the speed at which we are generating novel insights, new discoveries, backed by increasingly powerful hardware. </p> <p>That is why we created Mana Gen AI. </p> <p>Here we focus on Generative AI, knowing various and changing definitions of these domains have a degree of overlap. With time and support we will be able to help many people understand the technology, lest it become a magician's tool. </p> <p>Any sufficiently advanced technology is indistinguishable from magic.</p> <ul> <li>Arthur C. Clark</li> </ul> <p>In the documents you read here, you will be able to see an increseasingly consistent and understandable discussion of Gen()AI technologies, enabled by Gen()AI technologies herein described.  Like most powerful technology, Gen()AI can be a two edged sword and effective use requires responsible and thoughtful understanding. </p>"},{"location":"Understanding/index.html#the-base-components-of-genai","title":"The base components of Gen()AI","text":"<p>If you are new to this area, you may briefly peruse applications and challenges associated with Gen()AI. </p> <p>Getting into it, you will find the following outline: </p>"},{"location":"Understanding/index.html#whats-been-done-with-genai","title":"What's been done with Gen()AI?","text":"<ol> <li>Data provides the backbone connecting computation to our recorded reality.</li> <li>Models allow the data to be understood and used. [^n1]</li> <li>Prompts govern how we interact with the models.</li> <li>Agents allow for models to be used in more useful, effective, and complex manners.</li> <li>Ethical concerns help us to temper the responsible use of these powerful technologies.</li> <li>Studies help us to understand Gen()AI from an experimental and theoretical basis.  i</li> </ol>"},{"location":"Understanding/index.html#how-do-you-do-stuff-with-genai","title":"How do you do stuff with Gen()AI?","text":"<p>Of course, there will be some important 'how-to's, particularly in the data, models, prompts and agents. </p> <p>Competition is fierce to create the 'best' (based on certain metrics) Gen()AI, so much knowledge may not be known to protect IP and other secrets.</p> <p>Still, these trained foundation models may be used, with varying degrees of open-source licensing, for your project. Open and closed-source pre-trained models are available in many places that can be used hosted by yourself, or enabled by API services. Because of the cost and challenge involved with creating these models, it will likely be necessary to use the ones already made. </p> <p>If you are working on commercial projects, be sure to look at the Licenses to ensure you are legally compliant. </p> <p>And please, whatever you do, be cognisant of the ethical concerns</p>"},{"location":"Understanding/index.html#useful-references","title":"Useful References","text":"<p>There is so much quality material, it would be valuable for your time to check some of these out if you got the chance. </p> LLM Patterns An impressively thorough and well-written discussion on LLMs and patterns within them <p>Important patterns mentioned (references to discussions herein): * Evaluating and comparing * Retreival Augmented Generation (RAG) * Fine tuning * Caching to reduce latency.  * Guardrails to ensure output (and input) quality. * Data Flywheel to use data collection and feedback to improve model and experience * Cascade Breaking models up into smaller simpler tasks instead of big ones. * Monitoring to ensure value is being derived * Effective (defensive) UX to ensure the models can be used well.  </p> <ul> <li>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </li> <li>A cookbook of self-supervised Learning </li> <li>LLM Survey</li> <li>Large Language Models Explained</li> </ul> <p>Generative AI is a subset of machine learning that aim to creates new data samples or information based on an input. This technology has gained significant attention recently because they have been able to produce produce high-quality, realistic data across various domains, from images and videos to text and audio.</p> <p>A little more advanced</p> <ul> <li>Use Agents for increasingly powerful applications</li> <li>Optimize your model performance and serving</li> </ul> <p>In this section, we will focus on 'Understanding' the various components of GenAI, data, models and agents including methods and models that are initial or under development. </p> <p>Presentation bias</p> <p>This is presently highly transformer-based large-language models because language is presently more versatile than other modalities. Other models are discussed here. Many other techniques and technologies may not have entered into this yet. If you'd like to help us build this right, please consider contributing</p>"},{"location":"Understanding/agents/index.html","title":"Agents Gen(erative) AI","text":"<p>Agents in Gen()AI agents have access to 'tools' to provide them 'agency' beyond the ability to generate text or image based responses to the input data.</p> <p>Similar to bots, or other computerized automota, they may have the ability to run discretely, separately from standard chat-interfaces. Generally they involve the possibility of Human-in-the-loop to help correct odd components. </p>"},{"location":"Understanding/agents/index.html#basic-concepts","title":"Basic Concepts","text":"<ul> <li>Models: The 'intelligent' component returns an output for a given input. </li> <li>Input environments that can and do provide inputs. </li> <li>Language prompts that orient's and agent's response. </li> <li>Memory to enable writing and reading information that may be of use. </li> <li>Tools that enable more than text (or images) to be returned or otherwise acted upon. </li> <li>Interpreters that are used to process input or output. </li> <li>Chains which enable continuous flow of information, including memory, to downstream tasks. </li> <li>Agents can be quite different! Here are some examples of agents made both in academic and commercial settings. </li> <li>Systems of Agents that can allow for multiple agents with different sets of the components above, to interact and create powerful solutions.</li> </ul>"},{"location":"Understanding/agents/index.html#essential-references","title":"Essential references","text":"<p>Before we go on, there are several references that are of high merit that you may wish to check out!!!</p> <ul> <li>Agents overview by Lilian Weng As usual, a splendid post by Lilian Weng</li> <li>Awesome Agents of nicely curated list of systems using agents</li> </ul>"},{"location":"Understanding/agents/index.html#models","title":"Models","text":"<p>Models provide the computational core of Agents. Acting like a 'brain' that a takes in input prompts they return outputs. Generally the models may be considered <code>frozen</code> for a given agent, but sometimes, agentic feedback is used for helping model creation with recurrent training.</p> <p>Here you can learn how to build models, though it is often easier to use pre-trained models. </p>"},{"location":"Understanding/agents/index.html#prompts","title":"Prompts","text":"<p>Garbage In \u2192 Garbage Out</p> <p>The common realization that bad input will lead to bad outputs becomes more nuanced when considering the degree to which small changes in input prompts can lead to wildly different outcome performance. Consequently, well-chosen prompts can functionally enable an agent, or not. </p> <p>Because of the importance and breadth of details involved with prompting, please visit this section. Note, that prompts will be model-specific, and if the model changes, either completely or with new architecture, the continued performance of a given prompt or prompt strategy is not certain. </p>"},{"location":"Understanding/agents/index.html#memory","title":"Memory","text":"<p>Like people, agents can be better enabled when they have access to memory.  We discuss memory thoroughly here.</p>"},{"location":"Understanding/agents/index.html#tools","title":"Tools","text":""},{"location":"Understanding/agents/index.html#interpreters","title":"Interpreters","text":"<p>Both the input and output into an LLM model may be intepreted, or otherwise parsed in a manner that makes the input or output more impactful. </p> <ul> <li>Native function calls and json support with OpenAI </li> </ul>"},{"location":"Understanding/agents/index.html#systems","title":"Systems","text":"<p>Generative AI systems involve the interaction of multiple individual GenAI elements that can act, to a coordinated degree, independently of other AI Agents. </p>"},{"location":"Understanding/agents/index.html#to-organize","title":"TO ORGANIZE","text":"<ul> <li>This</li> </ul>"},{"location":"Understanding/agents/actions_and_tools.html","title":"Actions and tools","text":""},{"location":"Understanding/agents/actions_and_tools.html#action","title":"Action","text":"<p>Actions may be be internal or externally focused.  focused generally related to an agent's '<code>memory</code>, or externally focused, with tools, though their distinction may be moot. </p> <p>Internal actions generally relate reading, writing or updating, an agents memory, memory state, such as free-text <code>scratech-pad</code>, an ordered <code>memory-log</code> or a vector database.</p> <p>External actions may be to act on simulated or real environments, or otherwise tracked <code>state</code>, or to use a toolthat an agent may be 'equipped with' to run. These can be API calls or local function calls. </p>"},{"location":"Understanding/agents/actions_and_tools.html#executors","title":"Executors","text":"<p>The action that an agent may take is enabled by an <code>AgentExecutor</code> or interpreter of the LLM output, that coordinates the call to perform the action. </p> <p>Langchain Agent Executor</p>"},{"location":"Understanding/agents/actions_and_tools.html#tools","title":"Tools","text":"<p>Tools generally consist of single function calls to something that will return value to the end-point destination, be that the agent itself or a person interacting with an agent. </p>"},{"location":"Understanding/agents/actions_and_tools.html#toolkits","title":"Toolkits","text":"<p>Toolkits consist of tool pearings that often work together well. For instance, bash commands for file creation, deletion, naming and movement. Toolkits can be api-calls or </p> Langchain Toolkits <p></p> <p>Gorilla A Llama-focused high-quality API calling methods.</p> <p>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models Demonstrates that presenting documentation of tool usage is likely more valuable than providing examples.</p> <p>Tool LLM This describes a novel approach enabling over 16000 API's to be called through an intelligent routing mechanism. Github Uses RapidAPI connector to do so. </p>"},{"location":"Understanding/agents/agents.html","title":"Agents","text":"<p>TODO Traditional RL agents. LLM-enabled agents</p> <p>Grid:</p> <p>Memory Tools</p> <p>https://github.com/timvink/mkdocs-charts-plugin https://vega.github.io/editor/#/examples/vega-lite/point_offset_random</p>"},{"location":"Understanding/agents/chain_optimization.html","title":"Chain optimization","text":"<p>HOW TO OPTIMIZE PARAMETERS. </p> <p>Problems such as Hallucinations can be mitigated through downstream methods of process. </p> A stitch in time saves Nine <p>A process to mitigate model hallucination using RAG.  </p>"},{"location":"Understanding/agents/chains.html","title":"Chains","text":"<p>Language models produce outputs based on their model and input prompts. Chains allow for richer and more valuable outputs by connecting inputs + outputs with other components. These components may process GenAI output, enable the execution of actions and tools, and interact with memory. Chains can be used to build more complex and integrated systems to enable higher-quality reasoning and results.</p> <p>Because of their nature, chains can be constructed in a more basic, linear fashion - as in the case of the LLM-enabled chats. They can also be constructed more generally with parallel GenAI calls, resulting in graph chains of varying complexity, which have been shown to increase performance further. </p> <p>Each call to GenAI may be considered a chain node with constant parameters, such as prompt templates, and variable parameters that are governed by external functions (including other chain/GenAI calls). </p> <p>Both basic and graph can rely on thought systems that further improve their performance by using specific prompts that are separated in different calls or combined in a singular prompt, that guide GenAI chained outputs and inputs. </p>"},{"location":"Understanding/agents/chains.html#basic-chains","title":"Basic Chains","text":"<p>Input to a chain node may be passed directly, embedded into a prompt template, and/or processed with traditional algorithms, like regular expressions, and augmented with memory before being processed by the GenAI. </p>"},{"location":"Understanding/agents/chains.html#prompt-templates","title":"Prompt templates","text":"<p>The prompt templates are an unresolved string that is completed before passing to a GenAI request.  Basic templates codify general prompt-engineering patterns to lead to the more desired outputs.</p>"},{"location":"Understanding/agents/chains.html#thought-systems","title":"Thought Systems","text":"<p>Thought systems are chain patterns used by single agents and systems to enable more robust responses.  They can be executed programmatically given frameworks or sometimes done manually in a chat setting. </p> <p>Here are some known thought structures that are improving agentic output.</p> Chain-of-Thought Prompting Elicits Reasoning in Large Language Models <p></p>"},{"location":"Understanding/agents/chains.html#recursive","title":"Recursive","text":"Teaching Large Language Models to Self-Debug <code>transcoder</code> <p>Coding focused LLM system to continuously improve self.  </p> Language Models can Solve Computer Tasks Uses Recursive Criticism and Improvement. <p>Website, GitHub  Combining with Chain of Thought it is even better. The method: Plan: Critique, Improve  - Explicit RCI: \"Review your previous answer and find problems with your answer.\" \u2192 \"Based on the problems you found, improve your answer.\" Recursively Criticizes and Improves its output. This sort of prompting outperforms Chain of Thought, and combined it works even better.  </p>"},{"location":"Understanding/agents/chains.html#structural-decomposition","title":"Structural Decomposition","text":"Skeleton of Thought <p>A nice structure that resembles the thoughtful creation of answers allows for parallelization and hence speedup, with comparable or better results in answer generation.  </p> <p>Skeleton prompt template<pre><code>    [User:] You\u2019re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n    Provide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full\n    sentence, each skeleton point should be very short with only 3\u223c5 words. Generally, the skeleton should have 3\u223c10\n    points.\n    Question:\n    What are the typical types of Chinese dishes?\n    Skeleton:\n    1. Dumplings.\n    2. Noodles.\n    3. Dim Sum.\n    4. Hot Pot.\n    5. Wonton.\n    6. Ma Po Tofu.\n    7. Char Siu.\n    8. Fried Rice.\n    Question:\n    What are some practical tips for individuals to reduce their carbon emissions?\n    Skeleton:\n    1. Energy conservation.\n    2. Efficient transportation.\n    3. Home energy efficiency.\n    4. Reduce water consumption.\n    5. Sustainable diet.\n    6. Sustainable travel.\n    Now, please provide the skeleton for the following question.\n    {question}\n    Skeleton:\n    [Assistant:] 1.\n</code></pre> Point expanding prompt template<pre><code>    [User:] You\u2019re responsible for continuing the writing of one and only one point in the overall answer to the following\n    question.\n    {question}\n    The skeleton of the answer is\n    {skeleton}\n    Continue and only continue the writing of point {point index}. Write it **very shortly** in 1\u223c2 sentence and\n    do not continue with other points!\n    [Assistant:] {point index}. {point skeleton}\n</code></pre></p>"},{"location":"Understanding/agents/chains.html#graph-chains","title":"Graph chains","text":"<p>Algorithm of Thoughts A general extension of Chain of Thought, similar to Graph of Thoughts</p> <p></p> <p>Graph of Thoughts Generalizes Chain of Thought, Tree of Thoughts, and similar systems of thought</p> <p></p> Graph of Thought <p>An excellent thought on what next to consider when dealing with knowledge (or other output like information) generation chains. </p> Meta Tree of thought <p></p> Strategic Reasoning with Language Models Uses game trees and observed and inferred beliefs to achieve closer to optimal results.  <p>Powerful to consider for inferred beliefs and interacting in situations where negotiation or games are being played. </p> Large Language Model Guided Tree-of-Thought <p>Github</p> Tree of Thoughts: Deliberate Problem Solving with Large Language Models A method that allows for idea-expansion and selection of the final result output by choosing the best at each stage. <p>The thought flow Github</p> <p>\"Prompts compared\" <pre><code>    standard_prompt = '''\n    Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input}\n    '''\n    cot_prompt = '''\n    Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input}\n\n    Make a plan then write. Your output should be of the following format:\n\n    Plan:\n    Your plan here.\n\n    Passage:\n    Your passage here.\n    '''\n\n    vote_prompt = '''Given an instruction and several choices, decide which choice is most promising. Analyze each choice in detail, then conclude in the last line \"The best choice is {s}\", where s the integer id of the choice.\n    '''\n\n    compare_prompt = '''Briefly analyze the coherency of the following two passages. Conclude in the last line \"The more coherent passage is 1\", \"The more coherent passage is 2\", or \"The two passages are similarly coherent\".\n    '''\n\n    score_prompt = '''Analyze the following passage, then at the last line conclude \"Thus the coherency score is {s}\", where s is an integer from 1 to 10.\n    ''' \n</code></pre></p>"},{"location":"Understanding/agents/chains.html#problem-decomposition","title":"Problem decomposition","text":"<p>Breaking down the input into a divide-and-conquer approach is a valuable approach to more complex requests. Considering separate perspectives, within the same model, or within separate model calls with different prompt-inceptions as in agent systems can improve performance.</p> Question Decomposition Improves the Faithfulness of Model-Generated Reasoning <p> A nice discussion on it</p> Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent Through Multi-person Self-Collaboration <p>Uses a prompt that initiates a group of personas to be used within the same LLM call to facilitate collaborative analysis and creation of the final output. Solid improvement but comparisons to other techniques are potentially uncertain. \"Example prompt\" </p> <p>```python title=\"Trivia writing SPP'</p> <pre><code>spp_prompt = '''When faced with a task, begin by identifying the participants who will contribute to solving the task. Then, initiate a multi-round collaboration process until a final solution is reached. The participants will give critical comments and detailed suggestions whenever necessary.\n\nHere are some examples:\n---\nExample Task 1: Use numbers and basic arithmetic operations (+ - * /) to obtain 24. You need to use all numbers, and each number can only be used once.\nInput: 6 12 1 1\n\nParticipants: AI Assistant (you); Math Expert\n\nStart collaboration!\n\nMath Expert: Let's analyze the task in detail. You need to make sure that you meet the requirement, that you need to use exactly the four numbers (6 12 1 1) to construct 24. To reach 24, you can think of the common divisors of 24 such as 4, 6, 8, 3 and try to construct these first. Also you need to think of potential additions that can reach 24, such as 12 + 12.\nAI Assistant (you): Thanks for the hints! Here's one initial solution: (12 / (1 + 1)) * 6 = 24\nMath Expert: Let's check the answer step by step. (1+1) = 2, (12 / 2) = 6, 6 * 6 = 36 which is not 24! The answer is not correct. Can you fix this by considering other combinations? Please do not make similar mistakes.\nAI Assistant (you): Thanks for pointing out the mistake. Here is a revised solution considering 24 can also be reached by 3 * 8: (6 + 1 + 1) * (12 / 4) = 24.\nMath Expert: Let's first check if the calculation is correct. (6 + 1 + 1) = 8, 12 / 4 = 3, 8 * 3 = 24. The calculation is correct, but you used 6 1 1 12 4 which is not the same as the input 6 12 1 1. Can you avoid using a number that is not part of the input?\nAI Assistant (you): You are right, here is a revised solution considering 24 can be reached by 12 + 12 and without using any additional numbers: 6 * (1 - 1) + 12 = 24.\nMath Expert: Let's check the answer again. 1 - 1 = 0, 6 * 0 = 0, 0 + 12 = 12. I believe you are very close, here is a hint: try to change the \"1 - 1\" to \"1 + 1\".\nAI Assistant (you): Sure, here is the corrected answer:  6 * (1+1) + 12 = 24\nMath Expert: Let's verify the solution. 1 + 1 = 2, 6 * 2 = 12, 12 + 12 = 12. You used 1 1 6 12 which is identical to the input 6 12 1 1. Everything looks good!\n\nFinish collaboration!\n\nFinal answer: 6 * (1 + 1) + 12 = 24\n\n---\n\n'''\n</code></pre> <p>```</p> <p>??? tip Teach LLMs to Personalize \u2013 An Approach inspired by Writing Education</p> <pre><code>&lt;img width=\"531\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/2638d727-8fbd-4fc7-84a0-ae2bc0e8b2ab\"&gt;\n</code></pre>"},{"location":"Understanding/agents/chains.html#constraining-outputs","title":"Constraining outputs","text":"Certified Reasoning with Language models A 'logical guide' tool that an LLM can use. <p>It \" uses constrained decoding to ensure the model will incrementally generate one of the valid outputs.\"   Possible open source implementation here</p> Outlines guides the model generation of next-token logits to guide the generation corresponding to regex / JSON and pydantic schema. compatible with all models. <p>Also provides a way to functionalize templates to separate prompt logic.</p>"},{"location":"Understanding/agents/environments.html","title":"Environments","text":"<p>Environments consist of the information that agents have access too as well as 'what can be done' to influence the environment. An environment sends information that an agent can receive. </p> <p>The origin of the information can be 'a person' or a 'data stream' that is based in real-measurements, or a simulation. </p> <p>A chat-environment</p> <p>In a chat environment the GenAI receives text information from a user and then returns text information that is printed for the user to read.</p> <p>A town simulation</p> <p>In Generative Agents: Interactive Simulacra of Human Behavior A town is simulated to provide observable information and an interaction world with/between other agents. </p> <p>A camera and microphone</p> <p>As may be needed for a robot, a camera, and a microphone provide the inputs for the environment that it exists in. The signals received (and processes) only represent a portion of what might potentially be received. </p> <p>Madrona Game Enging</p>"},{"location":"Understanding/agents/evaluating_and_comparing.html","title":"Evaluating and comparing","text":"<p>Because of potential pitfalls with Generative AI technology, it is essential to evaluate, compare, and test models such that they meet the indendent requirements. </p> <p>Below are some tools that you can use to help with this!</p>"},{"location":"Understanding/agents/evaluating_and_comparing.html#repositories","title":"Repositories","text":"Helm contains code used in the Holistic Evaluation of Language Models project <p>Paper </p> Arthur.ai Bench Bench is a tool for evaluating LLMs for production use cases.  <p></p> <p></p> DeepEval provides a Pythonic way to run offline evaluations on your LLM pipelines <p>\"... so you can launch comfortably into production. The guiding philosophy is a \"Pytest for LLM\" that aims to make productionizing and evaluating LLMs as easy as ensuring all tests pass.\" </p> Auto Evaluator with github to evaluate appropriate components of chains to enable best performance <p></p>"},{"location":"Understanding/agents/evaluation.html","title":"Evaluation","text":"<p>AgentBench: Evaluating LLMs as Agents</p> <p>A comprehensive 8-environment evaluation for different agents from different models. Github</p> Example <p></p>"},{"location":"Understanding/agents/examples.html","title":"Examples","text":"<p>Agent types can be described by direct agentic ability to cause a change in the world.</p>"},{"location":"Understanding/agents/examples.html#text-agent","title":"Text Agent","text":"<p>An agent that can output only language text. Even thought the language can be 'interpreted' into different things, as is done in the environment. </p>"},{"location":"Understanding/agents/examples.html#text-image-agent","title":"Text + Image Agent","text":"<p>An agent that can output </p>"},{"location":"Understanding/agents/examples.html#robotic-agent","title":"Robotic Agent","text":"<p>A robotic agent can control mechanism impacting the mechanical position or other activity of a device. </p> <pre><code>graph TB\n    Agent((Agent)) --&gt;|makes| decision((Decision))\n    decision --&gt;|attempts| action((Action))\n    action --&gt;|passes| execution((Execution))\n    execution --&gt;|affects| environment((Environment))\n    execution --&gt;|generates| agentMemory((Agent's Memory))\n    agentMemory --&gt;|informs and effects| Agent\n    environment --&gt;|provides| observations((Observations))\n    observations --&gt;|informs and effects| Agent\n    execution --&gt;|queries| environment\n    AgentManager((Agent Manager)) --&gt;|affects| execution\n    Agent --&gt; |informs and effects| AgentManager\n    AgentManager --&gt; |informs and effects| Agent</code></pre>"},{"location":"Understanding/agents/examples.html#langchain-focused","title":"Langchain focused.","text":"<p>!!! GPT and PDFS</p>"},{"location":"Understanding/agents/examples.html#agent","title":"Agent","text":"ReAct <ul> <li>Github </li> <li>Effectively Observe, Think, Act, Repeat.</li> </ul> Reflexion: an autonomous agent with dynamic memory and self-reflection an agent with dynamic memory and self-reflection capabilities <p> - Github - Inspired github </p> Learning to Reason and Memorize with Self-Notes Allows model to deviate from input context at any time to reason and take notes <p></p> Large language models as tool makers Github Allows high-quality tools to be reused by more lightweight models. <p></p> CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation <p> </p> smolai https://www.youtube.com/watch?v=zsxyqz6SYp8&amp;t=1s An interesting example Agent-GPT <p>Website \u2192 Doesn't have agency/tools... So it is not good. A fancy wrapper for multi-task planning and execution. Limited at present. </p> AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn <p>Webpage Uses PEIL PLan execute inspect learn.</p> <p>GPT Engineer</p> DevOpsGPT <p><pre><code>Through the above introduction and Demo demonstration, you must be curious about how DevOpsGPT achieves the entire process of automated requirement development in an existing project. Below is a brief overview of the entire process:\n</code></pre> <pre><code>    Clarify requirement documents: Interact with DevOpsGPT to clarify and confirm details in requirement documents.\n    Generate interface documentation: DevOpsGPT can generate interface documentation based on the requirements, facilitating interface design and implementation for developers.\n    Write pseudocode based on existing projects: Analyze existing projects to generate corresponding pseudocode, providing developers with references and starting points.\n    Refine and optimize code functionality: Developers improve and optimize functionality based on the generated code.\n    Continuous integration: Utilize DevOps tools for continuous integration to automate code integration and testing.\n    Software version release: Deploy software versions to the target environment using DevOpsGPT and DevOps tools.\n</code></pre></p> UniversalNER Used ChatGPT to distill much smaller model for a certain domain, for Universal NER models. Cc-by-4-C distribution <p><pre><code>\"Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPT\u2019s capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We will release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation.\"\n</code></pre> https://arxiv.org/pdf/2308.03279.pdf https://github.com/universal-ner/universal-ner</p> <p>!!! tip \ufe0f\"Robo-GPT\"</p>"},{"location":"Understanding/agents/memory.html","title":"Memory","text":"<p>Agent memory is considered a state associated with a llm-call and effects the ability of LLM to respond, thereby helping to enable agentic ability. Memory augmented models enhance the capabilities of language models by ___ to improve their performance and efficiency. TODO: Read trillions of tokens paper. </p>"},{"location":"Understanding/agents/memory.html#memory-considerations","title":"Memory Considerations","text":"<p>Memory plays a crucial role in enhancing the efficiency of information recall and routing for different chains and agent interactions. </p> <p>In systems comprising Agents (and People), conversation buffers may be employed to keep track of information. These buffers, can be 'private',  can facilitate communication between any agents, storing response stacks that include agent-environment interactions.</p> <p>For text-based memory can consist of perfect text record or compressed summaries, that may or may not follow some form of memory-schema.</p> <p>Memory can be pushed (into prompt templates) and requested (based on GET memory requests from an LLM agent). </p>"},{"location":"Understanding/agents/memory.html#uses","title":"Uses","text":""},{"location":"Understanding/agents/memory.html#input-prompt-caching","title":"Input (prompt) Caching","text":"<p>Input caching is a technique that leverages memory to improve response time and efficiency. Instead of generating tokens based on the next input, it uses caching to identify responses that may have already been generated for similar prompts. This significantly enhances the efficiency of repeated queries. However, it may cause issues if the initial response was not satisfactory, as the system would return the same cached response.</p>"},{"location":"Understanding/agents/memory.html#parsed-information-routing","title":"Parsed information routing","text":"<p>Parsed information routing involves directing parsed or processed information to the appropriate destination. This can be particularly useful in systems with multiple agents or complex workflows.</p>"},{"location":"Understanding/agents/memory.html#implementations","title":"Implementations","text":"<p>Memory implementations can be based on memory types serialized and stored in many ways. Semantic searches can happen by looking at similar embeddings. </p> <p>These can be global or private, and structured inside agent classes or inside system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can be in memory and stored on disk or in the cloud. They allow informaion to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p> <p>Memory implementations can vary based on the type of memory used, and how it's serialized and stored. Semantic searches can be performed by comparing embeddings for similarity. These memory systems can be global or private, and can be structured within agent classes or within system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can exist in memory, stored on disk, or in the cloud. They allow information to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p>"},{"location":"Understanding/agents/memory.html#types","title":"Types","text":""},{"location":"Understanding/agents/memory.html#vector-databases","title":"Vector databases","text":"<p>Vector databases, such as Pinecone, Qdrant, Weaviate, Chroma, Faiss, Redis, Milvus, and ScaNN, use embeddings to create query vector databases. These databases allow for efficient semantic searches. </p> <p>!!! example 'Example vector databases'     Please read this for more information  Vector Databases (primer by Pinecone.io)     - https://github.com/Helicone/helicone     - Website Github</p>"},{"location":"Understanding/agents/memory.html#traditional-databases","title":"Traditional databases","text":"<p>Databases that rely on query-languages such as SQL or non-SQL based databases, or even 'csv-type' information stores can be accessed and generated using agents. </p> <p>The models may generate queries that can be executed by by an interpreter, though it is not guaranteed that the queries will be accurate. TODO: Find reference</p> <p>References</p> <p>For more information on memory implementations and caching, refer to the following resources:</p> <ul> <li>Langchain <code>memory</code></li> <li>Langchain <code>llm_caching</code></li> <li>Improving language models by retrieving from trillions of tokens</li> </ul>"},{"location":"Understanding/agents/rag.html","title":"Retrieval-Augmented Generation","text":"<p>Becuase models are expensive to update it can be easier to get information and then feed that into the model. </p>"},{"location":"Understanding/agents/rag.html#todo","title":"TODO","text":""},{"location":"Understanding/agents/systems.html","title":"Systems","text":"<p>When an agent (or model) engages in an interaction with another agent, the result is an agent system. This is achieved by implementing and equipping various agents, and then setting them up so that the output of one is used as the input of the other. Although one may argue that an agent's input can be perceived as another 'tool' where the different agent prompts the action, this argument isn't entirely valid. The reason is that, in most cases, the same considerations apply to all agents but not to all tools. Therefore, we deal with it separately.</p> <p>Binary system (asymmetric calling)</p> <p>In this system, ChatGPT initiates communication with DallE using a prompt. DallE responds by delivering an image. This image is then used in the final response of ChatGPT or returned as-is.</p> <p>Multi-body system (bidirectional calling)</p> <p>This system consists of multiple agents, and they engage in ongoing discussions about their daily activities. They also receive regular updates about their environment. An example of this type of system can be viewed in this paper.</p>"},{"location":"Understanding/agents/systems.html#research","title":"Research","text":"<p>MetaGPT</p> <p>MetaGPT enables different agents to interact and generate meaningful outputs based on varying tasks and personas. It's a reliable partially-formed solution. Check out the code for further knowledge!</p> <p>Self-play GPT</p> <p>This model leverages different game-roles and LLMs to provide feedback on how to optimize the model and facilitate autonomous enhancement during gameplay.</p> <p>Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind</p> <p>In this work, the Theory of Mind (ToM) concept is used to attempt to improve the performance of students. Github</p> Generative Agents: Interactive Simulacra of Human Behavior in a simulated town!!! <p>This paper discusses a simulation involving different agents exhibiting different personalities. The dynamic environment, shared in code can be manipulated by these agents. The paper explores various challenges and proposed solutions including: <pre><code>**Remembering**\n    _Observation Memory_ This is a memory stream that maintains a record of past experiences. These experiences are stored in \"memory objects\", which are described in natural language, and timestamped. The importance of each memory object is determined using metrics such as _recency_, _importance_, and _relevance_. \n    _Reflection Memory_ This memory type allows the agent to generate more abstract thoughts. These thoughts can be included along with reflections. This process is hardcoded to occur when the sum of importance scores exceeds a certain threshold.\n**Planning and Reacting**\n    _Recursive Planning_ In this process, the agent divides the day into chunks of \"goals\", which are further broken down into smaller time frames. The ability to adjust these plans based on interactions is a key feature of this mechanism.\n</code></pre></p> <p>Multi-Agent Collaboration via Reward Attribution Decomposition</p> <p>This work illuminates optimization techniques for multi-agents using distributed reward systems to achieve state-of-the-art performance. It introduces a joint optimization approach that depends on self and interactive terms.</p> <p>Super-AGI</p> <p>Super-AGI is a model that allows multiple agents to function. However, this system doesn't facilitate any communication between the agents.</p> <p>GPT-Bargaining</p> <p>This model applies several iterations to improve negotiation tactics based on external feedback.</p> <p>RL4L Allen ai</p> <p>RL4L AI employs a small critique model to enhance the output from the larger model. It uses a policy gradient to fine-tune the critique model while maintaining reasonable performance gains. Github</p> Showrunner Agents The Showrunner Agents use Large Language Models (LLMs) to generate episodic content. <p>It's a massively creative and multi-faceted process with a great potential. </p> <p>??? tip \"Improving Factuality and Reasoning in Language Models through Multiagent Debate     \"multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer.\"     They tried both concatenation or summarization of other results. Summarization reduces length and improves quality.      <pre><code>    # Debate Length Prompt\n    short_prompt = \"\"\" These are the solutions to the problem from other agents: {other_answers}\n        Based off the opinion of other agents, can you give an updated response . . .\"\"\"\n    long_prompt = \"\"\" These are the solutions to the problem from other agents: {other_answers}\n        Using the opinion of other agents as additional advice, can you give an updated response . . .\"\"\"\n</code></pre> Github</p> <p>??? tip \"Council      Very promising initial creation of networks of agents to create full-fledged teams for output products.      </p>"},{"location":"Understanding/agents/systems.html#open-source-implementations-unpublished","title":"Open Source Implementations (unpublished)","text":"<p>Swarms</p> <p>Very thoughtful next-level systems focusing on large-dimensions of swarms. Very initial stages but has a lot of promise.  Github</p>"},{"location":"Understanding/agents/systems.html#potentially-useful-tools","title":"Potentially useful tools","text":"<p>Nomadproject.io A simple and flexible scheduler and orchestrator to deploy and manage containers and non-containerized applications across on-prem and clouds at scale.</p> <p>Firecracker 'Our mission is to enable secure, multi-tenant, minimal-overhead execution of container and function workloads.'</p>"},{"location":"Understanding/architectures/index.html","title":"Architectures","text":"<p>Here we will discuss the architectural components needed to build Gen()AI models. While it is often useful or essential to use pre-trained models, it is likely that such pre-trained models can be further refined for specific use-cases. </p> <p>tl;dr</p> <ul> <li>Understand self-supervised learning</li> <li>Learn about models</li> <li>Optimize your models</li> </ul>"},{"location":"Understanding/architectures/index.html#background","title":"Background","text":"<p>There is a rich history of Generative AI architectures, which will be shared in future versions of this code. </p> <p>Of primary importance is the manner of model learning, or adapting to the input data. There are several fundamental types of model-updating: supervised learning, unsupervisedlearning, semi-supervised learning, self-supervised learning, reinforcement learning (RL), and combinations of thereof. </p> <p>Presently, the most successful models rely on  foundation models that are trained on large corpora of data in a self-supervised manner. These models can then be refined using supervised, semi-supervised, and/or reinforcement learning techniques. </p> <p>Once built, Gen()AI is generally called with language inputs to create a specifically desired end result.  These inputs, known as prompts will generally be model-specific but may sometimes share commonalities for more optimal usage, which we describe in prompt engineering.</p>"},{"location":"Understanding/architectures/index.html#foundation-models","title":"Foundation Models","text":"<p>Foundation models are large-scale models that are pre-trained with self or semi-supervision on vast amounts of data and can be fine-tuned for specific tasks. These models serve as a foundation or base for various applications, reducing the need to train models from scratch.</p>"},{"location":"Understanding/architectures/index.html#model-learning","title":"Model Learning","text":"<p>There are several fundamental ways that models can 'learn' in relation to how data interacts with the model. </p> To Compress or Not to Compress provides a coherent understanding of different manners of learning in relation to information theory. <p></p>"},{"location":"Understanding/architectures/index.html#self-supervised-learning","title":"Self-supervised learning","text":"<p>Self-supervision amounts to using a single data entry to train a model to predict a portion of the data itself. For instance, a model that is used to predict the next word in a string of text or a model that is used to generate a piece of an image that has been blanked out. This approach has proven to be highly effective, especially for tasks where labeled data is expensive to obtain or otherwise scarce.</p>"},{"location":"Understanding/architectures/index.html#supervised-learning","title":"Supervised learning","text":"<p>Supervised learning is a more traditional ML approach that generally involves predicting the association between an input and an output variable. While generally quite powerful, supervised learning can be limited by the volume and cost of obtaining quality 'labeled' data, where inputs and outputs are associated with a high degree of veracity. </p>"},{"location":"Understanding/architectures/index.html#unsupervised-learning","title":"Unsupervised learning","text":"<p>Unsupervised learning is often used for discovering insights and patterns in the way data is distributed or related. While not directly or consistently used in GenAI systems, it can be valuable for filtering and selecting data. </p>"},{"location":"Understanding/architectures/index.html#reinforcement-learning","title":"Reinforcement learning","text":"<p>Generally originating from game-play and robotics, reinforcement learning offers the capacity for models to interact with a generally more complex environment. When combined with self-supervision, reinforcement learning has proven to be essential to create powerful GPT architectures.</p>"},{"location":"Understanding/architectures/index.html#hybrid-learning-methods","title":"Hybrid learning methods","text":"<p>Hybrid Learning methods combine one or several methods above to enable more successful Generative AI. Semi-supervised learning is a form of hybrid learning where supervised and unsupervised learning are used to produce the final outcome. </p> <p>General Pretrained Transformer models (GPT) work this way by first doing unsupervised prediction. Then some supervised training is provided. Then an RL approach is used to create a loss model using reinforcment Learning with Human Feedback (RLHF) to score multiple potential outputs to provide more effective outputs. </p> <p>Particular types of RLHF, like instruction-training of Instruct GPT enables models to perform effectively. </p> <p></p>"},{"location":"Understanding/architectures/index.html#language-models-and-llms","title":"Language Models and LLMs","text":"<p>Language models (LMs) are a type of generative model trained to predict the next word in a sequence, given the previous words. They capture the statistical properties of language and can generate coherent and contextually relevant sentences.</p> <p>Large Language Models (LLMs) are a subset of language models that are trained on vast amounts of text data. Due to their size and the diversity of data they're trained on, LLMs can understand and generate a wide range of textual content, from prose and poetry to code and beyond. </p>"},{"location":"Understanding/architectures/index.html#gpt-architectures","title":"GPT architectures","text":"<p>Generative AI models are of two general categories: self-supervised, and Externally-supervised, and hybrid models. </p>"},{"location":"Understanding/architectures/index.html#model-classes","title":"Model Classes","text":"<p>Different model classes of models can often be used with multiple types of model learning. Because of their present degree of quality present model Architectures tend to be transformer-based, or diffusion-based, or made from any other sufficently capable AI method. While Generative Adversarial Networks, GANS were the initially most successful, the challenges in training them successfully can be difficult to surmount. Below we describe the model classes in greater detail.</p> <ul> <li>Hybrid models like GPT</li> <li>Transformers</li> <li>Diffusers</li> <li>Generative Adversarial Networks</li> <li>Reinforcement Learning</li> <li>Developing Architectures</li> </ul>"},{"location":"Understanding/architectures/index.html#quality-references","title":"Quality References","text":"<ul> <li>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </li> <li>Understanding Large Language Models</li> <li> What we know about LLMS (primer)</li> <li>Catching up on the weird world of LLMs</li> </ul>"},{"location":"Understanding/architectures/alignment.html","title":"Alignment","text":"<p>Raw generative models do not generally produce globally accurate outputs given input prompts. <sup>1</sup> </p> <p>Global alignment </p> <p>Ensuring the output of models are appropriately capable of </p> <ol> <li> <p>We will be describing text-focused models in this discussion though variations can be appropriately considered for other domains and datatypes This is due to the manner of training and next-word-prediction (or more arbitrary masked-word prediction) is probabilistically 'greedy'. Namely, within a sampling of outputs, the next-prediction will be sampled based on their immediate likelihood. To improve the outputs, the models are further refined using various approaches. These approaches 'align' the output to accurately considered\u00a0\u21a9</p> </li> </ol>"},{"location":"Understanding/architectures/embedding.html","title":"Embedding","text":"<p>Embeddings play a key role in AI as they translate tokens into numerical representation that can be processed by the AI. </p> <p>'What are Embeddings' is an essential read that elucidates the concept of embeddings in a digestible manner. For a deeper dive, check the accompanied Github page.</p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html","title":"Evaluating and comparing","text":"<p>There are many ways that you can evaluate your model, and the manner of evaluation will depend on your use-case. </p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#metrics","title":"Metrics","text":"<ul> <li>Exact Match (EM)  TODO: Finish this</li> </ul> <p>While single-LLM calls are useful to evaluate, comparing and evaluating system-evaluation will likely be essential to ensure successful deployment.</p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#general-discussions","title":"General Discussions","text":"How do we know how smart AI systems are? <p>\u201cAI systems, especially generative language systems like GPT-4, will become increasingly influential in our lives, as will claims about their cognitive capacities. Thus, designing methods to properly assess their intelligence\u2014and associated capabilities and limitations\u2014is an urgent matter. To scientifically evaluate claims of humanlike and even superhuman machine intelligence, we need more transparency on the ways these models are trained, and better experimental methods and benchmarks. Transparency will rely on the development of open-source (rather than closed, commercial) AI models. Better experimental methods and benchmarks will be brought about through collaborations between AI researchers and cognitive scientists who have long investigated how to do robust tests for intelligence, understanding, and other cognitive capabilities in children, animals, and other \u201calien\u201d intelligences.\u201d</p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#evaluation-tools","title":"Evaluation tools","text":"<p>Legal Bench is an ongoing open science effort to collaboratively curate tasks for evaluating LLM legal reasoning in English.</p> <p>The evaluation of models helps us to identify which, if any, model to use for a particular task at hand. Directly related to the manner of pre-training, fine-tuning, and any RLHF, the ways that we consider the output can also be used to improve the models. </p>"},{"location":"Understanding/architectures/evaluating_and_comparing.html#measure-what-matters","title":"Measure what matters","text":""},{"location":"Understanding/architectures/finetuning.html","title":"Finetuning","text":"Open Pipe Use powerful but expensive LLMs to fine-tune smaller and cheaper models suited to your exact needs. Evaluate model and prompt combinations in the playground. Query your past requests and export optimized training data."},{"location":"Understanding/architectures/optimization.html","title":"Optimization","text":"<p>Time is money and the ability to quickly allow your GenAI to create high-performing content is paramount. While related to engineering, there is not a fully settled solution. Here we share an understanding of good ways to make your model generate more efficiently, with minimal loss in quality. </p> <p>While most successful models may use a [combination of approaches(#combination-approaches) there are several methods used to reduce model sizes</p> <ol> <li>Pruning</li> <li>Quantization</li> <li>Knowledge Distillation</li> <li>Low-rank and sparsity approximations</li> <li>Neural Architecture Search (NAS)</li> </ol>"},{"location":"Understanding/architectures/optimization.html#overview","title":"Overview","text":"A Survey on Model Compression for Large Language Models"},{"location":"Understanding/architectures/optimization.html#combination-approaches","title":"Combination Approaches","text":"QLoRA: Efficient Finetuning of Quantized LLms uses Quantization and Low-Rank Adapters to enable SoTA models with even smaller models <p>Paper Example HF 4bit transformers</p>"},{"location":"Understanding/architectures/optimization.html#pruning","title":"Pruning","text":"<p>Eliminate weights that do not produce consistently valuable outputs. </p> Fast as Chita: Neural network pruning with combinatorial optimization <p>Arxiv paper  \"an optimization-based approach for pruning pre-trained neural networks at scale. CHITA (which stands for \u201cCombinatorial Hessian-free Iterative Thresholding Algorithm\u201d) outperforms existing pruning methods in terms of scalability and performance tradeoffs, and it does so by leveraging advances from several fields, including high-dimensional statistics, combinatorial optimization, and neural network pruning.\"  </p>"},{"location":"Understanding/architectures/optimization.html#quantization","title":"Quantization","text":"<p>Reduce the precision of the models from fp32 to fp16, int8, and even binary! </p> <p> Purpose of quantization</p> <p> </p> Quantization summarized image taken from [Advanced Practical Data Science Lecture 9: Compression Techniques and Distillation](https://harvard-iacs.github.io/2020F-AC295/lectures/lecture9/presentation/lecture9.pdf)"},{"location":"Understanding/architectures/optimization.html#examples","title":"Examples","text":"<p>??? code HF bitsandbytes and code     From Github</p>"},{"location":"Understanding/architectures/optimization.html#knowledge-distillation","title":"Knowledge Distillation","text":"<p>Train a new smaller model using the output of bigger models. (TODO) </p> <p>Knowledge Distillation and Compression Demo.ipynb</p>"},{"location":"Understanding/architectures/optimization.html#low-rank-and-sparsity-approximations","title":"Low rank and sparsity approximations","text":"<p>(TODO) </p>"},{"location":"Understanding/architectures/optimization.html#tooling","title":"Tooling","text":"<p>Bitsandbytes by provides a lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions.</p>"},{"location":"Understanding/architectures/pre_trained_models.html","title":"Pre trained models","text":"<p>There are a vast number of both open and closed-source models that can be used. A number of them can be downloaded and run on the appropriate hardware, others may be accessed through APIs. </p> <p>It is essential to compare and evaluate the models for your intended use-cases to ensure they meet technical, customer, and organizational requirements. </p>"},{"location":"Understanding/architectures/pre_trained_models.html#leaderboards-and-comparisons","title":"Leaderboards and comparisons","text":"<p>Here are a few boards that help to aggregate and test models that have been released. </p> <ul> <li>Hugging Face LLM leaderboard An essential chart for documenting the model performance across multiple models.</li> <li>lmsys.org leader board</li> </ul>"},{"location":"Understanding/architectures/pre_trained_models.html#text-oriented","title":"Text Oriented","text":"<p>Here are some notable models </p> <ul> <li>Bard</li> <li>Claud</li> <li>ChatGPT (OpenAI)</li> <li>Medpalm</li> <li>Llama2</li> <li>Llama2 uncensorred</li> <li>TinyLlama</li> <li>Open Llama </li> <li>UAE Falcon </li> <li>Orca (Microsoft) </li> <li>MosaicML</li> <li>LAION-AI An attempted open-source version of ChatGPT\"</li> <li>Unilm (MSFT)</li> <li>GPT4all</li> <li>DoctorGPT LOOK AT THIS</li> </ul>"},{"location":"Understanding/architectures/pre_trained_models.html#image-oriented","title":"Image Oriented","text":"<ul> <li> <p>StableLM: Stability AI Language Models </p> </li> <li> <p>Stable Diffusion</p> </li> </ul>"},{"location":"Understanding/architectures/recurrent_training.html","title":"Recurrent training","text":"<p>Self-Alignment with Instruction Backtranslation</p> <p></p> <p>The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then selecting high quality examples from among these candidates (self-curation). This data is then used to finetune a stronger model. F</p>"},{"location":"Understanding/architectures/reinforcement_feedback.html","title":"Reinforcement feedback","text":"<p>Reinforcement Learning Feedback </p> WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct <p>Llama-2 based reinforcement enables substantial improvement over other models.   Paper</p> Fabic is a technique to incorporate iterative feedback into the generative process of diffusion models based on StableDiffusion. <p>Paper</p>"},{"location":"Understanding/architectures/training.html","title":"Training","text":"<p>Training GenAI will generally be domain/modality specific.</p> <ol> <li>Self-supervised pretraining: Predicts next token. </li> <li>Supervised pretrainign: Trains to give generally expected output.</li> <li>Reinforcement Learning with Human Feedback: Trains a reward model that is used with Proximal Policy Optimization (PPO) to produce aligned output. </li> </ol> <p>Basics: Distributed Training https://neptune.ai/blog/distributed-training-frameworks-and-tools</p> <ul> <li>LLM Engineering by Huyen Chip</li> </ul>"},{"location":"Understanding/architectures/training.html#rlhf","title":"RLHF","text":""},{"location":"Understanding/architectures/training.html#frameworks","title":"Frameworks","text":"<ul> <li>Levanter (not just LLMS)  Codebase for training FMs with JAX. Using Haliax for naming tensors field-names instead of indexes. (for example Batch, Feature....). Full sharding and distributable / parallelizable. </li> <li> <p>DeepSpeed ZeRO++ A framework for accelerating model pre-training, finetuning, RLHF updating.  by minimizing communication overhead. A likely essential concept to be very familiar with. </p> </li> <li> <p>RL4LMs by microsoft A modular RL library to fine-tune language models to human preferences. paper</p> </li> </ul>"},{"location":"Understanding/architectures/training.html#methods-and-improvements","title":"Methods and Improvements","text":""},{"location":"Understanding/architectures/training.html#fine-tuning-using-distillation","title":"Fine Tuning using Distillation","text":"<p>Train on model trains a new model on the output of a new model.  - Alpaca </p>"},{"location":"Understanding/architectures/training.html#fine-tuning-optimizations","title":"Fine tuning Optimizations","text":"<ul> <li>Full Parameter Fine-Tuning for Large Language Models with Limited Resources. Introduces LOMO: LOw-Memory Optimization to fuse </li> </ul>"},{"location":"Understanding/architectures/training.html#adapter-layers","title":"Adapter layers","text":"<ul> <li>AdapterHub: A Framework for Adapting Transformers Website Adapters are efficient and performant layers that can optimize performance without needing to do inefficient fine-tuning. </li> </ul>"},{"location":"Understanding/architectures/training.html#rlhf_1","title":"RLHF","text":"<ul> <li> <p>RLHF: Reinforcement Learning from Human Feedback A splendid summary of the RLHF system. </p> </li> <li> <p>RLHF basics by hugging face A realy good intro to parse again.</p> </li> <li>RLHF for Palm in Pytorch</li> <li>AligningLargeLanguageModelsthroughSyntheticFeedback Using a heirarchy of systems to </li> </ul>"},{"location":"Understanding/architectures/training.html#ai-enabled-ranking","title":"AI-enabled ranking","text":"<ul> <li>Can foundation models label data like humans? using GPT to review model outputs produced biased results. Changing the prompt doesn't really help to de-bias it. Lots of additional considerations surrounding model evaluation</li> </ul>"},{"location":"Understanding/architectures/training.html#mixture-of-experts","title":"Mixture of Experts.","text":"<ul> <li>Scaling Expert Language Models with Unsupervised Domain Discovery \"parse language models on arbitrary text corpora. Our method clusters a corpus into sets of related documents, trains a separate expert language model on each cluster, and combines them in a sparse ensemble for inference. This approach generalizes embarrassingly parallel training by automatically discovering the domains for each expert, and eliminates nearly all the communication overhead of existing sparse language models. \"</li> </ul>"},{"location":"Understanding/architectures/training.html#pruning-and-compression","title":"Pruning and compression","text":"<ul> <li>SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot Remove up to ~50% parameters preserving </li> <li>SqueezeLLM They are able to have 2x fold in model size for equivalent performance in perplexity. They use 'Dense and SParce Quantization' Github</li> </ul>"},{"location":"Understanding/architectures/models/index.html","title":"Models","text":"Llama 2: Open Foundation and Fine-Tuned Chat Models A nearly open source set of 7B-70B models with quality performance Shepherd: A Critic for Language Model Generation A 7B model trained to critique outputs <p>Example chat response </p> Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data Parameter efficient LLama Tuning and risk minimization <p>with a new 'Self Distillation' with Feedback to improve itself even more. RESEARCH ONLY </p> <p>dic&gt;</p>"},{"location":"Understanding/architectures/models/index.html#mixture-of-experts","title":"Mixture of Experts","text":""},{"location":"Understanding/architectures/models/index.html#multi-modal-models","title":"Multi-Modal Models","text":"<p>While there is a great deal in several primary domains of Generative AI, Text, Image, sound, video, there are many other modalities that are of interest. Here we share prominent and interesting methods for these domains. These models will often rely on tokenization and embedding changes, but because they may impact the entire system we mention them here.</p>"},{"location":"Understanding/architectures/models/index.html#vision-language-models","title":"Vision-Language Models","text":"<p>Vision Language models are among the most prominent. </p> <p>TODO: Clip paper</p> SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs A really cool idea that uses pyramidal representations and compresses information into text-tokens of different levels. <p>It can be reconstructed as needed. These tokens then could be used in novel image generation via semantic mapping with an LLM.  </p> Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language Represents images into language and combines them with a Frozen LLM to produce output. <p> Github Website</p>"},{"location":"Understanding/architectures/models/index.html#tabular-models","title":"Tabular Models","text":"<ul> <li>Challenges in End-to-End Neural Scientific Table Recognitions</li> </ul>"},{"location":"Understanding/architectures/models/index.html#more-than-one-modal","title":"More than one modal","text":"Meta Transformer Combines embedding in from 12 modalities by adjoining individual models and flattening them together. <p> Github</p>"},{"location":"Understanding/architectures/models/index.html#model-agnostic-improvements","title":"Model agnostic improvements","text":"<p>Learning to Compress Prompts with Gist Tokens. Can enable 26x compression and 40% FLOP reduction and improvements by training 'gist tokens' to summarize information.</p> LM-INfinite: Simple On-the-Fly Length Generalization for Large Language Models provides an O(n) time/space extension allows LMMs to ability to go to 32k tokens and 2.7x speedup. <p> </p>"},{"location":"Understanding/architectures/models/index.html#to-sort","title":"TO SORT","text":"<p> Multimodal Neurons in Pretrained Text-Only Transformers \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.</p> Llama 2: Open Foundation and Fine-Tuned Chat Models A nearly open source set of 7B-70B models with quality performance <p></p> Shepherd: A Critic for Language Model Generation A 7B model trained to critique outputs <p>Example chat response </p>"},{"location":"Understanding/architectures/models/index.html#to-consider-and-sort","title":"To consider and sort","text":""},{"location":"Understanding/architectures/models/index.html#self-supervised-learning","title":"Self-supervised learning.","text":"<ul> <li>Diffusion LLMs</li> </ul> <p>Alignment methods.</p> <p>Additional models come up all the time.</p> <ul> <li>HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</li> <li>Generating Diverse High-Fidelity Images with VQ-VAE-2</li> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements.  </li> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements. </li> </ul> <p>??? tip \"Why you probably don't need to fine tune an LLM</p> <pre><code>Summary (with links internal to this project):\n**Why you shouldn't**\n1. Few Shot examples and better [prompts](../prompting/index.md) (and [chains](../agents/chains.md) helps a great deal.\n2. [Retrieval Augmented Generation](../agents/rag.md) will get you all the way there.\n\n\n**Why you should** \n1. High accuracy requirements\n2. Don't care about speed\n3. Methods above don't work\n</code></pre> <p>Architectures:</p> <ul> <li>Encoder-Decoder (EDT), is also sequence-to-sequence. </li> <li>Encoder-only: (BERT)</li> <li>Decoder-only (GPT) Next-token </li> <li>Multi-domain decoder-only transformer (Gato)</li> </ul>"},{"location":"Understanding/architectures/models/index.html#established-architectures","title":"Established Architectures","text":""},{"location":"Understanding/architectures/models/index.html#developing-architectures","title":"Developing Architectures","text":"<p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p>"},{"location":"Understanding/architectures/models/index.html#activations","title":"Activations","text":""},{"location":"Understanding/architectures/models/index.html#softmax","title":"Softmax","text":"<p>Softmax is an activation function that computes a probability-like output for logistic outputs. Generally given in the form</p> <p>$$ (softmax(x))\ud835\udc56=exp(\ud835\udc65\ud835\udc56)\u2211\ud835\udc57exp(\ud835\udc65\ud835\udc57)</p> <p>softmax(x_i) = \\exp(x_i)/\\sum_j\\exp(x_j) $$</p>"},{"location":"Understanding/architectures/models/index.html#is-softmax-off-by-1","title":"Is softmax Off by 1?","text":"<p>Based on some observations by Qualcom, where \"97%+ of outlier activations in LLMs occur in whitespace and punctuation positions.\u201d  there was indication that it is important to have 'no attention' given to some tokens. Adding a \\(1\\) to the demonimator allows for <code>no attention</code> to be had. This is describe here, discussed here and already found in the flaxformer architecture. A general conclusion is that it is likely more important for highly quantized weights, but 32 and 16 bit dtypes are probably unaffected. </p>"},{"location":"Understanding/architectures/models/components.html","title":"Components","text":"<p>The components of model classes include a number of operations. </p>"},{"location":"Understanding/architectures/models/components.html#activation-functions","title":"Activation Functions","text":""},{"location":"Understanding/architectures/models/components.html#softmax","title":"Softmax","text":"<p>Softmax is an activation function that computes a probability-like output for logistic outputs. Generally given in the form</p> <p>$$ (softmax(x))\ud835\udc56=exp(\ud835\udc65\ud835\udc56)\u2211\ud835\udc57exp(\ud835\udc65\ud835\udc57)</p> <p>softmax(x_i) = \\exp(x_i)/\\sum_j\\exp(x_j) $$</p>"},{"location":"Understanding/architectures/models/components.html#is-softmax-off-by-1","title":"Is softmax Off by 1?","text":"<p>Based on some observations by Qualcom, where \"97%+ of outlier activations in LLMs occur in whitespace and punctuation positions.\u201d  there was indication that it is important to have 'no attention' given to some tokens. Adding a \\(1\\) to the demonimator allows for <code>no attention</code> to be had. This is describe here, discussed here and already found in the flaxformer architecture. A general conclusion is that it is likely more important for highly quantized weights, but 32 and 16 bit dtypes are probably unaffected. </p>"},{"location":"Understanding/architectures/models/developing_architectures.html","title":"Developing architectures","text":"<p>Here we share novel and promising architectures that may supplement or supplant other presently established models.</p>"},{"location":"Understanding/architectures/models/developing_architectures.html#models","title":"Models","text":"<p>!!! \"Hyena Architecture Uses inspiration from FFT to create a drop in replacement for Transformer models.\"     Github implementation for PyTorch</p> <p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p> <p>Bayesian Flow Networks A new class of generative models for discrete and continuous data and generation</p> <p>Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity.</p>"},{"location":"Understanding/architectures/models/diffusers.html","title":"Diffusers","text":""},{"location":"Understanding/architectures/models/diffusers.html#this-has-yet-to-be-built-thanks-for-bearing-with-me","title":"This has yet to be built! Thanks for bearing with me.","text":""},{"location":"Understanding/architectures/models/diffusers.html#references","title":"References","text":"<ul> <li>Diffusion Models</li> </ul>"},{"location":"Understanding/architectures/models/gans.html","title":"Gans","text":""},{"location":"Understanding/architectures/models/gans.html#this-page-is-under-construction","title":"This page is under construction.","text":""},{"location":"Understanding/architectures/models/hybrid_models.html","title":"Hybrid models","text":"<p>Hybrid models are those that employ multiple different architectures to achieve the end-goal. </p>"},{"location":"Understanding/architectures/models/reinforcement_learning.html","title":"Reinforcement learning","text":"<p>Reinforcement learning-based models have a colorful history. </p> <p>TODO</p>"},{"location":"Understanding/architectures/models/reinforcement_learning.html#reinforcement-learning-with-human-feedback-rlhf","title":"Reinforcement Learning with Human Feedback (RLHF)","text":"<p>RLFH has been found to be an essential component to enabling GPT based GenAI to be performant. </p> <p>TODO</p>"},{"location":"Understanding/architectures/models/reinforcement_learning.html#notable-research","title":"Notable research","text":"Learning to Model the World with Language Uses multimodal agents to build world models to act in. <p>Also introduces Homegrid evaluation game. Fun continuous multimodal agent. Github </p>"},{"location":"Understanding/architectures/models/transformers.html","title":"Transformers","text":"<p>TODO</p>"},{"location":"Understanding/architectures/models/transformers.html#components","title":"Components","text":"<p>TODO: Describe transformers and components</p> <ol> <li>Attention: Query, Key, Vectors</li> <li>Positional Encoding</li> <li>Layer Normalization</li> </ol>"},{"location":"Understanding/architectures/models/transformers.html#attention-models","title":"Attention Models","text":"<p>Layer normalization observably improves results On Layer Normalization in the Transformer Architecture</p>"},{"location":"Understanding/architectures/models/transformers.html#reviews","title":"Reviews","text":"The Illustrated Transformer <p>??? tip \"The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture     A thorough exposition of transformer technology.\"</p>"},{"location":"Understanding/architectures/models/transformers.html#gpt","title":"GPT","text":"<ul> <li>Illustrated GPT</li> <li>How GPT3 works Excellent summary of the progress of GPT over time, revealing core components, optimizations, and essential variations to the major Foundation model architectures.</li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#useful-references-and-research","title":"Useful References and Research","text":""},{"location":"Understanding/architectures/models/transformers.html#general-introductions","title":"General Introductions","text":"<ul> <li> <p>Transformers by Lucas Beyer (presentation)</p> </li> <li> <p>Five years of progress in GPTs</p> </li> <li> <p>The Transformer Architecture of GPT Models</p> </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#seminal-documents","title":"Seminal documents","text":"<ul> <li> <p>Neural Machine Translation by Jointly Learning to Align and Translate First paper indicating the notion of 'attention' sort of mechanism.</p> </li> <li> <p>Attention Is All you Need Initial paper indicating that attention is very powerful and potential replacement of LLM architectures. </p> </li> <li> <p>Formal Algorithms for Transformers in 2023 Important discussion revealing the components of Transformers.</p> </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#positional-encoding","title":"Positional Encoding","text":"<p>This component helps to remove the impilcit position-independence that 'vanilla' attention methods have.  </p> <ul> <li> <p>A Gentle Introduction to Positional Encoding in Transformer Models, pt1</p> </li> <li> <p>Transformer Language Models without POsitional Encodings STill Learn Positional Information Indications that causal LMS may derive positional awareness from more than the positional embeddings: they learn it from the causal mask. </p> </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#modifications","title":"Modifications","text":"<ul> <li>A Simple yet Effective Learnable Positional Encoding Method for Improving Document Transformer Model They introduce a learnable sinusoidal positional encoding feed forward network. Demonstrates significant improvements over other datasets. </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#improvements-optimizations-and-variations","title":"Improvements, Optimizations, and Variations.","text":"<ul> <li> <p>Scaling Transformer to 1M tokens and beyond with RMT Github Uses a Recurrent Memory Transformer(RMT) architecture to extend understanding to large lengths. </p> </li> </ul> MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers <p>MEGABYTE segments sequences into patches and uses a local submodel within patches and a global model between patches. Very nice demonstration that allows for \\(O(N^{4/3}\\) scaling directly on bytes, thereby bypassing tokenization requirements found with traditional transformers.</p> <p></p> <p>Infinite former</p> <p>Uses a representation of the input sequence as a continuous signal expressed in a combination of N radial basis functions. Promising but potentially complex. Worth consideration.</p> Note <p>Github </p>"},{"location":"Understanding/architectures/models/transformers.html#computation-reduction","title":"Computation Reduction","text":"<p>SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression</p>"},{"location":"Understanding/architectures/models/transformers.html#fine-tuning","title":"Fine Tuning","text":"<p>Using examples to fine-tune a model can reduce the number of tokens needed to achieve a sufficiently reasonable response. Can be expensive to retrain though.</p> <p>Symbol Tuning Improves in-context learning in Language Models</p> Note <p></p>"},{"location":"Understanding/architectures/models/transformers.html#other-modalities","title":"Other modalities","text":""},{"location":"Understanding/architectures/models/transformers.html#vision","title":"Vision","text":""},{"location":"Understanding/architectures/models/transformers.html#graphs","title":"Graphs","text":"<p>Transformers Meet Directed Graphs</p> <p>An interesting-if-also-complex variation of Transformer GNNs that uses 'direction-aware' positional encodings to help handle both undirected and directed graphs.</p> Note <p></p>"},{"location":"Understanding/architectures/models/transformers.html#training-variations","title":"Training variations","text":""},{"location":"Understanding/architectures/models/transformers.html#fairness-enablement","title":"Fairness Enablement","text":"<ul> <li>Concept Erasure</li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#using-knowledge-links","title":"Using Knowledge Links","text":"<ul> <li>LinkBERT places in the context window hyperlinked references to achieve better performance and is a drop-in replacement for BERT models. </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#multimodal","title":"Multimodal","text":"<ul> <li>Visual GPT</li> <li>Language is not all you need</li> <li>Meta-Transformer: A Unified Framework for Multimodal Learning The first framework to perform unified learning across 12 modalities with unpaired data. It does so by learning an embedding that can be shared across the modalities. Github </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#abstractions","title":"Abstractions","text":"<ul> <li>Looped Transformers and Programmable Computers Understanding that transformer networks can simulate complex algorithms when hardcoded with specific weights and made intoa  loop. 'Machine Learning' 'Machine code'. \"We demonstrate that a constant number of encoder layers can emulate basic computing blocks, including embedding edit operations, non-linear functions, function calls, program counters, and conditional branches. Using these building blocks, we emulate a small instruction-set computer.\"</li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#code","title":"Code","text":"<ul> <li>Hugging Face Transformers An API to access a large number of pre-trained transformers. Pytorch based. </li> <li>Fast Transformers A quality collection of a number of transformer implementations written in Pytorch. </li> </ul>"},{"location":"Understanding/architectures/models/transformers.html#_1","title":"Transformers","text":""},{"location":"Understanding/background/tensor_maths.html","title":"Tensor maths","text":"<p>Tensor math is linear algebra on steroids. Here are some valuable resources to understand it better.</p> <p>TODO: Add all of the tensor series. </p> <p>https://www.kolda.net/publication/TensorReview.pdf</p> <p>https://arxiv.org/pdf/2308.01814.pdf</p> The Tensor Programs: 1 <p>Ouput embeddings of two samples will be i.I.d. under randompermutations. Introduces generalization to Tensors and creates  NETSOR  Computation Programs Introduces three general mapping types of function variables.</p> <pre><code>NETSOR programs are straight-line programs, where each variable follows one of three types, G, H, or A (such variables are called G-vars, H-vars, and A-vars), and after input variables, new variables can be introduced by one of the rules MatMul, LinComb, Nonlin to be discussed shortly. G and H are vector types and A is a matrix type; intuitively, G-vars should be thought of as vectors that are asymptotically Gaussian, H-vars are images of G-vars by coordinatewise nonlinearities, and A-vars are random matrices with iid Gaussian entries. Each type is annotated by dimensionality information:\n\nIf x is a (vector) variable of type G (or H) and has dimension n, we write x : G(n) (or x : H(n)).\nIf A is a (matrix) variable of type A and has size n1 \u00d7 n2, we write A : A(n1, n2)\nG is a subtype of H, so that x : G(n) implies x : H(n). \n</code></pre> <p>G is petty much a \u2018pass through\u2019 like an activation function. </p> <p>This a Github implementation </p> Tensor Programs IVb: Adaptive Optimization in the \u221e-Width Limit Demonstrates how to scale hyperparameters when changing widths of feature parameters generally <p>Micro update </p> <p>\"We show that optimal hyperparameters become stable across neural network sizes when we parametrize the model in maximal update parametrization (\u03bcP). This can be used to tune extremely large neural networks such as large pretrained transformers, as we have done in our work. More generally, \u03bcP reduces the fragility and uncertainty when transitioning from exploration to scaling up, which are not often talked about explicitly in the deep learning literature.\"</p>"},{"location":"Understanding/data/index.html","title":"Data","text":"<p>Data is the most important part of training any model. </p>"},{"location":"Understanding/data/index.html#amount-of-data-needed","title":"Amount of data needed.","text":"<p>The larger the model, the more data is needed. A rough order of estimate is that the number of tokens should be 10x the number of parameters used by the model. </p> Training Compute-Optimal Large Language Models The 'Chinchilla' paper of 2022, identifies scaling laws that help to understand the volume of data that is needed <p>to obtain 'optimal' performance for a given LLM models size. Use of it in other areas, such as for Llama reveals that the models may have been under-trained. - Primary takeaway: **\"All three approaches suggest that as compute budget increases, model size and the amount of training data should be increased in approximately equal proportions.\"  </p>"},{"location":"Understanding/data/index.html#bath-sizes-of-data-needed","title":"Bath sizes of data needed...","text":"<p>TODO</p>"},{"location":"Understanding/data/index.html#training-with-generated-data","title":"Training with generated data.","text":"<p>It is possible and sometimes even peferred to train with generated data produced by other models. There are notable concerns, however, as some evidence indicates that training with generated data can yield worse results, and if done consistently, can lead to complete degredation of model performance.  </p> Textbooks are all you need Used a volume of generated data, and transformer-classifiers to filter data to create a high quality coding-focused model. <p>Used 4 days on 8 A-100s to train to reach out-performing results. </p>"},{"location":"Understanding/data/selection.html","title":"Selection","text":"<p>Data selection acts as the backbone for training generative AI models. Without suitable data and an optimal selection strategy, it might be challenging to develop models that provide useful and relevant outputs.</p>"},{"location":"Understanding/data/selection.html#why-is-data-selection-important","title":"Why is Data Selection Important?","text":"<p>Data selection forms the initial step in any machine learning project. Selecting the right data can help train your GenAI model more efficiently and accurately. Improper data selection, and balancing, can cause you models to fail all together, or more insideously induce output biases that are of ethical concern </p>"},{"location":"Understanding/data/selection.html#role-in-training-models","title":"Role in Training Models","text":"<p>The right data selection dictates how well a model can generate the desired output. It decides what the design and parameters of the model will be.</p>"},{"location":"Understanding/data/selection.html#impact-on-model-performance","title":"Impact on Model Performance","text":"<p>The quality and relevance of selected data have a direct impact on the performance of the model. The right selection reduces the risk of overfitting and underfitting.</p>"},{"location":"Understanding/data/selection.html#strategies-for-effective-data-selection","title":"Strategies for Effective Data Selection","text":"<p>There are several strategies to ensure the data used for training Generative AI models is selected effectively.</p>"},{"location":"Understanding/data/selection.html#understanding-your-data","title":"Understanding Your Data","text":"<p>Before selecting data, take time to understand the data you have. Analyzing the data to identify patterns, trends or anomalies will give some direction on what data to use.</p>"},{"location":"Understanding/data/selection.html#choosing-relevant-data","title":"Choosing Relevant Data","text":"<p>Relevancy of data to the problem at hand is crucial. Inappropriate data can lead to inaccurate results and will impede the model\u2019s performance.</p>"},{"location":"Understanding/data/selection.html#balancing-your-dataset","title":"Balancing Your Dataset","text":"<p>In order to train an effective Generative AI model, it's important to balance your dataset. An imbalanced dataset could lead your model to be biased towards the class that is overrepresented. </p>"},{"location":"Understanding/data/selection.html#tools-for-data-selection","title":"Tools for Data Selection","text":"<p>There are different tools that can aid in effective data selection.</p>"},{"location":"Understanding/data/selection.html#automated-data","title":"Automated Data","text":"<p>Automated machine learning tools can greatly simplify data selection by providing features for automatic feature selection, data cleaning and preprocessing.</p>"},{"location":"Understanding/data/simulation.html","title":"Simulation","text":"<p>!!! code Madrona Madrona is a prototype game engine for creating high-throughput, GPU-accelerated simulators that run thousands of virtual environment instances, and generate millions of aggregate simulation steps per second, on a single GPU.\"</p>"},{"location":"Understanding/data/sources.html","title":"Sources","text":""},{"location":"Understanding/data/sources.html#data-sources","title":"Data sources","text":"<p>RedPajama Pile CommonCrawl (webscrape) C4 (CommonCrawl) Github Books Arxiv StackExchange</p> <ul> <li> <p>unarXive 2022: All arXiv Publications Pre-Processed for NLP</p> </li> <li> <p>Redpajama</p> </li> <li>BIG-bench</li> <li>Metaseq</li> <li>Kaggle-code</li> </ul> <p>The largest open source text dataset just dropped</p> Dolma. (by AI2) <p>WARNING: The license is not 'open source' 3 Trillion tokens of high quality data.</p> <ul> <li>Diverse: Documents, code, academic papers, wiki..</li> <li>Focused: English only.</li> <li>De-duplicated.</li> <li>Filtered for high quality.</li> </ul> <p>But most importantly: The largest open curated dataset for pretraining.</p> <p>\u2022 Link: https://huggingface.co/datasets/allenai/dolma \u2022 Blog: https://blog.allenai.org/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64 \u2022 Code: https://github.com/allenai/dolma \u2022 Paper: https://drive.google.com/file/d/12gOf5I5RytsD159nSP7iim_5zN31FCXq/view</p>"},{"location":"Understanding/data/tokenizing.html","title":"Tokenizing","text":"<p>In generative AI, the raw data\u2014whether it be in binary, text, or a different form\u2014is divided into individual units termed as tokens. These play a crucial role in easing the understanding and manipulation of data for the AI.</p>"},{"location":"Understanding/data/tokenizing.html#understanding-tokenization","title":"Understanding Tokenization","text":"<p>Tokenization is the process of splitting data into these individual units. The choice of a token largely depends on the data type and the expected outcome of the AI. In text data, for instance, tokens often correspond to single words or subwords. These tokens are then often represented in one-hot encoding. Research may eventually show that hierarchical tokenization, either trained, guessed, or otherwise constructed, could minimize token use. </p>"},{"location":"Understanding/data/tokenizing.html#heirarchichal-tokenization","title":"Heirarchichal Tokenization","text":"<p>Floret Vectors</p> Superbloom: Bloom filter meets Transformer <p>Wherein a bloom filter is used to create tokens/embeddings.    </p> Related to Superbloom: Learned Hashing <p>Which if you think of it, the \u2018hashing function\u2019 could just be a linear projection onto a hashing layer. A input unit (character or byte string) would be initialized randomly to have a \u2018representation vector\u2019, akin to a direct embedding. The challenge would be on inference when reconstructing outputs (it would be a Bloom look up for an output character, and not a simple mapping).</p>"},{"location":"Understanding/data/tokenizing.html#subword-units","title":"Subword Units","text":"<p>A subword unit, or a part of a word, can be a token in itself. The paper titled Neural Machine Translation of Rare Words with Subword Units brings to light the effectiveness of subword units in improving results. This type of tokenization was used in a neural machine translation system and it significantly improved the handling of rare words.</p>"},{"location":"Understanding/data/tokenizing.html#special-tokens","title":"Special tokens","text":"<p>There are special tokens that are used by high-level interpreters on what next to do. </p> Token Name Description START_TOKEN or BOS_TOKEN This is used to indicate the beginning of a sequence. BOS stands for \"Beginning Of Sequence\". STOP_TOKEN or EOS_TOKEN This is used to indicate the end of a sequence. EOS stands for \"End Of Sequence\". MASK_TOKEN This is used to represent a masked value, which the model needs to predict. MODALITY_TOKEN This is used to indicate the type of data in the sequence (such as text, images, etc.)"},{"location":"Understanding/data/tokenizing.html#speech-tokenization","title":"Speech tokenization","text":"Speech Tokenizer  is a unified speech tokenizer for speech language models, which adopts the Encoder-Decoder architecture with residual vector quantization (RVQ)"},{"location":"Understanding/data/tokenizing.html#multimodal-tokenization","title":"Multimodal Tokenization","text":"<p>Multimodal tokenization is an area of tokenization that focuses on incorporating multiple data forms or modes. This facet of tokenization has seen remarkable strides. Bytes are all you need\u2014a study utilizing transformer technology to input file bytes directly\u2014demonstrates that multimodal tokenization can assist in improving the AI's performance accuracy. The researchers in the study developed ByteFormer, a model based on their study\u2019s findings that can be accessed here.</p>"},{"location":"Understanding/data/tokenizing.html#tokenizing-might-not-be-necessary","title":"Tokenizing might not be necessary","text":"<p>It is regarded that tokenizing is a bit arbitrary and has disadvantages. There are promising results using methods without tokenization MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers that \"show that MEGABYTE allows byte-level models to perform competitively with subword models on long context language modeling\"</p>"},{"location":"Understanding/data/tokenizing.html#tools","title":"Tools","text":"<p>Examples of coding tools that facilitate tokenization include Tiktoken which utilizes Byte Pair Encoding (BPE) for tokenization and is purportedly used in GPT models. An alternative tool is <sup>2</sup>, which takes a unique top-down approach and results in almost 35% less tokens as opposed to the standard bottom-up approach.</p>"},{"location":"Understanding/data/tokenizing.html#open-source-tokenizers","title":"Open Source Tokenizers","text":"<ul> <li>Sentence Piece implements subword units (e.g., byte-pair-encoding (BPE) ) and unigram language model <sup>1</sup></li> <li>Tiktoken</li> <li>Token Monster</li> </ul>"},{"location":"Understanding/data/tokenizing.html#references","title":"References","text":"<ul> <li>Neural Machine Translation of Rare Words with Subword Units</li> <li>Bytes are all you need</li> <li>ByteFormer Github What are EmbeddingsGithub</li> </ul> <ol> <li> <p>Kudo \"subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training\". Effectively, this takes aliasing-like effects that cause different tokenization. It is more effective because it breaks it down in different ways.\u00a0\u21a9</p> </li> <li> <p>Token Monster \u21a9</p> </li> </ol>"},{"location":"Understanding/examples/index.html","title":"Examples","text":"FastWhisper This is an optimized implementation of OpenAI's Whisper <p>Uses a greedy decode for multilingual transcription. It supports all sizes of the Whisper model (from tiny to large).</p> humanscript A script interpreter that infers the meaning behind commands written in natural language using large language models. Human writeable commands are translated into code that is then executed on the fly. <p></p> <p>Fully GenAI pharmacist from scripts, images and videos</p> <p>ChatGPT clone with streamlit</p> <p>A Guide to building a full-stack web app with Llama Index</p> <p>GPT-graph A react-based ability to explore questions.</p>"},{"location":"Understanding/examples/index.html#research","title":"Research","text":"<p>GPT researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.</p> <p>LOOK INTO THIS</p>"},{"location":"Understanding/examples/index.html#summarization","title":"Summarization","text":""},{"location":"Understanding/examples/index.html#pdf","title":"PDF","text":"[Summarization with Langchain] https://github.com/EnkrateiaLucca/summarization_with_langchain A splendid view of a quick streamlit app that does PDF summarization. <p>Doctor GPT implements advanced LLM prompting for organizing, indexing and discussing PDFs, and does so without using any type of opinionated prompt processing frameworks </p>"},{"location":"Understanding/examples/index.html#video","title":"Video","text":"<p>Youtube URL to text</p>"},{"location":"Understanding/examples/index.html#multiple-use-case-examples","title":"Multiple Use-case examples","text":"<p>Langchain Javascript in the Real World</p>"},{"location":"Understanding/examples/by_domain.html","title":"By domain","text":""},{"location":"Understanding/examples/by_domain.html#coding","title":"Coding","text":"<p>Octopack Githubs</p> <p>!!! code \"Open Copilot</p> <pre><code>![image](https://user-images.githubusercontent.com/32633162/263495581-a0cdc888-d2de-46b7-8c0b-96e876050b6e.png)\n</code></pre>"},{"location":"Understanding/examples/by_domain.html#image","title":"Image","text":"<p>https://huggingface.co/spaces/jbilcke-hf/ai-comic-factory</p>"},{"location":"Understanding/overview/ai_in_general.html","title":"Ai in general","text":"<p>Here we provide selected references to frameworks and solutions surrounding AI in general</p>"},{"location":"Understanding/overview/ai_in_general.html#frameworks","title":"Frameworks","text":"<p>Pytorch Tensorflow</p>"},{"location":"Understanding/overview/ai_in_general.html#higher-level-frameworks","title":"Higher-level Frameworks","text":"<p>Higher level frameworks minimize the lines of code needed to make a model and keep track of everything. </p> <ul> <li>Catalyst Framework for boiler-plate minimal ML calling using pytorch. Enabled heirarchichal Attention networks</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#lightning","title":"Lightning","text":"<ul> <li>Lightning + Hydra Uses the [lightning] framework with Hydra-based config management. </li> <li>Lightning Hugging face adapter</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#must-have-knowledge","title":"Must-have knowledge","text":"<ul> <li>AI cannon by a16z</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#network-figures","title":"Network Figures","text":"<p>Being able to see the 'structure' of some neural networks make it easier to understand, and more aesthetic.  </p> <ul> <li>PlotNeuralNet and a nice writeup on how to use it. </li> </ul>"},{"location":"Understanding/overview/applications.html","title":"Overview","text":"<p>We explores different activities and fields that utilize Generative AI's capabilities and provide a few notable references for each. For an overview of applications (and challenges), we highly recommend Challenges and Applications of Large Language Models</p> <p>There is a philosophical overlap with 'predictive' AI where a predictive model could just be said to 'generate' either possible future outcomes or estimated classifications of data. </p> <p>There are many generally distinct domains of Gen()AI application, though many be compositional. Effectively any information that can be recorded onto a computer may be made by Gen()AI.</p> <ul> <li>Language</li> <li>Visual 2D</li> <li>Visual 3D</li> <li>Visual 2D with time</li> <li>Visual 3D with time</li> <li>Brain recordings</li> <li>Weather patterns</li> <li>Protein folding </li> </ul>"},{"location":"Understanding/overview/applications.html#general-activities","title":"General Activities","text":"<p>There are many activities that can be used in many, if not all, fields of applications. We mention a few below:</p>"},{"location":"Understanding/overview/applications.html#summarization","title":"Summarization","text":"<p>Summarization is a key application for Generative AI. It uses the technology to provide brief, accurate summaries of a larger body of text.</p>"},{"location":"Understanding/overview/applications.html#classification","title":"Classification","text":"<p>With or without examples LLMs can perform classification on input, though sometimes additional supervised training may be preferred to improve accuracy.</p>"},{"location":"Understanding/overview/applications.html#semantic-search","title":"Semantic Search","text":"<p>Generative AI has the capability to understand relationships between words and concepts. By embedding an input, the technology can measure semantic, or 'meaning', nearness via distance calculations. This capability enhances the potential for memory recall with imperfect inputs and improves action routing. </p>"},{"location":"Understanding/overview/applications.html#prose-generation","title":"Prose Generation","text":"<p>Generative AI can be utilized for a wide range of prose generation applications, such as:</p> <ul> <li>Drafting and refining text and notes.</li> <li>Brainstorming and ideation.</li> <li>Generating initial drafts for later human editing.</li> <li>Creating descriptions and explanations.</li> <li>Rewriting to target different audiences.</li> <li>Expanding on key points.</li> <li> <p>Improving flow and readability</p> </li> <li> <p>Pyprompt chatgpt</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#language-translation","title":"Language Translation","text":"<p>Generative AI is increasingly good at translating between domains. </p>"},{"location":"Understanding/overview/applications.html#personal-assistants-and-memory","title":"Personal assistants and memory","text":"<ul> <li>Quiver A LLM for self second brain. </li> </ul>"},{"location":"Understanding/overview/applications.html#code-generation","title":"Code Generation","text":"<p>Very powerfully it can generate code to accomplish a task based on natural language input. This is very promising but still requires human oversight, due to the challenge associated with using Automated AI systems without human input or oversight.</p> <ul> <li>Wizard Coding</li> <li>AutoPR</li> <li>Codium pr-agent </li> <li>Summarization with Langchain A splendid view of a quick streamlit app that does PDF summarization. </li> </ul>"},{"location":"Understanding/overview/applications.html#application-and-component-replacement","title":"Application and component replacement","text":"<ul> <li>GPT as backend</li> </ul>"},{"location":"Understanding/overview/applications.html#sound-and-music-generation","title":"Sound and Music Generation","text":"<ul> <li>AudioCraft (Meta)</li> </ul>"},{"location":"Understanding/overview/applications.html#audio-visual-generation","title":"Audio Visual Generation","text":"<ul> <li>Showrunner Agents</li> </ul>"},{"location":"Understanding/overview/applications.html#fields","title":"Fields","text":"<p>Here are a few fields where Gen()AI is already having formative impacts. </p>"},{"location":"Understanding/overview/applications.html#robotics","title":"Robotics","text":"<ul> <li>CLAIRIFY Translates English to domain-specific languages like robots. </li> <li>https://arxiv.org/abs/2303.14100</li> <li>RT-2 An impressive demonstration of multi-step fusing (PaLI-X) and Pathways Language model Embodied (PaLM-E) as components of it. </li> </ul>"},{"location":"Understanding/overview/applications.html#science","title":"Science","text":"Emergent autonomous scientific research"},{"location":"Understanding/overview/applications.html#healthcare","title":"Healthcare","text":"<ul> <li> <p>Health system-scale language models are all-purpose prediction engines Uses LLM based system to integrate real time clinical workflows with note-writing and electronic ordering. Generally quite-performant and. a great indication of how they could be used to predict things such as readmission rates, and many other applications. </p> </li> <li> <p>LLMs encode clinical knowledge</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#chemistry","title":"Chemistry","text":"Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction IMPORTANT uses heirarchichal metagraphs to stitch-together molecular nodes.  <p>This results in leaves that are 'actual' molecules. Using graph neural-diffusion, it does amazingly well even with minimal data-sets (100 examples).  </p>"},{"location":"Understanding/overview/applications.html#biology","title":"Biology","text":"<ul> <li>Evolutionary-scale prediction of atomic-level protein structure with a language model End to end Language model enabling structure sequence pairing, coupled with an equivariant transformer structure model at the end. </li> <li>https://arxiv.org/pdf/2303.16416.pdf</li> <li>https://arxiv.org/abs/2304.02496</li> <li>Biomedical simulation</li> </ul>"},{"location":"Understanding/overview/applications.html#kinesiology","title":"Kinesiology","text":"<ul> <li>Motion GPT</li> </ul>"},{"location":"Understanding/overview/applications.html#societal-simulations","title":"Societal simulations","text":"<ul> <li>Generative Agents: Interactive Simulacra of Human Behavior:    They gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior.The actions were rated more human than humans roleplaying.   Demo: https://t.co/pYNF4BBveG</li> </ul>"},{"location":"Understanding/overview/applications.html#finance","title":"Finance","text":"<ul> <li>ML for trading (NOT LLM based)</li> <li>https://github.com/irgolic/AutoPR</li> <li>Finance GPT LLMs for finance</li> </ul>"},{"location":"Understanding/overview/challenges.html","title":"Challenges","text":"<p>There are a host of challenges associated with the use of GenAI at multiple levels. These challenges may also be appropriately considered risks to add weight to their importance.</p> <p>At the base level technichal challenges creating and using the GenAI such that it is wholly consistent and coherent </p> <p>At a higher level, the concerns for displacement and capture of people's jobs must be taken into consideration. With arguments both minimizing and amplifying the concern, estimates still have around 300 million jobs replaced by AI, according to a Goldman Sachs report. AT the same time GDP could be increased by 7% and lift productivity. It is still apparent that upskilling to enable people to work with AI as an enabling tool is important to consider. </p> <p>At nearly the highest level of challenge is to have GenAI that is Aligned for the betterment of humanity and our planet and not to its detriment with dual use. Because of the expansive and moral-philosophical nature of this, as in what is defining 'betterment' it is difficult. Concretely, however, minimizing potential risks associated with GenAI, especially Autonomous Agents, are necessary to address at a functional level, both at organizations and within governments and the regulatory bodies that coordinate the two.</p> <p>In general ethical use of GenAI will necessarily address all or most of these challenges. </p>"},{"location":"Understanding/overview/challenges.html#technical-challenges","title":"Technical Challenges","text":"<p>!!! Open challenges in LLM research Challenges associated with GenAI.</p> <pre><code>```markdown\n\n1. Reduce and measure hallucinations\n2. Optimize context length and context construction\n3. Incorporate other data modalities\n4. Make LLMs faster and cheaper\n5. Design a new model architecture\n6. Develop GPU alternatives\n7. Make agents usable\n8. Improve learning from human preference\n9. Improve the efficiency of the chat interface\n10. Build LLMs for non-English languages\n```\n</code></pre>"},{"location":"Understanding/overview/challenges.html#ethical-challenges","title":"Ethical Challenges","text":""},{"location":"Understanding/overview/challenges.html#job-displacement","title":"Job displacement","text":"<p>Because GenAI can perform tasks at a speedy rate. </p>"},{"location":"Understanding/overview/challenges.html#copywrite-and-ip","title":"Copywrite and IP","text":"<p>Related to job-displacement, the content created with GenAI remains in a precarious state with regard's to copyright and IP. While there are indications that content generated purely from AI may not be copyrighted (in the US), it is generally accepted AI can provide the basis for content that may be copyrighted. The evolution of this may take years of debate and resolution of laws to settle before confusion is fully settled. </p> <p>Talkin\u2019 \u2018Bout AI Generation A thorough discussion on copyright issues</p> <p></p>"},{"location":"Understanding/overview/challenges.html#dual-use","title":"Dual Use","text":"<p>The technology may be found to have dual-use. </p>"},{"location":"Understanding/overview/extra_resources.html","title":"Extra resources","text":""},{"location":"Understanding/overview/extra_resources.html#quality-recordings","title":"Quality Recordings","text":"<ul> <li>Lex Fridman</li> <li>David Shapiro</li> <li>AI Explained</li> <li>Yannic Kilcher</li> </ul>"},{"location":"Understanding/overview/foundation_models.html","title":"Foundation models","text":"<p>By their nature, foundational models will be ever increasing in scope and potential. We share some seminal papers on foundation models here.  Continual evolution of models may be found in hubs such as Hugging Face. </p>"},{"location":"Understanding/overview/foundation_models.html#by-modality","title":"By Modality","text":""},{"location":"Understanding/overview/foundation_models.html#vision","title":"Vision","text":"Segment anything <p>Webpage</p>"},{"location":"Understanding/overview/foundation_models.html#by-domain","title":"By Domain","text":""},{"location":"Understanding/overview/foundation_models.html#biology-and-healthcare","title":"Biology and Healthcare","text":"<ul> <li>Foundation models for Retinas</li> </ul>"},{"location":"Understanding/overview/knowledge_graphs.html","title":"Knowledge graphs","text":""},{"location":"Understanding/overview/knowledge_graphs.html#building-knowledge-graphs","title":"Building Knowledge Graphs","text":"<p>Knowledge graphs can be created with the help of Generative AI. Understanding relationships between pieces of information allows the technology to create visual representations of connections, improving information processing.</p>"},{"location":"Understanding/overview/knowledge_graphs.html#general-approaches-and-summaries","title":"General approaches and summaries","text":"Natural Language is All a Graph Needs is a very powerful manner of fusing LLMs with KGs using natural language <ul> <li>Node classification and self-supervised link predictions. </li> <li>Scaleable natural-English graph prompts for instruction tuning</li> <li>Identifying a central node and doing neighbor sampling and explorations using LLMs. </li> <li>Avoids complex attention mechanisms and tokenizers.</li> </ul> <p>GPT for knowledge graphs</p> <p>Medium </p>"},{"location":"Understanding/overview/knowledge_graphs.html#description-of-graphs-for-llms","title":"Description of Graphs for LLMs","text":"Unifying Large Language Models and Knowledge Graphs: A Roadmap <p>[GPT4Graph: Can Large Language Models Understand Graph sTructure Data? An Empirical Evaluation and Benchmarking\"]</p> <p> </p>"},{"location":"Understanding/overview/knowledge_graphs.html#other-examples","title":"Other examples","text":"<p>Ontology mapping</p> OntoGPT uses two different methods to query knowledge graphs using LLMS <p>Uses SPIRES: Structured Prompt Interrogation and Recursive Extraction of Semantics A Zero-shot learning (ZSL) approach to extracting nested semantic structures from text This approach takes two inputs - 1) LinkML schema 2) free text, and outputs knowledge in a structure conformant with the supplied schema in JSON, YAML, RDF or OWL formats Uses GPT-3.5-turbo, GPT-4, or one of a variety of open LLMs on your local machine SPINDOCTOR: Structured Prompt Interpolation of Narrative Descriptions Or Controlled Terms for Ontological Reporting</p> Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals proposes a set of preprocessing operators that can transform KGs to be embedded within any method. <p>Github </p>"},{"location":"Understanding/overview/knowledge_graphs.html#other-papers-and-utilities","title":"Other Papers and utilities","text":"<p>Diffbot + Langchain for KG creation</p> Multimodal learning with graphs <p>Preprint Nature While not strictly GenAI focused, this introduces a comprehensive manner of combining cross-modal dependencies using geometric relationships. </p> <p></p> PyGraft is an open-source Python library for generating synthetic yet realistic schemas and (KGs) based on user-specified parameters. <p>Paper </p>"},{"location":"Understanding/overview/open_source.html","title":"Open source","text":"<p>Open source is eating the world</p> <p>While a bit hyperbolic, the power open source is hard to disregard. Enabling effective complexity to built into and between companies, it provides a legal framework that has accelerated the evolution of software and opened it up for many to use. </p> <p>Within AI, there is no exception, and it is potentially even more powerful. In discussions of a widely circulated memo that left Google, they describe how Open-source will reduce the moats when it comes to AI. </p> <p>As such, we emphasize the nature of this project is to interact and connect with open-source as effectively as possible, while relying on enabling the open-source community to create more effectively.</p>"},{"location":"Understanding/prompting/index.html","title":"Prompting","text":""},{"location":"Understanding/prompting/index.html#llm-prompting","title":"LLM Prompting","text":"<ul> <li>LLM Practical Guide based on paper.</li> <li>Prompting Guide</li> <li>Wolfram Prompt Repo</li> <li>Prompt Engine (MSFT) database tool MIT license</li> <li>scale.com/spellbook</li> <li>Prompt Hub For Generating image prompts</li> </ul>"},{"location":"Understanding/prompting/index.html#organization","title":"Organization","text":"<ul> <li>Notion.io plugin</li> </ul>"},{"location":"Understanding/prompting/index.html#prompt-engineering","title":"Prompt engineering","text":"<ul> <li>Prompting is Programming: A Query Language for Large Language Models</li> </ul>"},{"location":"Understanding/prompting/index.html#manual","title":"Manual","text":"<ul> <li> <p>OPEN AI best practices</p> </li> <li> <p>Go over all of these! https://www.promptingguide.ai/techniques</p> </li> <li>A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT </li> </ul>"},{"location":"Understanding/prompting/index.html#examples","title":"Examples","text":"<pre><code>Pretend you have an IQ of 120\n</code></pre>"},{"location":"Understanding/prompting/index.html#minimizing-ai-plagiarism-prompting-strategy","title":"Minimizing AI- plagiarism prompting strategy.","text":"<p>\"You are a creative writer, and you like to write everything differently from others. Your task is to follow the instructions below and continue writing at the end of the text given. The instructions (given in markdown format) are \u201cWrite in a way different from the actual continuation, if there is one\u201d, and \u201cNo plagiarism is allowed\u201d.\" https://arxiv.org/pdf/2304.08637.pdf </p>"},{"location":"Understanding/prompting/index.html#according-to","title":"'According To'","text":"<ul> <li>\u201cAccording to ...\u201d Prompting Language Models Improves Quoting from Pre-Training Data The grounding prompt <code>According to { some_reputable_source}</code> prompt inception additions increases output quality improves over the null prompt in nearly every dataset and metric, typically by 5-15%.</li> </ul> <pre><code>According to {some_reputable_source} ...\n</code></pre>"},{"location":"Understanding/prompting/index.html#summary","title":"Summary:","text":"<ul> <li>Provide several examples to ground it.</li> <li>Good to evaluate this and see if input examples give expected scores. Modify the prompt if it isn't. </li> <li>Consider prompt versioning to keep track of outputs more easily.</li> <li>Breag prompts into smaller prompts</li> <li>Chain of Thought Prompting</li> <li>Generate many outputs and pick final one or use LLM to pick best one. Self consistency technique</li> <li>NOTE: Not model universal and not robust to updated changes: not stable. </li> </ul>"},{"location":"Understanding/prompting/index.html#automatic","title":"Automatic","text":"<p>GPT Prompt Engineer</p> <p>A fairly simple automation tool to create the best prompts</p> Example <pre><code>    description = \"Given a prompt, generate a landing page headline.\" # this style of description tends to work well\n\n    test_cases = [\n        {\n            'prompt': 'Promoting an innovative new fitness app, Smartly',\n        },\n        {\n            'prompt': 'Why a vegan diet is beneficial for your health',\n        },\n        ...\n    ]\n</code></pre> <p></p>"},{"location":"Understanding/prompting/index.html#resources","title":"Resources","text":"<ul> <li>Awesome Prompts</li> <li>Prompt Engineering by Lillian Wang</li> <li>Prompt Engineering Guide</li> <li>Best practices for prompt engineering</li> <li>Chain of Thought Prompting Elicits Reasoning in Large Language Models</li> <li>Automatic Prompt Engineering \u2192 Gave a CoT improvement suggestion \"Let's work this out in a step by step by way to be sure we have the right answer.\"</li> </ul> <p>Techniques to improve reliability By OpenAI</p> <ul> <li>Give clearer instructions</li> <li>Split complex tasks into simpler subtasks</li> <li>Structure the instruction to keep the model on task</li> <li>Prompt the model to explain before answering</li> <li>Ask for justifications of many possible answers, and then synthesize</li> <li>Generate many outputs, and then use the model to pick the best one</li> <li>Fine-tune custom models to maximize performance</li> </ul>"},{"location":"Understanding/prompting/index.html#prompt-tuning","title":"Prompt tuning","text":"<p>Uses a layer to not change prompts but change the embedding of the prompts.  - The Power of Scale for Parameter-Efficient Prompt Tuning Boosted Prompting: few shot prompts that progressively solve more of the problem.</p>"},{"location":"Understanding/prompting/index.html#prompt-and-optimization","title":"Prompt and optimization","text":"<ul> <li>Large Language Models Can Self Improve Using Chain of thought to provide better examples and then fine-tune the LLM. </li> <li> <p>Refiner Iteratively improves itself based on an LLM critic </p> </li> <li> <p>PROMPT generator To save a few words by just entering a persona and igives prompt output. </p> </li> </ul>"},{"location":"Understanding/prompting/index.html#manual-prompt-optimization","title":"Manual Prompt optimization","text":""},{"location":"Understanding/prompting/index.html#auto-prompt-optimizations","title":"Auto Prompt Optimizations","text":"<p>A good description of advanced prompt tuning <pre><code>AutoPrompt [5] combines the original prompt input with a set of shared (across all input data) \u201ctrigger tokens\u201d that are selected via a gradient-based search to improve performance.\n\nPrefix Tuning [6] adds several \u201cprefix\u201d tokens to the prompt embedding in both input and hidden layers, then trains the parameters of this prefix (leaving model parameters fixed) with gradient descent as a parameter-efficient fine-tuning strategy.\n\nPrompt Tuning [7] is similar to prefix tuning, but prefix tokens are only added to the input layer. These tokens are fine-tuned on each task that the language model solves, allowing prefix tokens to condition the model for a given task.\n\nP-Tuning [8] adds task-specific anchor tokens to the model\u2019s input layer that are fine-tuned but allows these tokens to be placed at arbitrary locations (e.g., the middle of the prompt), making the approach more flexible than prefix tuning.\n\n[5] Shin, Taylor, et al. \"Autoprompt: Eliciting knowledge from language models with automatically generated prompts.\" arXiv preprint arXiv:2010.15980 (2020).\n\n[6] Li, Xiang Lisa, and Percy Liang. \"Prefix-tuning: Optimizing continuous prompts for a generation.\" arXiv preprint arXiv:2101.00190 (2021).\n\n[7] Lester, Brian, Rami Al-Rfou, and Noah Constant. \"The power of scale for parameter-efficient prompt tuning.\" arXiv preprint arXiv:2104.08691 (2021).\n\n[8] Liu, Xiao, et al. \"GPT understands, too.\" arXiv preprint arXiv:2103.10385 (2021).\n</code></pre></p>"},{"location":"Understanding/prompting/prompt_injections.html","title":"Prompt injections","text":"<p>Prompt injections involve the modification of an input prompt prior to model processing. </p> <p>Use of prompt injections, also 'prompt hacking' can allow for intentional bypasses of any pre-established alignment guardrails thereby enabling non-aligned output to occur. </p> <ul> <li>Universal and Transferable Adversarial Attacks on Aligned Language Models and paper demonstrate generally presently undefended attacks on models just by appending to the prompt. Prompt injection. </li> </ul>"},{"location":"Understanding/studies/studies.html","title":"Studies","text":"<p>We are in an age of experimental applied mathematics. Often times we do not know what the results of a particular model or method will be until it is programmed and evaluated. Though often times theory-can inform the best ways forward, we are still far from from a unified theory of AI, (or even intelligence for that matter) and we will likely always be learning things. </p> <p>For GenAI and LLMs, much of what has been learned has been surmised or known only in the gist. More thorough understanding has occurred through painstaking experiments, and anecdotal and statistical evaluations of models and methods. Still, we don't always know 'how' they are able to do what they do. </p> <p>It is debated that sufficiently large models exhibit 'emergence'. While not always defined universally, this can be considered as the ability for the model to perform tasks beyond what they initially were trained to do, or to be 'greater than the individual sum of the parts'. While this distinction may be of merit it remains a popular arena for academic debates. </p>"},{"location":"Understanding/studies/studies.html#_1","title":"Studies","text":"<p>??? note SEMANTIC UNCERTAINTY: LINGUISTIC INVARIANCES FOR UNCERTAINTY ESTIMATION IN NATURAL LANGUAGE GENERATION</p> <pre><code>&lt;img width=\"908\" alt=\"image\" src=\"https://github.com/ianderrington/genai/assets/76016868/c45f0580-2681-40cf-91c7-57bfde4f929d\"&gt;\n</code></pre> <p>??? tip Transformers learn through gradual rank increase      They \"identify incremental learning dynamics in transformers, where the difference between trained and initial weights progressively increases in rank. We rigorously prove this occurs under the simplifying assumptions of diagonal weight matrices and small initialization. Our experiments support the theory and also show that phenomenon can occur in practice without the simplifying assumptions.\"</p> Grokking <p>When training, if test loss starts to increase while the training loss continues to go down, it is often considered to be memorization. With hyperparameters (weight decay) extremely long training may result in the test loss eventually going down, allowing for generalization to occur. While not fully understood, it is important to be aware of this phenomenon. </p> <p>??? Multimodal Neurons in Pretrained Text-Only Transformers Neat demonstration \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.\"  </p> Scaling Data-Constrained Language Models Demonstrations that repeated token use is less valuable than new token use. <p>Github </p>"},{"location":"Using/index.html","title":"Use and Manage","text":"<p>Managing The GenAI amounts to effectively successfully working with the evolving technology in such a way that it creates. </p>"},{"location":"Using/by_application.html","title":"By application","text":""},{"location":"Using/by_application.html#healthcare","title":"Healthcare","text":"Genome-wide prediction of disease variant effects with a deep protein language model 'A Model that predects bad genetic variants' <p>Here we implemented a workflow generalizing ESM1b to protein sequences of any length and used it to predict all ~450 million possible missense variant effects across all 42,336 protein isoforms in the human genome.</p> The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics A quality set of JAX-enabled transformer models for use in downstream uses. <p>They use 6mer tokenization and embeddings. Non-commercial license.  Github </p> ChemChrow <p>Github</p>"},{"location":"Using/commercial_products.html","title":"Platforms","text":""},{"location":"Using/commercial_products.html#building-and-deploying","title":"Building and deploying","text":"<ul> <li>Arthur</li> <li>Fixie</li> </ul>"},{"location":"Using/commercial_products.html#llm-training-deployment","title":"LLM Training + Deployment","text":"<ul> <li>\ufe0fCodeTF From Salesforce</li> <li>Azure Open AI samples Sample end-to-end use cases with chatbots, content generation. </li> <li>RLHF with DeepSpeed (Microsoft)</li> <li>vLLM a python repo to help run LLMs. </li> </ul>"},{"location":"Using/commercial_products.html#a-few-self-referentially-useful-services-using-gpt-4","title":"A few self-referentially useful services Using GPT-4","text":"<ul> <li>Sourcegraph and the Cody.ai agent that it uses to help guide developers.</li> <li>LSIF.dev A community-driven source of knowledge for Language Server Index Format implementations\"</li> </ul>"},{"location":"Using/commercial_products.html#chat-toold","title":"Chat Toold","text":"<ul> <li>Azure Chat</li> </ul>"},{"location":"Using/commercial_products.html#coding-tools","title":"Coding Tools","text":"<ul> <li>Copilot - AI pair programmer by GitHub</li> <li>RepoCoder Github Provides a tool to enable AI agents to generate code for existing GitHub repositories </li> <li>TabNine - AI code completion tool</li> <li>DeepTabNine - Open source version of TabNine code completion model</li> <li>ChatGPT Does quite well with code creation </li> </ul>"},{"location":"Using/commercial_products.html#writing","title":"Writing","text":"<ul> <li>Sudowrite</li> </ul>"},{"location":"Using/governing.html","title":"Governing","text":"<p>Governing is an essential component to effective AI usage, especially within larg organizations or when the use of AI for a product has greater potential to cause harm in its design. Applications of AI need to be evaluated based on their risk to do harm and be used ethically.</p>"},{"location":"Using/governing.html#why-govern","title":"Why govern?","text":"<p>In order have the greatest potential positive impact in your use of AI, governance is essential. The larger the organization, the greater the importance of governance to help minimize needlessly duplicated internal systems and efforts. Even for smaller organizations, effective governance from the beginning will enable your organization to more reasonably create and deliver effective and responsible AI-enabled solutions. </p>"},{"location":"Using/governing.html#how-to-govern","title":"How to Govern","text":"<ol> <li>Establish an appropriate body of leadership and a surrounding community that supports the development of AI that is both responsible and effective. </li> <li>Create or adopt a set of AI principles that align with your company, </li> <li>Creast or adopt a set of procedures for creating, evaluating, and managing your AI systems. </li> <li>Create, license, or otherwise use AI _ML ops observability platforms/tools that you will use to implement and maintain AI-enabled projects that is consistent with your procedures and principles. </li> <li>Transparently communicate the development and status of your AI-enabled system with internal and regulatory bodies.</li> </ol>"},{"location":"Using/marking_and_detecting.html","title":"Marking and detecting","text":"<p>It is increasingly apparent that the gap between content created by people and by AI is closing. In fact Open AI confirms this. There are challenges with false-positive dections where person-created content, like the Constitution of the United States have been inappropriately attributed to AI. </p> <p>This is likely going to be worse as AI can be used to mimic the style of individuals, through fine-tuning, multi-shot prompting, etc..</p> <p>That said, there are a few detectors that might be useful in understanding content's origin -- they just need to be used with a degree of uncertainty.</p> <p>Here are a few:</p> <ul> <li>Sapling AI content detector</li> </ul>"},{"location":"Using/ml_ops.html","title":"Ml ops","text":"<p>AI or ML operations, or ML Ops enables streamlined enablement of AI-enabled solutions.</p>"},{"location":"Using/ml_ops.html#references","title":"References","text":"<p>Systems from Google</p>"},{"location":"Using/observability.html","title":"Observability","text":"<p>Understanding and enhancing Generative AI hinges largely on comprehensive monitoring and observability of the AI model's performance and its numerous operational parameters. In this light, observability refers to the capacity to examine and understand the inner workings of generative models, while closely monitoring their output quality. </p>"},{"location":"Using/observability.html#exploring-model-and-infrastructure-performance-monitoring","title":"Exploring Model and Infrastructure Performance Monitoring","text":""},{"location":"Using/observability.html#observing-the-model","title":"Observing the Model","text":"<p>Observation forms the bedrock of Generative AI models. Continual tracking and analysis of these models furnishes detailed insights into their operational efficacy and identifies potential areas for improvement, thereby optimizing their function overall.</p>"},{"location":"Using/observability.html#functionality-tracking","title":"Functionality Tracking","text":"<p>With software development, every function plays a crucial role. It's pivotal to observe these functions to identity bugs and areas that warrant enhancement. Consequently, this can boost software efficiency and minimize system lags.</p>"},{"location":"Using/observability.html#monitoring-the-infrastructure","title":"Monitoring the Infrastructure","text":"<p>Both hardware and software infrastructure holds immense importance to any AI model. Their observability is therefore key to pinpoint and solve potential glitches that could hinder the model's operational efficiency.</p>"},{"location":"Using/observability.html#a-closer-look-at-input-and-output-parameters-monitoring","title":"A Closer Look at Input and Output Parameters Monitoring","text":""},{"location":"Using/observability.html#keeping-an-eye-on-inputs","title":"Keeping an Eye on Inputs","text":"<p>Keeping a tab on the input parameters of your model can yield rich insights into how it functions. In this process, you can pick up on any anomalies or inconsistencies in the data that could impact the model's operations.</p>"},{"location":"Using/observability.html#observing-outputs","title":"Observing Outputs","text":"<p>A continuous cycle of tracking and observation of the output, in tandem with the coinciding input, allows us to measure the model's correctness levels. This can help identify recurring errors or boost the model's resilience against variable inputs.</p>"},{"location":"Using/observability.html#a-detailed-analysis-of-performance-metrics","title":"A Detailed Analysis of Performance Metrics","text":""},{"location":"Using/observability.html#observing-inference-costs","title":"Observing Inference Costs","text":"<p>Cost of inference forms a significant part of any computation process. A thorough evaluation at regular intervals can guide adaptations in the model to cut down on its resource consumption. This ensures the model operates economically, thereby elevating its efficiency.</p>"},{"location":"Using/observability.html#monitoring-inference-speed","title":"Monitoring Inference Speed","text":"<p>Monitoring the speed at which a model infers results can aid in optimizing its efficiency, thereby cutting down on delays and speeding up operations. It is through a careful track of these speeds that you can identify system bottlenecks and areas of productivity enhancement.</p>"},{"location":"Using/observability.html#libraries-and-tools","title":"Libraries and Tools","text":"<p>E2B's integration in AI agent technology stacks opens up new avenues, where it comfortably sits at the bottom, and is agnostic to the framework it operates in.</p> <p>llmonitor provides self-hosted model monitoring for costs/users/requrets, feedback, etc...</p>"},{"location":"Using/regulation.html","title":"Regulation","text":"<p>Because of challenges and ethical considerations surrounding GenAI, it is essential to know what is being considered and why and how that may impact specific fields and society at large.  The extent of its influence necessitates careful regulation to both maximize its potential benefits and mitigate potential risks.</p> <p>Here we highlight broad considerations and approaches relevant to the regulation of Generative AI.</p>"},{"location":"Using/regulation.html#key-considerations-in-genai-regulation","title":"Key Considerations in GenAI Regulation","text":""},{"location":"Using/regulation.html#ethical-regulations","title":"Ethical Regulations","text":"<p>GenAI has significant implications for ethics and public interest. Regulatory measures should ensure the ethical use of GenAI, balancing its capabilities with moral boundaries. Ethical regulations should cover principles of fairness, transparency, privacy, and accountability.</p>"},{"location":"Using/regulation.html#impact-on-society","title":"Impact on Society","text":"<p>Consider the potential societal impacts of GenAI. Regulations need to protect from possible misuse, including the creation of deepfake videos and misinformation campaigns. Regulatory measures could include stipulations against intrusive surveillance, deepfakes, and malicious intent.</p>"},{"location":"Using/regulation.html#data-privacy-and-security","title":"Data Privacy and Security","text":"<p>Privacy concerns with GenAI are also paramount. Data used in generative models should be thoroughly checked to ensure it does not contain sensitive information.</p>"},{"location":"Using/regulation.html#transparency-and-accountability","title":"Transparency and Accountability","text":"<p>Transparency in GenAI operations is vital. Users should understand the results produced by generative models and the reasoning behind them. Similarly, accountability measures should enforce repercussions for misuse or harmful outcomes from GenAI applications.</p>"},{"location":"Using/regulation.html#regulatory-approaches","title":"Regulatory Approaches","text":""},{"location":"Using/regulation.html#collaborative-design-of-policies","title":"Collaborative Design of Policies","text":"<p>Policy design and enforcement around GenAI require proactive collaboration between AI developers, researchers, policymakers, and stakeholders from all segments of society. </p>"},{"location":"Using/regulation.html#adaptable-regulatory-framework","title":"Adaptable Regulatory Framework","text":"<p>Given the rapid progress in AI, it's critical that regulatory frameworks can adapt quickly to evolving technologies. Legislation should be sufficiently flexible to accommodate advancements in GenAI yet robust enough to maintain its principles and intent.</p>"},{"location":"Using/regulation.html#proactive-vs-reactive-regulations","title":"Proactive vs. Reactive Regulations","text":"<p>While it's natural to regulate in response to emerging issues ('reactive regulation'), a more proactive approach would anticipate potential future issues and legislate accordingly.</p>"},{"location":"Using/regulation.html#international-harmonization","title":"International Harmonization","text":"<p>Since GenAI technologies operate globally, regulations also need to be harmonized across borders. International cooperation should be fostered for unified governance.</p>"},{"location":"Using/regulation.html#essential-references","title":"Essential References","text":"<ul> <li>Foundation model Providers EU AI compliance - An in-depth analysis on how Machine Learning companies can achieve compliance with the EU's proposed AI regulations.</li> </ul>"},{"location":"Using/web_plugins.html","title":"Web plugins","text":""},{"location":"Using/web_plugins.html#plugins","title":"Plugins","text":"<p>Plugins are can enable connection of GenAI with input media, often via web interfaces</p> <ul> <li> <p>Mini Wob++ For web interactive environments for accomplishing different tasks. Quite useful.</p> </li> <li> <p>\ufe0fPrompt Genius</p> </li> <li> <p>FastChat Conversation This very nice 'multi model' chat interface class allows for effective translation between different models.</p> </li> </ul>"},{"location":"Using/web_plugins.html#back-end","title":"Back-End","text":"<ul> <li>MaxAI.me A nice chrome pluging + eventual system  that makes your openAI connect to data more directly.</li> </ul>"},{"location":"Using/deploying/index.html","title":"Deploying","text":"<p>The deployment of models enables callers, people, or other software, to use them. While deployment may initially consist of only 'making a model available for calling'. </p> <p>Because the model may be one limiting- consider the deployment of the model to be separate from the deployment of the model's encapsulating project, though they are directly connected.  </p> <p>There are many component touchpoints along the way, and more so for customers that have higher requirements.</p> <p>Quickly, models of the desired specs must be stored in a file and then loaded for serving. Serving as user inputs that are routed to the served model, optionally batched to improve average request latency, and outputs returned routed appropriately to users. </p> <p>As would be done for other AI-enabled products, you will need to have in mind the following</p>"},{"location":"Using/deploying/index.html#1-caller-needs-customer-requirements","title":"1. Caller needs (customer requirements)","text":"<p>What the caller requires will depend on the target audience your offering is provided. Focusing on narrower audiences allow you to have fewer (initial) requirements and may enable MVP generation quickly. These audiences can expand or shift as needed. Often needs will require 'rapid' results that are 'good'. </p>"},{"location":"Using/deploying/index.html#2-servable-model-to-appropriately-service-customer-and-environmental-requirements","title":"2. Servable model to appropriately service customer and environmental requirements.","text":"<p>The models must be sufficient to provide the content that the model have a sufficiently reasonable latency that it can enable the throughput requirements of your model. </p> <p>To enable a properly servable model, it may likely be required to optimize the serving of your models.</p>"},{"location":"Using/deploying/index.html#compute-needed-to-enable-service","title":"Compute needed to enable service","text":"<p>Here are some general considerations (from AWS) regarding how to consider the requirements of model deployment.</p> <p></p>"},{"location":"Using/deploying/index.html#budget-available-the-compute","title":"Budget available the compute","text":"<p>Your calculated budget will be useful to consider the monetization strategy of your tool. While highly dependant on your business model, knowing when to inspire greater model serving optimization to prevent 'too much compute'. </p>"},{"location":"Using/deploying/index.html#compute-back-end-service-and-framework-that-will-work-with-the-budget-you-have","title":"Compute back end service and framework that will work with the budget you have","text":"<p>To determining your back-end will involve selecting from both DIY and full-service frameworks that you use on some compute host solution and perhaps connected with other tools and libraries that can help your solution. </p>"},{"location":"Using/deploying/index.html#front-end-that-provides-the-appropriate-visualization","title":"Front End that provides the appropriate visualization","text":"<p>At the end of a model that is ready to be deployed, you'll need to get the results to the end-user in a useful manner. Look into the discussion on front ends for some quality solutions and best practices to for your model output.</p> <p>Keep in mind the needs will change as the understanding of all of the answers above shifts. Still, it is important to get something that you can iterate from, particularly if your solution involves some form of a data flywheel.</p>"},{"location":"Using/deploying/index.html#tips","title":"Tips","text":"State of GPT by Andrej Karpathy A stellar presentation to update on the general state of Genai enabled by GPT"},{"location":"Using/deploying/index.html#references","title":"References","text":"Emerging Architectures for LLM Applications A very nice discussion of the components and their interactions via orchestration systems. <p> [^n1]</p> Challenges and Applications of Large Language Models Kaddour et al Well done and thorough."},{"location":"Using/deploying/index.html#overview-literature","title":"Overview Literature","text":"<p>Below are some overviews to help with practical aspects of Generative AI, particularly GPT and LLMs.</p> <ul> <li> <p>Neptune-nlp-models-infrastructure</p> </li> <li> <p>How to Deploy Large Size Deep Learning Models Into Production</p> </li> </ul>"},{"location":"Using/deploying/back_end.html","title":"Back end","text":""},{"location":"Using/deploying/back_end.html#libraries","title":"Libraries","text":"<p>FlexFlow Low-Latency, High-Performance LLM Serving</p> <p>Check this out!   </p> <p>llm A CLI utility and Python library for interacting with Large Language Models, including OpenAI, PaLM and local models installed on your own machine.</p> vLLM utilizes PagedAttention to manage attention keys/values to enable 24x throughput than other transformers w/out architecture changes <p>\"PagedAttention allows storing continuous keys and values in non-contiguous memory space. Specifically, PagedAttention partitions the KV cache of each sequence into blocks, each block containing the keys and values for a fixed number of tokens. During the attention computation, the PagedAttention kernel identifies and fetches these blocks efficiently.\"  Github</p> Text Generation Inference an open-sourced implementation forked from HF <p>\"A Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.\"   </p> <p>Lit-Gpt Hackable implementation of state-of-the-art open-source large language models released under the Apache 2.0 license.</p> <p>Torch Serve enable efficient serving.</p> Triton Inference Server Part of NVIDIA AI Inference <p>Tutorial</p> <p>litellm by BerriAI provides code to enable railways deployed on railway.app</p> <p>Railway.app</p>"},{"location":"Using/deploying/back_end.html#platforms","title":"Platforms","text":"<p>Azure-Chat-GPT to run GPT on Azure services</p> Amazon Sagemaker and the AWS suite allows for streamlined running of AI models in various manners <p>Example Code</p> <p>Lamini to help you build your AI moat</p> <p>[Lamini](</p>"},{"location":"Using/deploying/back_end.html#tutorials","title":"Tutorials","text":"<p>GCP Tutorial</p>"},{"location":"Using/deploying/computation.html","title":"Computation","text":""},{"location":"Using/deploying/computation.html#gpus","title":"GPUS","text":"<p>In order to create models, large volumes of matrix multiplication is necessary. GPUs are designed for this. </p> <p>Tim Dettmers on GPUs</p>"},{"location":"Using/deploying/frameworks.html","title":"Frameworks","text":"<p>There is a AI-Cambriatic explosion of services, methods, frameworks and tooling to better-enable the creation and deployment of models from beginning to end. While there may be complete end-to-end providers for generating valuable GenAI solutions, there is still a great deal of value in implementing and experimenting with your own stacks. </p> <p>There are additioanlly useful libraries and tools that are worthwhile checking out.</p> <p>tldr; Here are the prominent frameworks</p> <ul> <li>Langchain is a early system that has stellar success with a principled design allowing for extensive applications to built on top of it. </li> <li>Llama Ecosystem is a a community of Llama-focused modelers, based on the Meta model called Llama, Llama-2 and beyond. </li> <li>A number of others.</li> </ul> <p>As a note the excitement about the tooling around Generative AI make it hard to keep up with development and deprecation of powerful frameworks and tools. Some of the mentioned references may not be fully completed, or even nascent repos to build their intended purposes (described here). Please let us know if we are missing anything here. </p>"},{"location":"Using/deploying/frameworks.html#frameworks","title":"Frameworks","text":"<p>Starting with base programming languages, increasingly higher level frameworks enable training and calling of AI models. Higher level orchestration libraries and platforms allow creating and evaluating chains, agents, and systems that sometimmes use visual-interfaces. These can be often augmented with various tools/packages/repositories. On top of these involve mostly or all-complete frameworks and platforms that enable nearly complete. </p>"},{"location":"Using/deploying/frameworks.html#base-languages","title":"Base languages","text":"<p>Prominent languages include python, C++/CUDA, and Javascript. Because of its popularity, we will be python-focused in this project.</p>"},{"location":"Using/deploying/frameworks.html#ai-level-software-libraries","title":"AI-level software libraries","text":"<ul> <li>PyTorch a popular python-focused system for creating and using AI.</li> <li>Tensorflow a popular multi-language eco-system for creating and using AI.</li> <li>spAcy is a library for advanced Natural Language Processing in Python and Cython.</li> </ul>"},{"location":"Using/deploying/frameworks.html#higher-level","title":"Higher level","text":"Pytorch Lightning Enables model training with Pytorch and minimizes the boilerplate <p>Model parallelism</p> Deep Speed (by MSFT) empowers ChatGPT-like model training with a single click, offering 15x speedup over SOTA RLHF systems with unprecedented cost reduction at all scales <p>Blog on Deepspeed Ulysses </p> <p>DeepSpeed-Ulysses uses a simple, portable, and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence lengths \"DeepSpeed-Ulysses partitions individual samples along the sequence dimension among participating GPU. Then right before the attention computation, it employs all-to-all communication collective on the partitioned queries, keys and values such that each GPU receives the full sequence but only for a non-overlapping subset of the attention heads. This allows the participating GPUs to compute attention for different attention heads in parallel. Finally, DeepSpeed-Ulysses employs another all-to-all to gather the results along the attention heads while re-partitioning along the sequence dimension.\"  Tutorial here</p>"},{"location":"Using/deploying/frameworks.html#fine-tuning","title":"Fine Tuning","text":"<p>LLM Finetuning Hub is an evolving model finetuning codebase. </p>"},{"location":"Using/deploying/frameworks.html#interaction-and-orchestration-frameworks-and-languages","title":"Interaction and Orchestration Frameworks and Languages","text":"<p>Handling the inputs/outputs to GenAI in a consistent and reliable manner has spurred the creation of software libraries that can work with GenAI that is called as a service, or hosted locally.</p>"},{"location":"Using/deploying/frameworks.html#langchain","title":"LangChain","text":"<p>Langchain Is a primitive python or javascript-based primitive 'LLM' language that enables planned and agentic AI.</p>"},{"location":"Using/deploying/frameworks.html#going-deeper","title":"Going deeper","text":"<ul> <li>Langchain service deployment</li> <li>Awesome Langchain</li> <li>Toolkit Generates LangChain plugins</li> <li>Langflow </li> </ul> <p>Their Stack </p> <p>Tutorials:</p> <ul> <li>https://www.pinecone.io/learn/langchain-prompt-templates/</li> <li>https://learn.deeplearning.ai/langchain/lesson/3/memory</li> </ul>"},{"location":"Using/deploying/frameworks.html#lmql","title":"LMQL","text":"<p>LMQL is a query language that enables simplified representations of chats and agents with minimal code. </p> An example query string. <p>``` \"Greet LMQL:[GREETINGS]\\n\" where stops_at(GREETINGS, \".\") and not \"\\n\" in GREETINGS</p> <p>if \"Hi there\" in GREETINGS:     \"Can you reformulate your greeting in the speech of \\      victorian-era English: [VIC_GREETINGS]\\n\" where stops_at(VIC_GREETINGS, \".\")</p> <p>\"Analyse what part of this response makes it typically victorian:\\n\"</p> <p>for i in range(4):     \"-[THOUGHT]\\n\" where stops_at(THOUGHT, \".\")</p> <p>\"To summarize:[SUMMARY]\" ```</p>"},{"location":"Using/deploying/frameworks.html#llama-ecosystem","title":"Llama ecosystem","text":"<p>Llama is a library and set of models that has an expanding community due to the generally open-source nature of high-quality Llama 2 model. </p> Code and models surrounding Llama <ul> <li>[LlamaGPT](https://github.com/getumbrel/llama-gpt A self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device.</li> <li>Lit-Llama</li> <li>MedAlpaca</li> <li>Llama-2 on a CPU and Github</li> <li>GPT LLM Training Generates and trains fine-tuned LLAMA-2 LLMs for specific tasks. </li> <li>llama index and Github for integrating data ingestion and models. </li> <li>LlamaHub (community library of data loaders)</li> <li>LlamaLab (cutting-edge AGI projects using LlamaIndex)</li> <li>Ollama.ai Provides on mac silicon Llama2 calling. Has a great idea that resembles docker files for agent creation and pulling.</li> <li>Running Llama 2 and other Open-Source LLMs on CPU Inference Locally for Document Q&amp;A</li> <li>Llama.cpp 4 bit llama on macbooks. </li> </ul>"},{"location":"Using/deploying/frameworks.html#others","title":"Others","text":"EmbedChain  is a framework to easily create LLM powered bots over any dataset. <p>Example: ```python     import os</p> <pre><code>from embedchain import Llama2App\n\nos.environ['REPLICATE_API_TOKEN'] = \"REPLICATE API TOKEN\"\n\nzuck_bot = Llama2App()\n\n# Embed your data\nzuck_bot.add(\"youtube_video\", \"https://www.youtube.com/watch?v=Ff4fRgnuFgQ\")\nzuck_bot.add(\"web_page\", \"https://en.wikipedia.org/wiki/Mark_Zuckerberg\")\n\n# Nice, your bot is ready now. Start asking questions to your bot.\nzuck_bot.query(\"Who is Mark Zuckerberg?\")\n# Answer: Mark Zuckerberg is an American internet entrepreneur and business magnate. He is the co-founder and CEO of Facebook.\n</code></pre> <p>```</p> txtai 'is an all-in-one embeddings database for semantic search, LLM orchestration and language model workflows. <p></p> <ul> <li>Flowise</li> <li>Chain Forge A data flow prompt engineering environment for evaluating ana analyzing LLM responses</li> <li>llm-chain ChatGPT and Alpaca support. Agentic with bash commands.</li> <li>Agent Flow</li> <li>Auto Chain</li> <li>Chatall To interact with multiple chatbots at the same time.</li> <li>LocalAI drop-in replacement REST API that\u2019s compatible with OpenAI API specifications for local inferencing.</li> </ul> Open Agent IN DEVELOPMENT Microservices approach to AGI. Modular components for AI apps or AGI agents"},{"location":"Using/deploying/frameworks.html#specific-components","title":"Specific components","text":""},{"location":"Using/deploying/frameworks.html#retrieval-augmented","title":"Retrieval Augmented","text":"<p>??? code \"RAGAS is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines</p>"},{"location":"Using/deploying/front_end.html","title":"Front end","text":""},{"location":"Using/deploying/front_end.html#visualization-needs","title":"Visualization needs","text":""},{"location":"Using/deploying/front_end.html#front-ends","title":"Front Ends","text":"<p>People have to well-designed access to GPT technology. Here are several popular repos to start your product out with. </p>"},{"location":"Using/deploying/front_end.html#frameworks-and-tooling","title":"Frameworks and Tooling","text":"<ul> <li>OobaBooga Text generation WebUI</li> <li>Streamlit</li> <li>DemoGPT Connects Langchain and streamlit to create dynamic apps that can be repeatedly used for interacting with Chat- GPTs. </li> <li>GPT Graph Allows for a graphical network representation of chat interactions.</li> </ul>"},{"location":"Using/deploying/libraries_and_tools.html","title":"Libraries and tools","text":""},{"location":"Using/deploying/libraries_and_tools.html#llm-ops","title":"LLM Ops","text":"<ul> <li>LLM Ops</li> <li>Reliable GPT A wrapper that prevents failures due to rate limiting requests. </li> </ul>"},{"location":"Using/deploying/libraries_and_tools.html#models","title":"Models","text":"<p>Here we share a selection of repositories, that enable the creation of models.</p> <ul> <li>Hugging Face Transformers</li> </ul>"},{"location":"Using/deploying/libraries_and_tools.html#finetuning","title":"Finetuning","text":"<p>Please see the finetuning page for more in depth information on this. </p> <ul> <li>Adapters for Hugging Face</li> <li>Chatall To interact with multiple chatbots at the same time.</li> <li>LocalAI drop-in replacement REST API that\u2019s compatible with OpenAI API specifications for local inferencing.</li> </ul> Tool Bench 'This project (ToolLLM) aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerful LLMs with general tool-use capability.' <p></p>"},{"location":"Using/deploying/libraries_and_tools.html#serving","title":"Serving","text":"<p>Open LLM to run inference with any open-source large-language models, deploy to the cloud or on-premises, and build powerful AI apps.</p>"},{"location":"Using/deploying/libraries_and_tools.html#distributed","title":"Distributed","text":"<p>!!! \"Petals Run large language models at home, BitTorrent-style.\"</p> <pre><code>Generate text with distributed LLaMA 2 (70B), Stable Beluga 2, Guanaco-65B or BLOOM-176B and fine\u2011tune them for your own tasks \u2014 right from your desktop computer or Google Cola\n[Launch your own swarm](https://github.com/bigscience-workshop/petals/wiki/Launch-your-own-swarm)\n</code></pre>"},{"location":"Using/deploying/libraries_and_tools.html#programming-convenience","title":"Programming Convenience","text":"<p>!!! tip \"Magentic     A nice and simple plugin that allows a <code>@prompt</code> decorator to call functions as an llm, including function-choice calls.</p> <p>??? example \"their example <pre><code>from typing import Literal\n\nfrom magentic import prompt, FunctionCall\n\n\ndef activate_oven(temperature: int, mode: Literal[\"broil\", \"bake\", \"roast\"]) -&gt; str:\n\"\"\"Turn the oven on with the provided settings.\"\"\"\n    return f\"Preheating to {temperature} F with mode {mode}\"\n\n\n@prompt(\n    \"Prepare the oven so I can make {food}\",\n    functions=[activate_oven],\n)\ndef configure_oven(food: str) -&gt; FunctionCall[str]:\n    ...\n\n\noutput = configure_oven(\"cookies!\")\n# FunctionCall(&lt;function activate_oven at 0x1105a6200&gt;, temperature=350, mode='bake')\noutput()\n# 'Preheating to 350 F with mode bake'\n</code></pre></p>"},{"location":"Using/deploying/libraries_and_tools.html#memory-interaction","title":"Memory Interaction","text":"<ul> <li>Deploying on Azure for Embeddings</li> <li>Integrating with Azure Services</li> </ul> <p>GPTCache to quickly Cache your results to speed second-time queries.</p>"},{"location":"Using/deploying/libraries_and_tools.html#executors-and-interpeters","title":"Executors and Interpeters","text":"<p>Executors are programming levels of abstraction that encourage the execution of any tools or intractions with internal and external memories and states. </p> <p>Interpreters are executors that facilitate model computation by parsing, formatting, or otherwise preparing the data for effective use. They can also be used to interpret output to perform routing of actions. </p> <p>Such efforts can be used to reduce input complexity, token-count, to detect potentially unreasonable inputs or outputs. These interpreters may be agents or models themselves, thought that is not required. </p> <p>Link Routing</p> <p>A model may not be guaranteed to produce equivalent output based on a complex input string such as an html address. Consequently, pre-parsing the output and substituting a simple name for an address, such as 'html_1', and then re-introducing that within any output, both using RegEx, may enable more effective output. </p> <ul> <li> <p>Guardrails To help format output and prevent improper prompts.</p> </li> <li> <p>Semantic Kernel, Github</p> </li> <li> <p>\ufe0fGuidance Interleaving generation, prompting and logical control to single  continuous flow.</p> </li> </ul>"},{"location":"Using/deploying/libraries_and_tools.html#data-creation","title":"Data Creation","text":"<p>Generative AI is a splendid use-case for creating data that can be used to train or refine new models. Here are some tools that allow for creation of data for down-stream purposes, always being sure to be consistent with dual-use concerns.</p> <p>AutoLabel A nice pythonic system for generating semantic labels repeatedly for use in downstream datasets</p> <p>Kor For extracting structured data using LLMs.</p>"},{"location":"Using/deploying/libraries_and_tools.html#general","title":"General","text":""},{"location":"Using/deploying/libraries_and_tools.html#network-visualization","title":"Network Visualization","text":"<p>Being able to see the 'structure' of some neural networks make it easier to understand, and more aesthetic.  Please see PlotNeuralNet and a nice writeup on how to use it. </p>"},{"location":"Using/ethically/index.html","title":"Ethically","text":""},{"location":"Using/ethically/index.html#bias-and-fairness","title":"Bias and Fairness","text":"<p>Mitigating bias in data and models Evaluating model fairness Inclusive model development Transparency and Explainability</p>"},{"location":"Using/ethically/index.html#interpretability","title":"Interpretability","text":"<p>Techniques for explainability Right to explanation Safety</p>"},{"location":"Using/ethically/index.html#risk-mitigation","title":"Risk Mitigation","text":"<p>Risk assessment Safeguards against misuse Privacy</p>"},{"location":"Using/ethically/index.html#data-privacy","title":"Data privacy","text":"<p>Anonymization and de-identification Encryption and secure computing</p>"},{"location":"Using/ethically/index.html#governance","title":"Governance","text":"<p>Internal auditing processes External oversight Accountability measures Access and Inclusion</p>"},{"location":"Using/ethically/index.html#fair-and-equitable-access","title":"Fair and equitable access","text":"<p>Digital divides Participatory design Compliance</p>"},{"location":"Using/ethically/index.html#laws-and-regulations","title":"Laws and regulations","text":"<p>Responsible development guidelines Ethics review processes</p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html","title":"Alignment and exential concerns","text":"<p>There is a notable degree of concern for the potential for Generative, and eventually General AI, to cause harm. The harm can occur either accidentally or to the intentional use of GenAI. </p> <p>There is also self-existenial concerns related to GenAI models themselves. This is found due to the potential that when models are trained on data that is produced by other models, there can be a degredation in performance, known as model collapse. </p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#background","title":"Background","text":"<p>TODO: This sections needs complete remodling. </p>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#alignment-with-people","title":"Alignment with People","text":"<ul> <li>Personal Universes: A Solutiont to the Multi-Agent Value Alignment Problem</li> </ul>"},{"location":"Using/ethically/alignment_and_exential_concerns.html#alignment-with-genai","title":"Alignment with GenAI","text":"<ul> <li>Model Collapse Explained</li> </ul>"},{"location":"Using/ethically/dual_use_concerns.html","title":"Dual use concerns","text":"<p>The potential for AI to generate beneficial results or outcomes is very promising. At the same time, however, AI can be intentionally used for harmful outcomes. Such is known as a dual-use concern.  This has been found in a number of research articles, and quite prominently when working to evaluate the safety of drug discovery</p>"},{"location":"Using/ethically/fairness.html","title":"Fairness","text":""},{"location":"Using/ethically/fairness.html#elements-of-ai-fairness","title":"Elements of AI Fairness","text":"<p>Understanding AI fairness can be complex, but let's break it down into simple, digestible elements.</p>"},{"location":"Using/ethically/fairness.html#1-understanding-bias","title":"1. Understanding Bias","text":"<p>Bias in AI systems comes from various sources. It could be in the data used to train the AI, the design of the AI algorithms, or the ways AI systems are deployed and used. AI fairness, therefore, needs to address these sources of bias.</p> <p>Data Bias: This happens when the data used to train the AI is not representative of the population it will be serving, leading to biased predictions or decisions. An example is if an AI system was trained on data mostly from one demographic group, it might not perform well on other groups.</p> <p>Algorithmic Bias: This is when the algorithms that power AI systems inherently favor one outcome over another. They might do this due to design flaws, biased inputs, or even the optimization goals set by their creators.</p>"},{"location":"Using/ethically/fairness.html#2-fairness-metrics","title":"2. Fairness Metrics","text":"<p>Measuring fairness is a crucial aspect of AI fairness. This involves setting and monitoring fairness metrics that determine how well an AI system is performing in terms of fairness.</p> <p>Disparity Metrics: Measures how an AI's decisions or predictions differ among various demographic groups.</p> <p>Equality Metrics: Measures how equally an AI system treats individuals, regardless of their demographic group.</p>"},{"location":"Using/ethically/fairness.html#3-transparency","title":"3. Transparency","text":"<p>Transparency is about making sure the workings of an AI system are understandable to people. This includes both the technical side (e.g., how the AI's algorithms work) and the practical side (e.g., how decisions made by the AI impact individuals).</p> <p>Explainability: AI systems should be designed to provide explanations about their decisions or predictions. This helps individuals understand how a system came to a certain conclusion.</p> <p>Interpretability: This involves designing AI systems in ways that their workings can be understood by humans, even if they don't have technical expertise in AI.</p>"},{"location":"Using/ethically/fairness.html#4-accountability","title":"4. Accountability","text":"<p>Accountability in AI fairness refers to the obligation of AI system developers and operators to answer for the system's effects on individuals and society.</p> <p>Auditing: Regular checks on an AI system's decisions and performance to ensure it's upholding fairness standards.</p> <p>Redress Mechanisms: Clear pathways for people to challenge decisions made by an AI system, particularly if they believe they've been treated unfairly.</p>"},{"location":"Using/ethically/fairness.html#5-inclusion","title":"5. Inclusion","text":"<p>Inclusion is about making sure AI systems serve all individuals fairly and equitably, regardless of their demographic characteristics.</p> <p>Diversity in Design: This involves ensuring that the teams creating AI systems are diverse, which can help to avoid some forms of bias and make the systems more effective for a wider range of individuals.</p> <p>Accessibility: AI systems should be designed in ways that they can be used and understood by people with varying abilities, languages, and cultural contexts.</p> <p>NOTE: Generated with GPT-4</p>"},{"location":"Using/responsibly/index.html","title":"Responsibly","text":"<p>Be sure to consider the unintended consequences.</p> <ul> <li>Sundar Pichai, Google's CEO</li> </ul> OWASP <p>The OWASP Top 10 for Large Language Model Applications project aims to educate developers, designers, architects, managers, and organizations about the potential security risks when deploying and managing Large Language Models (LLMs). The project provides a list of the top 10 most critical vulnerabilities often seen in LLM applications, highlighting their potential impact, ease of exploitation, and prevalence in real-world applications. Examples of vulnerabilities include prompt injections, data leakage, inadequate sandboxing, and unauthorized code execution, among others. The goal is to raise awareness of these vulnerabilities, suggest remediation strategies, and ultimately improve the security posture of LLM applications. You can read our group charter for more information</p>"}]}