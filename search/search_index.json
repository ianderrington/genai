{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"\ud83c\udf89 Welcome!","text":"<p>Welcome to our open-source project on Generative AI, or GenAI \ud83e\udd16. The field of GenAI is rapidly expanding and becoming increasingly complex, and our mission is to make this topic more accessible and understandable for everyone.</p> <p>This project aims to provide comprehensive, full-spectrum knowledge on a range of GenAI topics \ud83d\udcd8. We've built this documentation in Markdown to encourage collaboration and continuous learning through GitHub pull requests \ud83e\udd1d.</p> <p>One of our main goals is to have this project written by GenAI itself \ud83d\ude80, enabling us to keep up with the complexity of information and advances in the field. To achieve this, we are focusing on:</p> <ul> <li>\ud83d\udcdd Creating a useful, base documentation repository that aids authors in generating self-descriptive repositories.</li> <li>\ud83d\udd04 Developing an automated merge and build system for the website that delivers information in an aesthetic and readable manner.</li> <li>\ud83d\udd01 Establishing a self-referential build system using Langchain and learned information, potentially utilizing AutoPR, among others.</li> </ul> <p>We are aware this is an ambitious task, but we believe in the power of GenAI to explain itself in a way that everyone can understand and benefit from \ud83d\udcaa. If you share our vision and would like to contribute, we warmly welcome your input. P</p> <p>lease follow these guidelines to create a PR. Together, let's push the boundaries of what we can do with GenAI! \ud83c\udf0d</p> <p>Quick navigation</p> <p>You can type <code>,</code> or <code>.</code> to go forward/backwards. You can also press <code>/</code> at any time and start searching for what you're looking for~</p>"},{"location":"to_sort.html","title":"To sort","text":"<p>phi 1 https://www.reddit.com/r/LocalLLaMA/comments/14ez6qf/microsoft_makes_new_13b_coding_llm_that/ chat law https://arxiv.org/abs/2306.16092v1?utm_source=tldrai  talk codebase https://github.com/rsaryev/talk-codebase?utm_source=tldrai</p> <p>https://martinfowler.com/articles/building-boba.html?utm_source=tldrai</p> <p>rap reproducible analytic pipelines https://digital.nhs.uk/blog/data-points-blog/2023/why-were-getting-our-data-teams-to-rap#:~:text=Reproducible%20analytical%20pipelines%20(RAP)%20are,in%20our%20Data%20Services%20directorate</p> <p>build your own data https://arxiv.org/abs/2306.13651v1?utm_source=tldrai self supervized</p> <p>https://styledrop.github.io/ https://www.youtube.com/watch?v=Ff4fRgnuFgQ&amp;t=9s</p> <p>https://github.com/langchain-ai/streamlit-agent https://github.com/smol-ai/developer https://github.com/vinayprabhu/X-is-all-you-need https://github.com/ThomasEwing04/SMOL_AI https://github.com/kyrolabs/awesome-langchain https://cameronrwolfe.substack.com/p/teaching-language-models-to-use-tools?r=2bjtip&amp;utm_medium=ios&amp;utm_campaign=post</p> <p>https://www.quivr.app/chat</p>"},{"location":"Managing/brainstorming.html","title":"Brainstorming","text":""},{"location":"Managing/brainstorming.html#ideas","title":"Ideas","text":"<p>Ideas are a dime a dozen.</p> <p>But if you don't have one, you won't find a cent.</p> <p>Here are some ideas of things that might be explored particularly in conjunction with this. </p> <ul> <li>A codebase watcher and executor agent for public codebases like in github. This would have a vector database + query  (+ build) system that would allow the code base to be queried and interacted with via 'execution' of various functions.  They would allow for tested execution of external codebases (and functions). Kind of like code interpreter but for not making new code but calling code that is already needed. This would allow code to use other code just as a person would.</li> </ul>"},{"location":"Managing/build_plan.html","title":"Build plan","text":"<p>To investigate: - [ ] build with https://docusaurus.io/ - [ ] Integrate example python notebooks and build with https://github.com/outerbounds/nbdoc - [ ] Build interactive graph representation of this site that includes summary information. Check this out and the examples     - [ ] https://melaniewalsh.github.io/Intro-Cultural-Analytics/06-Network-Analysis/02-Making-Network-Viz-with-Bokeh.html - [ ] Enable multiple LLM integration, for instance with Llama on OSX. </p>"},{"location":"Managing/contributing.html","title":"Contributing","text":"<p>In order to contribute...</p>"},{"location":"Managing/managing.html","title":"Managing","text":"<p>You cannot manage effectively what you do not understand effectively.</p> <p>Thanks for being interested in this project. This relays how we are putting together the components that enable this project to exist.</p>"},{"location":"Understanding/index.html","title":"Index","text":"<p>Background overview</p>"},{"location":"Understanding/agents/index.html","title":"Agents Gen(erative) AI","text":"<p>Agents in Gen()AI agents have access to 'tools' to provide them 'agency' beyond the ability to generate text or image based responses to the input data.</p> <p>Similar to bots, or other computerized automota, they may have the ability to run discretely, separately from standard chat-interfaces. Generally they involve the possibility of Human-in-the-loop to help correct odd components. </p>"},{"location":"Understanding/agents/index.html#basic-concepts","title":"Basic Concepts","text":"<ul> <li>Models: The 'intelligent' component returns an output for a given input. </li> <li>Input prompts that orient's and agent's response. </li> <li>Memory to enable writing and reading information that may be of use. </li> <li>Tools that enable more than text (or images) to be returned or otherwise acted upon. </li> <li>Interpreters that are used to process input or output. </li> <li>Chains which enable continuous flow of information, including memory, to downstream tasks. </li> <li>Agents can be quite different! Here are some examples of agents made both in academic and commercial settings. </li> <li>Systems of Agents that can allow for multiple agents with different sets of the components above, to interact and create powerful solutions.</li> </ul>"},{"location":"Understanding/agents/index.html#essential-references","title":"Essential references","text":"<p>Before we go on, there are several references that are of high merit that you may wish to check out!!!</p> <ul> <li>Agents overview by Lilian Weng As usual, a splendid post by Lilian Weng</li> <li>Awesome Agents of nicely curated list of systems using agents</li> </ul>"},{"location":"Understanding/agents/index.html#models","title":"Models","text":"<p>Models provide the computational core of Agents. Acting like a 'brain' that atakes in input prompts they return outputs. Generally the models may be considered <code>frozen</code> for a given agent, but sometimes, agentic feedback is used for helping model creation as with distillation </p> <p>We describe models thoroughly in an educational manner here and in an applied manner here. </p>"},{"location":"Understanding/agents/index.html#prompts","title":"Prompts","text":"<p>Garbage In \u2192 Garbage Out</p> <p>The common realization that bad input will lead to bad outputs becomes more nuanced when considering the degree to which small changes in input prompts can lead to wildly different outcome performance. Consequently, well-chosen prompts can functionally enable an agent, or not. </p> <p>Because of the importance and breadth of details involved with prompting, please visit this section. Note, that prompts will be model-specific, and if the model changes, either completely or with new architecture, the continued performance of a given prompt or prompt strategy is not certain. </p>"},{"location":"Understanding/agents/index.html#memory","title":"Memory","text":"<p>Like people, agents can be better enabled when they have access to memory.  We discuss memory thoroughly here.</p>"},{"location":"Understanding/agents/index.html#tools","title":"Tools","text":""},{"location":"Understanding/agents/index.html#interpreters","title":"Interpreters","text":"<p>Both the input and output into an LLM model may be intepreted, or otherwise parsed in a manner that makes the input or output more impactful. </p> <ul> <li>Native function calls and json support with OpenAI </li> </ul>"},{"location":"Understanding/agents/index.html#systems","title":"Systems","text":"<p>Generative AI systems involve the interaction of multiple individual GenAI elements that can act, to a coordinated degree, independently of other AI Agents. </p>"},{"location":"Understanding/agents/index.html#to-organize","title":"TO ORGANIZE","text":"<ul> <li> <p>\ufe0fGuidance Interleaving generation, prompting and logical control to single  continuous flow.</p> </li> <li> <p>AutoLabel A nice pythonic system for generating semantic labels repeatedly for use in downstream datasets</p> </li> <li> <p>This</p> </li> <li> <p>Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data Parameter efficient LLama Tuning and risk minimization with a new 'Self Distillation' with Feedback to improve itself even more. RESEARCH ONLY</p> </li> </ul>"},{"location":"Understanding/agents/actions_and_tools.html","title":"Actions and tools","text":""},{"location":"Understanding/agents/actions_and_tools.html#action","title":"Action","text":"<p>Actions may be be internal or externally focused.  focused generally related to an agent's '<code>memory</code>, or externally focused, with tools, though their distinction may be moot. </p> <p>Internal actions generally relate reading, writing or updating, an agents memory, memory state, such as free-text <code>scratech-pad</code>, an ordered <code>memory-log</code> or a vector database.</p> <p>External actions may be to act on simulated or real environments, or otherwise tracked <code>state</code>, or to use a toolthat an agent may be 'equipped with' to run. These can be API calls or local function calls. </p>"},{"location":"Understanding/agents/actions_and_tools.html#executors","title":"Executors","text":"<p>The action that an agent may take is enabled by an <code>AgentExecutor</code> or interpreter of the LLM output, that coordinates the call to perform the action. </p> <p>References</p> <ul> <li>Langchain Agent Executor</li> </ul>"},{"location":"Understanding/agents/actions_and_tools.html#tools","title":"Tools","text":"<p>Tools generally consist of single function calls to something that will return value to the end-point destination, be that the agent itself or a person interacting with an agent. </p>"},{"location":"Understanding/agents/actions_and_tools.html#toolkits","title":"Toolkits","text":"<p>Toolkits consist of tool pearings that often work together well. For instance, bash commands for file creation, deletion, naming and movement. Toolkits can be api-calls or </p> <p>References</p> <ul> <li>Langchain Toolkits</li> <li>Tool LLM This describes a novel approach enabling over 16000 API's to be called through an intelligent routing mechanism. Github Uses RapidAPI connector to do so.  </li> <li>Gorilla A Llama-focused high-quality API calling methods. </li> </ul>"},{"location":"Understanding/agents/chains.html","title":"Chains","text":""},{"location":"Understanding/agents/chains.html#chains","title":"Chains","text":"<p>Chains can be considered linked generative interactions where information can be processed with interepreters, tools, or other agents/GenAIs. Done well, they can be built up to form reasoning systems that can enable more successful reasoning, or task completion. </p> <p>These cna enable passing concepts or data and re-introducing them directly throughout the database. </p>"},{"location":"Understanding/agents/chains.html#basic-chains","title":"Basic Chains","text":"<p>Break an article up. This concept needs to carry forward in all mentions of items.</p> <p>jStarting from an input, an input may first analyzed with another algorithm, such as by splitting or substituting for html link for a token representing a variable. This output may then be directed to part of a template. The prompt-template. The prompt-templates then fill in the information. This information is then passed to the LLM. Then the LLM generates the output. This output may then again be processed to re-introduce extracted information removed the original prompt call (like htmls), to use the output to affect the next actions to be taken, such as printing the output for a person, calling programatic functions (tools) or sharing with specific downstream chains (routing).</p>"},{"location":"Understanding/agents/chains.html#examples","title":"Examples","text":"<ul> <li>Basic Chain (Chat) </li> <li>With human interaction</li> <li> <p>With prompt structuring. </p> </li> <li> <p>Routing Chain</p> </li> </ul> <p>Chain with memory storage and retrieval Chain with memory retrival  Multi-model chains.</p> <p>(Other chains from lang-chain)</p>"},{"location":"Understanding/agents/chains.html#resources","title":"Resources","text":"<ul> <li>Chain of thought hub</li> </ul>"},{"location":"Understanding/agents/chains.html#concepts","title":"Concepts","text":""},{"location":"Understanding/agents/chains.html#thought-structures","title":"Thought Structures","text":"<ul> <li>Skeleton of Thought A fun structure that resembles thoughtful creation of answers allowing for parallelization and hence speedup, with comparable or better results in answer generation. </li> <li>Large Language Model Guided Tree-of-Thought Github</li> <li> <p>\u203c\ufe0fTree of Thoughts: Deliberate Problem Solving with Large Language Models Github IDEA: Write Tree of Thoughts into Langchain?</p> </li> <li> <p>\u203c\ufe0fMeta Tree of thought</p> </li> <li> <p>Graph of Thought An excellent thought on what next to consider when dealing with knowledge (or other output like information) generation chains. </p> </li> <li> <p>Certified Reasoning with Language models A 'logical guide' tool that an LLM can use. It \" uses constrained decoding to ensure the model will incrementally generate one of the valid outputs.\" </p> </li> </ul>"},{"location":"Understanding/agents/chains.html#enhancements","title":"Enhancements","text":"<ul> <li>\u203c\ufe0f EmbedChain Creates embeddings for bots to be used. </li> </ul>"},{"location":"Understanding/agents/chains.html#implementation-frameworks","title":"Implementation Frameworks","text":""},{"location":"Understanding/agents/chains.html#langchain","title":"Langchain","text":"<ul> <li>\u203c\ufe0fLangchain A primative python or javascript based primitive 'LLM' language that enables planned and agentic AI.</li> <li>\u203c\ufe0fLangflow </li> <li>\u203c\ufe0fAwesome Langchain</li> <li>\u203c\ufe0fToolkit Generates LangChain plugins</li> </ul>"},{"location":"Understanding/agents/chains.html#tutorials","title":"Tutorials","text":"<ul> <li>https://www.pinecone.io/learn/langchain-prompt-templates/</li> <li>https://learn.deeplearning.ai/langchain/lesson/3/memory</li> </ul>"},{"location":"Understanding/agents/chains.html#llama-index","title":"Llama index","text":"<ul> <li>llama index and Github for integrating data ingestion and models. </li> <li>LlamaHub (community library of data loaders)</li> <li>LlamaLab (cutting-edge AGI projects using LlamaIndex)</li> </ul>"},{"location":"Understanding/agents/chains.html#others","title":"Others","text":"<ul> <li>\u203c\ufe0fFlowise</li> <li>\uff01Chain Forge A data flow prompt engineering environment for evaluating ana analyzing LLM responses</li> <li>\u203c\ufe0fllm-chain ChatGPT and Alpaca support. Agentic with bash commands.</li> <li>Auto Chain </li> <li>\u203c\ufe0fOllama.ai Provides on mac silicon Llama2 calling. Has a great idea that resembles docker files for agent creation and pulling.</li> </ul>"},{"location":"Understanding/agents/environments.html","title":"Environments","text":"<p>Environments consist of the information that an agent, or system of agents has access too. It can be the set of origins from where the agent gets its observations. These origins can places like be 'a person' as is for a chat-interface, a web-stream, for an alert agent. a simulation of a town. </p> <p>The environment also 'interprets' the output of any agent, possibly changing the environment or executing other sub-commands.  Effectively, the environment can be considered as performing tool-execution. </p> <p>In another example, the environment might parse an English-text output into a python-executable, and </p> <p>The environment can be considered, </p>"},{"location":"Understanding/agents/examples.html","title":"Examples","text":"<p>Agent types can be described by direct agentic ability to cause a change in the world.</p>"},{"location":"Understanding/agents/examples.html#text-agent","title":"Text Agent","text":"<p>An agent that can output only language text. Even thought the language can be 'interpreted' into different things, as is done in the environment. </p>"},{"location":"Understanding/agents/examples.html#text-image-agent","title":"Text + Image Agent","text":"<p>An agent that can output </p>"},{"location":"Understanding/agents/examples.html#robotic-agent","title":"Robotic Agent","text":"<p>A robotic agent can control mechanism impacting the mechanical position or other activity of a device. </p> <pre><code>graph TB\n    Agent((Agent)) --&gt;|makes| decision((Decision))\n    decision --&gt;|attempts| action((Action))\n    action --&gt;|passes| execution((Execution))\n    execution --&gt;|affects| environment((Environment))\n    execution --&gt;|generates| agentMemory((Agent's Memory))\n    agentMemory --&gt;|informs and effects| Agent\n    environment --&gt;|provides| observations((Observations))\n    observations --&gt;|informs and effects| Agent\n    execution --&gt;|queries| environment\n    AgentManager((Agent Manager)) --&gt;|affects| execution\n    Agent --&gt; |informs and effects| AgentManager\n    AgentManager --&gt; |informs and effects| Agent</code></pre>"},{"location":"Understanding/agents/examples.html#agent","title":"Agent","text":"<ul> <li>Learning to Reason and Memorize with Self-Notes \"Allows model to deviate from input context at any time to reason and take notes\"</li> </ul> <ul> <li>Large language models as tool makers Github Allows high-quality tools to be reused by more lightweight models.</li> </ul> <ul> <li>CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation</li> </ul> <ul> <li>\u203c\ufe0f ReAct Github </li> <li>Effectively Observe, Think, Act, Repeat. Has limited action space </li> <li>Reflexion: \"Reflexion, an approach that endows an agent with dynamic memory and self-reflection capabilities to enhance its existing reasoning trace and task-specific action choice abilities\"</li> <li>Github</li> <li>Inspired github </li> <li> <p>Teaching Large Language Models to Self-Debug <code>transcoder</code> </p> </li> <li> <p>Language Models can Solve Computer Tasks, Website, GitHub USes Recursive Criticism and Improvement. Combining with Chain of Thought it is even better. The method: Plan: Critique, Improve </p> </li> <li> <p>Explicit RCI: \"Review your previous answer and find problems with your answer.\" \u2192 \"Based on the problems you found, improve your answer.\" Recursively Criticizes and Improves its output. This sort of prompting outperforms Chain of Thought, and combined it works even better.  </p> </li> <li> <p>smolai https://www.youtube.com/watch?v=zsxyqz6SYp8&amp;t=1s</p> </li> <li> <p>LAION-AI An attempt an open-version of ChatGPT</p> </li> <li> <p>\u203c\ufe0fRobo-GPT</p> </li> <li> <p>Agent-GPT and Website \u2192 Doesn't have agency/tools... So it is not good. A fancy wrapper for multi-task planning and execution. Limited at present. </p> </li> <li> <p>\u203c\ufe0f  [AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn] (https://arxiv.org/pdf/2306.08640.pdf) Webpage Uses PEIL PLan execute inspect learn. Code coming soon. </p> </li> <li>\u203c\ufe0f GPT Engineer</li> </ul>"},{"location":"Understanding/agents/interpreters.html","title":"Interpreters","text":"<p>Interpreters facilitate model computation by parsing, formatting, or otherwise preparing the data for effective use. They can also be used to interpret output. </p> <p>Such efforts can be used to reduce input complexity, token-count, to detect potentially unreasonable inputs or outputs. These interpreters may be agents or models themselves, thought that is not required. </p> <p>Link Routing</p> <p>A model may not be guaranteed to produce equivalent output based on a complex input string such as an html address. Consequently, pre-parsing the output and substituting a simple name for an address, such as 'html_1', and then re-introducing that within any output, both using RegEx, may enable more effective output. </p>"},{"location":"Understanding/agents/interpreters.html#input-interpreters","title":"Input Interpreters","text":"<ul> <li> <p>Strategic Reasoning with Language Models Uses game trees and observed and inferred beliefs to achieve closer to optimal results. Powerful to consider for inferred beliefs and interacting in situations where negotiation or games are being played. </p> </li> <li> <p>\u203c\ufe0f Rebuff a prompt injection detection service.</p> </li> </ul>"},{"location":"Understanding/agents/interpreters.html#output-interpreters","title":"Output Interpreters","text":""},{"location":"Understanding/agents/interpreters.html#hybrid-interpreters","title":"Hybrid Interpreters","text":"<ul> <li> <p>\u203c\ufe0f Guardrails To help format output and prevent improper prompts.</p> </li> <li> <p>\u203c\ufe0fSemantic Kernel, Github</p> </li> </ul>"},{"location":"Understanding/agents/memory.html","title":"Memory","text":"<p>Agent memory is considered a state associated with a llm-call and effects the ability of LLM to respond, thereby helping to enable agentic ability. Memory augmented models enhance the capabilities of language models by ___ to improve their performance and efficiency. TODO: Read trillions of tokens paper. </p>"},{"location":"Understanding/agents/memory.html#memory-considerations","title":"Memory Considerations","text":"<p>Memory plays a crucial role in enhancing the efficiency of information recall and routing for different chains and agent interactions. </p> <p>In systems comprising Agents (and People), conversation buffers may be employed to keep track of information. These buffers, can be 'private',  can facilitate communication between any agents, storing response stacks that include agent-environment interactions.</p> <p>For text-based memory can consist of perfect text record or compressed summaries, that may or may not follow some form of memory-schema.</p> <p>Memory can be pushed (into prompt templates) and requested (based on GET memory requests from an LLM agent). </p>"},{"location":"Understanding/agents/memory.html#uses","title":"Uses","text":""},{"location":"Understanding/agents/memory.html#input-prompt-caching","title":"Input (prompt) Caching","text":"<p>Input caching is a technique that leverages memory to improve response time and efficiency. Instead of generating tokens based on the next input, it uses caching to identify responses that may have already been generated for similar prompts. This significantly enhances the efficiency of repeated queries. However, it may cause issues if the initial response was not satisfactory, as the system would return the same cached response.</p>"},{"location":"Understanding/agents/memory.html#parsed-information-routing","title":"Parsed information routing","text":"<p>Parsed information routing involves directing parsed or processed information to the appropriate destination. This can be particularly useful in systems with multiple agents or complex workflows.</p>"},{"location":"Understanding/agents/memory.html#implementations","title":"Implementations","text":"<p>Memory implementations can be based on memory types serialized and stored in many ways. Semantic searches can happen by looking at similar embeddings. </p> <p>These can be global or private, and structured inside agent classes or inside system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can be in memory and stored on disk or in the cloud. They allow informaion to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p> <p>Memory implementations can vary based on the type of memory used, and how it's serialized and stored. Semantic searches can be performed by comparing embeddings for similarity. These memory systems can be global or private, and can be structured within agent classes or within system message boards. They can be 'limited' or 'unlimited' (within appropriately established allocation limits). They can exist in memory, stored on disk, or in the cloud. They allow information to be routed at the appropriate time, and 'skipped' if necessary to work within context-window limitations.</p>"},{"location":"Understanding/agents/memory.html#types","title":"Types","text":""},{"location":"Understanding/agents/memory.html#vector-databases","title":"Vector databases","text":"<p>Vector databases, such as Pinecone, Qdrant, Weaviate, Chroma, Faiss, Redis, Milvus, and ScaNN, use embeddings to create query vector databases. These databases allow for efficient semantic searches. </p> <p>!!! example 'Example vector databases'     Please read this for more information  Vector Databases (primer by Pinecone.io)     - https://github.com/Helicone/helicone     - Website Github</p>"},{"location":"Understanding/agents/memory.html#traditional-databases","title":"Traditional databases","text":"<p>Databases that rely on query-languages such as SQL or non-SQL based databases, or even 'csv-type' information stores can be accessed and generated using agents. </p> <p>The models may generate queries that can be executed by by interpreters, though it is not guaranteed that the queries will be accurate. TODO: Find reference</p> <p>References</p> <p>For more information on memory implementations and caching, refer to the following resources:</p> <ul> <li>Langchain <code>memory</code></li> <li>Langchain <code>llm_caching</code></li> <li>Improving language models by retrieving from trillions of tokens</li> </ul>"},{"location":"Understanding/agents/systems.html","title":"Systems","text":"<p>When an agent (or model) interacts with a different agent in some way, it becomes a system of agents. This can be created by incepting and equipping different agents and enabling their output to be ingested and returned. It could be considered that an agent's input can be regarded as nother 'tool' where the call to the tool is to the different agent. While a reasonable perspective, because the same considerations can generally be applied to all agents, but not tools, we consider it separately. </p> <p>Binary system (asymmetric calling)</p> <p>ChatGPT calls DallE with a prompt it generated. DallE returns an image that is either returned or otherwise used in Chat GPT's final response.</p> <p>Multi-body system (bidirectional calling)</p> <p>A group of agents discussing their daily affairs and getting periodic environmental updates, like this paper</p>"},{"location":"Understanding/agents/systems.html#examples","title":"Examples","text":"<ul> <li> <p>MetaGPT An amazing solution that allows for interacting agents. </p> </li> <li> <p>Self-play GPT Uses different LLMs and different roles to provide feedback on how to improve and enable autonomous improvement while game playing. </p> </li> <li> <p>Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind Uses Theory fo Mind to try to improve student performance. Github</p> </li> <li> <p>Generative Agents: Interactive Simulacra of Human Behavior A simulation of different agents of different personalities with a time-evolving environment that could be manipulated by the agents.   In it they discuss several challenges and solutions:</p> <p>Remembering</p> <p>Observation Memory A memory stream maintaining a record of experience: memory objects with a description in natural language, and timestamping. Uses, recency, importance and relevance_ to add weight to information that is more recent, how the memory is compared in relation to other memories, and how the information pertains to the present situation. </p> <p>Reflection Memory Which is a separate tipe of memory that allow more abstract thoughts for the agent. They can be included alongside the reflections. (Hardcoded when this happens, in relation to sum of importance scores &gt; threshold)</p> <p>Planning and Reacting</p> <p>Recursive Planning used to generate the day into several chunks of goals. These are then broken down to smaller timespaces. Plans can change based on interactions. (perhaps present status, planned and past) </p> </li> <li> <p>Multi-Agent Collaboration via Reward Attribution Decomposition     Describes optimization of multi agent with distributed reward systems to get SOA performance. It is a joint optimization allowing decentralized Q-function that relies on self and interactive terms. </p> </li> <li> <p>Super-AGI  Allows multiple agents (no communication though)</p> </li> <li> <p>GPT-Bargaining Uses multiple rounds to improve negotiation tactics based on external feedback. </p> </li> <li> <p>RL4L Allen ai Uses smaller critique model feedback to improve larger model output with a policy gradient to fine-tune the critique model while allowing reasonable performance gains. Github</p> </li> </ul>"},{"location":"Understanding/data/data.html","title":"Data","text":"<p>Data is the most important part of training any model. </p> <p>Data can be 'real' or 'simulated', though there is general consensus that simulated data can lead to worse models. </p>"},{"location":"Understanding/data/data.html#simulated","title":"Simulated","text":"<ul> <li>\u201cTextbooks are all you need\u201d A to-be opensourced high-quality model by Microsoft revealing the importance of high-quality input data. only used 4 days on 8 A-100s to train to reach out-performing results. (It also uses a lot of simulated data). Coding-focused model. </li> </ul>"},{"location":"Understanding/data/data.html#llm-extraction","title":"LLM-extraction","text":"<ul> <li>\u203c\ufe0fKor For extracting structured data using LLMs.</li> </ul>"},{"location":"Understanding/data/data.html#scaling-laws","title":"Scaling Laws","text":"<ul> <li>The 'Chinchilla' paper of 2022 This paper identifies scaling laws that help to understand the volume of data that is needed to obtain 'optimal' performance for a given LLM models size. Use of it in other areas, such as for Llama reveals that the models may have been under-trained.</li> <li>Primary takeaway: **\"All three approaches suggest that as compute budget increases, model size and the amount of training data should be increased in approximately equal proportions.\" **</li> </ul> <p>References</p> <ul> <li>Github page on Embeddings</li> </ul>"},{"location":"Understanding/data/embedding.html","title":"Embedding","text":"<p>Embeddings play a key role in AI as they translate tokens into numerical representation that can be processed by the AI. </p> <p>'What are Embeddings' is an essential read that elucidates the concept of embeddings in a digestible manner. For a deeper dive, check the accompanied Github page.</p>"},{"location":"Understanding/data/sources.html","title":"Sources","text":""},{"location":"Understanding/data/sources.html#data-sources","title":"Data sources","text":"<p>RedPajama Pile CommonCrawl (webscrape) C4 (CommonCrawl) Github Books Arxiv StackExchange</p> <ul> <li> <p>unarXive 2022: All arXiv Publications Pre-Processed for NLP</p> </li> <li> <p>Redpajama</p> </li> <li>BIG-bench APACHE 2.0</li> <li>Metaseq For working with Oen pre-trained transformers (from fairseq)</li> </ul>"},{"location":"Understanding/data/tokenizing.html","title":"Tokenizing","text":"<p>In generative AI, the raw data\u2014whether it be in binary, text, or a different form\u2014is divided into individual units termed as tokens. These play a crucial role in easing the understanding and manipulation of data for the AI.</p>"},{"location":"Understanding/data/tokenizing.html#understanding-tokenization","title":"Understanding Tokenization","text":"<p>Tokenization is the process of splitting data into these individual units. The choice of a token largely depends on the data type and the expected outcome of the AI. In text data, for instance, tokens often correspond to single words or subwords. </p>"},{"location":"Understanding/data/tokenizing.html#subword-units","title":"Subword Units","text":"<p>A subword unit, or a part of a word, can be a token in itself. The paper titled Neural Machine Translation of Rare Words with Subword Units brings to light the effectiveness of subword units in improving results. This type of tokenization was used in a neural machine translation system and it significantly improved the handling of rare words.</p>"},{"location":"Understanding/data/tokenizing.html#special-tokens","title":"Special tokens","text":"<p>There are special tokens that are used by high-level interpreters on what next to do. </p> Token Name Description START_TOKEN or BOS_TOKEN This is used to indicate the beginning of a sequence. BOS stands for \"Beginning Of Sequence\". STOP_TOKEN or EOS_TOKEN This is used to indicate the end of a sequence. EOS stands for \"End Of Sequence\". MASK_TOKEN This is used to represent a masked value, which the model needs to predict. MODALITY_TOKEN This is used to indicate the type of data in the sequence (such as text, images, etc.)"},{"location":"Understanding/data/tokenizing.html#multimodal-tokenization","title":"Multimodal Tokenization","text":"<p>Multimodal tokenization is an area of tokenization that focuses on incorporating multiple data forms or modes. This facet of tokenization has seen remarkable strides. Bytes are all you need\u2014a study utilizing transformer technology to input file bytes directly\u2014demonstrates that multimodal tokenization can assist in improving the AI's performance accuracy. The researchers in the study developed ByteFormer, a model based on their study\u2019s findings that can be accessed here.</p>"},{"location":"Understanding/data/tokenizing.html#tools","title":"Tools","text":"<p>Examples of coding tools that facilitate tokenization include Tiktoken which utilizes Byte Pair Encoding (BPE) for tokenization and is purportedly used in GPT models. An alternative tool is 2, which takes a unique top-down approach and results in almost 35% less tokens as opposed to the standard bottom-up approach.</p>"},{"location":"Understanding/data/tokenizing.html#open-source-tokenizers","title":"Open Source Tokenizers","text":"<ul> <li>Sentence Piece implements subword units (e.g., byte-pair-encoding (BPE) ) and unigram language model 1</li> <li>Tiktoken</li> <li>Token Monster</li> </ul>"},{"location":"Understanding/data/tokenizing.html#references","title":"References","text":"<ul> <li>Neural Machine Translation of Rare Words with Subword Units</li> <li>Bytes are all you need</li> <li>ByteFormer Github What are EmbeddingsGithub</li> </ul> <ol> <li> <p>Kudo \"subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training\". Effectively, this takes aliasing-like effects that cause different tokenization. It is more effective because it breaks it down in different ways.\u00a0\u21a9</p> </li> <li> <p>Token Monster \u21a9</p> </li> </ol>"},{"location":"Understanding/enablement/index.html","title":"Enablement","text":""},{"location":"Understanding/enablement/index.html#system-architecture","title":"System Architecture","text":""},{"location":"Understanding/enablement/index.html#references","title":"References","text":"<ul> <li>Emerging Architectures for LLM Applications A very nice discussion of the components and their interactions via orchestration systems.</li> </ul> <p> [^n1]</p>"},{"location":"Understanding/enablement/index.html#engineering-and-deployment","title":"Engineering and Deployment","text":"<ul> <li>Deploying on Azure for Embeddings</li> <li>Integrating with Azure Services</li> <li>Langchain service deployment</li> </ul>"},{"location":"Understanding/enablement/index.html#caching","title":"Caching","text":"<ul> <li>GPTCache</li> </ul>"},{"location":"Understanding/enablement/index.html#llm-ops","title":"LLM Ops","text":"<ul> <li>LLM Ops</li> <li>Reliable GPT A wrapper that prevents failures due to rate limiting requests. </li> </ul>"},{"location":"Understanding/enablement/commercial_products.html","title":"Platforms","text":""},{"location":"Understanding/enablement/commercial_products.html#building-and-deploying","title":"Building and deploying","text":"<ul> <li>Fixie</li> </ul>"},{"location":"Understanding/enablement/commercial_products.html#llm-training-deployment","title":"LLM Training + Deployment","text":"<ul> <li>\ufe0fCodeTF From Salesforce</li> <li>Azure Open AI samples Sample end-to-end use cases with chatbots, content generation. </li> <li>RLHF with DeepSpeed (Microsoft)</li> <li>vLLM a python repo to help run LLMs. </li> </ul>"},{"location":"Understanding/enablement/commercial_products.html#a-few-self-referentially-useful-services-using-gpt-4","title":"A few self-referentially useful services Using GPT-4","text":"<ul> <li>Sourcegraph and the Cody.ai agent that it uses to help guide developers.</li> <li>LSIF.dev A community-driven source of knowledge for Language Server Index Format implementations\"</li> </ul>"},{"location":"Understanding/enablement/commercial_products.html#coding-tools","title":"Coding Tools","text":"<ul> <li>Copilot - AI pair programmer by GitHub</li> <li>RepoCoder Github Provides a tool to enable AI agents to generate code for existing GitHub repositories </li> <li>TabNine - AI code completion tool</li> <li>DeepTabNine - Open source version of TabNine code completion model</li> <li>ChatGPT Does quite well with code creation </li> </ul>"},{"location":"Understanding/enablement/commercial_products.html#writing","title":"Writing","text":"<p>Sudowrite</p>"},{"location":"Understanding/enablement/computation.html","title":"Computation","text":"<p>\ud83d\udea7 This section is under construction \ud83c\udfd7\ufe0f</p>"},{"location":"Understanding/enablement/computation.html#gpus","title":"GPUs","text":"<p>In order to create models, large volumes of matrix multiplication is necessary. GPUs are designed for this. </p> <p>Tim Dettmers on GPUs</p>"},{"location":"Understanding/enablement/computation.html#cloud-computation","title":"Cloud computation","text":""},{"location":"Understanding/enablement/computation.html#local-computation","title":"Local computation","text":""},{"location":"Understanding/enablement/computation.html#references","title":"References","text":"<p>\ufffc</p>"},{"location":"Understanding/enablement/deployment.html","title":"Deployment","text":"<p>Like other applications, deployment of LLM technologies will rely on front-end and back-end components. Front-end will allow for ease-of-use of the components. Back-end components enable the hosting, serving, and recording of any information that is needed for observability. </p>"},{"location":"Understanding/enablement/deployment.html#front-end-interfaces","title":"Front End Interfaces","text":"<p>People have to access it to be useful</p> <ul> <li>GPT Graph Allows for a graphical network representation of chat interactions.</li> </ul>"},{"location":"Understanding/enablement/deployment.html#open-source-methods","title":"Open source methods","text":"<ul> <li>Streamlit</li> <li>DemoGPT Connects Langchain and streamlit to create dynamic apps that can be repeatedly used for interacting with Chat- GPTs. </li> </ul>"},{"location":"Understanding/enablement/examples.html","title":"Examples","text":"<ul> <li>Fully GenAI pharmacist from scripts, images and videos</li> <li> <p>ChatGPT clone with streamlit</p> </li> <li> <p>A Guide to building a full-stack web app with Llama Index</p> </li> <li> <p>GPT-graph A react based abiliyt to explore qeustions. </p> </li> </ul> <p>-</p>"},{"location":"Understanding/enablement/frameworks.html","title":"Frameworks","text":""},{"location":"Understanding/enablement/frameworks.html#operational-toolkits-for-llmops","title":"Operational Toolkits for LLMops","text":"<ul> <li>\u203c\ufe0fHugging Face Transformers</li> <li>\u203c\ufe0fAdapters for Hugging Face</li> <li> <p>\u203c\ufe0fOpen LLM</p> </li> <li> <p>Chatall To interact with multiple chatbots at the same time.</p> </li> <li>\u203c\ufe0f LocalAI drop-in replacement REST API that\u2019s compatible with OpenAI API specifications for local inferencing.</li> </ul>"},{"location":"Understanding/enablement/frameworks.html#llama","title":"Llama","text":"<p>Llama is Meta's now open-source model. Llama 2 is MIT and free for commercial use. </p> <ul> <li>Ollama.ai A very nice command-line wrapper for running Llama models on your computer. </li> <li>Llama from Meta Direct from the source </li> <li>For Llama</li> <li> <p>MedAlpaca</p> </li> <li> <p>Llama-2 on a CPU and Github</p> </li> </ul>"},{"location":"Understanding/enablement/frameworks.html#_1","title":"Frameworks","text":""},{"location":"Understanding/enablement/marking_and_detecting.html","title":"Marking and detecting","text":"<ul> <li>Sapling AI content detector</li> </ul>"},{"location":"Understanding/enablement/models.html","title":"Models","text":"<p>This needs to be cleaned up and expanded. It needs to be made into a table. It needs to hav ethe appropriate license types mentioned directly.</p>"},{"location":"Understanding/enablement/models.html#models","title":"Models","text":""},{"location":"Understanding/enablement/models.html#leaderboards-and-comparisons","title":"Leaderboards and comparisons","text":"<ul> <li>Hugging Face LLM leaderboard An essential chart for documenting the model peformance across multiple models.</li> <li>lmsys.org leader board</li> </ul>"},{"location":"Understanding/enablement/models.html#text-oriented","title":"Text Oriented","text":"<ul> <li>Bard</li> <li>Claud</li> <li>ChatGPT (OpenAI)</li> <li>Medpalm</li> <li>Llama2(Not completely open source.)</li> <li>Open Llama (Non-commercial ??)</li> <li>UAE Falcon (Apache License)</li> <li>Orca (Microsoft) (Not yet released)</li> <li>MosaicML</li> </ul>"},{"location":"Understanding/enablement/models.html#image-oriented","title":"Image Oriented","text":"<ul> <li>StableLM: Stability AI Language Models  CC BY-SA-4.0</li> </ul>"},{"location":"Understanding/enablement/models.html#open-source-1-code","title":"Open Source 1 Code","text":"<ul> <li>Unilm (MSFT)</li> </ul>"},{"location":"Understanding/enablement/models.html#open-source-1-code-parameters","title":"Open Source 1 Code + Parameters","text":"<ul> <li>GPT4all</li> <li>[]</li> </ul> <ol> <li> <p>Please look at licenses for appropriate potential for commercial-usage.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"Understanding/enablement/observability.html","title":"Observability","text":"<p>\ud83d\udea7 This section is under construction \ud83c\udfd7\ufe0f</p> <p>GenAI observability is essential to monitoring the quality of the output. </p> <p>Observability aims to track:</p> <ol> <li>Models, Functions, and utilized software+hardware infrastructure. </li> <li>Inputs</li> <li>Outputs</li> <li>Inference costs and speeds</li> </ol>"},{"location":"Understanding/enablement/plugins.html","title":"Plugins","text":""},{"location":"Understanding/enablement/plugins.html#plugins","title":"Plugins","text":"<p>Plugins are can enable connection of GenAI with input media, often via web interfaces</p> <ul> <li> <p>Mini Wob++ For web interactive environments for accomplishing different tasks. Quite useful.</p> </li> <li> <p>\ufe0fPrompt Genius</p> </li> <li> <p>FastChat Conversation This very nice 'multi model' chat interface class allows for effective translation between different models.</p> </li> </ul>"},{"location":"Understanding/enablement/plugins.html#back-end","title":"Back-End","text":"<ul> <li>MaxAI.me A nice chrome pluging + eventual system  that makes your openAI connect to data more directly.</li> </ul>"},{"location":"Understanding/enablement/regulation.html","title":"Regulation","text":"<p>Because of challenges and ethical considerations surrounding  GenAI, it is essential to know what is being considered and why and how that may impact specific fields and society at large. </p> <p>Here we discuss general considerations and approaches surrounding regulating GenAI. </p>"},{"location":"Understanding/enablement/regulation.html#important-considerations","title":"Important considerations","text":"<p>TODO: Finish Me</p>"},{"location":"Understanding/enablement/regulation.html#references","title":"References","text":"<ul> <li>Foundation model Providers EU AI compliance</li> </ul>"},{"location":"Understanding/ethical_concerns/index.html","title":"Ethical concerns","text":""},{"location":"Understanding/ethical_concerns/index.html#bias-and-fairness","title":"Bias and Fairness","text":"<p>Mitigating bias in data and models Evaluating model fairness Inclusive model development Transparency and Explainability</p>"},{"location":"Understanding/ethical_concerns/index.html#interpretability","title":"Interpretability","text":"<p>Techniques for explainability Right to explanation Safety</p>"},{"location":"Understanding/ethical_concerns/index.html#risk-mitigation","title":"Risk Mitigation","text":"<p>Risk assessment Safeguards against misuse Privacy</p>"},{"location":"Understanding/ethical_concerns/index.html#data-privacy","title":"Data privacy","text":"<p>Anonymization and de-identification Encryption and secure computing</p>"},{"location":"Understanding/ethical_concerns/index.html#governance","title":"Governance","text":"<p>Internal auditing processes External oversight Accountability measures Access and Inclusion</p>"},{"location":"Understanding/ethical_concerns/index.html#fair-and-equitable-access","title":"Fair and equitable access","text":"<p>Digital divides Participatory design Compliance</p>"},{"location":"Understanding/ethical_concerns/index.html#laws-and-regulations","title":"Laws and regulations","text":"<p>Responsible development guidelines Ethics review processes</p>"},{"location":"Understanding/ethical_concerns/alignment_and_exential_concerns.html","title":"Alignment and exential concerns","text":"<p>There is a notable degree of concern for the potential for Generative, and eventually General AI, to cause harm. The harm can occur either accidentally or to the intentional use of GenAI. </p> <p>There is also self-existenial concerns related to GenAI models themselves. This is found due to the potential that when models are trained on data that is produced by other models, there can be a degredation in performance, known as model collapse. </p>"},{"location":"Understanding/ethical_concerns/alignment_and_exential_concerns.html#background","title":"Background","text":"<p>TODO: This sections needs complete remodling. </p>"},{"location":"Understanding/ethical_concerns/alignment_and_exential_concerns.html#alignment-with-people","title":"Alignment with People","text":"<ul> <li>Personal Universes: A Solutiont to the Multi-Agent Value Alignment Problem</li> </ul>"},{"location":"Understanding/ethical_concerns/alignment_and_exential_concerns.html#alignment-with-genai","title":"Alignment with GenAI","text":"<ul> <li>Model Collapse Explained</li> </ul>"},{"location":"Understanding/ethical_concerns/fairness.html","title":"Fairness","text":""},{"location":"Understanding/ethical_concerns/fairness.html#elements-of-ai-fairness","title":"Elements of AI Fairness","text":"<p>Understanding AI fairness can be complex, but let's break it down into simple, digestible elements.</p>"},{"location":"Understanding/ethical_concerns/fairness.html#1-understanding-bias","title":"1. Understanding Bias","text":"<p>Bias in AI systems comes from various sources. It could be in the data used to train the AI, the design of the AI algorithms, or the ways AI systems are deployed and used. AI fairness, therefore, needs to address these sources of bias.</p> <p>Data Bias: This happens when the data used to train the AI is not representative of the population it will be serving, leading to biased predictions or decisions. An example is if an AI system was trained on data mostly from one demographic group, it might not perform well on other groups.</p> <p>Algorithmic Bias: This is when the algorithms that power AI systems inherently favor one outcome over another. They might do this due to design flaws, biased inputs, or even the optimization goals set by their creators.</p>"},{"location":"Understanding/ethical_concerns/fairness.html#2-fairness-metrics","title":"2. Fairness Metrics","text":"<p>Measuring fairness is a crucial aspect of AI fairness. This involves setting and monitoring fairness metrics that determine how well an AI system is performing in terms of fairness.</p> <p>Disparity Metrics: Measures how an AI's decisions or predictions differ among various demographic groups.</p> <p>Equality Metrics: Measures how equally an AI system treats individuals, regardless of their demographic group.</p>"},{"location":"Understanding/ethical_concerns/fairness.html#3-transparency","title":"3. Transparency","text":"<p>Transparency is about making sure the workings of an AI system are understandable to people. This includes both the technical side (e.g., how the AI's algorithms work) and the practical side (e.g., how decisions made by the AI impact individuals).</p> <p>Explainability: AI systems should be designed to provide explanations about their decisions or predictions. This helps individuals understand how a system came to a certain conclusion.</p> <p>Interpretability: This involves designing AI systems in ways that their workings can be understood by humans, even if they don't have technical expertise in AI.</p>"},{"location":"Understanding/ethical_concerns/fairness.html#4-accountability","title":"4. Accountability","text":"<p>Accountability in AI fairness refers to the obligation of AI system developers and operators to answer for the system's effects on individuals and society.</p> <p>Auditing: Regular checks on an AI system's decisions and performance to ensure it's upholding fairness standards.</p> <p>Redress Mechanisms: Clear pathways for people to challenge decisions made by an AI system, particularly if they believe they've been treated unfairly.</p>"},{"location":"Understanding/ethical_concerns/fairness.html#5-inclusion","title":"5. Inclusion","text":"<p>Inclusion is about making sure AI systems serve all individuals fairly and equitably, regardless of their demographic characteristics.</p> <p>Diversity in Design: This involves ensuring that the teams creating AI systems are diverse, which can help to avoid some forms of bias and make the systems more effective for a wider range of individuals.</p> <p>Accessibility: AI systems should be designed in ways that they can be used and understood by people with varying abilities, languages, and cultural contexts.</p> <p>NOTE: Generated with GPT-4</p>"},{"location":"Understanding/model_creation/index.html","title":"Model creation","text":""},{"location":"Understanding/model_creation/index.html#models-for-genai","title":"Models for Gen()AI","text":"<p>Here we will discuss the models essential components of Gen()AI. </p> <p>There are two primary domains of Generative AI, text-oriented or image-oriented, though there is great indication that many other (multi-)modalities will be very important for the future. </p> <p>We discuss the general complete models used in creating Generative AI. Initial incarnations of this will focus on the most observably promising core-models, transformers. </p> <p>Because we generally call Gen()AI with language inputs, there are different ways to use language to achieve the appropriately desired results. These inputs, prompts will be model-specific, but may share commonalities for more-optimal usage and we discuss that more thoroughly here</p>"},{"location":"Understanding/model_creation/index.html#potentially-model-agnostic-improvements","title":"(potentially) model agnostic improvements","text":"<ul> <li>Learning to Compress Prompts with Gist Tokens. Can enable 26x compression and 40% FLOP reduction and improvements. Trains 'gist tokens' to summarize information. </li> </ul>"},{"location":"Understanding/model_creation/index.html#to-sort","title":"TO SORT","text":"<ul> <li>Token Embedding: Mapping to a vector space. </li> <li>Positional Embedding: Learned or hard-coded mapping to position of sequence to a vector space</li> <li>Attention: Token being predicted is mapped to a query vector and tokens in context are mapped to key and value vectors. Inner products are used to combine to extract information. </li> <li>Bi-directional / unmasked</li> <li>Unidirectional / masked self attetion</li> <li>Cross attention applies attention to the primary sequence and treates the second token sequence the context. </li> <li>Multi-head attention. Multiple attention heads in parallel.</li> <li>Layer normalization. Found to be computationally efficient version sets m = beta = 0 or root mean square layer normalizagion or <code>RMSnorm</code>. </li> <li>Unembedding: Learns to convert vector intot he vocuabulary elements. </li> </ul> <p>Architectures:</p> <ul> <li>Encoder-Decoder (EDT), is also sequence-to-sequence. </li> <li>Encoder-only: (BERT)</li> <li>Decoder-only (GPT) Next-token </li> <li>Multi-domain decoder-only transformer (Gato)</li> </ul>"},{"location":"Understanding/model_creation/alignment.html","title":"Alignment","text":"<p>Raw generative models do not generally produce globally accurate outputs given input prompts. 1 </p> <p>Global alignment </p> <p>Ensuring the output of models are appropriately capable of </p> <ol> <li> <p>We will be describing text-focused models in this discussion though variations can be appropriately considered for other domains and datatypes This is due to the manner of training and next-word-prediction (or more arbitrary masked-word prediction) is probabilistically 'greedy'. Namely, within a sampling of outputs, the next-prediction will be sampled based on their immediate likelihood. To improve the outputs, the models are further refined using various approaches. These approaches 'align' the output to accurately considered\u00a0\u21a9</p> </li> </ol>"},{"location":"Understanding/model_creation/evaluation.html","title":"Evaluation","text":"<p>The evaluation of models helps us to identify which, if any, model to use for a particular task at hand. Directly related to the manner of pre-training, fine-tuning, and any RLHF, the ways that we consider the output can also be used to improve the models. </p>"},{"location":"Understanding/model_creation/evaluation.html#measure-what-matters","title":"Measure what matters","text":""},{"location":"Understanding/model_creation/evaluation.html#general-discussions","title":"General Discussions","text":"<p>How do we know how smart AI systems are?</p> <p>\u201cAI systems, especially generative language systems like GPT-4, will become increasingly influential in our lives, as will claims about their cognitive capacities. Thus, designing methods to properly assess their intelligence\u2014and associated capabilities and limitations\u2014is an urgent matter. To scientifically evaluate claims of humanlike and even superhuman machine intelligence, we need more transparency on the ways these models are trained, and better experimental methods and benchmarks. Transparency will rely on the development of open-source (rather than closed, commercial) AI models. Better experimental methods and benchmarks will be brought about through collaborations between AI researchers and cognitive scientists who have long investigated how to do robust tests for intelligence, understanding, and other cognitive capabilities in children, animals, and other \u201calien\u201d intelligences.\u201d</p>"},{"location":"Understanding/model_creation/evaluation.html#metrics","title":"Metrics","text":"<ul> <li>Exact Match (EM)  TODO: Finish this</li> </ul>"},{"location":"Understanding/model_creation/models.html","title":"Models","text":"<p>Here we discuss models / architecture, and not models that are trained and released. Please see the Available Models for specific maners of both using or creating models. </p> <p>Genrative AI models are of two general categories. Self-supervised, and Externally-supervised, and hybrid models. Often times self-supervised models then pass into external-supervision to improve the quality of the output.</p> <p>Self supervision amounts to using a single data-entry itself to train a model, without interacting with other data points. For instance, a model used to predict </p> <p>Because of their present degree of quality present model Architectures tend to be transformer-based, or diffusion-based, though they can also be hybrids, or made from any other standard AI method. While Generative Adversarial Networks, GANS were the inititally most successful, the challenges in training them successfully can be challenging. </p> <p>Transformers Diffusers</p>"},{"location":"Understanding/model_creation/models.html#references","title":"References","text":""},{"location":"Understanding/model_creation/models.html#self-supervised-learning","title":"Self-supervised learning.","text":"<ul> <li>Diffusion LLMs</li> </ul> <p>Alignment methods.</p> <p>Additional models come up all the time.</p> <ul> <li>\u203c\ufe0f Retentive Network: A successor to Transformer for Large Language Models Important LLM-like system using similar components that may help it to be more scaleable than <code>O(N^2)</code> memory and <code>O(N)</code> inference complexity. </li> </ul>"},{"location":"Understanding/model_creation/models.html#mixture-of-experts","title":"Mixture of Experts","text":""},{"location":"Understanding/model_creation/models.html#multimodal","title":"MultiModal","text":"<ul> <li> <p>SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs A really cool idea that uses pyramidal representations and compresses information into text-tokens of different levels. It can reconstruct it as needbe. These tokens then could be used in novel image generation via semantic mapping with an LLM. </p> </li> <li> <p>Multimodal Neurons in Pretrained Text-Only Transformers Neat demonstration \"finding multimodal neurons in text-only transformer MLPs and show that these neurons consistently translate image semantics into language.\"  </p> </li> </ul>"},{"location":"Understanding/model_creation/training.html","title":"Training","text":"<ul> <li>LLM Engineering by Huyen Chip</li> <li>The whole training process by Huyen Chip</li> </ul>"},{"location":"Understanding/model_creation/training.html#frameworks","title":"Frameworks","text":"<ul> <li>Levanter (not just LLMS)  Codebase for training FMs with JAX. Using Haliax for naming tensors field-names instead of indexes. (for example Batch, Feature....). Full sharding and distributable / parallelizable. </li> <li> <p>DeepSpeed ZeRO++ A framework for accelerating model pre-training, finetuning, RLHF updating.  by minimizing communication overhead. A likely essential concept to be very familiar with. </p> </li> <li> <p>\u203c\ufe0fRL4LMs by microsoft A modular RL library to fine-tune language models to human preferences. paper</p> </li> </ul>"},{"location":"Understanding/model_creation/training.html#methods-and-improvements","title":"Methods and Improvements","text":""},{"location":"Understanding/model_creation/training.html#fine-tuning-using-distillation","title":"Fine Tuning using Distillation","text":"<p>Train on model trains a new model on the output of a new model.  - Alpaca </p>"},{"location":"Understanding/model_creation/training.html#fine-tuning-optimizations","title":"Fine tuning Optimizations","text":"<ul> <li>Full Parameter Fine-Tuning for Large Language Models with Limited Resources. Introduces LOMO: LOw-Memory Optimization to fuse </li> </ul>"},{"location":"Understanding/model_creation/training.html#adapter-layers","title":"Adapter layers","text":"<ul> <li>AdapterHub: A Framework for Adapting Transformers Website Adapters are efficient and performant layers that can optimize performance without needing to do inefficient fine-tuning. </li> </ul>"},{"location":"Understanding/model_creation/training.html#rlhf","title":"RLHF","text":"<ul> <li>\u203c\ufe0f RLHF basics by hugging face A realy good intro to parse again.</li> <li>RLHF for Palm in Pytorch</li> <li>AligningLargeLanguageModelsthroughSyntheticFeedback Using a heirarchy of systems to </li> </ul>"},{"location":"Understanding/model_creation/training.html#ai-enabled-ranking","title":"AI-enabled ranking","text":"<ul> <li>Can foundation models label data like humans? using GPT to review model outputs produced biased results. Changing the prompt doesn't really help to de-bias it. Lots of additional considerations surrounding model evaluation</li> </ul>"},{"location":"Understanding/model_creation/training.html#mixture-of-experts","title":"Mixture of Experts.","text":"<ul> <li>Scaling Expert Language Models with Unsupervised Domain Discovery \"parse language models on arbitrary text corpora. Our method clusters a corpus into sets of related documents, trains a separate expert language model on each cluster, and combines them in a sparse ensemble for inference. This approach generalizes embarrassingly parallel training by automatically discovering the domains for each expert, and eliminates nearly all the communication overhead of existing sparse language models. \"</li> </ul>"},{"location":"Understanding/model_creation/training.html#pruning-and-compression","title":"Pruning and compression","text":"<ul> <li>SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot Remove up to ~50% parameters preserving </li> <li>SqueezeLLM They are able to have 2x fold in model size for equivalent performance in perplexity. They use 'Dense and SParce Quantization' Github</li> </ul>"},{"location":"Understanding/model_creation/classes/diffusers.html","title":"Diffusers","text":""},{"location":"Understanding/model_creation/classes/diffusers.html#this-has-yet-to-be-built-thanks-for-bearing-with-me","title":"This has yet to be built! Thanks for bearing with me.","text":""},{"location":"Understanding/model_creation/classes/diffusers.html#references","title":"References","text":"<ul> <li>Diffusion Models</li> </ul>"},{"location":"Understanding/model_creation/classes/gans.html","title":"Gans","text":""},{"location":"Understanding/model_creation/classes/gans.html#this-page-is-under-construction","title":"This page is under construction.","text":""},{"location":"Understanding/model_creation/classes/transformers.html","title":"Classes","text":""},{"location":"Understanding/model_creation/classes/transformers.html#transformers","title":"Transformers","text":"<ul> <li>The Illustrated Transformer</li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#components","title":"Components","text":"<p>TODO: Describe transformers and components</p> <ol> <li>Attention: Query, Key, Vectors</li> <li>Positional Encoding</li> <li>Layer Normalization</li> </ol>"},{"location":"Understanding/model_creation/classes/transformers.html#attention-models","title":"Attention Models","text":"<p>Layer normalization observaly improves results On Layer Normalization in the Transformer Architecture</p>"},{"location":"Understanding/model_creation/classes/transformers.html#softmax","title":"Softmax?","text":"<p>The softmax is dominantly researched activation function. There may be other activation functions that are better, such as the </p>"},{"location":"Understanding/model_creation/classes/transformers.html#gpt","title":"GPT","text":"<ul> <li>Illustrated GPT</li> <li>How GPT3 works Excellent summary of the progress of GPT over time, revealing core components, optimizations, and essential variations to the major Foundation model architectures.</li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#useful-references-and-research","title":"Useful References and Research","text":""},{"location":"Understanding/model_creation/classes/transformers.html#general-introductions","title":"General Introductions","text":"<ul> <li> <p>Transformers by Lucas Beyer (presentation)</p> </li> <li> <p>Five years of progress in GPTs</p> </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#seminal-documents","title":"Seminal documents","text":"<ul> <li> <p>Neural Machine Translation by Jointly Learning to Align and Translate First paper indicating the notion of 'attention' sort of mechanism.</p> </li> <li> <p>Attention Is All you Need Initial paper indicating that attention is very powerful and potential replacement of LLM architectures. </p> </li> <li> <p>Formal Algorithms for Transformers in 2023 Important discussion revealing the components of Transformers.</p> </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#positional-encoding","title":"Positional Encoding","text":"<p>This component helps to remove the impilcit position-independence that 'vanilla' attention methods have.  </p> <ul> <li> <p>A Gentle Introduction to Positional Encoding in Transformer Models, pt1</p> </li> <li> <p>Transformer Language Models without POsitional Encodings STill Learn Positional Information Indications that causal LMS may derive positional awareness from more than the positional embeddings: they learn it from the causal mask. </p> </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#modifications","title":"Modifications","text":"<ul> <li>A Simple yet Effective Learnable Positional Encoding Method for Improving Document Transformer Model They introduce a learnable sinusoidal positional encoding feed forward network. Demonstrates significant improvements over other datasets. </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#improvements-optimizations-and-variations","title":"Improvements, Optimizations, and variations.","text":"<ul> <li> <p>Scaling Transformer to 1M tokens and beyond with RMT Github Uses a Recurrent Memory Transformer(RMT) architecture to extend understanding to large lengths. </p> </li> <li> <p>\u203c\ufe0fMEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers MEGABYTE segments sequences into patches and uses a local submodel within patches and a global model between patches</p> </li> <li> <p>Hyena Architecture Uses inspiration from FFT to create a drop in replacement for Transformer models. </p> </li> <li> <p>Infinite former   Uses a representation of input sequence as a continuous signal expressed in a combination of N radial basis functions. Promising but potentially complex. Worth consideration   Github </p> </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#computation-reduction","title":"Computation Reduction","text":"<p>SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression</p>"},{"location":"Understanding/model_creation/classes/transformers.html#fine-tuning","title":"Fine Tuning","text":"<p>Using examples to fine-tune a model can reduce the number of tokens needed to achieve a sufficiently reasonable response. Can be expensive to retrain though.</p> <ul> <li>Symbol Tuning Improves in-context learning in Language Models </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#other-modalities","title":"Other modalities","text":""},{"location":"Understanding/model_creation/classes/transformers.html#vision","title":"Vision","text":""},{"location":"Understanding/model_creation/classes/transformers.html#graphs","title":"Graphs","text":"<ul> <li>Transformers Meet Directed Graphs An interesting-if-also-complex variation of Transformer GNNs that uses 'direction-aware' positional encodings to help handle both undirected and directed graphs. </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#training-variations","title":"Training variations","text":""},{"location":"Understanding/model_creation/classes/transformers.html#fairness-enablement","title":"Fairness Enablement","text":"<ul> <li>Concept Erasure</li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#using-knowledge-links","title":"Using Knowledge Links","text":"<ul> <li>LinkBERT places in the context window hyperlinked references to achieve better performance and is a drop-in replacement for BERT models. </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#multimodal","title":"Multimodal","text":"<ul> <li>Visual GPT</li> <li>Language is not all you need</li> <li>Meta-Transformer: A Unified Framework for Multimodal Learning The first framework to perform unified learning across 12 modalities with unpaired data. It does so by learning an embedding that can be shared across the modalities. Github </li> </ul>"},{"location":"Understanding/model_creation/classes/transformers.html#abstractions","title":"Abstractions","text":"<ul> <li>Looped Transformers and Programmable Computers Understanding that transformer networks can simulate complex algorithms when hardcoded with specific weights and made intoa  loop. 'Machine Learning' 'Machine code'. \"We demonstrate that a constant number of encoder layers can emulate basic computing blocks, including embedding edit operations, non-linear functions, function calls, program counters, and conditional branches. Using these building blocks, we emulate a small instruction-set computer.\"</li> </ul>"},{"location":"Understanding/overview/ai_in_general.html","title":"Ai in general","text":"<p>Here we provide selected references to frameworks and solutions surrounding AI in general</p>"},{"location":"Understanding/overview/ai_in_general.html#frameworks","title":"Frameworks","text":"<ul> <li>Catalyst Framework for boiler-plate minimal ML calling using pytorch. Enabled heirarchichal Attention networks</li> <li>Lightning + Hydra A nice minimal bioler plate framework using Hydra-based config management. </li> </ul>"},{"location":"Understanding/overview/ai_in_general.html#references","title":"References","text":"<ul> <li>AI cannon by a16z</li> </ul>"},{"location":"Understanding/overview/applications.html","title":"Applications","text":""},{"location":"Understanding/overview/applications.html#general-categories","title":"General Categories","text":""},{"location":"Understanding/overview/applications.html#summarization","title":"Summarization","text":"<p>This can be used to summarize documents. </p> <p>Codebases: - [Summarization with Langchain] https://github.com/EnkrateiaLucca/summarization_with_langchain A splendid view of a quick streamlit app that does PDF summarization. </p>"},{"location":"Understanding/overview/applications.html#semantic-search","title":"Semantic Search","text":"<p>Embedding of an input has the niceness that semantic, or 'meaning' nearness can be found via distance calculations. This enables semantic search. This is important for memory recall with imperfect inputs, and for action routing based. </p>"},{"location":"Understanding/overview/applications.html#knowledge-graph-building","title":"Knowledge graph building","text":"<ul> <li> <p>GPT for knowledge graphs and Github</p> </li> <li> <p>Ontology mapping</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#prose-generation","title":"Prose Generation","text":"<p>Here is a non-extensive list of useful manners to use LLM generation of prose generation:</p> <ul> <li>Cleaning up draft, or lower quality texts or notes</li> <li>Brainstorming and ideation </li> <li>Providing an initial draft for human editing</li> <li>Generating summaries and executive summaries</li> <li>Creating descriptions and explanations</li> <li>Rewriting for different target audiences</li> <li>Expanding on key points </li> <li>Improving flow and readability</li> <li>Adding examples and analogies</li> <li>Filling in missing details</li> <li>Extrapolating from key points</li> <li>Creating fictional scenarios</li> <li>Writing product descriptions</li> <li>Writing blog posts and news articles</li> <li>Writing stories and novels</li> </ul>"},{"location":"Understanding/overview/applications.html#code-generation","title":"Code Generation","text":"<p>Very powerfully it can generate code to accomplish a task based on natural language input. This is very promising but still requires human oversight, due to the challenge associated with using Automated AI systems without human input or oversight.</p>"},{"location":"Understanding/overview/applications.html#references-by-field","title":"References by field","text":""},{"location":"Understanding/overview/applications.html#code","title":"Code","text":"<ul> <li>Wizard Coding</li> <li>AutoPR</li> <li>Codium pr-agent </li> <li>[Summarization with Langchain] https://github.com/EnkrateiaLucca/summarization_with_langchain A splendid view of a quick streamlit app that does PDF summarization. </li> </ul>"},{"location":"Understanding/overview/applications.html#component-replacements","title":"Component replacements","text":"<ul> <li>GPT as backend</li> </ul>"},{"location":"Understanding/overview/applications.html#book-writing","title":"Book Writing","text":"<ul> <li> <p>Pyprompt chatgpt</p> </li> <li> <p>Motion GPT</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#science-and-tech","title":"Science and Tech","text":"<ul> <li>Emergent autonomous scientific research </li> </ul>"},{"location":"Understanding/overview/applications.html#robotics","title":"Robotics","text":"<ul> <li>CLAIRIFY Translates English to domain-specific languages like robots. </li> <li>https://arxiv.org/abs/2303.14100</li> <li>RT-2 An impressive demonstration of multi-step fusing (PaLI-X) and Pathways Language model Embodied (PaLM-E) as components of it. </li> </ul>"},{"location":"Understanding/overview/applications.html#healthcare","title":"Healthcare","text":"<ul> <li> <p>Health system-scale language models are all-purpose prediction engines Uses LLM based system to integrate real time clinical workflows with note-writing and electronic ordering. Generally quite-performant and. a great indication of how they could be used to predict things such as readmission rates, and many other applications. </p> </li> <li> <p>LLMs encode clinical knowledge</p> </li> </ul>"},{"location":"Understanding/overview/applications.html#chemistry","title":"Chemistry","text":"<ul> <li>Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction A quality framework using heirarchichal metagraphs to stitch-together molecular nodes resulting in leaves that are 'actual' molecules. Using graph neural-diffusion, it does amazingly well even with minimal data-sets (100 examples).  </li> </ul>"},{"location":"Understanding/overview/applications.html#biology","title":"Biology","text":"<ul> <li>Evolutionary-scale prediction of atomic-level protein structure with a language model End to end Language model enabling structure sequence pairing, coupled with an equivariant transformer structure model at the end. </li> <li>https://arxiv.org/pdf/2303.16416.pdf</li> <li>https://arxiv.org/abs/2304.02496</li> <li>\uff01Biomedical simulation</li> </ul>"},{"location":"Understanding/overview/applications.html#societal-simulations","title":"Societal simulations","text":"<ul> <li>Generative Agents: Interactive Simulacra of Human Behavior:    They gave 25 AI agents motivations &amp; memory, and put them in a simulated town. Not only did they engage in complex behavior (including throwing a Valentine\u2019s Day party) but the actions were rated more human than humans roleplaying.   Demo: https://t.co/pYNF4BBveG</li> </ul>"},{"location":"Understanding/overview/applications.html#finance","title":"Finance","text":"<ul> <li>ML for trading (NOT LLM based)</li> <li>https://github.com/irgolic/AutoPR</li> <li>Finance GPT LLMs for finance</li> </ul>"},{"location":"Understanding/overview/applications.html#second-brain","title":"Second Brain","text":"<ul> <li>\u203c\ufe0f \u203c\ufe0f Quiver A LLM for self Second brain. </li> </ul>"},{"location":"Understanding/overview/challenges.html","title":"Challenges","text":"<p>Challenges associated with GenAI.</p> <p>Apart from ethical considerations, there are general challenges associated with the technology.</p> <p>Importantly, applications that rely on the output of these models may have challenges due to</p> <ol> <li>The stochastic nature of the output</li> <li>Changes in the output over time for models that are non-static. See, for instance ChatGPT's behavior changing over time</li> <li>The technical difficulties associated with training such mdoels.</li> <li>The quality of the input data.</li> </ol> <p>While some of these all of these challenges can be mitigated through better engineering.</p> <ol> <li>Better methods and reduce temperature:</li> <li>Freeze models. Use Have continuous monitoring of models, and use pLLM-observability tools]</li> </ol>"},{"location":"Understanding/overview/extra_resources.html","title":"Extra resources","text":""},{"location":"Understanding/overview/extra_resources.html#videos","title":"Videos","text":"<p>State of GPT by Andrej Karpathy </p> <ul> <li>Lex Fridman</li> <li>David Shapiro</li> <li>AI Explained</li> <li> <p>Yannic Kilcher</p> </li> <li></li> </ul>"},{"location":"Understanding/overview/extra_resources.html#whole-system","title":"Whole system","text":"<ul> <li>\u203c\ufe0f Emerging Architectures for LLM Applications A very nice high overview of the component market for LLM architectures.</li> </ul>"},{"location":"Understanding/overview/extra_resources.html#llms","title":"LLMs","text":"<ul> <li> <p>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </p> </li> <li> <p>Understanding Large Language Models</p> </li> </ul>"},{"location":"Understanding/overview/extra_resources.html#llm-prompting","title":"LLM Prompting","text":"<ul> <li> <p>\u203c\ufe0fLLM Practical Guide based on paper.</p> </li> <li> <p>\u203c\ufe0fPrompting Guide</p> </li> <li>Wolfram Prompt Repo</li> <li>\u203c\ufe0fPrompt Engine (MSFT) database tool MIT license</li> </ul>"},{"location":"Understanding/overview/extra_resources.html#video-podcasts","title":"Video + Podcasts","text":"<ul> <li>Lex Fridman</li> <li>David Shapiro</li> <li>AI Explained</li> <li>Yannic Kilcher</li> <li>State of GPT by Andrej Karpathy</li> </ul>"},{"location":"Understanding/overview/extra_resources.html#overview-research","title":"Overview Research","text":"<ul> <li>[Challenges and Applications of Large Language Models Kaddour et al](https://arxiv.org/abs/2307.10169]</li> </ul>"},{"location":"Understanding/overview/overview.html","title":"Overview","text":"<p>The base components of GENAI 1. Applications 1. Challenges</p>"},{"location":"Understanding/overview/overview.html#organization","title":"Organization","text":"<ol> <li>Data is the p</li> <li>Models</li> <li>Prompts</li> <li>Agents</li> <li>Engineering and Management</li> <li>Ethics</li> <li>Studies</li> </ol>"},{"location":"Understanding/overview/overview.html#available-models","title":"Available models","text":"<p>There are both open and closed-source models, that can be used. Because of computation requirements, more-powerful hardware may be needed to run these models, so they are often run with cloud-based services. We share an incomplete list here</p>"},{"location":"Understanding/overview/overview.html#references","title":"References","text":"<p>References</p> <ul> <li>A Survey of Large Language Models A very comprehensive paper discussing LLM technology. </li> <li>A cookbook of self-supervised Learning </li> <li>LLM Survey</li> <li></li> </ul>"},{"location":"Understanding/prompt_engineering/prompt_injections.html","title":"Prompt engineering","text":""},{"location":"Understanding/prompt_engineering/prompt_injections.html#important-references","title":"Important references","text":"<ul> <li>LLM attacks</li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html","title":"Prompting","text":""},{"location":"Understanding/prompt_engineering/prompting.html#llm-prompting","title":"LLM Prompting","text":"<ul> <li>\u203c\ufe0fPrompting Guide</li> <li>Wolfram Prompt Repo</li> <li> <p>\u203c\ufe0fPrompt Engine (MSFT) database tool MIT license</p> </li> <li> <p>scale.com/spellbook</p> </li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html#prompt-engineering","title":"Prompt engineering","text":"<ul> <li> Prompting is Programming: A Query Language for Large Language Models</li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html#manual","title":"Manual","text":"<ul> <li> <p>OPEN AI best practices</p> </li> <li> <p>Go over all of these! https://www.promptingguide.ai/techniques</p> </li> <li>A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT </li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html#examples","title":"Examples","text":"<pre><code>Pretend you have an IQ of 120\n</code></pre>"},{"location":"Understanding/prompt_engineering/prompting.html#minimizing-ai-plagiarism-prompting-strategy","title":"Minimizing AI- plagiarism prompting strategy.","text":"<p>\"You are a creative writer, and you like to write everything differently from others. Your task is to follow the instructions below and continue writing at the end of the text given. The instructions (given in markdown format) are \u201cWrite in a way different from the actual continuation, if there is one\u201d, and \u201cNo plagiarism is allowed\u201d.\" https://arxiv.org/pdf/2304.08637.pdf </p>"},{"location":"Understanding/prompt_engineering/prompting.html#according-to","title":"'According To'","text":"<ul> <li>\u201cAccording to ...\u201d Prompting Language Models Improves Quoting from Pre-Training Data The grounding prompt <code>According to { some_reputable_source}</code> prompt inception additions increases output quality improves over the null prompt in nearly every dataset and metric, typically by 5-15%.</li> </ul> <pre><code>According to {some_reputable_source} ...\n</code></pre>"},{"location":"Understanding/prompt_engineering/prompting.html#summary","title":"Summary:","text":"<ul> <li>Provide several examples to ground it.</li> <li>Good to evaluate this and see if input examples give expected scores. Modify the prompt if it isn't. </li> <li>Consider prompt versioning to keep track of outputs more easily.</li> <li>Breag prompts into smaller prompts</li> <li>Chain of Thought Prompting</li> <li>Generate many outputs and pick final one or use LLM to pick best one. Self consistency technique</li> <li>NOTE: Not model universal and not robust to updated changes: not stable. </li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html#automatic","title":"Automatic","text":""},{"location":"Understanding/prompt_engineering/prompting.html#resources","title":"Resources","text":"<ul> <li>\u203c\ufe0f Awesome Prompts</li> <li>\u203c\ufe0f Prompt Engineering by Lillian Wang</li> <li>Prompt Engineering Guide</li> <li>Best practices for prompt engineering</li> <li>Chain of Thought Prompting Elicits Reasoning in Large Language Models</li> <li>Automatic Prompt Engineering \u2192 Gave a CoT improvement suggestion \"Let's work this out in a step by step by way to be sure we have the right answer.\"</li> <li>Techniques to improve reliability By OpenAI </li> <li>Give clearer instructions</li> <li>Split complex tasks into simpler subtasks</li> <li>Structure the instruction to keep the model on task</li> <li>Prompt the model to explain before answering</li> <li>Ask for justifications of many possible answers, and then synthesize</li> <li>Generate many outputs, and then use the model to pick the best one</li> <li>Fine-tune custom models to maximize performance</li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html#prompt-tuning","title":"Prompt tuning","text":"<p>Uses a layer to not change prompts but change the embedding of the prompts.  - The Power of Scale for Parameter-Efficient Prompt Tuning Boosted Prompting: few shot prompts that progressively solve more of the problem.</p>"},{"location":"Understanding/prompt_engineering/prompting.html#prompt-and-optimization","title":"Prompt and optimization","text":"<ul> <li>Large Language Models Can Self Improve Using Chain of thought to provide better examples and then fine-tune the LLM. </li> <li> <p>Refiner Iteratively improves itself based on an LLM critic </p> </li> <li> <p>PROMPT generator To save a few words by just entering a persona and igives prompt output. </p> </li> </ul>"},{"location":"Understanding/prompt_engineering/prompting.html#manual-prompt-optimization","title":"Manual Prompt optimization","text":""},{"location":"Understanding/prompt_engineering/prompting.html#auto-prompt-optimizations","title":"Auto Prompt Optimizations","text":"<p>A good description of advanced prompt tuning <pre><code>AutoPrompt [5] combines the original prompt input with a set of shared (across all input data) \u201ctrigger tokens\u201d that are selected via a gradient-based search to improve performance.\n\nPrefix Tuning [6] adds several \u201cprefix\u201d tokens to the prompt embedding in both input and hidden layers, then trains the parameters of this prefix (leaving model parameters fixed) with gradient descent as a parameter-efficient fine-tuning strategy.\n\nPrompt Tuning [7] is similar to prefix tuning, but prefix tokens are only added to the input layer. These tokens are fine-tuned on each task that the language model solves, allowing prefix tokens to condition the model for a given task.\n\nP-Tuning [8] adds task-specific anchor tokens to the model\u2019s input layer that are fine-tuned but allows these tokens to be placed at arbitrary locations (e.g., the middle of the prompt), making the approach more flexible than prefix tuning.\n\n[5] Shin, Taylor, et al. \"Autoprompt: Eliciting knowledge from language models with automatically generated prompts.\" arXiv preprint arXiv:2010.15980 (2020).\n\n[6] Li, Xiang Lisa, and Percy Liang. \"Prefix-tuning: Optimizing continuous prompts for a generation.\" arXiv preprint arXiv:2101.00190 (2021).\n\n[7] Lester, Brian, Rami Al-Rfou, and Noah Constant. \"The power of scale for parameter-efficient prompt tuning.\" arXiv preprint arXiv:2104.08691 (2021).\n\n[8] Liu, Xiao, et al. \"GPT understands, too.\" arXiv preprint arXiv:2103.10385 (2021).\n</code></pre></p>"},{"location":"Understanding/studies/studies.html","title":"Studies","text":"<p>We are in an age of experimental applied mathematics. Often times we do not know what the results of a particular model or method will be until it is programmed and evaluated. Though often times theory-can inform the best ways forward, we are still a ways a way from a unified theory of AI, (or even intelligence for that matter) and we will likely always be learning things. </p> <p>For GenAI, and LLMs, much of what has been learned has been surmised or known only in gist. More thorough understanding has occured through painstaking experiments, anecdotal and statistical evaluations of models and methods. Still we don't always know 'how' they are able to do what they do. </p> <p>It is debated that sufficiently large models exhibit 'emergence'. While not always defined universally, this can be considered as the ability for the model to perform tasks beyond what they initially were trained to do, or to be 'greater than the individual sum of the parts'. While this distinction may be of merit it remains a popular arena for academic debates. </p>"},{"location":"Understanding/studies/studies.html#references","title":"References","text":"<ul> <li>Transformers learn through gradual rank increase They \"identify incremental learning dynamics in transformers, where the difference between trained and initial weights progressively increases in rank. We rigorously prove this occurs under the simplifying assumptions of diagonal weight matrices and small initialization. Our experiments support the theory and also show that phenomenon can occur in practice without the simplifying assumptions.\"</li> </ul>"}]}