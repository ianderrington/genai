<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Implicit vs. Explicit Knowledge</title>
    
    

    <meta property="og:url" content="https://www.managen.ai//shared/implicit-vs-explicit-knowledges.html">

    <meta property="og:title" content="Implicit vs. Explicit Knowledge">
    <meta property="og:description" content="LLMs learn probabilistic representation of linear knowledge representations, not necessarily higher order concepts and considerations. While relationships between text may be inferred, it may not be explicitly encoded, which can be of considerable value, in some instances, for instance when talking about 'Apple falling', LLM may be able to infer the possibliity of talking about the company and it's stocks, but could also allow for an apple falling down to the ground. It allows an 'implicit' understanding. Once trained, these understandings can be modified by prompting changes, making there application non-universal, and not necessarily modifiable. "">

    <meta property="og:type"  content="website" />
    <meta property="og:image" content="">
    <meta property="og:url" content="https://www.managen.ai//shared/implicit-vs-explicit-knowledges.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Implicit vs. Explicit Knowledge">
    <meta name="twitter:description" content="Implicit vs. Explicit Knowledge">
    <meta name="twitter:image" content="">
    <!--Import stylesheet  -->
    <link rel="stylesheet" href="../../stylesheets/share-card.css">
    <style>
        .page-url { display: block; }
        .iframe .backlink-url { display: none; }
   

     </style>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config",""),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-MPQ831MCNS",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
<script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
    <script>
       (function(d, w) {
          if (w.self !== w.top) {
             d.className += " iframe";
          }
       }(document.documentElement, window));

        window.onload = function() {
            var links = document.getElementsByTagName('a');
            for (var i = 0; i < links.length; i++) {
                links[i].target = '_blank';
            }
        };
        function copyToClipboard(elementId) {
            var url = document.getElementById(elementId).href;
            navigator.clipboard.writeText(url).then(function() {
                // Show copied popup
                var popup = document.getElementById("copied-popup");
                popup.classList.add("show");

                // Hide popup after 2 seconds
                setTimeout(function() { popup.classList.remove("show"); }, 2000);
            }, function(err) {
                console.error('Could not copy text: ', err);
            });
        }
    </script>
</head>
<body>
    
    <div class="blog-content">
        <h1><p>Implicit vs. Explicit Knowledge</p></h1>
        <p>LLMs learn probabilistic representation of linear knowledge representations, not necessarily higher order concepts and considerations. While relationships between text may be inferred, it may not be explicitly encoded, which can be of considerable value, in some instances, for instance when talking about 'Apple falling', LLM may be able to infer the possibliity of talking about the company and it's stocks, but could also allow for an apple falling down to the ground. It allows an 'implicit' understanding. Once trained, these understandings can be modified by prompting changes, making there application non-universal, and not necessarily modifiable. </p>
<p>Knowledge graphs, however, offer explicit representations of relations between items, by providing concrete associations, numerical or textual. They can be formally verified and easily modified. </p>
<h4 id="comparison-between-statistical-llm-and-symbolic-kg-knowledge-representation">Comparison between statistical (LLM) and symbolic (KG) knowledge representation</h4>
    </div>
    <a href="https://www.managen.ai//shared/implicit-vs-explicit-knowledges.html" class="page-url" id="page-url"></a>
    <!-- Clipboard copy icon/button -->
    <span class="copy-icon" id="copy-icon" class="h3" onclick="copyToClipboard('page-url' )">Share link! &#128203; </span>
    <!-- Copied popup -->
    <div class="copied-popup" id="copied-popup">Link copied!</div>
    <a href="https://www.managen.ai//Understanding/agents/knowledge_graphs.html" class="backlink-url" id="backlink-url">See the main site!</a>
</body>
</html>
