<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning</title>
    
    

    <meta property="og:url" content="https://www.managen.ai//shared/rlef.html">

    <meta property="og:title" content="RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning">
    <meta property="og:description" content="**Developments**"">

    <meta property="og:type"  content="website" />
    <meta property="og:image" content="https://github.com/user-attachments/assets/0b19c6f1-1a0d-41fd-aebf-e59fd598b965">
    <meta property="og:url" content="https://www.managen.ai//shared/rlef.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning">
    <meta name="twitter:description" content="RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning">
    <meta name="twitter:image" content="https://github.com/user-attachments/assets/0b19c6f1-1a0d-41fd-aebf-e59fd598b965">
    <!--Import stylesheet  -->
    <link rel="stylesheet" href="../../stylesheets/share-card.css">
    <style>
        .page-url { display: block; }
        .iframe .backlink-url { display: none; }
   

     </style>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config",""),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-MPQ831MCNS",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
<script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
    <script>
       (function(d, w) {
          if (w.self !== w.top) {
             d.className += " iframe";
          }
       }(document.documentElement, window));

        window.onload = function() {
            var links = document.getElementsByTagName('a');
            for (var i = 0; i < links.length; i++) {
                links[i].target = '_blank';
            }
        };
        function copyToClipboard(elementId) {
            var url = document.getElementById(elementId).href;
            navigator.clipboard.writeText(url).then(function() {
                // Show copied popup
                var popup = document.getElementById("copied-popup");
                popup.classList.add("show");

                // Hide popup after 2 seconds
                setTimeout(function() { popup.classList.remove("show"); }, 2000);
            }, function(err) {
                console.error('Could not copy text: ', err);
            });
        }
    </script>
</head>
<body>
    
    <div class="blog-content">
        <h1><p><a href="https://arxiv.org/pdf/2410.02089">RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning</a></p></h1>
        <p><strong>Developments</strong></p>
<p>Training LLMs to use inference-time feedback using large scale RL. Makes even the 8B Llama3.1 beat GPT-4 on CodeContests, and SOTA with the 70B.</p>
<p><strong>Author summary:</strong></p>
<p>LLMs for code should do much better if they can iterate on tests -- but they don't. Our new work (RLEF) addresses this with execution feedback at RL <em>training time</em> to use execution feedback at <em>inference time</em>.</p>
<p>Notably, RLEF models are very sample efficient for inference. Competitive programming questions are often approached by sampling a large number of candidate programs; we can reach SOTA with just up to 3 samples.</p>
<p><img width="1214" alt="image" src="https://github.com/user-attachments/assets/0b19c6f1-1a0d-41fd-aebf-e59fd598b965"></p>
<h2 id="cgpo-constrained-generative-policy-optimization">CGPO - Constrained Generative Policy optimization</h2>
    </div>
    <a href="https://www.managen.ai//shared/rlef.html" class="page-url" id="page-url"></a>
    <!-- Clipboard copy icon/button -->
    <span class="copy-icon" id="copy-icon" class="h3" onclick="copyToClipboard('page-url' )">Share link! &#128203; </span>
    <!-- Copied popup -->
    <div class="copied-popup" id="copied-popup">Link copied!</div>
    <a href="https://www.managen.ai//Understanding/architectures/training/feedback.html" class="backlink-url" id="backlink-url">See the main site!</a>
</body>
</html>
