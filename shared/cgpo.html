<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Perfect Blend: Redefining RLHF with Mixture of Judges</title>
    
    

    <meta property="og:url" content="https://www.managen.ai//shared/cgpo.html">

    <meta property="og:title" content="The Perfect Blend: Redefining RLHF with Mixture of Judges">
    <meta property="og:description" content="**Developments** The authors show a novel method of post-tuning feedback training using three new scalable RLHF optimizers to deal with reward hacking in multi-task LLMs. Using two types of judges, rule-based and LLM-based, the sysem is able to evaluate LLM generation and any violation of NLP tasks. For multi task optimization, each task is managed individually with diffeerent optimization settings and reward models, judge mixes, and optimizer hyper paremeters. Thee resulting systme is able to reach SOTA in math, coding, engagemnt and safety. "">

    <meta property="og:type"  content="website" />
    <meta property="og:image" content="https://github.com/user-attachments/assets/f3f3c712-668a-4634-bb65-aa8b372ccf44">
    <meta property="og:url" content="https://www.managen.ai//shared/cgpo.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="The Perfect Blend: Redefining RLHF with Mixture of Judges">
    <meta name="twitter:description" content="The Perfect Blend: Redefining RLHF with Mixture of Judges">
    <meta name="twitter:image" content="https://github.com/user-attachments/assets/f3f3c712-668a-4634-bb65-aa8b372ccf44">
    <!--Import stylesheet  -->
    <link rel="stylesheet" href="../../stylesheets/share-card.css">
    <style>
        .page-url { display: block; }
        .iframe .backlink-url { display: none; }
   

     </style>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config",""),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-MPQ831MCNS",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
<script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
    <script>
       (function(d, w) {
          if (w.self !== w.top) {
             d.className += " iframe";
          }
       }(document.documentElement, window));

        window.onload = function() {
            var links = document.getElementsByTagName('a');
            for (var i = 0; i < links.length; i++) {
                links[i].target = '_blank';
            }
        };
        function copyToClipboard(elementId) {
            var url = document.getElementById(elementId).href;
            navigator.clipboard.writeText(url).then(function() {
                // Show copied popup
                var popup = document.getElementById("copied-popup");
                popup.classList.add("show");

                // Hide popup after 2 seconds
                setTimeout(function() { popup.classList.remove("show"); }, 2000);
            }, function(err) {
                console.error('Could not copy text: ', err);
            });
        }
    </script>
</head>
<body>
    
    <div class="blog-content">
        <h1><p><a href="https://arxiv.org/pdf/2409.20370">The Perfect Blend: Redefining RLHF with Mixture of Judges</a></p></h1>
        <p><strong>Developments</strong> The authors show a novel method of post-tuning feedback training using three new scalable RLHF optimizers to deal with reward hacking in multi-task LLMs. Using two types of judges, rule-based and LLM-based, the sysem is able to evaluate LLM generation and any violation of NLP tasks. For multi task optimization, each task is managed individually with diffeerent optimization settings and reward models, judge mixes, and optimizer hyper paremeters. Thee resulting systme is able to reach SOTA in math, coding, engagemnt and safety. </p>
<p><img width="1230" alt="image" src="https://github.com/user-attachments/assets/f3f3c712-668a-4634-bb65-aa8b372ccf44"></p>
<p><img width="1129" alt="image" src="https://github.com/user-attachments/assets/101fdcb5-d2cd-469d-8eaa-6d77fed036ea"></p>
<h2 id="rl-free-feedback">RL-free feedback</h2>
    </div>
    <a href="https://www.managen.ai//shared/cgpo.html" class="page-url" id="page-url"></a>
    <!-- Clipboard copy icon/button -->
    <span class="copy-icon" id="copy-icon" class="h3" onclick="copyToClipboard('page-url' )">Share link! &#128203; </span>
    <!-- Copied popup -->
    <div class="copied-popup" id="copied-popup">Link copied!</div>
    <a href="https://www.managen.ai//Understanding/architectures/training/feedback.html" class="backlink-url" id="backlink-url">See the main site!</a>
</body>
</html>
